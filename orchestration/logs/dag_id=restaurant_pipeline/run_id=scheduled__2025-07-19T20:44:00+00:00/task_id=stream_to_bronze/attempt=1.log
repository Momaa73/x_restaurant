[2025-07-19T20:47:52.167+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T20:44:00+00:00 [queued]>
[2025-07-19T20:47:52.172+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T20:44:00+00:00 [queued]>
[2025-07-19T20:47:52.172+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-19T20:47:52.179+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): stream_to_bronze> on 2025-07-19 20:44:00+00:00
[2025-07-19T20:47:52.182+0000] {standard_task_runner.py:57} INFO - Started process 3790 to run task
[2025-07-19T20:47:52.184+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restaurant_pipeline', 'stream_to_bronze', 'scheduled__2025-07-19T20:44:00+00:00', '--job-id', '1211', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_pipeline.py', '--cfg-path', '/tmp/tmp_yz_6_s4']
[2025-07-19T20:47:52.185+0000] {standard_task_runner.py:85} INFO - Job 1211: Subtask stream_to_bronze
[2025-07-19T20:47:52.208+0000] {task_command.py:416} INFO - Running <TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T20:44:00+00:00 [running]> on host e3f5d8fc4eef
[2025-07-19T20:47:52.246+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='moran' AIRFLOW_CTX_DAG_ID='restaurant_pipeline' AIRFLOW_CTX_TASK_ID='stream_to_bronze' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T20:44:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T20:44:00+00:00'
[2025-07-19T20:47:52.247+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-07-19T20:47:52.247+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', "docker exec -e AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T20:44:00+00:00' spark-iceberg spark-submit /home/iceberg/spark/stream_to_bronze.py"]
[2025-07-19T20:47:52.251+0000] {subprocess.py:86} INFO - Output:
[2025-07-19T20:47:53.864+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SparkContext: Running Spark version 3.5.6
[2025-07-19T20:47:53.865+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T20:47:53.865+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SparkContext: Java version 17.0.15
[2025-07-19T20:47:53.880+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO ResourceUtils: ==============================================================
[2025-07-19T20:47:53.881+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-19T20:47:53.881+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO ResourceUtils: ==============================================================
[2025-07-19T20:47:53.881+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SparkContext: Submitted application: StreamToBronze
[2025-07-19T20:47:53.892+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-19T20:47:53.897+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO ResourceProfile: Limiting resource is cpu
[2025-07-19T20:47:53.897+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-19T20:47:53.924+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SecurityManager: Changing view acls to: root,spark
[2025-07-19T20:47:53.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SecurityManager: Changing modify acls to: root,spark
[2025-07-19T20:47:53.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SecurityManager: Changing view acls groups to:
[2025-07-19T20:47:53.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SecurityManager: Changing modify acls groups to:
[2025-07-19T20:47:53.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2025-07-19T20:47:53.954+0000] {subprocess.py:93} INFO - 25/07/19 20:47:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-19T20:47:54.093+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Utils: Successfully started service 'sparkDriver' on port 41809.
[2025-07-19T20:47:54.110+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO SparkEnv: Registering MapOutputTracker
[2025-07-19T20:47:54.138+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-19T20:47:54.147+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-19T20:47:54.148+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-19T20:47:54.150+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-19T20:47:54.161+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8e5b07d0-abcf-48a6-b9da-5eafbf92eaeb
[2025-07-19T20:47:54.168+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-19T20:47:54.178+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-19T20:47:54.237+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-19T20:47:54.267+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-19T20:47:54.272+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-19T20:47:54.329+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Executor: Starting executor ID driver on host 8b44f3d35cfa
[2025-07-19T20:47:54.329+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T20:47:54.329+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Executor: Java version 17.0.15
[2025-07-19T20:47:54.333+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-19T20:47:54.333+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@640369b4 for default.
[2025-07-19T20:47:54.343+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46433.
[2025-07-19T20:47:54.343+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO NettyBlockTransferService: Server created on 8b44f3d35cfa:46433
[2025-07-19T20:47:54.345+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-19T20:47:54.352+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8b44f3d35cfa, 46433, None)
[2025-07-19T20:47:54.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManagerMasterEndpoint: Registering block manager 8b44f3d35cfa:46433 with 434.4 MiB RAM, BlockManagerId(driver, 8b44f3d35cfa, 46433, None)
[2025-07-19T20:47:54.358+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8b44f3d35cfa, 46433, None)
[2025-07-19T20:47:54.358+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8b44f3d35cfa, 46433, None)
[2025-07-19T20:47:54.583+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-19T20:47:54.588+0000] {subprocess.py:93} INFO - 25/07/19 20:47:54 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
[2025-07-19T20:47:55.734+0000] {subprocess.py:93} INFO - 25/07/19 20:47:55 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-07-19T20:47:55.743+0000] {subprocess.py:93} INFO - 25/07/19 20:47:55 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-07-19T20:47:55.743+0000] {subprocess.py:93} INFO - 25/07/19 20:47:55 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-07-19T20:47:56.414+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:56.428+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-07-19T20:47:56.467+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00 resolved to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00.
[2025-07-19T20:47:56.467+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T20:47:56.509+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/metadata using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/.metadata.e2a23358-f13e-4d80-a50a-aeedf7e58449.tmp
[2025-07-19T20:47:56.562+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/.metadata.e2a23358-f13e-4d80-a50a-aeedf7e58449.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/metadata
[2025-07-19T20:47:56.584+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Starting [id = 4ea6f76f-42e1-458f-8af4-e164e5eb522c, runId = 7dcfafb9-36e9-4e63-be5e-96bcfd822de6]. Use file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00 to store the query checkpoint.
[2025-07-19T20:47:56.590+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@12cb8d8d] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@28183d4d]
[2025-07-19T20:47:56.612+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:47:56.614+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:47:56.615+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T20:47:56.616+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T20:47:56.715+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:56.723+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00 resolved to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00.
[2025-07-19T20:47:56.724+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T20:47:56.736+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/metadata using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/.metadata.16b7f6a6-2b8b-4a08-87ea-ea24b7778cfc.tmp
[2025-07-19T20:47:56.770+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/.metadata.16b7f6a6-2b8b-4a08-87ea-ea24b7778cfc.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/metadata
[2025-07-19T20:47:56.781+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Starting [id = 302fc0f2-ecb3-4b30-9b45-e72bb5225779, runId = 3851e258-c04f-469c-9e1b-1d5426ca45a3]. Use file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00 to store the query checkpoint.
[2025-07-19T20:47:56.782+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@587e496b] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@56b9bdcc]
[2025-07-19T20:47:56.783+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:47:56.784+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:47:56.784+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T20:47:56.785+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T20:47:56.869+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T20:47:56.870+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:47:56.871+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:47:56.872+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:47:56.872+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T20:47:56.872+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T20:47:56.872+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:47:56.873+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:47:56.874+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:47:56.875+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:47:56.875+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:47:56.875+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:47:56.875+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:47:56.875+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:47:56.875+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:47:56.876+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:47:56.877+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:47:56.877+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:47:56.878+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:47:56.878+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:47:56.878+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:47:56.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:47:56.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:47:56.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:47:56.879+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:47:56.879+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:47:56.879+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:47:56.880+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:47:56.880+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:47:56.880+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:47:56.881+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:47:56.882+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:47:56.882+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:47:56.883+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:47:56.883+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:47:56.884+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:47:56.884+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:47:56.885+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:47:56.886+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:47:56.887+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:47:56.887+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:47:56.887+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:47:56.888+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:47:56.888+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:47:56.888+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:47:56.889+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:47:56.889+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:47:56.889+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:47:56.890+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:47:56.890+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:47:56.891+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T20:47:56.892+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:47:56.893+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:47:56.896+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:47:56.897+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T20:47:56.898+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T20:47:56.898+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:47:56.899+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:47:56.899+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:47:56.900+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:47:56.900+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:47:56.901+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:47:56.901+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:47:56.901+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:47:56.902+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:47:56.903+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:47:56.903+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T20:47:56.904+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:47:56.904+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:47:56.905+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:47:56.906+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:47:56.906+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:47:56.907+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:47:56.907+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:47:56.908+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:47:56.908+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:47:56.909+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:47:56.909+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:47:56.909+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:47:56.910+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:47:56.910+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:47:56.911+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:47:56.912+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:47:56.914+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:47:56.914+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:47:56.915+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:47:56.915+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:47:56.916+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:47:56.916+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:47:56.917+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:47:56.917+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:47:56.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:47:56.919+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:47:56.919+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:47:56.920+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:47:56.920+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:47:56.920+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:47:56.920+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:47:56.921+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:47:56.921+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:47:56.921+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:47:56.922+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:47:56.922+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:47:56.922+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:47:56.923+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:47:56.923+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:47:56.923+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:47:56.924+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:47:56.924+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:47:56.924+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:47:56.924+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:47:56.924+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:47:56.925+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:47:56.925+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:47:56.925+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:47:56.926+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:47:56.926+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:47:56.926+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:47:56.927+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:47:56.927+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:47:56.927+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:47:56.927+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:56.928+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00 resolved to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00.
[2025-07-19T20:47:56.928+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T20:47:56.928+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/metadata using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/.metadata.248dddbf-7dc5-48eb-b7f2-c3fcc32ba303.tmp
[2025-07-19T20:47:56.943+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T20:47:56.943+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T20:47:56.944+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:47:56.944+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:47:56.944+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka startTimeMs: 1752958076940
[2025-07-19T20:47:56.946+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:47:56.947+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:47:56.947+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka startTimeMs: 1752958076941
[2025-07-19T20:47:56.957+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/.metadata.248dddbf-7dc5-48eb-b7f2-c3fcc32ba303.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/metadata
[2025-07-19T20:47:56.971+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Starting [id = b0ea99b8-5ad6-454d-8c07-6fb91d8182de, runId = 1de00c25-9d15-45b4-834f-e4fa238248c8]. Use file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00 to store the query checkpoint.
[2025-07-19T20:47:56.973+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@74eb55e5] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@7a2cb4d0]
[2025-07-19T20:47:56.977+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:47:56.979+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:47:56.980+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T20:47:56.980+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T20:47:56.986+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T20:47:56.986+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:47:56.987+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:47:56.987+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:47:56.987+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T20:47:56.987+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T20:47:56.987+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:47:56.987+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:47:56.988+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:47:56.988+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:47:56.988+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:47:56.988+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:47:56.988+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:47:56.988+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:47:56.989+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:47:56.990+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:47:56.991+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:47:56.992+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:47:56.993+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:47:56.994+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:47:56.994+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T20:47:56.994+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:47:56.994+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:47:56.994+0000] {subprocess.py:93} INFO - 25/07/19 20:47:56 INFO AppInfoParser: Kafka startTimeMs: 1752958076988
[2025-07-19T20:47:57.155+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/sources/0/.0.9a44fe81-b9de-49a7-ac50-4a590e435d0c.tmp
[2025-07-19T20:47:57.156+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/sources/0/.0.a15642e0-793d-4722-af19-4bc876e5f256.tmp
[2025-07-19T20:47:57.156+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/sources/0/.0.6f9f2690-3c23-47a7-84e8-54a1b5b0a611.tmp
[2025-07-19T20:47:57.187+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/sources/0/.0.a15642e0-793d-4722-af19-4bc876e5f256.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/sources/0/0
[2025-07-19T20:47:57.188+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/sources/0/.0.9a44fe81-b9de-49a7-ac50-4a590e435d0c.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/sources/0/0
[2025-07-19T20:47:57.189+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/sources/0/.0.6f9f2690-3c23-47a7-84e8-54a1b5b0a611.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/sources/0/0
[2025-07-19T20:47:57.190+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaMicroBatchStream: Initial offsets: {"checkins":{"0":0}}
[2025-07-19T20:47:57.191+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaMicroBatchStream: Initial offsets: {"reservations":{"0":0}}
[2025-07-19T20:47:57.192+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaMicroBatchStream: Initial offsets: {"feedback":{"0":0}}
[2025-07-19T20:47:57.209+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/.0.2a859c29-678b-473b-9726-1c6fec89eae0.tmp
[2025-07-19T20:47:57.210+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/.0.36552456-a93d-4e3e-912e-82f29e276939.tmp
[2025-07-19T20:47:57.210+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/offsets/.0.81ce0e8b-564e-4e62-83b3-859a51498df5.tmp
[2025-07-19T20:47:57.241+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/.0.2a859c29-678b-473b-9726-1c6fec89eae0.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/0
[2025-07-19T20:47:57.242+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/.0.36552456-a93d-4e3e-912e-82f29e276939.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/0
[2025-07-19T20:47:57.242+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752958077197,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:47:57.242+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752958077197,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:47:57.245+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/offsets/.0.81ce0e8b-564e-4e62-83b3-859a51498df5.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/offsets/0
[2025-07-19T20:47:57.245+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752958077197,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:47:57.427+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.427+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.427+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.427+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.427+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.427+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.428+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.429+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.429+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.620+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CodeGenerator: Code generated in 88.59775 ms
[2025-07-19T20:47:57.637+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.638+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.638+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.673+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.673+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.674+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.714+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.714+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.714+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.716+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.719+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.719+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.719+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.719+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.720+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.722+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.731+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.733+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.733+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.735+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.739+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.805+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.807+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.808+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:47:57.824+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.824+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.824+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.839+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:47:57.839+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.840+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.840+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.840+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.840+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:47:57.851+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.868+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.873+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:47:57.975+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CodeGenerator: Code generated in 43.68175 ms
[2025-07-19T20:47:57.984+0000] {subprocess.py:93} INFO - 25/07/19 20:47:57 INFO CodeGenerator: Code generated in 48.030917 ms
[2025-07-19T20:47:58.004+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 63.187792 ms
[2025-07-19T20:47:58.214+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T20:47:58.216+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T20:47:58.217+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T20:47:58.265+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T20:47:58.271+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T20:47:58.271+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8b44f3d35cfa:46433 (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T20:47:58.271+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8b44f3d35cfa:46433 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:47:58.271+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T20:47:58.271+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 0 from start at <unknown>:0
[2025-07-19T20:47:58.272+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8b44f3d35cfa:46433 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:47:58.272+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 1 from start at <unknown>:0
[2025-07-19T20:47:58.285+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 2 from start at <unknown>:0
[2025-07-19T20:47:58.305+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T20:47:58.306+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T20:47:58.306+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T20:47:58.324+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.6 MiB)
[2025-07-19T20:47:58.326+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 8b44f3d35cfa:46433 (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T20:47:58.326+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T20:47:58.327+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 5 from start at <unknown>:0
[2025-07-19T20:47:58.328+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T20:47:58.329+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8b44f3d35cfa:46433 (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T20:47:58.329+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 3 from start at <unknown>:0
[2025-07-19T20:47:58.330+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:47:58.330+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:47:58.330+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8b44f3d35cfa:46433 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T20:47:58.331+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 4 from start at <unknown>:0
[2025-07-19T20:47:58.331+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:47:58.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:47:58.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:47:58.358+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:47:58.374+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Registering RDD 14 (start at <unknown>:0) as input to shuffle 2
[2025-07-19T20:47:58.378+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:47:58.379+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-07-19T20:47:58.379+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2025-07-19T20:47:58.380+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2025-07-19T20:47:58.382+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[14] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:47:58.396+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 32.3 KiB, free 433.5 MiB)
[2025-07-19T20:47:58.408+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 433.5 MiB)
[2025-07-19T20:47:58.412+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 8b44f3d35cfa:46433 (size: 14.1 KiB, free: 434.2 MiB)
[2025-07-19T20:47:58.412+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:47:58.445+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[14] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T20:47:58.457+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-19T20:47:58.473+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Registering RDD 17 (start at <unknown>:0) as input to shuffle 1
[2025-07-19T20:47:58.474+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Got job 2 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:47:58.474+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Final stage: ResultStage 3 (start at <unknown>:0)
[2025-07-19T20:47:58.475+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-07-19T20:47:58.475+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
[2025-07-19T20:47:58.476+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:47:58.478+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 35.8 KiB, free 433.4 MiB)
[2025-07-19T20:47:58.485+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.4 MiB)
[2025-07-19T20:47:58.486+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 8b44f3d35cfa:46433 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T20:47:58.487+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:47:58.487+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T20:47:58.488+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-19T20:47:58.498+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9925 bytes)
[2025-07-19T20:47:58.503+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Registering RDD 15 (start at <unknown>:0) as input to shuffle 0
[2025-07-19T20:47:58.510+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:47:58.512+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Final stage: ResultStage 5 (start at <unknown>:0)
[2025-07-19T20:47:58.512+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-07-19T20:47:58.512+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2025-07-19T20:47:58.514+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9924 bytes)
[2025-07-19T20:47:58.516+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:47:58.518+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-19T20:47:58.519+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[2025-07-19T20:47:58.519+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 33.8 KiB, free 433.4 MiB)
[2025-07-19T20:47:58.519+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.6 KiB, free 433.4 MiB)
[2025-07-19T20:47:58.520+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 8b44f3d35cfa:46433 (size: 14.6 KiB, free: 434.2 MiB)
[2025-07-19T20:47:58.520+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:47:58.521+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T20:47:58.522+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-19T20:47:58.532+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9929 bytes)
[2025-07-19T20:47:58.533+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
[2025-07-19T20:47:58.622+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 19.78825 ms
[2025-07-19T20:47:58.625+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 22.556958 ms
[2025-07-19T20:47:58.625+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 23.42625 ms
[2025-07-19T20:47:58.637+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 13.280875 ms
[2025-07-19T20:47:58.638+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 14.108541 ms
[2025-07-19T20:47:58.640+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 16.047084 ms
[2025-07-19T20:47:58.650+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 5.749459 ms
[2025-07-19T20:47:58.651+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 8.323667 ms
[2025-07-19T20:47:58.672+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 10.887417 ms
[2025-07-19T20:47:58.675+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 11.43575 ms
[2025-07-19T20:47:58.682+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reservations-0 fromOffset=0 untilOffset=222, for query queryId=4ea6f76f-42e1-458f-8af4-e164e5eb522c batchId=0 taskId=2 partitionId=0
[2025-07-19T20:47:58.683+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=checkins-0 fromOffset=0 untilOffset=222, for query queryId=302fc0f2-ecb3-4b30-9b45-e72bb5225779 batchId=0 taskId=1 partitionId=0
[2025-07-19T20:47:58.683+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=feedback-0 fromOffset=0 untilOffset=222, for query queryId=b0ea99b8-5ad6-454d-8c07-6fb91d8182de batchId=0 taskId=0 partitionId=0
[2025-07-19T20:47:58.716+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 12.279542 ms
[2025-07-19T20:47:58.731+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO CodeGenerator: Code generated in 10.445959 ms
[2025-07-19T20:47:58.749+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T20:47:58.750+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T20:47:58.751+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T20:47:58.752+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:47:58.753+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:47:58.754+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:47:58.755+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T20:47:58.756+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:47:58.757+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:47:58.758+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:47:58.759+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:47:58.759+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:47:58.759+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:47:58.760+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:47:58.760+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:47:58.761+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:47:58.762+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:47:58.762+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T20:47:58.762+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T20:47:58.763+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T20:47:58.763+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:47:58.764+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T20:47:58.764+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:47:58.765+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T20:47:58.765+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:47:58.765+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2
[2025-07-19T20:47:58.766+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T20:47:58.766+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T20:47:58.766+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:47:58.766+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T20:47:58.767+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T20:47:58.767+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T20:47:58.768+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T20:47:58.769+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T20:47:58.769+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor
[2025-07-19T20:47:58.771+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T20:47:58.771+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T20:47:58.772+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T20:47:58.772+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T20:47:58.772+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T20:47:58.773+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T20:47:58.773+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:47:58.773+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T20:47:58.773+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T20:47:58.773+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T20:47:58.773+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:47:58.774+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:47:58.775+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:47:58.776+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:47:58.777+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:47:58.777+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:47:58.777+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:47:58.777+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:47:58.777+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:47:58.777+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:47:58.778+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:47:58.779+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:47:58.779+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T20:47:58.779+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:47:58.779+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:47:58.779+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:47:58.779+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:47:58.780+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:47:58.780+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:47:58.780+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:47:58.781+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:47:58.781+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:47:58.781+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:47:58.781+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:47:58.781+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:47:58.781+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:47:58.782+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:47:58.782+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:47:58.782+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T20:47:58.783+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T20:47:58.784+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T20:47:58.784+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:47:58.784+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T20:47:58.784+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:47:58.784+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T20:47:58.785+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:47:58.785+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3
[2025-07-19T20:47:58.785+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T20:47:58.785+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T20:47:58.785+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor
[2025-07-19T20:47:58.786+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T20:47:58.787+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T20:47:58.787+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T20:47:58.787+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T20:47:58.787+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T20:47:58.787+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T20:47:58.787+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:47:58.788+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T20:47:58.788+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T20:47:58.788+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T20:47:58.788+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:47:58.788+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:47:58.788+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:47:58.789+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:47:58.790+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:47:58.791+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:47:58.792+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:47:58.793+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:47:58.793+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:47:58.793+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:47:58.793+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:47:58.793+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:47:58.793+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:47:58.794+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:47:58.794+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:47:58.794+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T20:47:58.795+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:47:58.795+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:47:58.795+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:47:58.796+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:47:58.797+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:47:58.797+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:47:58.798+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:47:58.798+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:47:58.798+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:47:58.798+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:47:58.799+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:47:58.800+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:47:58.800+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:47:58.800+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:47:58.800+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka startTimeMs: 1752958078794
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:47:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka startTimeMs: 1752958078795
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO AppInfoParser: Kafka startTimeMs: 1752958078796
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Assigned to partition(s): feedback-0
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Assigned to partition(s): checkins-0
[2025-07-19T20:47:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Assigned to partition(s): reservations-0
[2025-07-19T20:47:58.805+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Seeking to offset 0 for partition feedback-0
[2025-07-19T20:47:58.805+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Seeking to offset 0 for partition reservations-0
[2025-07-19T20:47:58.805+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Seeking to offset 0 for partition checkins-0
[2025-07-19T20:47:58.812+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T20:47:58.812+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T20:47:58.812+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T20:47:58.846+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Seeking to earliest offset of partition checkins-0
[2025-07-19T20:47:58.847+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Seeking to earliest offset of partition feedback-0
[2025-07-19T20:47:58.847+0000] {subprocess.py:93} INFO - 25/07/19 20:47:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Seeking to earliest offset of partition reservations-0
[2025-07-19T20:47:59.354+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:47:59.354+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:47:59.355+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:47:59.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Seeking to latest offset of partition feedback-0
[2025-07-19T20:47:59.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Seeking to latest offset of partition reservations-0
[2025-07-19T20:47:59.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Seeking to latest offset of partition checkins-0
[2025-07-19T20:47:59.357+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=222, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:47:59.358+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=222, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:47:59.358+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=222, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:47:59.631+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO KafkaDataConsumer: From Kafka topicPartition=reservations-0 groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor read 222 records through 1 polls (polled  out 222 records), taking 551423209 nanos, during time span of 829462709 nanos.
[2025-07-19T20:47:59.633+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO KafkaDataConsumer: From Kafka topicPartition=feedback-0 groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor read 222 records through 1 polls (polled  out 222 records), taking 551552001 nanos, during time span of 831404750 nanos.
[2025-07-19T20:47:59.634+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO KafkaDataConsumer: From Kafka topicPartition=checkins-0 groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor read 222 records through 1 polls (polled  out 222 records), taking 551850875 nanos, during time span of 831829876 nanos.
[2025-07-19T20:47:59.645+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2642 bytes result sent to driver
[2025-07-19T20:47:59.646+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2642 bytes result sent to driver
[2025-07-19T20:47:59.647+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2642 bytes result sent to driver
[2025-07-19T20:47:59.661+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1133 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T20:47:59.666+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-19T20:47:59.667+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 1158 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T20:47:59.668+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-19T20:47:59.668+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1177 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T20:47:59.668+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-19T20:47:59.677+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: ShuffleMapStage 4 (start at <unknown>:0) finished in 1.162 s
[2025-07-19T20:47:59.679+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T20:47:59.680+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 2)
[2025-07-19T20:47:59.680+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5, ResultStage 3)
[2025-07-19T20:47:59.680+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: failed: Set()
[2025-07-19T20:47:59.681+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: Submitting ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:47:59.732+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 39.6 KiB, free 433.3 MiB)
[2025-07-19T20:47:59.733+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.3 MiB)
[2025-07-19T20:47:59.733+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 8b44f3d35cfa:46433 (size: 19.6 KiB, free: 434.1 MiB)
[2025-07-19T20:47:59.734+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:47:59.736+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 5 (StateStoreRDD[21] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:47:59.736+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSchedulerImpl: Adding task set 5.0 with 200 tasks resource profile 0
[2025-07-19T20:47:59.740+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: ShuffleMapStage 2 (start at <unknown>:0) finished in 1.265 s
[2025-07-19T20:47:59.740+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T20:47:59.740+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ResultStage 5)
[2025-07-19T20:47:59.740+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 3)
[2025-07-19T20:47:59.741+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: failed: Set()
[2025-07-19T20:47:59.741+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: Submitting ResultStage 3 (StateStoreRDD[23] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:47:59.742+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 3) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.742+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 4) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.743+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 5) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.743+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 6) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.744+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 7) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.744+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 8) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.744+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 9) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.745+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 10) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:47:59.745+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 4.0 in stage 5.0 (TID 5)
[2025-07-19T20:47:59.746+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 3.0 in stage 5.0 (TID 4)
[2025-07-19T20:47:59.747+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 1.0 in stage 5.0 (TID 3)
[2025-07-19T20:47:59.747+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 5.0 in stage 5.0 (TID 6)
[2025-07-19T20:47:59.748+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 6.0 in stage 5.0 (TID 7)
[2025-07-19T20:47:59.756+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 7.0 in stage 5.0 (TID 8)
[2025-07-19T20:47:59.757+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 9.0 in stage 5.0 (TID 9)
[2025-07-19T20:47:59.757+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO Executor: Running task 11.0 in stage 5.0 (TID 10)
[2025-07-19T20:47:59.797+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.798+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.798+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.799+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.799+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.800+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.800+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.800+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T20:47:59.801+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T20:47:59.802+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T20:47:59.805+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:47:59.805+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T20:47:59.806+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T20:47:59.806+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T20:47:59.806+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T20:47:59.807+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T20:47:59.807+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 40.1 KiB, free 433.3 MiB)
[2025-07-19T20:47:59.809+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.2 MiB)
[2025-07-19T20:47:59.809+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 8b44f3d35cfa:46433 (size: 19.9 KiB, free: 434.1 MiB)
[2025-07-19T20:47:59.809+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:47:59.810+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (StateStoreRDD[23] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:47:59.811+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSchedulerImpl: Adding task set 3.0 with 200 tasks resource profile 0
[2025-07-19T20:47:59.812+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: State Store maintenance task started
[2025-07-19T20:47:59.814+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: ShuffleMapStage 0 (start at <unknown>:0) finished in 1.421 s
[2025-07-19T20:47:59.815+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T20:47:59.816+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: running: Set(ResultStage 5, ResultStage 3)
[2025-07-19T20:47:59.817+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: waiting: Set(ResultStage 1)
[2025-07-19T20:47:59.817+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: failed: Set()
[2025-07-19T20:47:59.819+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: Submitting ResultStage 1 (StateStoreRDD[22] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:47:59.826+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19c93345
[2025-07-19T20:47:59.829+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.834+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11] for update
[2025-07-19T20:47:59.840+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@269a3210
[2025-07-19T20:47:59.841+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.841+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9] for update
[2025-07-19T20:47:59.847+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodeGenerator: Code generated in 6.334667 ms
[2025-07-19T20:47:59.852+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c7a59f1
[2025-07-19T20:47:59.854+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.857+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1] for update
[2025-07-19T20:47:59.862+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e8f84d9
[2025-07-19T20:47:59.872+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.873+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4] for update
[2025-07-19T20:47:59.874+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodeGenerator: Code generated in 5.715791 ms
[2025-07-19T20:47:59.882+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2de84571
[2025-07-19T20:47:59.883+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.883+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6] for update
[2025-07-19T20:47:59.900+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c865c9c
[2025-07-19T20:47:59.901+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.902+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5] for update
[2025-07-19T20:47:59.909+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@567e765b
[2025-07-19T20:47:59.913+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.917+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3] for update
[2025-07-19T20:47:59.922+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 38.8 KiB, free 433.2 MiB)
[2025-07-19T20:47:59.923+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1af6076f
[2025-07-19T20:47:59.923+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:47:59.924+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7] for update
[2025-07-19T20:47:59.924+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.2 MiB)
[2025-07-19T20:47:59.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 8b44f3d35cfa:46433 (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T20:47:59.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:47:59.925+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 1 (StateStoreRDD[22] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:47:59.927+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
[2025-07-19T20:47:59.958+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:47:59.961+0000] {subprocess.py:93} INFO - 25/07/19 20:47:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.1.delta.13dc2034-0807-4ebc-b0a4-3701e61851be.TID9.tmp
[2025-07-19T20:48:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.1.delta.4a3b7326-6451-43bf-ac35-a068fa082270.TID6.tmp
[2025-07-19T20:48:00.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.1.delta.0c2d6a31-f940-41cd-aae7-d7a2ed21b37a.TID4.tmp
[2025-07-19T20:48:00.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.1.delta.466004cf-2cae-47c7-848d-5cb3c2bbddb1.TID8.tmp
[2025-07-19T20:48:00.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.1.delta.b80bd314-b5ab-4257-b769-e4c8ca8944c5.TID10.tmp
[2025-07-19T20:48:00.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.1.delta.a8c23f4f-0cb2-4686-a6c4-72fe19065133.TID3.tmp
[2025-07-19T20:48:00.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.1.delta.488c6e0b-cfb5-43be-9a0c-5ecf86a558a0.TID5.tmp
[2025-07-19T20:48:00.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.1.delta.ebc27d06-9b6b-4583-810e-04fc1400acb7.TID7.tmp
[2025-07-19T20:48:00.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodeGenerator: Code generated in 3.257917 ms
[2025-07-19T20:48:00.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.1.delta.0c2d6a31-f940-41cd-aae7-d7a2ed21b37a.TID4.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta
[2025-07-19T20:48:00.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta
[2025-07-19T20:48:00.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.1.delta.4a3b7326-6451-43bf-ac35-a068fa082270.TID6.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta
[2025-07-19T20:48:00.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta
[2025-07-19T20:48:00.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.1.delta.b80bd314-b5ab-4257-b769-e4c8ca8944c5.TID10.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta
[2025-07-19T20:48:00.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta
[2025-07-19T20:48:00.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.1.delta.488c6e0b-cfb5-43be-9a0c-5ecf86a558a0.TID5.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta
[2025-07-19T20:48:00.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta
[2025-07-19T20:48:00.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.1.delta.ebc27d06-9b6b-4583-810e-04fc1400acb7.TID7.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta
[2025-07-19T20:48:00.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 10, attempt 0, stage 5.0)
[2025-07-19T20:48:00.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta
[2025-07-19T20:48:00.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.1.delta.a8c23f4f-0cb2-4686-a6c4-72fe19065133.TID3.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta
[2025-07-19T20:48:00.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta
[2025-07-19T20:48:00.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 5, attempt 0, stage 5.0)
[2025-07-19T20:48:00.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 3, attempt 0, stage 5.0)
[2025-07-19T20:48:00.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 6, attempt 0, stage 5.0)
[2025-07-19T20:48:00.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 7, attempt 0, stage 5.0)
[2025-07-19T20:48:00.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 4, attempt 0, stage 5.0)
[2025-07-19T20:48:00.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.1.delta.13dc2034-0807-4ebc-b0a4-3701e61851be.TID9.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta
[2025-07-19T20:48:00.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta
[2025-07-19T20:48:00.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 9, attempt 0, stage 5.0)
[2025-07-19T20:48:00.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.1.delta.466004cf-2cae-47c7-848d-5cb3c2bbddb1.TID8.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta
[2025-07-19T20:48:00.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta
[2025-07-19T20:48:00.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 8, attempt 0, stage 5.0)
[2025-07-19T20:48:00.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 8b44f3d35cfa:46433 in memory (size: 14.6 KiB, free: 434.1 MiB)
[2025-07-19T20:48:00.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 8b44f3d35cfa:46433 in memory (size: 14.1 KiB, free: 434.1 MiB)
[2025-07-19T20:48:00.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 8b44f3d35cfa:46433 in memory (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T20:48:00.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 4 (task 5, attempt 0, stage 5.0)
[2025-07-19T20:48:00.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 1 (task 3, attempt 0, stage 5.0)
[2025-07-19T20:48:00.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 3 (task 4, attempt 0, stage 5.0)
[2025-07-19T20:48:00.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 6 (task 7, attempt 0, stage 5.0)
[2025-07-19T20:48:00.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 9 (task 9, attempt 0, stage 5.0)
[2025-07-19T20:48:00.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 11 (task 10, attempt 0, stage 5.0)
[2025-07-19T20:48:00.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 7 (task 8, attempt 0, stage 5.0)
[2025-07-19T20:48:00.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 5 (task 6, attempt 0, stage 5.0)
[2025-07-19T20:48:00.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 4.0 in stage 5.0 (TID 5). 9128 bytes result sent to driver
[2025-07-19T20:48:00.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 5.0 in stage 5.0 (TID 6). 9117 bytes result sent to driver
[2025-07-19T20:48:00.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 6.0 in stage 5.0 (TID 7). 9119 bytes result sent to driver
[2025-07-19T20:48:00.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 11.0 in stage 5.0 (TID 10). 9103 bytes result sent to driver
[2025-07-19T20:48:00.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 1.0 in stage 5.0 (TID 3). 9115 bytes result sent to driver
[2025-07-19T20:48:00.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 11) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 9.0 in stage 5.0 (TID 9). 9127 bytes result sent to driver
[2025-07-19T20:48:00.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 12) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 12.0 in stage 5.0 (TID 11)
[2025-07-19T20:48:00.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 7.0 in stage 5.0 (TID 8). 9118 bytes result sent to driver
[2025-07-19T20:48:00.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 3.0 in stage 5.0 (TID 4). 9119 bytes result sent to driver
[2025-07-19T20:48:00.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 13) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 14) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 16.0 in stage 5.0 (TID 13)
[2025-07-19T20:48:00.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 15) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 16) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 17) (8b44f3d35cfa, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 14.0 in stage 5.0 (TID 12)
[2025-07-19T20:48:00.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 20.0 in stage 5.0 (TID 16)
[2025-07-19T20:48:00.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 18.0 in stage 5.0 (TID 14)
[2025-07-19T20:48:00.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 19.0 in stage 5.0 (TID 15)
[2025-07-19T20:48:00.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 18) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 7) in 873 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:48:00.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 22.0 in stage 5.0 (TID 18)
[2025-07-19T20:48:00.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 21.0 in stage 5.0 (TID 17)
[2025-07-19T20:48:00.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 6) in 877 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:48:00.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 5) in 878 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:48:00.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 10) in 881 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:48:00.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 4) in 885 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:48:00.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 9) in 887 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 8) in 887 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36a9f9c7
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 3) in 892 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19] for update
[2025-07-19T20:48:00.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@87a9c0b
[2025-07-19T20:48:00.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21] for update
[2025-07-19T20:48:00.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ab0a9db
[2025-07-19T20:48:00.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16] for update
[2025-07-19T20:48:00.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.1.delta.b2474cbe-cc73-4034-87b2-0fb8597c3b5a.TID15.tmp
[2025-07-19T20:48:00.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b9774a8
[2025-07-19T20:48:00.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18] for update
[2025-07-19T20:48:00.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.1.delta.3ab3fb67-fdf0-4df3-98a2-98381b7f6f34.TID17.tmp
[2025-07-19T20:48:00.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.1.delta.bdedc982-9ec3-4d76-91db-c3ff1ab03bc4.TID13.tmp
[2025-07-19T20:48:00.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d15d1c5
[2025-07-19T20:48:00.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22] for update
[2025-07-19T20:48:00.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.1.delta.896c12ca-631b-465f-baa4-0927c12d8635.TID14.tmp
[2025-07-19T20:48:00.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1727db92
[2025-07-19T20:48:00.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12] for update
[2025-07-19T20:48:00.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.1.delta.5a7bc3c3-fa8a-4747-bf0b-aa040409cf85.TID18.tmp
[2025-07-19T20:48:00.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65e51dad
[2025-07-19T20:48:00.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14] for update
[2025-07-19T20:48:00.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.1.delta.d9f5a37a-a627-4819-8d04-1c6453b702d4.TID11.tmp
[2025-07-19T20:48:00.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72867416
[2025-07-19T20:48:00.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20] for update
[2025-07-19T20:48:00.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.1.delta.3ab3fb67-fdf0-4df3-98a2-98381b7f6f34.TID17.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta
[2025-07-19T20:48:00.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta
[2025-07-19T20:48:00.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 17, attempt 0, stage 5.0)
[2025-07-19T20:48:00.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.1.delta.b2474cbe-cc73-4034-87b2-0fb8597c3b5a.TID15.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta
[2025-07-19T20:48:00.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta
[2025-07-19T20:48:00.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 15, attempt 0, stage 5.0)
[2025-07-19T20:48:00.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.1.delta.260b69ec-9e64-4266-b358-f061c3172ef8.TID12.tmp
[2025-07-19T20:48:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.1.delta.4d91202d-44ce-4f2a-9a3c-3eb697ca8add.TID16.tmp
[2025-07-19T20:48:00.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.1.delta.896c12ca-631b-465f-baa4-0927c12d8635.TID14.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta
[2025-07-19T20:48:00.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta
[2025-07-19T20:48:00.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 14, attempt 0, stage 5.0)
[2025-07-19T20:48:00.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.1.delta.bdedc982-9ec3-4d76-91db-c3ff1ab03bc4.TID13.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta
[2025-07-19T20:48:00.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta
[2025-07-19T20:48:00.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 13, attempt 0, stage 5.0)
[2025-07-19T20:48:00.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.1.delta.5a7bc3c3-fa8a-4747-bf0b-aa040409cf85.TID18.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta
[2025-07-19T20:48:00.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta
[2025-07-19T20:48:00.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 18, attempt 0, stage 5.0)
[2025-07-19T20:48:00.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 21 (task 17, attempt 0, stage 5.0)
[2025-07-19T20:48:00.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 21.0 in stage 5.0 (TID 17). 9082 bytes result sent to driver
[2025-07-19T20:48:00.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.1.delta.d9f5a37a-a627-4819-8d04-1c6453b702d4.TID11.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta
[2025-07-19T20:48:00.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 19) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta
[2025-07-19T20:48:00.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 11, attempt 0, stage 5.0)
[2025-07-19T20:48:00.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 23.0 in stage 5.0 (TID 19)
[2025-07-19T20:48:00.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 17) in 241 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:48:00.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 19 (task 15, attempt 0, stage 5.0)
[2025-07-19T20:48:00.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 19.0 in stage 5.0 (TID 15). 9087 bytes result sent to driver
[2025-07-19T20:48:00.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 18 (task 14, attempt 0, stage 5.0)
[2025-07-19T20:48:00.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 18.0 in stage 5.0 (TID 14). 9075 bytes result sent to driver
[2025-07-19T20:48:00.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 20) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 24.0 in stage 5.0 (TID 20)
[2025-07-19T20:48:00.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 21) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 14) in 263 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:48:00.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 15) in 264 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:48:00.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 25.0 in stage 5.0 (TID 21)
[2025-07-19T20:48:00.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T20:48:00.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T20:48:00.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:00.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 12 (task 11, attempt 0, stage 5.0)
[2025-07-19T20:48:00.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 22 (task 18, attempt 0, stage 5.0)
[2025-07-19T20:48:00.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 16 (task 13, attempt 0, stage 5.0)
[2025-07-19T20:48:00.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 22.0 in stage 5.0 (TID 18). 9085 bytes result sent to driver
[2025-07-19T20:48:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 22) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 26.0 in stage 5.0 (TID 22)
[2025-07-19T20:48:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 12.0 in stage 5.0 (TID 11). 9096 bytes result sent to driver
[2025-07-19T20:48:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34da2677
[2025-07-19T20:48:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 23) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.1.delta.4d91202d-44ce-4f2a-9a3c-3eb697ca8add.TID16.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta
[2025-07-19T20:48:00.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24] for update
[2025-07-19T20:48:00.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta
[2025-07-19T20:48:00.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 16.0 in stage 5.0 (TID 13). 9079 bytes result sent to driver
[2025-07-19T20:48:00.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 29.0 in stage 5.0 (TID 23)
[2025-07-19T20:48:00.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 16, attempt 0, stage 5.0)
[2025-07-19T20:48:00.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 24) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:00.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 18) in 291 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:48:00.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 13) in 299 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:48:00.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 11) in 302 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:48:00.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.1.delta.260b69ec-9e64-4266-b358-f061c3172ef8.TID12.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta
[2025-07-19T20:48:00.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta
[2025-07-19T20:48:00.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 30.0 in stage 5.0 (TID 24)
[2025-07-19T20:48:00.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 12, attempt 0, stage 5.0)
[2025-07-19T20:48:00.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@412a6901
[2025-07-19T20:48:00.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23] for update
[2025-07-19T20:48:00.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:00.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:00.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.1.delta.babcfeb3-0cb6-4b0e-b3d0-d3c8ac56d942.TID20.tmp
[2025-07-19T20:48:00.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ef8c848
[2025-07-19T20:48:00.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25] for update
[2025-07-19T20:48:00.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c49437b
[2025-07-19T20:48:00.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.1.delta.7e940b61-b287-4db5-89d7-93a65f4d8fd4.TID19.tmp
[2025-07-19T20:48:00.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30] for update
[2025-07-19T20:48:00.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.1.delta.ea6f1811-3def-40f7-a7ac-eb732c6d6757.TID21.tmp
[2025-07-19T20:48:00.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7095a6aa
[2025-07-19T20:48:00.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29] for update
[2025-07-19T20:48:00.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@539545c
[2025-07-19T20:48:00.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.1.delta.c24a7c0f-ed14-4fbd-9481-a6d443edc782.TID24.tmp
[2025-07-19T20:48:00.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26] for update
[2025-07-19T20:48:00.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 20 (task 16, attempt 0, stage 5.0)
[2025-07-19T20:48:00.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.1.delta.1f733c45-87ac-4e3b-a84b-674734db52a5.TID23.tmp
[2025-07-19T20:48:00.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Committed partition 14 (task 12, attempt 0, stage 5.0)
[2025-07-19T20:48:00.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 14.0 in stage 5.0 (TID 12). 9097 bytes result sent to driver
[2025-07-19T20:48:00.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 12) in 367 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:48:00.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 25) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 32.0 in stage 5.0 (TID 25)
[2025-07-19T20:48:00.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Finished task 20.0 in stage 5.0 (TID 16). 9086 bytes result sent to driver
[2025-07-19T20:48:00.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 26) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:00.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.1.delta.babcfeb3-0cb6-4b0e-b3d0-d3c8ac56d942.TID20.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta
[2025-07-19T20:48:00.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 16) in 371 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:48:00.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta
[2025-07-19T20:48:00.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 20, attempt 0, stage 5.0)
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO Executor: Running task 35.0 in stage 5.0 (TID 26)
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b65d43c
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32] for update
[2025-07-19T20:48:00.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:00.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.1.delta.38847157-b3b5-4774-bb0f-9f8d6b85b92f.TID22.tmp
[2025-07-19T20:48:01.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.1.delta.7e940b61-b287-4db5-89d7-93a65f4d8fd4.TID19.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta
[2025-07-19T20:48:01.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta
[2025-07-19T20:48:01.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.1.delta.ea6f1811-3def-40f7-a7ac-eb732c6d6757.TID21.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta
[2025-07-19T20:48:01.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta
[2025-07-19T20:48:01.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 19, attempt 0, stage 5.0)
[2025-07-19T20:48:01.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 21, attempt 0, stage 5.0)
[2025-07-19T20:48:01.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6804606e
[2025-07-19T20:48:01.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35] for update
[2025-07-19T20:48:01.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.1.delta.c24a7c0f-ed14-4fbd-9481-a6d443edc782.TID24.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta
[2025-07-19T20:48:01.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta
[2025-07-19T20:48:01.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 24, attempt 0, stage 5.0)
[2025-07-19T20:48:01.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.1.delta.daad3140-c7f8-4c00-8a12-7b10c489fca8.TID25.tmp
[2025-07-19T20:48:01.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.1.delta.c0ceef79-8d9b-48a1-ab20-63123015a26a.TID26.tmp
[2025-07-19T20:48:01.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 24 (task 20, attempt 0, stage 5.0)
[2025-07-19T20:48:01.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 24.0 in stage 5.0 (TID 20). 9092 bytes result sent to driver
[2025-07-19T20:48:01.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 27) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.1.delta.1f733c45-87ac-4e3b-a84b-674734db52a5.TID23.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta
[2025-07-19T20:48:01.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta
[2025-07-19T20:48:01.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 20) in 201 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:48:01.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 23, attempt 0, stage 5.0)
[2025-07-19T20:48:01.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 37.0 in stage 5.0 (TID 27)
[2025-07-19T20:48:01.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 23 (task 19, attempt 0, stage 5.0)
[2025-07-19T20:48:01.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 25 (task 21, attempt 0, stage 5.0)
[2025-07-19T20:48:01.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:01.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 25.0 in stage 5.0 (TID 21). 9140 bytes result sent to driver
[2025-07-19T20:48:01.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 23.0 in stage 5.0 (TID 19). 9081 bytes result sent to driver
[2025-07-19T20:48:01.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 28) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 38.0 in stage 5.0 (TID 28)
[2025-07-19T20:48:01.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 29) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 39.0 in stage 5.0 (TID 29)
[2025-07-19T20:48:01.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 19) in 247 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:48:01.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 21) in 229 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:48:01.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:01.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:01.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.1.delta.38847157-b3b5-4774-bb0f-9f8d6b85b92f.TID22.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta
[2025-07-19T20:48:01.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta
[2025-07-19T20:48:01.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 22, attempt 0, stage 5.0)
[2025-07-19T20:48:01.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af0d8c4
[2025-07-19T20:48:01.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37] for update
[2025-07-19T20:48:01.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 30 (task 24, attempt 0, stage 5.0)
[2025-07-19T20:48:01.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 30.0 in stage 5.0 (TID 24). 9077 bytes result sent to driver
[2025-07-19T20:48:01.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 30) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 41.0 in stage 5.0 (TID 30)
[2025-07-19T20:48:01.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fd27f54
[2025-07-19T20:48:01.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 24) in 228 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:48:01.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39] for update
[2025-07-19T20:48:01.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.1.delta.daad3140-c7f8-4c00-8a12-7b10c489fca8.TID25.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta
[2025-07-19T20:48:01.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta
[2025-07-19T20:48:01.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 25, attempt 0, stage 5.0)
[2025-07-19T20:48:01.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.1.delta.32738cfa-3cc4-4658-94cb-d2fae590e993.TID27.tmp
[2025-07-19T20:48:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70166196
[2025-07-19T20:48:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.1.delta.c0ceef79-8d9b-48a1-ab20-63123015a26a.TID26.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta
[2025-07-19T20:48:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta
[2025-07-19T20:48:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38] for update
[2025-07-19T20:48:01.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 26, attempt 0, stage 5.0)
[2025-07-19T20:48:01.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.158+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 29 (task 23, attempt 0, stage 5.0)
[2025-07-19T20:48:01.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 29.0 in stage 5.0 (TID 23). 9067 bytes result sent to driver
[2025-07-19T20:48:01.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 31) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.1.delta.ad7bbd83-ed89-40dc-80c1-3c24e91d2c45.TID29.tmp
[2025-07-19T20:48:01.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 43.0 in stage 5.0 (TID 31)
[2025-07-19T20:48:01.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 23) in 263 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:48:01.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:01.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.1.delta.58038543-90cc-4aaf-ab4d-464d39160c51.TID28.tmp
[2025-07-19T20:48:01.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 26 (task 22, attempt 0, stage 5.0)
[2025-07-19T20:48:01.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 26.0 in stage 5.0 (TID 22). 9072 bytes result sent to driver
[2025-07-19T20:48:01.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 32) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 22) in 282 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:48:01.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 45.0 in stage 5.0 (TID 32)
[2025-07-19T20:48:01.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77bbdab2
[2025-07-19T20:48:01.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43] for update
[2025-07-19T20:48:01.196+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 35 (task 26, attempt 0, stage 5.0)
[2025-07-19T20:48:01.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 35.0 in stage 5.0 (TID 26). 9088 bytes result sent to driver
[2025-07-19T20:48:01.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 33) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54a617ef
[2025-07-19T20:48:01.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45] for update
[2025-07-19T20:48:01.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 26) in 222 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:48:01.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 32 (task 25, attempt 0, stage 5.0)
[2025-07-19T20:48:01.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 46.0 in stage 5.0 (TID 33)
[2025-07-19T20:48:01.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 32.0 in stage 5.0 (TID 25). 9122 bytes result sent to driver
[2025-07-19T20:48:01.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 34) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a6f5c93
[2025-07-19T20:48:01.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41] for update
[2025-07-19T20:48:01.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 25) in 258 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:48:01.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.1.delta.32738cfa-3cc4-4658-94cb-d2fae590e993.TID27.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta
[2025-07-19T20:48:01.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta
[2025-07-19T20:48:01.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.1.delta.9025c4d0-eeaf-4187-9b20-a97f493dd82d.TID31.tmp
[2025-07-19T20:48:01.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 47.0 in stage 5.0 (TID 34)
[2025-07-19T20:48:01.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 27, attempt 0, stage 5.0)
[2025-07-19T20:48:01.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.1.delta.ad7bbd83-ed89-40dc-80c1-3c24e91d2c45.TID29.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta
[2025-07-19T20:48:01.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta
[2025-07-19T20:48:01.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 29, attempt 0, stage 5.0)
[2025-07-19T20:48:01.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.1.delta.bc62ce83-71fe-466e-84af-3c12d9b49b40.TID32.tmp
[2025-07-19T20:48:01.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47f434c3
[2025-07-19T20:48:01.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46] for update
[2025-07-19T20:48:01.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.1.delta.58038543-90cc-4aaf-ab4d-464d39160c51.TID28.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta
[2025-07-19T20:48:01.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta
[2025-07-19T20:48:01.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 28, attempt 0, stage 5.0)
[2025-07-19T20:48:01.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.1.delta.943940c0-6d5e-47e2-bf70-764d72efc39b.TID30.tmp
[2025-07-19T20:48:01.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T20:48:01.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.1.delta.8a7f468c-6990-4271-826e-76fa113612e5.TID33.tmp
[2025-07-19T20:48:01.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@85a6b87
[2025-07-19T20:48:01.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47] for update
[2025-07-19T20:48:01.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 39 (task 29, attempt 0, stage 5.0)
[2025-07-19T20:48:01.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 39.0 in stage 5.0 (TID 29). 9067 bytes result sent to driver
[2025-07-19T20:48:01.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 35) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 29) in 231 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:48:01.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 48.0 in stage 5.0 (TID 35)
[2025-07-19T20:48:01.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 37 (task 27, attempt 0, stage 5.0)
[2025-07-19T20:48:01.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 37.0 in stage 5.0 (TID 27). 9128 bytes result sent to driver
[2025-07-19T20:48:01.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 36) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 51.0 in stage 5.0 (TID 36)
[2025-07-19T20:48:01.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 27) in 270 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:48:01.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 38 (task 28, attempt 0, stage 5.0)
[2025-07-19T20:48:01.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:01.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 38.0 in stage 5.0 (TID 28). 9073 bytes result sent to driver
[2025-07-19T20:48:01.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 37) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 28) in 258 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:48:01.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.1.delta.9025c4d0-eeaf-4187-9b20-a97f493dd82d.TID31.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta
[2025-07-19T20:48:01.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta
[2025-07-19T20:48:01.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.1.delta.bc62ce83-71fe-466e-84af-3c12d9b49b40.TID32.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta
[2025-07-19T20:48:01.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta
[2025-07-19T20:48:01.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 31, attempt 0, stage 5.0)
[2025-07-19T20:48:01.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 32, attempt 0, stage 5.0)
[2025-07-19T20:48:01.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 52.0 in stage 5.0 (TID 37)
[2025-07-19T20:48:01.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c1cf9d6
[2025-07-19T20:48:01.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51] for update
[2025-07-19T20:48:01.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5078c988
[2025-07-19T20:48:01.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48] for update
[2025-07-19T20:48:01.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.1.delta.656fb7ac-992a-4e4a-b8f2-950295155af7.TID34.tmp
[2025-07-19T20:48:01.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.1.delta.cdee7eef-3281-4f86-8ad8-38162ef24e6d.TID35.tmp
[2025-07-19T20:48:01.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@612ccbe7
[2025-07-19T20:48:01.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52] for update
[2025-07-19T20:48:01.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.1.delta.8a7f468c-6990-4271-826e-76fa113612e5.TID33.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta
[2025-07-19T20:48:01.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta
[2025-07-19T20:48:01.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 33, attempt 0, stage 5.0)
[2025-07-19T20:48:01.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 45 (task 32, attempt 0, stage 5.0)
[2025-07-19T20:48:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 45.0 in stage 5.0 (TID 32). 9085 bytes result sent to driver
[2025-07-19T20:48:01.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.1.delta.2a0b98cc-2a85-4515-99b8-2d39a7f402e0.TID36.tmp
[2025-07-19T20:48:01.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 38) (8b44f3d35cfa, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.1.delta.943940c0-6d5e-47e2-bf70-764d72efc39b.TID30.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta
[2025-07-19T20:48:01.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta
[2025-07-19T20:48:01.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 32) in 214 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:48:01.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 53.0 in stage 5.0 (TID 38)
[2025-07-19T20:48:01.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 43 (task 31, attempt 0, stage 5.0)
[2025-07-19T20:48:01.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 43.0 in stage 5.0 (TID 31). 9075 bytes result sent to driver
[2025-07-19T20:48:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 39) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 56.0 in stage 5.0 (TID 39)
[2025-07-19T20:48:01.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 31) in 234 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:48:01.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 30, attempt 0, stage 5.0)
[2025-07-19T20:48:01.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:01.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.1.delta.46dabede-9cc4-482a-b69d-e59f4927e0d7.TID37.tmp
[2025-07-19T20:48:01.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68ede47e
[2025-07-19T20:48:01.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 46 (task 33, attempt 0, stage 5.0)
[2025-07-19T20:48:01.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53] for update
[2025-07-19T20:48:01.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 46.0 in stage 5.0 (TID 33). 9139 bytes result sent to driver
[2025-07-19T20:48:01.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 40) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 57.0 in stage 5.0 (TID 40)
[2025-07-19T20:48:01.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 33) in 218 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:48:01.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:01.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.1.delta.656fb7ac-992a-4e4a-b8f2-950295155af7.TID34.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta
[2025-07-19T20:48:01.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta
[2025-07-19T20:48:01.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 34, attempt 0, stage 5.0)
[2025-07-19T20:48:01.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.1.delta.cdee7eef-3281-4f86-8ad8-38162ef24e6d.TID35.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta
[2025-07-19T20:48:01.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta
[2025-07-19T20:48:01.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e41d349
[2025-07-19T20:48:01.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56] for update
[2025-07-19T20:48:01.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 35, attempt 0, stage 5.0)
[2025-07-19T20:48:01.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 41 (task 30, attempt 0, stage 5.0)
[2025-07-19T20:48:01.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 41.0 in stage 5.0 (TID 30). 9075 bytes result sent to driver
[2025-07-19T20:48:01.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.1.delta.840ad076-8382-4f14-a012-17911dac6161.TID38.tmp
[2025-07-19T20:48:01.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 41) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f0779bc
[2025-07-19T20:48:01.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57] for update
[2025-07-19T20:48:01.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 58.0 in stage 5.0 (TID 41)
[2025-07-19T20:48:01.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 30) in 333 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:48:01.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.1.delta.bd4f29f7-23d3-4f01-ae48-a0812e72ab77.TID39.tmp
[2025-07-19T20:48:01.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.1.delta.f2d3134c-0eb7-4c4b-97b2-1eb167799a46.TID40.tmp
[2025-07-19T20:48:01.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6da133ed
[2025-07-19T20:48:01.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58] for update
[2025-07-19T20:48:01.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 48 (task 35, attempt 0, stage 5.0)
[2025-07-19T20:48:01.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 48.0 in stage 5.0 (TID 35). 9043 bytes result sent to driver
[2025-07-19T20:48:01.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 42) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 35) in 174 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:48:01.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 59.0 in stage 5.0 (TID 42)
[2025-07-19T20:48:01.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 47 (task 34, attempt 0, stage 5.0)
[2025-07-19T20:48:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.1.delta.2a0b98cc-2a85-4515-99b8-2d39a7f402e0.TID36.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta
[2025-07-19T20:48:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta
[2025-07-19T20:48:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.1.delta.46dabede-9cc4-482a-b69d-e59f4927e0d7.TID37.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta
[2025-07-19T20:48:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta
[2025-07-19T20:48:01.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 47.0 in stage 5.0 (TID 34). 9041 bytes result sent to driver
[2025-07-19T20:48:01.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 36, attempt 0, stage 5.0)
[2025-07-19T20:48:01.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fc0b715
[2025-07-19T20:48:01.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59] for update
[2025-07-19T20:48:01.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 43) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 34) in 273 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:48:01.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 37, attempt 0, stage 5.0)
[2025-07-19T20:48:01.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.1.delta.fc7d4450-3d07-4f78-bbc3-253a83165d0f.TID41.tmp
[2025-07-19T20:48:01.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 60.0 in stage 5.0 (TID 43)
[2025-07-19T20:48:01.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.1.delta.5ae75bfd-436e-4a4b-ae0b-d8b9a5cafcde.TID42.tmp
[2025-07-19T20:48:01.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b5a9774
[2025-07-19T20:48:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60] for update
[2025-07-19T20:48:01.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.1.delta.bd4f29f7-23d3-4f01-ae48-a0812e72ab77.TID39.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta
[2025-07-19T20:48:01.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 52 (task 37, attempt 0, stage 5.0)
[2025-07-19T20:48:01.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta
[2025-07-19T20:48:01.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 52.0 in stage 5.0 (TID 37). 9069 bytes result sent to driver
[2025-07-19T20:48:01.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.1.delta.840ad076-8382-4f14-a012-17911dac6161.TID38.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta
[2025-07-19T20:48:01.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta
[2025-07-19T20:48:01.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 38, attempt 0, stage 5.0)
[2025-07-19T20:48:01.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 44) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 39, attempt 0, stage 5.0)
[2025-07-19T20:48:01.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 37) in 221 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:48:01.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 51 (task 36, attempt 0, stage 5.0)
[2025-07-19T20:48:01.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 62.0 in stage 5.0 (TID 44)
[2025-07-19T20:48:01.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 51.0 in stage 5.0 (TID 36). 9085 bytes result sent to driver
[2025-07-19T20:48:01.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.1.delta.f2d3134c-0eb7-4c4b-97b2-1eb167799a46.TID40.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta
[2025-07-19T20:48:01.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta
[2025-07-19T20:48:01.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 45) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 40, attempt 0, stage 5.0)
[2025-07-19T20:48:01.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 63.0 in stage 5.0 (TID 45)
[2025-07-19T20:48:01.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 36) in 253 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:48:01.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.1.delta.0347aa65-46e0-44f7-a9c3-e78be5f3d901.TID43.tmp
[2025-07-19T20:48:01.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 53 (task 38, attempt 0, stage 5.0)
[2025-07-19T20:48:01.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:01.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 53.0 in stage 5.0 (TID 38). 9093 bytes result sent to driver
[2025-07-19T20:48:01.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 46) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 64.0 in stage 5.0 (TID 46)
[2025-07-19T20:48:01.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 38) in 197 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:48:01.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 56 (task 39, attempt 0, stage 5.0)
[2025-07-19T20:48:01.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:01.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 56.0 in stage 5.0 (TID 39). 9092 bytes result sent to driver
[2025-07-19T20:48:01.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 47) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 65.0 in stage 5.0 (TID 47)
[2025-07-19T20:48:01.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.1.delta.fc7d4450-3d07-4f78-bbc3-253a83165d0f.TID41.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta
[2025-07-19T20:48:01.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b113ecc
[2025-07-19T20:48:01.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62] for update
[2025-07-19T20:48:01.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta
[2025-07-19T20:48:01.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 41, attempt 0, stage 5.0)
[2025-07-19T20:48:01.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 39) in 201 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:48:01.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b063bf0
[2025-07-19T20:48:01.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65] for update
[2025-07-19T20:48:01.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.1.delta.5ae75bfd-436e-4a4b-ae0b-d8b9a5cafcde.TID42.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta
[2025-07-19T20:48:01.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta
[2025-07-19T20:48:01.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 57 (task 40, attempt 0, stage 5.0)
[2025-07-19T20:48:01.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 57.0 in stage 5.0 (TID 40). 9089 bytes result sent to driver
[2025-07-19T20:48:01.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 48) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 40) in 200 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:48:01.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 42, attempt 0, stage 5.0)
[2025-07-19T20:48:01.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 66.0 in stage 5.0 (TID 48)
[2025-07-19T20:48:01.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@540d94bf
[2025-07-19T20:48:01.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64] for update
[2025-07-19T20:48:01.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.1.delta.f0c7a902-e419-47f3-8866-c5a033b96f0d.TID47.tmp
[2025-07-19T20:48:01.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 58 (task 41, attempt 0, stage 5.0)
[2025-07-19T20:48:01.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 58.0 in stage 5.0 (TID 41). 9081 bytes result sent to driver
[2025-07-19T20:48:01.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 49) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 41) in 187 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:48:01.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 68.0 in stage 5.0 (TID 49)
[2025-07-19T20:48:01.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.1.delta.3122f680-75ae-47e4-af16-61bfd96567d4.TID44.tmp
[2025-07-19T20:48:01.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b7a0841
[2025-07-19T20:48:01.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63] for update
[2025-07-19T20:48:01.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fe5250a
[2025-07-19T20:48:01.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66] for update
[2025-07-19T20:48:01.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 59 (task 42, attempt 0, stage 5.0)
[2025-07-19T20:48:01.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 59.0 in stage 5.0 (TID 42). 9090 bytes result sent to driver
[2025-07-19T20:48:01.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 50) (8b44f3d35cfa, executor driver, partition 69, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 69.0 in stage 5.0 (TID 50)
[2025-07-19T20:48:01.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.1.delta.ceae398c-4fd6-4580-a6c0-8a076f8f89b9.TID45.tmp
[2025-07-19T20:48:01.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 42) in 184 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:48:01.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.1.delta.9503db73-2d87-4529-956d-7b5d2a518c49.TID46.tmp
[2025-07-19T20:48:01.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.1.delta.0347aa65-46e0-44f7-a9c3-e78be5f3d901.TID43.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta
[2025-07-19T20:48:01.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta
[2025-07-19T20:48:01.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 43, attempt 0, stage 5.0)
[2025-07-19T20:48:01.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30084f14
[2025-07-19T20:48:01.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68] for update
[2025-07-19T20:48:01.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71363e0a
[2025-07-19T20:48:01.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69] for update
[2025-07-19T20:48:01.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.1.delta.76db53bf-e0a1-48e4-ae55-ee60192f86a1.TID48.tmp
[2025-07-19T20:48:01.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.1.delta.f0c7a902-e419-47f3-8866-c5a033b96f0d.TID47.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta
[2025-07-19T20:48:01.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta
[2025-07-19T20:48:01.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 47, attempt 0, stage 5.0)
[2025-07-19T20:48:01.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.1.delta.2c22bdec-de41-4c91-a794-bca33a748136.TID49.tmp
[2025-07-19T20:48:01.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 60 (task 43, attempt 0, stage 5.0)
[2025-07-19T20:48:01.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 60.0 in stage 5.0 (TID 43). 9079 bytes result sent to driver
[2025-07-19T20:48:01.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 51) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 43) in 214 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:48:01.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 71.0 in stage 5.0 (TID 51)
[2025-07-19T20:48:01.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:01.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.1.delta.3122f680-75ae-47e4-af16-61bfd96567d4.TID44.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta
[2025-07-19T20:48:01.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta
[2025-07-19T20:48:01.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.1.delta.6f1e7b67-4283-4dbc-a57d-9ff3bbd95796.TID50.tmp
[2025-07-19T20:48:01.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 44, attempt 0, stage 5.0)
[2025-07-19T20:48:01.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3be1a1d1
[2025-07-19T20:48:01.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71] for update
[2025-07-19T20:48:01.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 65 (task 47, attempt 0, stage 5.0)
[2025-07-19T20:48:01.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 65.0 in stage 5.0 (TID 47). 9042 bytes result sent to driver
[2025-07-19T20:48:01.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.1.delta.9503db73-2d87-4529-956d-7b5d2a518c49.TID46.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta
[2025-07-19T20:48:01.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta
[2025-07-19T20:48:01.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 52) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 47) in 141 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:48:01.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 46, attempt 0, stage 5.0)
[2025-07-19T20:48:01.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 72.0 in stage 5.0 (TID 52)
[2025-07-19T20:48:01.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.1.delta.ceae398c-4fd6-4580-a6c0-8a076f8f89b9.TID45.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta
[2025-07-19T20:48:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta
[2025-07-19T20:48:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 45, attempt 0, stage 5.0)
[2025-07-19T20:48:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.1.delta.e80c24bc-ef78-4621-9974-ebbff66d6492.TID51.tmp
[2025-07-19T20:48:01.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45b53fef
[2025-07-19T20:48:01.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72] for update
[2025-07-19T20:48:01.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.1.delta.2c22bdec-de41-4c91-a794-bca33a748136.TID49.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta
[2025-07-19T20:48:01.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta
[2025-07-19T20:48:01.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 49, attempt 0, stage 5.0)
[2025-07-19T20:48:01.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 62 (task 44, attempt 0, stage 5.0)
[2025-07-19T20:48:01.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.1.delta.76db53bf-e0a1-48e4-ae55-ee60192f86a1.TID48.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta
[2025-07-19T20:48:01.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta
[2025-07-19T20:48:01.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 62.0 in stage 5.0 (TID 44). 9085 bytes result sent to driver
[2025-07-19T20:48:01.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 48, attempt 0, stage 5.0)
[2025-07-19T20:48:01.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 53) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.1.delta.29f5ff43-1cf0-4416-a99a-face9b8344a7.TID52.tmp
[2025-07-19T20:48:01.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.1.delta.6f1e7b67-4283-4dbc-a57d-9ff3bbd95796.TID50.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta
[2025-07-19T20:48:01.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta
[2025-07-19T20:48:01.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 50, attempt 0, stage 5.0)
[2025-07-19T20:48:01.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 63 (task 45, attempt 0, stage 5.0)
[2025-07-19T20:48:01.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 63.0 in stage 5.0 (TID 45). 9032 bytes result sent to driver
[2025-07-19T20:48:01.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 73.0 in stage 5.0 (TID 53)
[2025-07-19T20:48:01.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 44) in 225 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:48:01.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 64 (task 46, attempt 0, stage 5.0)
[2025-07-19T20:48:01.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 54) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 64.0 in stage 5.0 (TID 46). 9049 bytes result sent to driver
[2025-07-19T20:48:01.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 75.0 in stage 5.0 (TID 54)
[2025-07-19T20:48:01.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 45) in 221 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:48:01.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 55) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 77.0 in stage 5.0 (TID 55)
[2025-07-19T20:48:01.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 46) in 205 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:48:01.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 66 (task 48, attempt 0, stage 5.0)
[2025-07-19T20:48:01.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.1.delta.e80c24bc-ef78-4621-9974-ebbff66d6492.TID51.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta
[2025-07-19T20:48:01.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta
[2025-07-19T20:48:01.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 51, attempt 0, stage 5.0)
[2025-07-19T20:48:01.803+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 66.0 in stage 5.0 (TID 48). 9059 bytes result sent to driver
[2025-07-19T20:48:01.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 56) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 78.0 in stage 5.0 (TID 56)
[2025-07-19T20:48:01.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@409b0e90
[2025-07-19T20:48:01.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 68 (task 49, attempt 0, stage 5.0)
[2025-07-19T20:48:01.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77] for update
[2025-07-19T20:48:01.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 68.0 in stage 5.0 (TID 49). 9028 bytes result sent to driver
[2025-07-19T20:48:01.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 57) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 69 (task 50, attempt 0, stage 5.0)
[2025-07-19T20:48:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 79.0 in stage 5.0 (TID 57)
[2025-07-19T20:48:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 69.0 in stage 5.0 (TID 50). 9022 bytes result sent to driver
[2025-07-19T20:48:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 58) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a0683a8
[2025-07-19T20:48:01.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:01.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 82.0 in stage 5.0 (TID 58)
[2025-07-19T20:48:01.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73] for update
[2025-07-19T20:48:01.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 48) in 206 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:48:01.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:01.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:01.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.1.delta.d11f31ac-cc68-4ef1-a943-6500c5cfc6b3.TID55.tmp
[2025-07-19T20:48:01.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 49) in 191 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:48:01.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.1.delta.29f5ff43-1cf0-4416-a99a-face9b8344a7.TID52.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta
[2025-07-19T20:48:01.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d0c40e8
[2025-07-19T20:48:01.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta
[2025-07-19T20:48:01.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75] for update
[2025-07-19T20:48:01.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 50) in 178 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:48:01.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 52, attempt 0, stage 5.0)
[2025-07-19T20:48:01.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cf2866b
[2025-07-19T20:48:01.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82] for update
[2025-07-19T20:48:01.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 71 (task 51, attempt 0, stage 5.0)
[2025-07-19T20:48:01.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 71.0 in stage 5.0 (TID 51). 9116 bytes result sent to driver
[2025-07-19T20:48:01.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.1.delta.15a88880-349c-47e8-9e4f-78c4470976e4.TID53.tmp
[2025-07-19T20:48:01.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 59) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@308d06a3
[2025-07-19T20:48:01.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79] for update
[2025-07-19T20:48:01.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 83.0 in stage 5.0 (TID 59)
[2025-07-19T20:48:01.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 51) in 157 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:48:01.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.1.delta.a628f1cf-fbcc-451b-baa6-19d3a1e10e4d.TID54.tmp
[2025-07-19T20:48:01.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37f798c1
[2025-07-19T20:48:01.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78] for update
[2025-07-19T20:48:01.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 72 (task 52, attempt 0, stage 5.0)
[2025-07-19T20:48:01.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 72.0 in stage 5.0 (TID 52). 9069 bytes result sent to driver
[2025-07-19T20:48:01.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.1.delta.cb5350f8-d9c5-4856-9816-886a5d3fa010.TID58.tmp
[2025-07-19T20:48:01.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 60) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 52) in 155 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:48:01.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 85.0 in stage 5.0 (TID 60)
[2025-07-19T20:48:01.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f180d91
[2025-07-19T20:48:01.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83] for update
[2025-07-19T20:48:01.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.1.delta.9d7b3290-8268-45e1-868d-fe4ea5f30682.TID56.tmp
[2025-07-19T20:48:01.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.1.delta.beb2092d-538a-4120-9c4c-de727757c10e.TID57.tmp
[2025-07-19T20:48:01.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.1.delta.d11f31ac-cc68-4ef1-a943-6500c5cfc6b3.TID55.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta
[2025-07-19T20:48:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta
[2025-07-19T20:48:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@287af6a5
[2025-07-19T20:48:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85] for update
[2025-07-19T20:48:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 55, attempt 0, stage 5.0)
[2025-07-19T20:48:01.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.1.delta.fdb97183-a55b-4d79-91b4-4254f727fdbe.TID59.tmp
[2025-07-19T20:48:01.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:01.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.1.delta.15a88880-349c-47e8-9e4f-78c4470976e4.TID53.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta
[2025-07-19T20:48:01.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta
[2025-07-19T20:48:01.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 53, attempt 0, stage 5.0)
[2025-07-19T20:48:01.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.1.delta.a628f1cf-fbcc-451b-baa6-19d3a1e10e4d.TID54.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta
[2025-07-19T20:48:01.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta
[2025-07-19T20:48:01.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.1.delta.f307cb8e-3cd9-4125-9271-63589a9d0c6f.TID60.tmp
[2025-07-19T20:48:01.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 54, attempt 0, stage 5.0)
[2025-07-19T20:48:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.1.delta.beb2092d-538a-4120-9c4c-de727757c10e.TID57.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta
[2025-07-19T20:48:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta
[2025-07-19T20:48:01.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 57, attempt 0, stage 5.0)
[2025-07-19T20:48:01.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 77 (task 55, attempt 0, stage 5.0)
[2025-07-19T20:48:01.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 77.0 in stage 5.0 (TID 55). 9079 bytes result sent to driver
[2025-07-19T20:48:01.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.1.delta.cb5350f8-d9c5-4856-9816-886a5d3fa010.TID58.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta
[2025-07-19T20:48:01.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta
[2025-07-19T20:48:01.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 58, attempt 0, stage 5.0)
[2025-07-19T20:48:01.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 61) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.1.delta.9d7b3290-8268-45e1-868d-fe4ea5f30682.TID56.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta
[2025-07-19T20:48:01.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta
[2025-07-19T20:48:01.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 55) in 184 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:48:01.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 56, attempt 0, stage 5.0)
[2025-07-19T20:48:01.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 73 (task 53, attempt 0, stage 5.0)
[2025-07-19T20:48:01.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 86.0 in stage 5.0 (TID 61)
[2025-07-19T20:48:01.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 73.0 in stage 5.0 (TID 53). 9094 bytes result sent to driver
[2025-07-19T20:48:01.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 62) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 87.0 in stage 5.0 (TID 62)
[2025-07-19T20:48:01.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 53) in 199 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:48:01.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:01.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 75 (task 54, attempt 0, stage 5.0)
[2025-07-19T20:48:01.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 75.0 in stage 5.0 (TID 54). 9075 bytes result sent to driver
[2025-07-19T20:48:01.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 63) (8b44f3d35cfa, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 89.0 in stage 5.0 (TID 63)
[2025-07-19T20:48:01.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 54) in 207 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:48:01.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 79 (task 57, attempt 0, stage 5.0)
[2025-07-19T20:48:01.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.1.delta.fdb97183-a55b-4d79-91b4-4254f727fdbe.TID59.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta
[2025-07-19T20:48:01.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta
[2025-07-19T20:48:01.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 59, attempt 0, stage 5.0)
[2025-07-19T20:48:01.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18424c84
[2025-07-19T20:48:01.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:01.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86] for update
[2025-07-19T20:48:01.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 79.0 in stage 5.0 (TID 57). 9081 bytes result sent to driver
[2025-07-19T20:48:01.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:01.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:01.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 64) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:01.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Committed partition 78 (task 56, attempt 0, stage 5.0)
[2025-07-19T20:48:01.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Finished task 78.0 in stage 5.0 (TID 56). 9088 bytes result sent to driver
[2025-07-19T20:48:01.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 92.0 in stage 5.0 (TID 64)
[2025-07-19T20:48:01.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 57) in 186 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:48:02.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 65) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 56) in 197 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:48:02.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO Executor: Running task 94.0 in stage 5.0 (TID 65)
[2025-07-19T20:48:02.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c1924d4
[2025-07-19T20:48:02.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.1.delta.f307cb8e-3cd9-4125-9271-63589a9d0c6f.TID60.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87] for update
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 60, attempt 0, stage 5.0)
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@769c2b57
[2025-07-19T20:48:02.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 82 (task 58, attempt 0, stage 5.0)
[2025-07-19T20:48:02.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89] for update
[2025-07-19T20:48:02.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 82.0 in stage 5.0 (TID 58). 9081 bytes result sent to driver
[2025-07-19T20:48:02.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 66) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 95.0 in stage 5.0 (TID 66)
[2025-07-19T20:48:02.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 58) in 200 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:48:02.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.1.delta.ac4f7db4-8da0-43b2-a2c8-0226a176c967.TID61.tmp
[2025-07-19T20:48:02.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66f1d769
[2025-07-19T20:48:02.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94] for update
[2025-07-19T20:48:02.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 85 (task 60, attempt 0, stage 5.0)
[2025-07-19T20:48:02.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 83 (task 59, attempt 0, stage 5.0)
[2025-07-19T20:48:02.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 85.0 in stage 5.0 (TID 60). 9047 bytes result sent to driver
[2025-07-19T20:48:02.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 83.0 in stage 5.0 (TID 59). 9037 bytes result sent to driver
[2025-07-19T20:48:02.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.1.delta.68601da2-c648-4d36-befe-5f84cebcd9a9.TID63.tmp
[2025-07-19T20:48:02.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 96.0 in stage 5.0 (TID 67) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.1.delta.647f8da9-e3d6-4530-b915-4e31000c6ece.TID62.tmp
[2025-07-19T20:48:02.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 60) in 149 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:48:02.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 96.0 in stage 5.0 (TID 67)
[2025-07-19T20:48:02.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ba4c11a
[2025-07-19T20:48:02.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 97.0 in stage 5.0 (TID 68) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92] for update
[2025-07-19T20:48:02.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 59) in 178 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:48:02.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.1.delta.4c770731-daa1-4d2b-8ab0-a122568a4fd2.TID65.tmp
[2025-07-19T20:48:02.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 97.0 in stage 5.0 (TID 68)
[2025-07-19T20:48:02.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:02.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69a50d59
[2025-07-19T20:48:02.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:02.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95] for update
[2025-07-19T20:48:02.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a4f71b7
[2025-07-19T20:48:02.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.057+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97] for update
[2025-07-19T20:48:02.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.1.delta.8a4d5545-152b-4927-aa3b-e6216e2dfd8f.TID64.tmp
[2025-07-19T20:48:02.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.1.delta.ac4f7db4-8da0-43b2-a2c8-0226a176c967.TID61.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta
[2025-07-19T20:48:02.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta
[2025-07-19T20:48:02.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 61, attempt 0, stage 5.0)
[2025-07-19T20:48:02.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.1.delta.6ba1277e-89cf-4529-873d-dd0b6416c15b.TID66.tmp
[2025-07-19T20:48:02.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.1.delta.4c770731-daa1-4d2b-8ab0-a122568a4fd2.TID65.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta
[2025-07-19T20:48:02.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.1.delta.68601da2-c648-4d36-befe-5f84cebcd9a9.TID63.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta
[2025-07-19T20:48:02.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta
[2025-07-19T20:48:02.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta
[2025-07-19T20:48:02.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 63, attempt 0, stage 5.0)
[2025-07-19T20:48:02.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 65, attempt 0, stage 5.0)
[2025-07-19T20:48:02.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.1.delta.647f8da9-e3d6-4530-b915-4e31000c6ece.TID62.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta
[2025-07-19T20:48:02.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta
[2025-07-19T20:48:02.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 62, attempt 0, stage 5.0)
[2025-07-19T20:48:02.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.1.delta.08920806-9269-442e-a45e-11361a7eaec6.TID68.tmp
[2025-07-19T20:48:02.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 86 (task 61, attempt 0, stage 5.0)
[2025-07-19T20:48:02.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 86.0 in stage 5.0 (TID 61). 9050 bytes result sent to driver
[2025-07-19T20:48:02.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e031820
[2025-07-19T20:48:02.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96] for update
[2025-07-19T20:48:02.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 98.0 in stage 5.0 (TID 69) (8b44f3d35cfa, executor driver, partition 98, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 61) in 132 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:48:02.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 94 (task 65, attempt 0, stage 5.0)
[2025-07-19T20:48:02.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 89 (task 63, attempt 0, stage 5.0)
[2025-07-19T20:48:02.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 94.0 in stage 5.0 (TID 65). 9048 bytes result sent to driver
[2025-07-19T20:48:02.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 99.0 in stage 5.0 (TID 70) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 65) in 99 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:48:02.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 89.0 in stage 5.0 (TID 63). 9034 bytes result sent to driver
[2025-07-19T20:48:02.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 99.0 in stage 5.0 (TID 70)
[2025-07-19T20:48:02.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 98.0 in stage 5.0 (TID 69)
[2025-07-19T20:48:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 100.0 in stage 5.0 (TID 71) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 63) in 120 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:48:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.1.delta.d267e598-98cf-4e5e-a92e-c2b9d31ae361.TID67.tmp
[2025-07-19T20:48:02.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 100.0 in stage 5.0 (TID 71)
[2025-07-19T20:48:02.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:02.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.1.delta.6ba1277e-89cf-4529-873d-dd0b6416c15b.TID66.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta
[2025-07-19T20:48:02.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta
[2025-07-19T20:48:02.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 66, attempt 0, stage 5.0)
[2025-07-19T20:48:02.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@294618d1
[2025-07-19T20:48:02.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99] for update
[2025-07-19T20:48:02.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 87 (task 62, attempt 0, stage 5.0)
[2025-07-19T20:48:02.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 87.0 in stage 5.0 (TID 62). 9050 bytes result sent to driver
[2025-07-19T20:48:02.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 102.0 in stage 5.0 (TID 72) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5124eab9
[2025-07-19T20:48:02.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100] for update
[2025-07-19T20:48:02.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 102.0 in stage 5.0 (TID 72)
[2025-07-19T20:48:02.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 62) in 157 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:48:02.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.1.delta.4ca46988-c72c-4d6c-bd13-3fd5c0ad252f.TID70.tmp
[2025-07-19T20:48:02.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@447c58af
[2025-07-19T20:48:02.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98] for update
[2025-07-19T20:48:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.1.delta.8a4d5545-152b-4927-aa3b-e6216e2dfd8f.TID64.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta
[2025-07-19T20:48:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta
[2025-07-19T20:48:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 64, attempt 0, stage 5.0)
[2025-07-19T20:48:02.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35a50c7b
[2025-07-19T20:48:02.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102] for update
[2025-07-19T20:48:02.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.1.delta.a004a85d-7267-40d4-b819-97c95438a8e4.TID69.tmp
[2025-07-19T20:48:02.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.1.delta.08920806-9269-442e-a45e-11361a7eaec6.TID68.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta
[2025-07-19T20:48:02.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta
[2025-07-19T20:48:02.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 68, attempt 0, stage 5.0)
[2025-07-19T20:48:02.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.1.delta.996ba6e1-b315-4dad-b9f6-494e6d021020.TID71.tmp
[2025-07-19T20:48:02.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 95 (task 66, attempt 0, stage 5.0)
[2025-07-19T20:48:02.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 95.0 in stage 5.0 (TID 66). 9036 bytes result sent to driver
[2025-07-19T20:48:02.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 104.0 in stage 5.0 (TID 73) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 66) in 145 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:48:02.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.1.delta.9246a886-4f38-4269-ab8b-e5ef2bf44228.TID72.tmp
[2025-07-19T20:48:02.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 104.0 in stage 5.0 (TID 73)
[2025-07-19T20:48:02.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.1.delta.d267e598-98cf-4e5e-a92e-c2b9d31ae361.TID67.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta
[2025-07-19T20:48:02.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta
[2025-07-19T20:48:02.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 67, attempt 0, stage 5.0)
[2025-07-19T20:48:02.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 92 (task 64, attempt 0, stage 5.0)
[2025-07-19T20:48:02.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55eb470f
[2025-07-19T20:48:02.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 92.0 in stage 5.0 (TID 64). 9077 bytes result sent to driver
[2025-07-19T20:48:02.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104] for update
[2025-07-19T20:48:02.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 97 (task 68, attempt 0, stage 5.0)
[2025-07-19T20:48:02.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 97.0 in stage 5.0 (TID 68). 9079 bytes result sent to driver
[2025-07-19T20:48:02.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 105.0 in stage 5.0 (TID 74) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 106.0 in stage 5.0 (TID 75) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 105.0 in stage 5.0 (TID 74)
[2025-07-19T20:48:02.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 106.0 in stage 5.0 (TID 75)
[2025-07-19T20:48:02.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 97.0 in stage 5.0 (TID 68) in 146 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:48:02.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 64) in 185 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:48:02.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f3b17c5
[2025-07-19T20:48:02.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.1.delta.4ca46988-c72c-4d6c-bd13-3fd5c0ad252f.TID70.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta
[2025-07-19T20:48:02.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta
[2025-07-19T20:48:02.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106] for update
[2025-07-19T20:48:02.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 70, attempt 0, stage 5.0)
[2025-07-19T20:48:02.196+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.1.delta.fc70ba4f-744b-443b-a0ee-345081223fb4.TID73.tmp
[2025-07-19T20:48:02.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.1.delta.a004a85d-7267-40d4-b819-97c95438a8e4.TID69.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta
[2025-07-19T20:48:02.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta
[2025-07-19T20:48:02.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 69, attempt 0, stage 5.0)
[2025-07-19T20:48:02.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cd4ceef
[2025-07-19T20:48:02.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 96 (task 67, attempt 0, stage 5.0)
[2025-07-19T20:48:02.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 96.0 in stage 5.0 (TID 67). 9074 bytes result sent to driver
[2025-07-19T20:48:02.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105] for update
[2025-07-19T20:48:02.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.1.delta.0c2faf94-1c68-495b-8ee2-aad60f8784d8.TID74.tmp
[2025-07-19T20:48:02.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.1.delta.47fcb5ad-8c9d-4411-b054-a86e601dac2f.TID75.tmp
[2025-07-19T20:48:02.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 107.0 in stage 5.0 (TID 76) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.1.delta.996ba6e1-b315-4dad-b9f6-494e6d021020.TID71.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta
[2025-07-19T20:48:02.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta
[2025-07-19T20:48:02.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 107.0 in stage 5.0 (TID 76)
[2025-07-19T20:48:02.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 71, attempt 0, stage 5.0)
[2025-07-19T20:48:02.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 96.0 in stage 5.0 (TID 67) in 205 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:48:02.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 98 (task 69, attempt 0, stage 5.0)
[2025-07-19T20:48:02.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 98.0 in stage 5.0 (TID 69). 9071 bytes result sent to driver
[2025-07-19T20:48:02.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 109.0 in stage 5.0 (TID 77) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 109.0 in stage 5.0 (TID 77)
[2025-07-19T20:48:02.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 98.0 in stage 5.0 (TID 69) in 156 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:48:02.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:02.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.1.delta.9246a886-4f38-4269-ab8b-e5ef2bf44228.TID72.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta
[2025-07-19T20:48:02.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta
[2025-07-19T20:48:02.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 72, attempt 0, stage 5.0)
[2025-07-19T20:48:02.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 99 (task 70, attempt 0, stage 5.0)
[2025-07-19T20:48:02.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 99.0 in stage 5.0 (TID 70). 9079 bytes result sent to driver
[2025-07-19T20:48:02.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@107f85ff
[2025-07-19T20:48:02.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107] for update
[2025-07-19T20:48:02.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 100 (task 71, attempt 0, stage 5.0)
[2025-07-19T20:48:02.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 100.0 in stage 5.0 (TID 71). 9087 bytes result sent to driver
[2025-07-19T20:48:02.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 110.0 in stage 5.0 (TID 78) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 99.0 in stage 5.0 (TID 70) in 172 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:48:02.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 110.0 in stage 5.0 (TID 78)
[2025-07-19T20:48:02.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 111.0 in stage 5.0 (TID 79) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 111.0 in stage 5.0 (TID 79)
[2025-07-19T20:48:02.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 100.0 in stage 5.0 (TID 71) in 173 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:48:02.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51acf1c2
[2025-07-19T20:48:02.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109] for update
[2025-07-19T20:48:02.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a03c764
[2025-07-19T20:48:02.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 102 (task 72, attempt 0, stage 5.0)
[2025-07-19T20:48:02.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110] for update
[2025-07-19T20:48:02.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.1.delta.fc70ba4f-744b-443b-a0ee-345081223fb4.TID73.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta
[2025-07-19T20:48:02.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta
[2025-07-19T20:48:02.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 102.0 in stage 5.0 (TID 72). 9079 bytes result sent to driver
[2025-07-19T20:48:02.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 113.0 in stage 5.0 (TID 80) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.1.delta.a270739f-8437-4f59-9287-a67c44a8311c.TID76.tmp
[2025-07-19T20:48:02.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 102.0 in stage 5.0 (TID 72) in 171 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:48:02.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 73, attempt 0, stage 5.0)
[2025-07-19T20:48:02.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 113.0 in stage 5.0 (TID 80)
[2025-07-19T20:48:02.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.1.delta.47fcb5ad-8c9d-4411-b054-a86e601dac2f.TID75.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta
[2025-07-19T20:48:02.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta
[2025-07-19T20:48:02.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 75, attempt 0, stage 5.0)
[2025-07-19T20:48:02.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.1.delta.f979759a-0141-49cb-8fe2-3463f3e322df.TID77.tmp
[2025-07-19T20:48:02.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@238e7203
[2025-07-19T20:48:02.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111] for update
[2025-07-19T20:48:02.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.1.delta.29c99f4a-a7e2-4008-8176-a523a7a00d13.TID78.tmp
[2025-07-19T20:48:02.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.1.delta.0c2faf94-1c68-495b-8ee2-aad60f8784d8.TID74.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta
[2025-07-19T20:48:02.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta
[2025-07-19T20:48:02.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 74, attempt 0, stage 5.0)
[2025-07-19T20:48:02.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 104 (task 73, attempt 0, stage 5.0)
[2025-07-19T20:48:02.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 104.0 in stage 5.0 (TID 73). 9084 bytes result sent to driver
[2025-07-19T20:48:02.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 117.0 in stage 5.0 (TID 81) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 117.0 in stage 5.0 (TID 81)
[2025-07-19T20:48:02.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 104.0 in stage 5.0 (TID 73) in 158 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:48:02.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60a5c79
[2025-07-19T20:48:02.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113] for update
[2025-07-19T20:48:02.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:48:02.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.1.delta.2b9ffcbd-155c-4b87-8ccc-3b1e84f7039c.TID79.tmp
[2025-07-19T20:48:02.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 106 (task 75, attempt 0, stage 5.0)
[2025-07-19T20:48:02.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 106.0 in stage 5.0 (TID 75). 9077 bytes result sent to driver
[2025-07-19T20:48:02.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 118.0 in stage 5.0 (TID 82) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eabdd8f
[2025-07-19T20:48:02.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 106.0 in stage 5.0 (TID 75) in 160 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:48:02.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117] for update
[2025-07-19T20:48:02.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 105 (task 74, attempt 0, stage 5.0)
[2025-07-19T20:48:02.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 118.0 in stage 5.0 (TID 82)
[2025-07-19T20:48:02.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 105.0 in stage 5.0 (TID 74). 9085 bytes result sent to driver
[2025-07-19T20:48:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 119.0 in stage 5.0 (TID 83) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.1.delta.cb33d970-ad4d-428e-99e6-1aadd1bea71f.TID80.tmp
[2025-07-19T20:48:02.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 105.0 in stage 5.0 (TID 74) in 167 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:48:02.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 119.0 in stage 5.0 (TID 83)
[2025-07-19T20:48:02.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.1.delta.a270739f-8437-4f59-9287-a67c44a8311c.TID76.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta
[2025-07-19T20:48:02.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta
[2025-07-19T20:48:02.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T20:48:02.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 76, attempt 0, stage 5.0)
[2025-07-19T20:48:02.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.1.delta.f979759a-0141-49cb-8fe2-3463f3e322df.TID77.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta
[2025-07-19T20:48:02.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta
[2025-07-19T20:48:02.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 77, attempt 0, stage 5.0)
[2025-07-19T20:48:02.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17d21bde
[2025-07-19T20:48:02.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119] for update
[2025-07-19T20:48:02.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.1.delta.29c99f4a-a7e2-4008-8176-a523a7a00d13.TID78.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta
[2025-07-19T20:48:02.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta
[2025-07-19T20:48:02.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 78, attempt 0, stage 5.0)
[2025-07-19T20:48:02.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d01b883
[2025-07-19T20:48:02.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.1.delta.0d42fa75-cc8b-4cf5-bc95-2fb2056983df.TID81.tmp
[2025-07-19T20:48:02.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118] for update
[2025-07-19T20:48:02.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.1.delta.e78b5103-dd34-41ab-a0a6-6d3cf11bba5a.TID83.tmp
[2025-07-19T20:48:02.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.1.delta.2b9ffcbd-155c-4b87-8ccc-3b1e84f7039c.TID79.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta
[2025-07-19T20:48:02.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta
[2025-07-19T20:48:02.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 79, attempt 0, stage 5.0)
[2025-07-19T20:48:02.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.1.delta.c8081945-9d68-4e1d-be2f-9942a50e69b3.TID82.tmp
[2025-07-19T20:48:02.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 109 (task 77, attempt 0, stage 5.0)
[2025-07-19T20:48:02.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 110 (task 78, attempt 0, stage 5.0)
[2025-07-19T20:48:02.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 109.0 in stage 5.0 (TID 77). 9036 bytes result sent to driver
[2025-07-19T20:48:02.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 110.0 in stage 5.0 (TID 78). 9017 bytes result sent to driver
[2025-07-19T20:48:02.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 120.0 in stage 5.0 (TID 84) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 121.0 in stage 5.0 (TID 85) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 120.0 in stage 5.0 (TID 84)
[2025-07-19T20:48:02.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 107 (task 76, attempt 0, stage 5.0)
[2025-07-19T20:48:02.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 107.0 in stage 5.0 (TID 76). 9040 bytes result sent to driver
[2025-07-19T20:48:02.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 109.0 in stage 5.0 (TID 77) in 163 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:48:02.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 110.0 in stage 5.0 (TID 78) in 139 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:48:02.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:02.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 121.0 in stage 5.0 (TID 85)
[2025-07-19T20:48:02.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 122.0 in stage 5.0 (TID 86) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 107.0 in stage 5.0 (TID 76) in 182 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:48:02.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 122.0 in stage 5.0 (TID 86)
[2025-07-19T20:48:02.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.1.delta.cb33d970-ad4d-428e-99e6-1aadd1bea71f.TID80.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta
[2025-07-19T20:48:02.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta
[2025-07-19T20:48:02.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 80, attempt 0, stage 5.0)
[2025-07-19T20:48:02.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:02.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 111 (task 79, attempt 0, stage 5.0)
[2025-07-19T20:48:02.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 111.0 in stage 5.0 (TID 79). 9050 bytes result sent to driver
[2025-07-19T20:48:02.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 123.0 in stage 5.0 (TID 87) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 123.0 in stage 5.0 (TID 87)
[2025-07-19T20:48:02.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 111.0 in stage 5.0 (TID 79) in 154 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:48:02.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23ba77e0
[2025-07-19T20:48:02.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120] for update
[2025-07-19T20:48:02.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 113 (task 80, attempt 0, stage 5.0)
[2025-07-19T20:48:02.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 113.0 in stage 5.0 (TID 80). 9051 bytes result sent to driver
[2025-07-19T20:48:02.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 127.0 in stage 5.0 (TID 88) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.1.delta.0d42fa75-cc8b-4cf5-bc95-2fb2056983df.TID81.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta
[2025-07-19T20:48:02.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta
[2025-07-19T20:48:02.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 113.0 in stage 5.0 (TID 80) in 152 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:48:02.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 127.0 in stage 5.0 (TID 88)
[2025-07-19T20:48:02.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 81, attempt 0, stage 5.0)
[2025-07-19T20:48:02.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e69cff0
[2025-07-19T20:48:02.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123] for update
[2025-07-19T20:48:02.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.1.delta.e78b5103-dd34-41ab-a0a6-6d3cf11bba5a.TID83.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta
[2025-07-19T20:48:02.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta
[2025-07-19T20:48:02.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 83, attempt 0, stage 5.0)
[2025-07-19T20:48:02.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.1.delta.5b5b5a37-49cd-4ed1-b036-47ce3e276adf.TID84.tmp
[2025-07-19T20:48:02.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.1.delta.d3f1aeb8-e8a7-4b57-b391-19c422b942cc.TID87.tmp
[2025-07-19T20:48:02.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3227d475
[2025-07-19T20:48:02.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.1.delta.c8081945-9d68-4e1d-be2f-9942a50e69b3.TID82.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta
[2025-07-19T20:48:02.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta
[2025-07-19T20:48:02.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121] for update
[2025-07-19T20:48:02.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 82, attempt 0, stage 5.0)
[2025-07-19T20:48:02.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cc4268f
[2025-07-19T20:48:02.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122] for update
[2025-07-19T20:48:02.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 117 (task 81, attempt 0, stage 5.0)
[2025-07-19T20:48:02.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 117.0 in stage 5.0 (TID 81). 9034 bytes result sent to driver
[2025-07-19T20:48:02.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 119 (task 83, attempt 0, stage 5.0)
[2025-07-19T20:48:02.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 119.0 in stage 5.0 (TID 83). 9036 bytes result sent to driver
[2025-07-19T20:48:02.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 128.0 in stage 5.0 (TID 89) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.1.delta.d77de5de-4f79-4ba8-99c2-5c2af4037110.TID85.tmp
[2025-07-19T20:48:02.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 129.0 in stage 5.0 (TID 90) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 117.0 in stage 5.0 (TID 81) in 169 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:48:02.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 129.0 in stage 5.0 (TID 90)
[2025-07-19T20:48:02.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 119.0 in stage 5.0 (TID 83) in 144 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:48:02.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d0a8822
[2025-07-19T20:48:02.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127] for update
[2025-07-19T20:48:02.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 128.0 in stage 5.0 (TID 89)
[2025-07-19T20:48:02.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.1.delta.e0d46eca-84b8-41ee-a5a5-d9407b8fb9d1.TID86.tmp
[2025-07-19T20:48:02.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:02.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@625dbb8f
[2025-07-19T20:48:02.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 118 (task 82, attempt 0, stage 5.0)
[2025-07-19T20:48:02.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129] for update
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 118.0 in stage 5.0 (TID 82). 9077 bytes result sent to driver
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 130.0 in stage 5.0 (TID 91) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 130.0 in stage 5.0 (TID 91)
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 118.0 in stage 5.0 (TID 82) in 168 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.1.delta.d3f1aeb8-e8a7-4b57-b391-19c422b942cc.TID87.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta
[2025-07-19T20:48:02.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta
[2025-07-19T20:48:02.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 87, attempt 0, stage 5.0)
[2025-07-19T20:48:02.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.1.delta.d0f1055e-e771-42aa-af03-1df84cd423dc.TID90.tmp
[2025-07-19T20:48:02.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.1.delta.310bdda5-d001-415f-a233-273b3a8dd5e8.TID88.tmp
[2025-07-19T20:48:02.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6431be9b
[2025-07-19T20:48:02.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128] for update
[2025-07-19T20:48:02.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.1.delta.5b5b5a37-49cd-4ed1-b036-47ce3e276adf.TID84.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta
[2025-07-19T20:48:02.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta
[2025-07-19T20:48:02.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 84, attempt 0, stage 5.0)
[2025-07-19T20:48:02.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@95a8a51
[2025-07-19T20:48:02.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130] for update
[2025-07-19T20:48:02.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.1.delta.e0d46eca-84b8-41ee-a5a5-d9407b8fb9d1.TID86.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta
[2025-07-19T20:48:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta
[2025-07-19T20:48:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 86, attempt 0, stage 5.0)
[2025-07-19T20:48:02.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 123 (task 87, attempt 0, stage 5.0)
[2025-07-19T20:48:02.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 123.0 in stage 5.0 (TID 87). 9071 bytes result sent to driver
[2025-07-19T20:48:02.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 131.0 in stage 5.0 (TID 92) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 123.0 in stage 5.0 (TID 87) in 135 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:48:02.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 131.0 in stage 5.0 (TID 92)
[2025-07-19T20:48:02.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.1.delta.d77de5de-4f79-4ba8-99c2-5c2af4037110.TID85.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta
[2025-07-19T20:48:02.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta
[2025-07-19T20:48:02.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 85, attempt 0, stage 5.0)
[2025-07-19T20:48:02.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 120 (task 84, attempt 0, stage 5.0)
[2025-07-19T20:48:02.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 120.0 in stage 5.0 (TID 84). 9077 bytes result sent to driver
[2025-07-19T20:48:02.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 122 (task 86, attempt 0, stage 5.0)
[2025-07-19T20:48:02.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 133.0 in stage 5.0 (TID 93) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 133.0 in stage 5.0 (TID 93)
[2025-07-19T20:48:02.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 122.0 in stage 5.0 (TID 86). 9103 bytes result sent to driver
[2025-07-19T20:48:02.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.1.delta.a32c4201-e25e-4084-a874-6d16645787ce.TID89.tmp
[2025-07-19T20:48:02.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2745855a
[2025-07-19T20:48:02.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 135.0 in stage 5.0 (TID 94) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131] for update
[2025-07-19T20:48:02.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 120.0 in stage 5.0 (TID 84) in 230 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:48:02.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 135.0 in stage 5.0 (TID 94)
[2025-07-19T20:48:02.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42e44bd
[2025-07-19T20:48:02.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.1.delta.2043dd1e-e2e8-464d-b24a-4d3f42a41e2c.TID91.tmp
[2025-07-19T20:48:02.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133] for update
[2025-07-19T20:48:02.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:02.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 122.0 in stage 5.0 (TID 86) in 243 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:48:02.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.1.delta.4f748a6a-5371-4573-ba55-6c43181f18b2.TID93.tmp
[2025-07-19T20:48:02.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Committed partition 121 (task 85, attempt 0, stage 5.0)
[2025-07-19T20:48:02.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Finished task 121.0 in stage 5.0 (TID 85). 9077 bytes result sent to driver
[2025-07-19T20:48:02.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.1.delta.8d053596-dcaf-4de9-a645-40c5ddb05559.TID92.tmp
[2025-07-19T20:48:02.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@aea9483
[2025-07-19T20:48:02.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Starting task 136.0 in stage 5.0 (TID 95) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:02.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO Executor: Running task 136.0 in stage 5.0 (TID 95)
[2025-07-19T20:48:02.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135] for update
[2025-07-19T20:48:02.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO TaskSetManager: Finished task 121.0 in stage 5.0 (TID 85) in 502 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:48:02.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.1.delta.d0f1055e-e771-42aa-af03-1df84cd423dc.TID90.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta
[2025-07-19T20:48:02.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta
[2025-07-19T20:48:02.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 90, attempt 0, stage 5.0)
[2025-07-19T20:48:02.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:02.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:02.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.1.delta.310bdda5-d001-415f-a233-273b3a8dd5e8.TID88.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta
[2025-07-19T20:48:02.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta
[2025-07-19T20:48:02.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 88, attempt 0, stage 5.0)
[2025-07-19T20:48:02.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.1.delta.580f2f9c-2be4-4e29-8cdc-802de9f08f6f.TID94.tmp
[2025-07-19T20:48:02.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73bae815
[2025-07-19T20:48:02.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:02.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136] for update
[2025-07-19T20:48:02.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:02.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.1.delta.4f748a6a-5371-4573-ba55-6c43181f18b2.TID93.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta
[2025-07-19T20:48:03.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta
[2025-07-19T20:48:03.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:02 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 93, attempt 0, stage 5.0)
[2025-07-19T20:48:03.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.1.delta.c785e96c-6645-43fb-91c8-7e844143da52.TID95.tmp
[2025-07-19T20:48:03.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.1.delta.a32c4201-e25e-4084-a874-6d16645787ce.TID89.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta
[2025-07-19T20:48:03.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta
[2025-07-19T20:48:03.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 89, attempt 0, stage 5.0)
[2025-07-19T20:48:03.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 129 (task 90, attempt 0, stage 5.0)
[2025-07-19T20:48:03.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 129.0 in stage 5.0 (TID 90). 9086 bytes result sent to driver
[2025-07-19T20:48:03.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 127 (task 88, attempt 0, stage 5.0)
[2025-07-19T20:48:03.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.1.delta.8d053596-dcaf-4de9-a645-40c5ddb05559.TID92.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta
[2025-07-19T20:48:03.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 137.0 in stage 5.0 (TID 96) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta
[2025-07-19T20:48:03.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 137.0 in stage 5.0 (TID 96)
[2025-07-19T20:48:03.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 129.0 in stage 5.0 (TID 90) in 545 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:48:03.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:03.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 127.0 in stage 5.0 (TID 88). 9110 bytes result sent to driver
[2025-07-19T20:48:03.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 133 (task 93, attempt 0, stage 5.0)
[2025-07-19T20:48:03.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 138.0 in stage 5.0 (TID 97) (8b44f3d35cfa, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 127.0 in stage 5.0 (TID 88) in 602 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:48:03.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.1.delta.580f2f9c-2be4-4e29-8cdc-802de9f08f6f.TID94.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta
[2025-07-19T20:48:03.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta
[2025-07-19T20:48:03.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 138.0 in stage 5.0 (TID 97)
[2025-07-19T20:48:03.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.1.delta.2043dd1e-e2e8-464d-b24a-4d3f42a41e2c.TID91.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta
[2025-07-19T20:48:03.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta
[2025-07-19T20:48:03.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 92, attempt 0, stage 5.0)
[2025-07-19T20:48:03.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 94, attempt 0, stage 5.0)
[2025-07-19T20:48:03.073+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d13419e
[2025-07-19T20:48:03.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 91, attempt 0, stage 5.0)
[2025-07-19T20:48:03.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 133.0 in stage 5.0 (TID 93). 9077 bytes result sent to driver
[2025-07-19T20:48:03.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137] for update
[2025-07-19T20:48:03.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 139.0 in stage 5.0 (TID 98) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 133.0 in stage 5.0 (TID 93) in 453 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:48:03.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 139.0 in stage 5.0 (TID 98)
[2025-07-19T20:48:03.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3eebb678
[2025-07-19T20:48:03.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138] for update
[2025-07-19T20:48:03.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 128 (task 89, attempt 0, stage 5.0)
[2025-07-19T20:48:03.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 128.0 in stage 5.0 (TID 89). 9067 bytes result sent to driver
[2025-07-19T20:48:03.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 140.0 in stage 5.0 (TID 99) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 140.0 in stage 5.0 (TID 99)
[2025-07-19T20:48:03.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 128.0 in stage 5.0 (TID 89) in 607 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:48:03.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:03.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.1.delta.c785e96c-6645-43fb-91c8-7e844143da52.TID95.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta
[2025-07-19T20:48:03.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta
[2025-07-19T20:48:03.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.1.delta.4cee044b-a377-41b2-8af4-a71a814ae3c9.TID96.tmp
[2025-07-19T20:48:03.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 95, attempt 0, stage 5.0)
[2025-07-19T20:48:03.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@268addc5
[2025-07-19T20:48:03.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139] for update
[2025-07-19T20:48:03.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.1.delta.a49eaf5f-7972-4786-bd9d-de62236745e0.TID97.tmp
[2025-07-19T20:48:03.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 131 (task 92, attempt 0, stage 5.0)
[2025-07-19T20:48:03.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 131.0 in stage 5.0 (TID 92). 9045 bytes result sent to driver
[2025-07-19T20:48:03.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 144.0 in stage 5.0 (TID 100) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 130 (task 91, attempt 0, stage 5.0)
[2025-07-19T20:48:03.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 130.0 in stage 5.0 (TID 91). 9091 bytes result sent to driver
[2025-07-19T20:48:03.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 135 (task 94, attempt 0, stage 5.0)
[2025-07-19T20:48:03.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 135.0 in stage 5.0 (TID 94). 9036 bytes result sent to driver
[2025-07-19T20:48:03.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 145.0 in stage 5.0 (TID 101) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 149.0 in stage 5.0 (TID 102) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 145.0 in stage 5.0 (TID 101)
[2025-07-19T20:48:03.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 130.0 in stage 5.0 (TID 91) in 622 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:48:03.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 144.0 in stage 5.0 (TID 100)
[2025-07-19T20:48:03.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 149.0 in stage 5.0 (TID 102)
[2025-07-19T20:48:03.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 135.0 in stage 5.0 (TID 94) in 507 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:48:03.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 131.0 in stage 5.0 (TID 92) in 571 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:48:03.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7617f3e7
[2025-07-19T20:48:03.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140] for update
[2025-07-19T20:48:03.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.1.delta.0cba2c49-373a-4c1e-82c7-74183c1a557d.TID98.tmp
[2025-07-19T20:48:03.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 136 (task 95, attempt 0, stage 5.0)
[2025-07-19T20:48:03.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@712c8e6e
[2025-07-19T20:48:03.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145] for update
[2025-07-19T20:48:03.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.1.delta.8be5fe55-b246-477e-9f23-0e8fbdc77894.TID99.tmp
[2025-07-19T20:48:03.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34c88947
[2025-07-19T20:48:03.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 136.0 in stage 5.0 (TID 95). 9034 bytes result sent to driver
[2025-07-19T20:48:03.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144] for update
[2025-07-19T20:48:03.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 150.0 in stage 5.0 (TID 103) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 150.0 in stage 5.0 (TID 103)
[2025-07-19T20:48:03.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 136.0 in stage 5.0 (TID 95) in 324 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:48:03.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12ba7a99
[2025-07-19T20:48:03.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:03.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149] for update
[2025-07-19T20:48:03.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.1.delta.a49eaf5f-7972-4786-bd9d-de62236745e0.TID97.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta
[2025-07-19T20:48:03.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta
[2025-07-19T20:48:03.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 97, attempt 0, stage 5.0)
[2025-07-19T20:48:03.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.1.delta.6e2ea1db-0c29-4b98-b218-e9269d6344ce.TID101.tmp
[2025-07-19T20:48:03.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fde867
[2025-07-19T20:48:03.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.1.delta.1106b45a-21b2-489a-bcd5-47454943ab71.TID100.tmp
[2025-07-19T20:48:03.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150] for update
[2025-07-19T20:48:03.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.1.delta.4cee044b-a377-41b2-8af4-a71a814ae3c9.TID96.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta
[2025-07-19T20:48:03.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta
[2025-07-19T20:48:03.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 96, attempt 0, stage 5.0)
[2025-07-19T20:48:03.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.1.delta.d9e31aed-79d2-4e3c-a0f0-bc11c3652b81.TID102.tmp
[2025-07-19T20:48:03.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.1.delta.0cba2c49-373a-4c1e-82c7-74183c1a557d.TID98.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta
[2025-07-19T20:48:03.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta
[2025-07-19T20:48:03.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 98, attempt 0, stage 5.0)
[2025-07-19T20:48:03.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.1.delta.d1f52cff-d310-48aa-862a-b823653b24ea.TID103.tmp
[2025-07-19T20:48:03.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.1.delta.8be5fe55-b246-477e-9f23-0e8fbdc77894.TID99.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta
[2025-07-19T20:48:03.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta
[2025-07-19T20:48:03.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 99, attempt 0, stage 5.0)
[2025-07-19T20:48:03.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 138 (task 97, attempt 0, stage 5.0)
[2025-07-19T20:48:03.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 138.0 in stage 5.0 (TID 97). 9086 bytes result sent to driver
[2025-07-19T20:48:03.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 138.0 in stage 5.0 (TID 97) in 255 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:48:03.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 153.0 in stage 5.0 (TID 104) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 153.0 in stage 5.0 (TID 104)
[2025-07-19T20:48:03.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 140 (task 99, attempt 0, stage 5.0)
[2025-07-19T20:48:03.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 140.0 in stage 5.0 (TID 99). 9081 bytes result sent to driver
[2025-07-19T20:48:03.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 137 (task 96, attempt 0, stage 5.0)
[2025-07-19T20:48:03.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 154.0 in stage 5.0 (TID 105) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 154.0 in stage 5.0 (TID 105)
[2025-07-19T20:48:03.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 137.0 in stage 5.0 (TID 96). 9094 bytes result sent to driver
[2025-07-19T20:48:03.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 155.0 in stage 5.0 (TID 106) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 155.0 in stage 5.0 (TID 106)
[2025-07-19T20:48:03.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 140.0 in stage 5.0 (TID 99) in 222 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:48:03.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 137.0 in stage 5.0 (TID 96) in 284 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:48:03.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:03.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 139 (task 98, attempt 0, stage 5.0)
[2025-07-19T20:48:03.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 139.0 in stage 5.0 (TID 98). 9081 bytes result sent to driver
[2025-07-19T20:48:03.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 158.0 in stage 5.0 (TID 107) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 139.0 in stage 5.0 (TID 98) in 251 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:48:03.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 158.0 in stage 5.0 (TID 107)
[2025-07-19T20:48:03.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.1.delta.6e2ea1db-0c29-4b98-b218-e9269d6344ce.TID101.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta
[2025-07-19T20:48:03.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta
[2025-07-19T20:48:03.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.1.delta.1106b45a-21b2-489a-bcd5-47454943ab71.TID100.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta
[2025-07-19T20:48:03.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta
[2025-07-19T20:48:03.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 101, attempt 0, stage 5.0)
[2025-07-19T20:48:03.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@188a12ba
[2025-07-19T20:48:03.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 100, attempt 0, stage 5.0)
[2025-07-19T20:48:03.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153] for update
[2025-07-19T20:48:03.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.1.delta.d9e31aed-79d2-4e3c-a0f0-bc11c3652b81.TID102.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta
[2025-07-19T20:48:03.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta
[2025-07-19T20:48:03.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 102, attempt 0, stage 5.0)
[2025-07-19T20:48:03.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.1.delta.d1f52cff-d310-48aa-862a-b823653b24ea.TID103.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta
[2025-07-19T20:48:03.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta
[2025-07-19T20:48:03.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 103, attempt 0, stage 5.0)
[2025-07-19T20:48:03.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2662ebfa
[2025-07-19T20:48:03.336+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158] for update
[2025-07-19T20:48:03.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 144 (task 100, attempt 0, stage 5.0)
[2025-07-19T20:48:03.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67726be9
[2025-07-19T20:48:03.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155] for update
[2025-07-19T20:48:03.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.1.delta.d651dc78-4c0e-4290-828f-7eb6798147b8.TID104.tmp
[2025-07-19T20:48:03.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 144.0 in stage 5.0 (TID 100). 9074 bytes result sent to driver
[2025-07-19T20:48:03.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 144.0 in stage 5.0 (TID 100) in 235 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.1.delta.8c5a8680-c705-4412-9e9e-185d878b4739.TID107.tmp
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 159.0 in stage 5.0 (TID 108) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 159.0 in stage 5.0 (TID 108)
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 145 (task 101, attempt 0, stage 5.0)
[2025-07-19T20:48:03.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 149 (task 102, attempt 0, stage 5.0)
[2025-07-19T20:48:03.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 149.0 in stage 5.0 (TID 102). 9099 bytes result sent to driver
[2025-07-19T20:48:03.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 160.0 in stage 5.0 (TID 109) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d3177d1
[2025-07-19T20:48:03.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154] for update
[2025-07-19T20:48:03.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 149.0 in stage 5.0 (TID 102) in 240 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:48:03.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 150 (task 103, attempt 0, stage 5.0)
[2025-07-19T20:48:03.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 160.0 in stage 5.0 (TID 109)
[2025-07-19T20:48:03.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 145.0 in stage 5.0 (TID 101). 9091 bytes result sent to driver
[2025-07-19T20:48:03.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 161.0 in stage 5.0 (TID 110) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 150.0 in stage 5.0 (TID 103). 9083 bytes result sent to driver
[2025-07-19T20:48:03.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 161.0 in stage 5.0 (TID 110)
[2025-07-19T20:48:03.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 162.0 in stage 5.0 (TID 111) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27224e4e
[2025-07-19T20:48:03.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 145.0 in stage 5.0 (TID 101) in 250 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:48:03.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 162.0 in stage 5.0 (TID 111)
[2025-07-19T20:48:03.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159] for update
[2025-07-19T20:48:03.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@401e6190
[2025-07-19T20:48:03.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 150.0 in stage 5.0 (TID 103) in 220 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:48:03.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.1.delta.1fcfbe42-0bda-42df-8a69-ad315f78159c.TID106.tmp
[2025-07-19T20:48:03.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160] for update
[2025-07-19T20:48:03.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T20:48:03.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.1.delta.3a9de87d-d615-4f2f-a746-ffd9922fb505.TID105.tmp
[2025-07-19T20:48:03.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.1.delta.ac45562d-9554-4c0b-ae8e-15aa8dc3fbd4.TID109.tmp
[2025-07-19T20:48:03.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@546edb49
[2025-07-19T20:48:03.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162] for update
[2025-07-19T20:48:03.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.1.delta.e82d6b6a-698d-4e3b-b5cb-b7cbe86c1dba.TID108.tmp
[2025-07-19T20:48:03.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63a4c98d
[2025-07-19T20:48:03.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161] for update
[2025-07-19T20:48:03.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.1.delta.8c5a8680-c705-4412-9e9e-185d878b4739.TID107.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta
[2025-07-19T20:48:03.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta
[2025-07-19T20:48:03.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.1.delta.d651dc78-4c0e-4290-828f-7eb6798147b8.TID104.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta
[2025-07-19T20:48:03.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta
[2025-07-19T20:48:03.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 107, attempt 0, stage 5.0)
[2025-07-19T20:48:03.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 104, attempt 0, stage 5.0)
[2025-07-19T20:48:03.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.1.delta.799af9f8-8b4a-436c-bc62-1d6dfc95bc2f.TID110.tmp
[2025-07-19T20:48:03.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.1.delta.55dc5088-5311-40ee-a05f-67976d378abe.TID111.tmp
[2025-07-19T20:48:03.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 153 (task 104, attempt 0, stage 5.0)
[2025-07-19T20:48:03.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 153.0 in stage 5.0 (TID 104). 9082 bytes result sent to driver
[2025-07-19T20:48:03.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.1.delta.3a9de87d-d615-4f2f-a746-ffd9922fb505.TID105.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta
[2025-07-19T20:48:03.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta
[2025-07-19T20:48:03.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 163.0 in stage 5.0 (TID 112) (8b44f3d35cfa, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 105, attempt 0, stage 5.0)
[2025-07-19T20:48:03.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 153.0 in stage 5.0 (TID 104) in 151 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:48:03.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 163.0 in stage 5.0 (TID 112)
[2025-07-19T20:48:03.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.1.delta.1fcfbe42-0bda-42df-8a69-ad315f78159c.TID106.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta
[2025-07-19T20:48:03.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta
[2025-07-19T20:48:03.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 106, attempt 0, stage 5.0)
[2025-07-19T20:48:03.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.1.delta.ac45562d-9554-4c0b-ae8e-15aa8dc3fbd4.TID109.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta
[2025-07-19T20:48:03.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta
[2025-07-19T20:48:03.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 158 (task 107, attempt 0, stage 5.0)
[2025-07-19T20:48:03.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 158.0 in stage 5.0 (TID 107). 9085 bytes result sent to driver
[2025-07-19T20:48:03.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:48:03.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 165.0 in stage 5.0 (TID 113) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 165.0 in stage 5.0 (TID 113)
[2025-07-19T20:48:03.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 158.0 in stage 5.0 (TID 107) in 157 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:48:03.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 109, attempt 0, stage 5.0)
[2025-07-19T20:48:03.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:03.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 155 (task 106, attempt 0, stage 5.0)
[2025-07-19T20:48:03.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.1.delta.e82d6b6a-698d-4e3b-b5cb-b7cbe86c1dba.TID108.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta
[2025-07-19T20:48:03.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta
[2025-07-19T20:48:03.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 154 (task 105, attempt 0, stage 5.0)
[2025-07-19T20:48:03.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 155.0 in stage 5.0 (TID 106). 9093 bytes result sent to driver
[2025-07-19T20:48:03.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 108, attempt 0, stage 5.0)
[2025-07-19T20:48:03.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27a437f2
[2025-07-19T20:48:03.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 154.0 in stage 5.0 (TID 105). 9099 bytes result sent to driver
[2025-07-19T20:48:03.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 169.0 in stage 5.0 (TID 114) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 170.0 in stage 5.0 (TID 115) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163] for update
[2025-07-19T20:48:03.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 170.0 in stage 5.0 (TID 115)
[2025-07-19T20:48:03.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 155.0 in stage 5.0 (TID 106) in 178 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:48:03.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 169.0 in stage 5.0 (TID 114)
[2025-07-19T20:48:03.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 154.0 in stage 5.0 (TID 105) in 186 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:48:03.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 160 (task 109, attempt 0, stage 5.0)
[2025-07-19T20:48:03.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 160.0 in stage 5.0 (TID 109). 9040 bytes result sent to driver
[2025-07-19T20:48:03.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.1.delta.799af9f8-8b4a-436c-bc62-1d6dfc95bc2f.TID110.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta
[2025-07-19T20:48:03.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta
[2025-07-19T20:48:03.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 110, attempt 0, stage 5.0)
[2025-07-19T20:48:03.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@573d6dbf
[2025-07-19T20:48:03.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 172.0 in stage 5.0 (TID 116) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165] for update
[2025-07-19T20:48:03.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 172.0 in stage 5.0 (TID 116)
[2025-07-19T20:48:03.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:03.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 160.0 in stage 5.0 (TID 109) in 138 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:48:03.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5786fe03
[2025-07-19T20:48:03.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172] for update
[2025-07-19T20:48:03.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.1.delta.e26628d0-f1da-49cc-a0b6-29e3df601bfd.TID112.tmp
[2025-07-19T20:48:03.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 159 (task 108, attempt 0, stage 5.0)
[2025-07-19T20:48:03.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 161 (task 110, attempt 0, stage 5.0)
[2025-07-19T20:48:03.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 161.0 in stage 5.0 (TID 110). 9035 bytes result sent to driver
[2025-07-19T20:48:03.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 159.0 in stage 5.0 (TID 108). 9037 bytes result sent to driver
[2025-07-19T20:48:03.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 174.0 in stage 5.0 (TID 117) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42afb04a
[2025-07-19T20:48:03.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.1.delta.55dc5088-5311-40ee-a05f-67976d378abe.TID111.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta
[2025-07-19T20:48:03.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta
[2025-07-19T20:48:03.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170] for update
[2025-07-19T20:48:03.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 111, attempt 0, stage 5.0)
[2025-07-19T20:48:03.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 159.0 in stage 5.0 (TID 108) in 167 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:48:03.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 175.0 in stage 5.0 (TID 118) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 161.0 in stage 5.0 (TID 110) in 154 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:48:03.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 174.0 in stage 5.0 (TID 117)
[2025-07-19T20:48:03.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 175.0 in stage 5.0 (TID 118)
[2025-07-19T20:48:03.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.1.delta.f36f9668-a2ca-4299-a4ea-eca8fc573a8d.TID116.tmp
[2025-07-19T20:48:03.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.1.delta.73fefed2-c653-4079-a782-f8da8e392b9f.TID113.tmp
[2025-07-19T20:48:03.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c344768
[2025-07-19T20:48:03.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169] for update
[2025-07-19T20:48:03.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.1.delta.1240c6b3-d1d2-41f4-b7f0-cfa3c9770fb4.TID115.tmp
[2025-07-19T20:48:03.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 162 (task 111, attempt 0, stage 5.0)
[2025-07-19T20:48:03.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 162.0 in stage 5.0 (TID 111). 9033 bytes result sent to driver
[2025-07-19T20:48:03.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.1.delta.13f9d1b8-e56c-47a9-ae06-28c61c875d49.TID114.tmp
[2025-07-19T20:48:03.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 177.0 in stage 5.0 (TID 119) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@622a58f1
[2025-07-19T20:48:03.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 162.0 in stage 5.0 (TID 111) in 190 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:48:03.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 177.0 in stage 5.0 (TID 119)
[2025-07-19T20:48:03.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175] for update
[2025-07-19T20:48:03.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.1.delta.e26628d0-f1da-49cc-a0b6-29e3df601bfd.TID112.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta
[2025-07-19T20:48:03.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta
[2025-07-19T20:48:03.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 112, attempt 0, stage 5.0)
[2025-07-19T20:48:03.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12f0d796
[2025-07-19T20:48:03.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174] for update
[2025-07-19T20:48:03.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e0d67b8
[2025-07-19T20:48:03.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177] for update
[2025-07-19T20:48:03.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.1.delta.f36f9668-a2ca-4299-a4ea-eca8fc573a8d.TID116.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta
[2025-07-19T20:48:03.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.1.delta.73fefed2-c653-4079-a782-f8da8e392b9f.TID113.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta
[2025-07-19T20:48:03.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta
[2025-07-19T20:48:03.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta
[2025-07-19T20:48:03.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.1.delta.9b292486-deea-40cd-9463-5d297f439b26.TID117.tmp
[2025-07-19T20:48:03.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.1.delta.5a465a2f-c9c5-458e-9dd7-06af94bb12a0.TID118.tmp
[2025-07-19T20:48:03.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 116, attempt 0, stage 5.0)
[2025-07-19T20:48:03.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.1.delta.1240c6b3-d1d2-41f4-b7f0-cfa3c9770fb4.TID115.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta
[2025-07-19T20:48:03.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta
[2025-07-19T20:48:03.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 115, attempt 0, stage 5.0)
[2025-07-19T20:48:03.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 113, attempt 0, stage 5.0)
[2025-07-19T20:48:03.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.1.delta.4caa1630-143e-40cb-959c-e537d64513a6.TID119.tmp
[2025-07-19T20:48:03.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 163 (task 112, attempt 0, stage 5.0)
[2025-07-19T20:48:03.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 163.0 in stage 5.0 (TID 112). 9050 bytes result sent to driver
[2025-07-19T20:48:03.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 178.0 in stage 5.0 (TID 120) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 163.0 in stage 5.0 (TID 112) in 163 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:48:03.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 178.0 in stage 5.0 (TID 120)
[2025-07-19T20:48:03.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.1.delta.13f9d1b8-e56c-47a9-ae06-28c61c875d49.TID114.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta
[2025-07-19T20:48:03.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta
[2025-07-19T20:48:03.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 114, attempt 0, stage 5.0)
[2025-07-19T20:48:03.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 172 (task 116, attempt 0, stage 5.0)
[2025-07-19T20:48:03.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 172.0 in stage 5.0 (TID 116). 9043 bytes result sent to driver
[2025-07-19T20:48:03.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 179.0 in stage 5.0 (TID 121) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 172.0 in stage 5.0 (TID 116) in 135 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:48:03.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 179.0 in stage 5.0 (TID 121)
[2025-07-19T20:48:03.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e0d22cc
[2025-07-19T20:48:03.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.1.delta.5a465a2f-c9c5-458e-9dd7-06af94bb12a0.TID118.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta
[2025-07-19T20:48:03.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta
[2025-07-19T20:48:03.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178] for update
[2025-07-19T20:48:03.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 118, attempt 0, stage 5.0)
[2025-07-19T20:48:03.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:48:03.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49bcedc8
[2025-07-19T20:48:03.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179] for update
[2025-07-19T20:48:03.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 165 (task 113, attempt 0, stage 5.0)
[2025-07-19T20:48:03.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 165.0 in stage 5.0 (TID 113). 9030 bytes result sent to driver
[2025-07-19T20:48:03.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 180.0 in stage 5.0 (TID 122) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 180.0 in stage 5.0 (TID 122)
[2025-07-19T20:48:03.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 165.0 in stage 5.0 (TID 113) in 185 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:48:03.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 169 (task 114, attempt 0, stage 5.0)
[2025-07-19T20:48:03.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 170 (task 115, attempt 0, stage 5.0)
[2025-07-19T20:48:03.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 169.0 in stage 5.0 (TID 114). 9010 bytes result sent to driver
[2025-07-19T20:48:03.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 170.0 in stage 5.0 (TID 115). 9039 bytes result sent to driver
[2025-07-19T20:48:03.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 181.0 in stage 5.0 (TID 123) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 182.0 in stage 5.0 (TID 124) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 169.0 in stage 5.0 (TID 114) in 176 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:48:03.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 170.0 in stage 5.0 (TID 115) in 176 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:48:03.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 181.0 in stage 5.0 (TID 123)
[2025-07-19T20:48:03.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.1.delta.9b292486-deea-40cd-9463-5d297f439b26.TID117.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta
[2025-07-19T20:48:03.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta
[2025-07-19T20:48:03.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.1.delta.ae18323a-3658-4e26-9cc2-635f2dbba1a9.TID120.tmp
[2025-07-19T20:48:03.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:03.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 182.0 in stage 5.0 (TID 124)
[2025-07-19T20:48:03.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 117, attempt 0, stage 5.0)
[2025-07-19T20:48:03.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:03.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.1.delta.0c00a8bb-786e-4cf7-9d27-5cfa4ec8e5d2.TID121.tmp
[2025-07-19T20:48:03.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:03.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 175 (task 118, attempt 0, stage 5.0)
[2025-07-19T20:48:03.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 175.0 in stage 5.0 (TID 118). 9027 bytes result sent to driver
[2025-07-19T20:48:03.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 183.0 in stage 5.0 (TID 125) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@756f4ec7
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 175.0 in stage 5.0 (TID 118) in 155 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.1.delta.4caa1630-143e-40cb-959c-e537d64513a6.TID119.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 119, attempt 0, stage 5.0)
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180] for update
[2025-07-19T20:48:03.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 183.0 in stage 5.0 (TID 125)
[2025-07-19T20:48:03.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cadcb1b
[2025-07-19T20:48:03.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182] for update
[2025-07-19T20:48:03.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 174 (task 117, attempt 0, stage 5.0)
[2025-07-19T20:48:03.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 174.0 in stage 5.0 (TID 117). 9072 bytes result sent to driver
[2025-07-19T20:48:03.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 185.0 in stage 5.0 (TID 126) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 174.0 in stage 5.0 (TID 117) in 185 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:48:03.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 185.0 in stage 5.0 (TID 126)
[2025-07-19T20:48:03.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ca82bfc
[2025-07-19T20:48:03.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181] for update
[2025-07-19T20:48:03.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.1.delta.ee6f4569-9af0-46db-b8aa-ca444e80416a.TID122.tmp
[2025-07-19T20:48:03.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.1.delta.ae18323a-3658-4e26-9cc2-635f2dbba1a9.TID120.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta
[2025-07-19T20:48:03.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta
[2025-07-19T20:48:03.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 120, attempt 0, stage 5.0)
[2025-07-19T20:48:03.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16efd687
[2025-07-19T20:48:03.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183] for update
[2025-07-19T20:48:03.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T20:48:03.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.1.delta.9eec1771-a418-48bd-9e19-16a667e74a91.TID124.tmp
[2025-07-19T20:48:03.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 177 (task 119, attempt 0, stage 5.0)
[2025-07-19T20:48:03.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 177.0 in stage 5.0 (TID 119). 9087 bytes result sent to driver
[2025-07-19T20:48:03.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 186.0 in stage 5.0 (TID 127) (8b44f3d35cfa, executor driver, partition 186, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 177.0 in stage 5.0 (TID 119) in 173 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:48:03.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 186.0 in stage 5.0 (TID 127)
[2025-07-19T20:48:03.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e2828a4
[2025-07-19T20:48:03.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.1.delta.275d47ec-801c-4395-84c8-3a454764ba87.TID125.tmp
[2025-07-19T20:48:03.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185] for update
[2025-07-19T20:48:03.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.1.delta.ea1bb043-3fe6-446b-b8ef-fac680c5e9ec.TID123.tmp
[2025-07-19T20:48:03.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.1.delta.0c00a8bb-786e-4cf7-9d27-5cfa4ec8e5d2.TID121.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta
[2025-07-19T20:48:03.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta
[2025-07-19T20:48:03.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21f5de83
[2025-07-19T20:48:03.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186] for update
[2025-07-19T20:48:03.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 121, attempt 0, stage 5.0)
[2025-07-19T20:48:03.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 178 (task 120, attempt 0, stage 5.0)
[2025-07-19T20:48:03.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 178.0 in stage 5.0 (TID 120). 9115 bytes result sent to driver
[2025-07-19T20:48:03.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.1.delta.7976ed2f-0e60-446f-ae22-595289f6173a.TID126.tmp
[2025-07-19T20:48:03.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 187.0 in stage 5.0 (TID 128) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 178.0 in stage 5.0 (TID 120) in 172 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:48:03.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.1.delta.4ca10ffb-736a-483d-942c-843c88efa5b3.TID127.tmp
[2025-07-19T20:48:03.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 187.0 in stage 5.0 (TID 128)
[2025-07-19T20:48:03.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@362f7a65
[2025-07-19T20:48:03.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187] for update
[2025-07-19T20:48:03.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 179 (task 121, attempt 0, stage 5.0)
[2025-07-19T20:48:03.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 179.0 in stage 5.0 (TID 121). 9096 bytes result sent to driver
[2025-07-19T20:48:03.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.1.delta.9eec1771-a418-48bd-9e19-16a667e74a91.TID124.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta
[2025-07-19T20:48:03.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta
[2025-07-19T20:48:03.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 124, attempt 0, stage 5.0)
[2025-07-19T20:48:03.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.1.delta.ee6f4569-9af0-46db-b8aa-ca444e80416a.TID122.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta
[2025-07-19T20:48:03.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta
[2025-07-19T20:48:03.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 122, attempt 0, stage 5.0)
[2025-07-19T20:48:03.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.1.delta.ea1bb043-3fe6-446b-b8ef-fac680c5e9ec.TID123.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta
[2025-07-19T20:48:03.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta
[2025-07-19T20:48:03.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 123, attempt 0, stage 5.0)
[2025-07-19T20:48:03.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 188.0 in stage 5.0 (TID 129) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.1.delta.275d47ec-801c-4395-84c8-3a454764ba87.TID125.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta
[2025-07-19T20:48:03.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta
[2025-07-19T20:48:03.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 125, attempt 0, stage 5.0)
[2025-07-19T20:48:03.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.1.delta.91dacfd2-7250-4585-b1c0-cb43aa5c9cb3.TID128.tmp
[2025-07-19T20:48:03.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 179.0 in stage 5.0 (TID 121) in 188 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:48:03.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 188.0 in stage 5.0 (TID 129)
[2025-07-19T20:48:03.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 180 (task 122, attempt 0, stage 5.0)
[2025-07-19T20:48:03.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e4c56d
[2025-07-19T20:48:03.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 180.0 in stage 5.0 (TID 122). 9100 bytes result sent to driver
[2025-07-19T20:48:03.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188] for update
[2025-07-19T20:48:03.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 190.0 in stage 5.0 (TID 130) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 180.0 in stage 5.0 (TID 122) in 182 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:48:03.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.1.delta.7976ed2f-0e60-446f-ae22-595289f6173a.TID126.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta
[2025-07-19T20:48:03.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta
[2025-07-19T20:48:03.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.1.delta.4ca10ffb-736a-483d-942c-843c88efa5b3.TID127.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta
[2025-07-19T20:48:03.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta
[2025-07-19T20:48:03.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 183 (task 125, attempt 0, stage 5.0)
[2025-07-19T20:48:03.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 127, attempt 0, stage 5.0)
[2025-07-19T20:48:03.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 183.0 in stage 5.0 (TID 125). 9092 bytes result sent to driver
[2025-07-19T20:48:03.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 190.0 in stage 5.0 (TID 130)
[2025-07-19T20:48:03.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 126, attempt 0, stage 5.0)
[2025-07-19T20:48:03.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 192.0 in stage 5.0 (TID 131) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 181 (task 123, attempt 0, stage 5.0)
[2025-07-19T20:48:03.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 181.0 in stage 5.0 (TID 123). 9080 bytes result sent to driver
[2025-07-19T20:48:03.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 195.0 in stage 5.0 (TID 132) (8b44f3d35cfa, executor driver, partition 195, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 182 (task 124, attempt 0, stage 5.0)
[2025-07-19T20:48:03.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 182.0 in stage 5.0 (TID 124). 9074 bytes result sent to driver
[2025-07-19T20:48:03.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.1.delta.a71d31d5-306a-4c5a-968b-6c3d4d9d4d64.TID129.tmp
[2025-07-19T20:48:03.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 192.0 in stage 5.0 (TID 131)
[2025-07-19T20:48:03.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 195.0 in stage 5.0 (TID 132)
[2025-07-19T20:48:03.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 199.0 in stage 5.0 (TID 133) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 183.0 in stage 5.0 (TID 125) in 176 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:48:03.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 199.0 in stage 5.0 (TID 133)
[2025-07-19T20:48:03.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 182.0 in stage 5.0 (TID 124) in 193 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:48:03.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 181.0 in stage 5.0 (TID 123) in 194 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:48:03.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:03.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:03.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:03.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 185 (task 126, attempt 0, stage 5.0)
[2025-07-19T20:48:03.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 186 (task 127, attempt 0, stage 5.0)
[2025-07-19T20:48:03.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@170f11a3
[2025-07-19T20:48:03.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.1.delta.91dacfd2-7250-4585-b1c0-cb43aa5c9cb3.TID128.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta
[2025-07-19T20:48:03.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta
[2025-07-19T20:48:03.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190] for update
[2025-07-19T20:48:03.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 128, attempt 0, stage 5.0)
[2025-07-19T20:48:03.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 186.0 in stage 5.0 (TID 127). 9067 bytes result sent to driver
[2025-07-19T20:48:03.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 185.0 in stage 5.0 (TID 126). 9068 bytes result sent to driver
[2025-07-19T20:48:03.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 134) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 134)
[2025-07-19T20:48:03.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 135) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 185.0 in stage 5.0 (TID 126) in 173 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:48:03.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 186.0 in stage 5.0 (TID 127) in 146 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:48:03.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a3b5d74
[2025-07-19T20:48:03.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 2.0 in stage 5.0 (TID 135)
[2025-07-19T20:48:03.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199] for update
[2025-07-19T20:48:03.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.1.delta.d2d79ca4-cc9d-44b5-a473-b90fba5af00e.TID130.tmp
[2025-07-19T20:48:03.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3302cd99
[2025-07-19T20:48:03.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192] for update
[2025-07-19T20:48:03.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68bf745f
[2025-07-19T20:48:03.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 187 (task 128, attempt 0, stage 5.0)
[2025-07-19T20:48:03.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 187.0 in stage 5.0 (TID 128). 9037 bytes result sent to driver
[2025-07-19T20:48:03.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 136) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195] for update
[2025-07-19T20:48:03.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.1.delta.6d6d6f7f-0c6f-4aa0-80a4-8b60eb12b200.TID133.tmp
[2025-07-19T20:48:03.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 187.0 in stage 5.0 (TID 128) in 117 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:48:03.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 8.0 in stage 5.0 (TID 136)
[2025-07-19T20:48:03.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.1.delta.3cb6d761-b283-4986-9b96-50296c849fb2.TID131.tmp
[2025-07-19T20:48:03.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.1.delta.a71d31d5-306a-4c5a-968b-6c3d4d9d4d64.TID129.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta
[2025-07-19T20:48:03.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta
[2025-07-19T20:48:03.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 129, attempt 0, stage 5.0)
[2025-07-19T20:48:03.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.1.delta.775f2411-f91a-4c85-84f3-34bff57e2cef.TID132.tmp
[2025-07-19T20:48:03.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/.schema.5d8ef809-1ec1-43f8-a002-cde863e8602b.TID134.tmp
[2025-07-19T20:48:03.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 188 (task 129, attempt 0, stage 5.0)
[2025-07-19T20:48:03.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.1.delta.d2d79ca4-cc9d-44b5-a473-b90fba5af00e.TID130.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta
[2025-07-19T20:48:03.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta
[2025-07-19T20:48:03.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 188.0 in stage 5.0 (TID 129). 9095 bytes result sent to driver
[2025-07-19T20:48:03.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 137) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 188.0 in stage 5.0 (TID 129) in 123 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:48:03.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 130, attempt 0, stage 5.0)
[2025-07-19T20:48:03.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 10.0 in stage 5.0 (TID 137)
[2025-07-19T20:48:03.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.1.delta.6d6d6f7f-0c6f-4aa0-80a4-8b60eb12b200.TID133.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta
[2025-07-19T20:48:03.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta
[2025-07-19T20:48:03.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 133, attempt 0, stage 5.0)
[2025-07-19T20:48:03.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.1.delta.3cb6d761-b283-4986-9b96-50296c849fb2.TID131.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta
[2025-07-19T20:48:03.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta
[2025-07-19T20:48:03.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 131, attempt 0, stage 5.0)
[2025-07-19T20:48:03.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.1.delta.775f2411-f91a-4c85-84f3-34bff57e2cef.TID132.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta
[2025-07-19T20:48:03.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta
[2025-07-19T20:48:03.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 132, attempt 0, stage 5.0)
[2025-07-19T20:48:03.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 199 (task 133, attempt 0, stage 5.0)
[2025-07-19T20:48:03.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 199.0 in stage 5.0 (TID 133). 9027 bytes result sent to driver
[2025-07-19T20:48:03.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 199.0 in stage 5.0 (TID 133) in 108 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:48:03.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 138) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 190 (task 130, attempt 0, stage 5.0)
[2025-07-19T20:48:03.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 13.0 in stage 5.0 (TID 138)
[2025-07-19T20:48:03.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 190.0 in stage 5.0 (TID 130). 9091 bytes result sent to driver
[2025-07-19T20:48:03.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:03.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 139) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 15.0 in stage 5.0 (TID 139)
[2025-07-19T20:48:03.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 190.0 in stage 5.0 (TID 130) in 132 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:48:03.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 195 (task 132, attempt 0, stage 5.0)
[2025-07-19T20:48:03.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 195.0 in stage 5.0 (TID 132). 9037 bytes result sent to driver
[2025-07-19T20:48:03.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO DataWritingSparkTask: Committed partition 192 (task 131, attempt 0, stage 5.0)
[2025-07-19T20:48:03.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Finished task 192.0 in stage 5.0 (TID 131). 9044 bytes result sent to driver
[2025-07-19T20:48:03.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/.schema.5d8ef809-1ec1-43f8-a002-cde863e8602b.TID134.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/schema
[2025-07-19T20:48:03.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 140) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 141) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:03.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f9917bb
[2025-07-19T20:48:03.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0] for update
[2025-07-19T20:48:03.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 195.0 in stage 5.0 (TID 132) in 128 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:48:03.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO TaskSetManager: Finished task 192.0 in stage 5.0 (TID 131) in 131 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:48:03.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 17.0 in stage 5.0 (TID 140)
[2025-07-19T20:48:03.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO Executor: Running task 27.0 in stage 5.0 (TID 141)
[2025-07-19T20:48:03.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:03.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:03.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:03.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75bfe7
[2025-07-19T20:48:03.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2] for update
[2025-07-19T20:48:03.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aa2ea30
[2025-07-19T20:48:03.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:03.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27] for update
[2025-07-19T20:48:03.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.1.delta.b9b899d5-19cd-4926-99cb-05da16a0e094.TID134.tmp
[2025-07-19T20:48:03.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:03.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@674bcf2d
[2025-07-19T20:48:03.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.1.delta.fe31faca-a996-4371-8eed-bff3f269ea3e.TID135.tmp
[2025-07-19T20:48:03.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15] for update
[2025-07-19T20:48:04.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50270fdd
[2025-07-19T20:48:04.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17] for update
[2025-07-19T20:48:04.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.1.delta.b5f05b75-f661-4b96-a3e1-7b60bf64c0e2.TID141.tmp
[2025-07-19T20:48:04.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.1.delta.b2e3bfdb-4cc1-4f88-b4a5-eedd1e8d756b.TID139.tmp
[2025-07-19T20:48:04.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e0d2dfd
[2025-07-19T20:48:04.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.1.delta.d7597ed0-e3e9-407a-b0d7-6c496493ba90.TID140.tmp
[2025-07-19T20:48:04.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13] for update
[2025-07-19T20:48:04.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a520b4f
[2025-07-19T20:48:04.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10] for update
[2025-07-19T20:48:04.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@353df014
[2025-07-19T20:48:04.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8] for update
[2025-07-19T20:48:04.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.1.delta.0aef318c-f646-4564-b8cf-eb69a4cea988.TID138.tmp
[2025-07-19T20:48:04.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.1.delta.fe31faca-a996-4371-8eed-bff3f269ea3e.TID135.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta
[2025-07-19T20:48:04.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta
[2025-07-19T20:48:04.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 135, attempt 0, stage 5.0)
[2025-07-19T20:48:04.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.1.delta.b9b899d5-19cd-4926-99cb-05da16a0e094.TID134.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta
[2025-07-19T20:48:04.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta
[2025-07-19T20:48:04.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 134, attempt 0, stage 5.0)
[2025-07-19T20:48:04.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 2 (task 135, attempt 0, stage 5.0)
[2025-07-19T20:48:04.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.1.delta.d3ea1bdb-a25a-400e-a901-287f1c488d59.TID137.tmp
[2025-07-19T20:48:04.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 0 (task 134, attempt 0, stage 5.0)
[2025-07-19T20:48:04.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 134). 6243 bytes result sent to driver
[2025-07-19T20:48:04.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 142) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 2.0 in stage 5.0 (TID 135). 6243 bytes result sent to driver
[2025-07-19T20:48:04.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 143) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 31.0 in stage 5.0 (TID 143)
[2025-07-19T20:48:04.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 134) in 192 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:48:04.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 135) in 188 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:48:04.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.1.delta.41ef1a7a-0a8d-4c4e-a284-0f158e2c487c.TID136.tmp
[2025-07-19T20:48:04.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 28.0 in stage 5.0 (TID 142)
[2025-07-19T20:48:04.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.1.delta.b5f05b75-f661-4b96-a3e1-7b60bf64c0e2.TID141.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta
[2025-07-19T20:48:04.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta
[2025-07-19T20:48:04.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 141, attempt 0, stage 5.0)
[2025-07-19T20:48:04.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.1.delta.d7597ed0-e3e9-407a-b0d7-6c496493ba90.TID140.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta
[2025-07-19T20:48:04.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta
[2025-07-19T20:48:04.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.1.delta.b2e3bfdb-4cc1-4f88-b4a5-eedd1e8d756b.TID139.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta
[2025-07-19T20:48:04.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 140, attempt 0, stage 5.0)
[2025-07-19T20:48:04.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta
[2025-07-19T20:48:04.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 139, attempt 0, stage 5.0)
[2025-07-19T20:48:04.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 27 (task 141, attempt 0, stage 5.0)
[2025-07-19T20:48:04.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16715f0d
[2025-07-19T20:48:04.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 15 (task 139, attempt 0, stage 5.0)
[2025-07-19T20:48:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 17 (task 140, attempt 0, stage 5.0)
[2025-07-19T20:48:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28] for update
[2025-07-19T20:48:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 27.0 in stage 5.0 (TID 141). 6243 bytes result sent to driver
[2025-07-19T20:48:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 15.0 in stage 5.0 (TID 139). 6243 bytes result sent to driver
[2025-07-19T20:48:04.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 17.0 in stage 5.0 (TID 140). 6243 bytes result sent to driver
[2025-07-19T20:48:04.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 144) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 145) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 33.0 in stage 5.0 (TID 144)
[2025-07-19T20:48:04.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 34.0 in stage 5.0 (TID 145)
[2025-07-19T20:48:04.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 146) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 36.0 in stage 5.0 (TID 146)
[2025-07-19T20:48:04.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:04.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 141) in 116 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:48:04.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 140) in 117 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:48:04.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 139) in 123 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:48:04.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.1.delta.327c8848-f530-42d9-990c-c7bb368fb1de.TID142.tmp
[2025-07-19T20:48:04.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.1.delta.0aef318c-f646-4564-b8cf-eb69a4cea988.TID138.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta
[2025-07-19T20:48:04.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67c210d0
[2025-07-19T20:48:04.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta
[2025-07-19T20:48:04.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 138, attempt 0, stage 5.0)
[2025-07-19T20:48:04.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31] for update
[2025-07-19T20:48:04.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 13 (task 138, attempt 0, stage 5.0)
[2025-07-19T20:48:04.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.1.delta.d3ea1bdb-a25a-400e-a901-287f1c488d59.TID137.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta
[2025-07-19T20:48:04.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta
[2025-07-19T20:48:04.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 13.0 in stage 5.0 (TID 138). 6243 bytes result sent to driver
[2025-07-19T20:48:04.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 147) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 137, attempt 0, stage 5.0)
[2025-07-19T20:48:04.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1692cf98
[2025-07-19T20:48:04.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 40.0 in stage 5.0 (TID 147)
[2025-07-19T20:48:04.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 138) in 146 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:48:04.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36] for update
[2025-07-19T20:48:04.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.1.delta.54c78a5c-31a2-486b-be00-baa83bfb7e88.TID143.tmp
[2025-07-19T20:48:04.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74bf77f4
[2025-07-19T20:48:04.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34] for update
[2025-07-19T20:48:04.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:04.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.1.delta.41ef1a7a-0a8d-4c4e-a284-0f158e2c487c.TID136.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta
[2025-07-19T20:48:04.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta
[2025-07-19T20:48:04.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 10 (task 137, attempt 0, stage 5.0)
[2025-07-19T20:48:04.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 136, attempt 0, stage 5.0)
[2025-07-19T20:48:04.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 10.0 in stage 5.0 (TID 137). 6243 bytes result sent to driver
[2025-07-19T20:48:04.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 148) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 42.0 in stage 5.0 (TID 148)
[2025-07-19T20:48:04.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 137) in 191 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:48:04.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.1.delta.bca4f985-ed74-421b-966a-453a0e09c411.TID146.tmp
[2025-07-19T20:48:04.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8e70060
[2025-07-19T20:48:04.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33] for update
[2025-07-19T20:48:04.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 8 (task 136, attempt 0, stage 5.0)
[2025-07-19T20:48:04.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 8.0 in stage 5.0 (TID 136). 6243 bytes result sent to driver
[2025-07-19T20:48:04.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 149) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 44.0 in stage 5.0 (TID 149)
[2025-07-19T20:48:04.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 136) in 239 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:48:04.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68eb5a97
[2025-07-19T20:48:04.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.1.delta.cbcc31e1-4ca7-43ba-a9ee-0dbc87630503.TID145.tmp
[2025-07-19T20:48:04.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40] for update
[2025-07-19T20:48:04.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.1.delta.bd6eafea-a600-49c7-8479-d8a529176053.TID144.tmp
[2025-07-19T20:48:04.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.1.delta.327c8848-f530-42d9-990c-c7bb368fb1de.TID142.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta
[2025-07-19T20:48:04.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta
[2025-07-19T20:48:04.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 142, attempt 0, stage 5.0)
[2025-07-19T20:48:04.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dfc49e9
[2025-07-19T20:48:04.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42] for update
[2025-07-19T20:48:04.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 28 (task 142, attempt 0, stage 5.0)
[2025-07-19T20:48:04.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 28.0 in stage 5.0 (TID 142). 6243 bytes result sent to driver
[2025-07-19T20:48:04.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 150) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 49.0 in stage 5.0 (TID 150)
[2025-07-19T20:48:04.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 142) in 100 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:48:04.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@718a800
[2025-07-19T20:48:04.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44] for update
[2025-07-19T20:48:04.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:04.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.1.delta.9c255485-e5cf-4acb-8997-fcadafd26f79.TID147.tmp
[2025-07-19T20:48:04.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78ecff37
[2025-07-19T20:48:04.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.1.delta.54c78a5c-31a2-486b-be00-baa83bfb7e88.TID143.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta
[2025-07-19T20:48:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49] for update
[2025-07-19T20:48:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta
[2025-07-19T20:48:04.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.1.delta.36577fa9-2eb0-4953-80bf-fa1069944c2e.TID149.tmp
[2025-07-19T20:48:04.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 143, attempt 0, stage 5.0)
[2025-07-19T20:48:04.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.1.delta.646647a4-06ab-42f7-82aa-498bfa73ee96.TID148.tmp
[2025-07-19T20:48:04.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.1.delta.bca4f985-ed74-421b-966a-453a0e09c411.TID146.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta
[2025-07-19T20:48:04.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta
[2025-07-19T20:48:04.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 146, attempt 0, stage 5.0)
[2025-07-19T20:48:04.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 31 (task 143, attempt 0, stage 5.0)
[2025-07-19T20:48:04.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 31.0 in stage 5.0 (TID 143). 6243 bytes result sent to driver
[2025-07-19T20:48:04.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 151) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 36 (task 146, attempt 0, stage 5.0)
[2025-07-19T20:48:04.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 36.0 in stage 5.0 (TID 146). 6243 bytes result sent to driver
[2025-07-19T20:48:04.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 152) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 146) in 121 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:48:04.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 143) in 150 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:48:04.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 54.0 in stage 5.0 (TID 152)
[2025-07-19T20:48:04.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 50.0 in stage 5.0 (TID 151)
[2025-07-19T20:48:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.1.delta.bd6eafea-a600-49c7-8479-d8a529176053.TID144.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta
[2025-07-19T20:48:04.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta
[2025-07-19T20:48:04.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 144, attempt 0, stage 5.0)
[2025-07-19T20:48:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 33 (task 144, attempt 0, stage 5.0)
[2025-07-19T20:48:04.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 33.0 in stage 5.0 (TID 144). 6243 bytes result sent to driver
[2025-07-19T20:48:04.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.1.delta.7cb4ecd3-6c72-4d86-97e9-72c40e747c2c.TID150.tmp
[2025-07-19T20:48:04.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 153) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 55.0 in stage 5.0 (TID 153)
[2025-07-19T20:48:04.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 144) in 145 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:48:04.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.1.delta.cbcc31e1-4ca7-43ba-a9ee-0dbc87630503.TID145.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta
[2025-07-19T20:48:04.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta
[2025-07-19T20:48:04.223+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 145, attempt 0, stage 5.0)
[2025-07-19T20:48:04.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10cdc886
[2025-07-19T20:48:04.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54] for update
[2025-07-19T20:48:04.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 34 (task 145, attempt 0, stage 5.0)
[2025-07-19T20:48:04.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 34.0 in stage 5.0 (TID 145). 6243 bytes result sent to driver
[2025-07-19T20:48:04.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 154) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 145) in 155 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:48:04.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 61.0 in stage 5.0 (TID 154)
[2025-07-19T20:48:04.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39764a40
[2025-07-19T20:48:04.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55] for update
[2025-07-19T20:48:04.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:04.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1800cb6e
[2025-07-19T20:48:04.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50] for update
[2025-07-19T20:48:04.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.1.delta.36577fa9-2eb0-4953-80bf-fa1069944c2e.TID149.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta
[2025-07-19T20:48:04.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta
[2025-07-19T20:48:04.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 149, attempt 0, stage 5.0)
[2025-07-19T20:48:04.256+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.1.delta.54f4d3a6-0008-443b-a5ef-3aaff307f018.TID152.tmp
[2025-07-19T20:48:04.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54d627e3
[2025-07-19T20:48:04.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.1.delta.646647a4-06ab-42f7-82aa-498bfa73ee96.TID148.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta
[2025-07-19T20:48:04.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta
[2025-07-19T20:48:04.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 148, attempt 0, stage 5.0)
[2025-07-19T20:48:04.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61] for update
[2025-07-19T20:48:04.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 44 (task 149, attempt 0, stage 5.0)
[2025-07-19T20:48:04.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 44.0 in stage 5.0 (TID 149). 6243 bytes result sent to driver
[2025-07-19T20:48:04.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 149) in 130 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:48:04.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 155) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 67.0 in stage 5.0 (TID 155)
[2025-07-19T20:48:04.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.1.delta.9c255485-e5cf-4acb-8997-fcadafd26f79.TID147.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta
[2025-07-19T20:48:04.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta
[2025-07-19T20:48:04.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 147, attempt 0, stage 5.0)
[2025-07-19T20:48:04.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 42 (task 148, attempt 0, stage 5.0)
[2025-07-19T20:48:04.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 42.0 in stage 5.0 (TID 148). 6243 bytes result sent to driver
[2025-07-19T20:48:04.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:04.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 156) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 70.0 in stage 5.0 (TID 156)
[2025-07-19T20:48:04.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.1.delta.ce8683d1-6849-4adc-a20f-eacb4eee20b1.TID151.tmp
[2025-07-19T20:48:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.1.delta.6a7ee2ae-b083-435d-a408-8bb2272f227c.TID153.tmp
[2025-07-19T20:48:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 40 (task 147, attempt 0, stage 5.0)
[2025-07-19T20:48:04.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 148) in 151 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:48:04.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 40.0 in stage 5.0 (TID 147). 6286 bytes result sent to driver
[2025-07-19T20:48:04.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 157) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 74.0 in stage 5.0 (TID 157)
[2025-07-19T20:48:04.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.1.delta.bd689093-734d-4bab-93e4-b65dc08a65cf.TID154.tmp
[2025-07-19T20:48:04.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 147) in 185 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:48:04.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9790b0b
[2025-07-19T20:48:04.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67] for update
[2025-07-19T20:48:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.1.delta.7cb4ecd3-6c72-4d86-97e9-72c40e747c2c.TID150.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta
[2025-07-19T20:48:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta
[2025-07-19T20:48:04.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 150, attempt 0, stage 5.0)
[2025-07-19T20:48:04.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f0de82e
[2025-07-19T20:48:04.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 49 (task 150, attempt 0, stage 5.0)
[2025-07-19T20:48:04.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74] for update
[2025-07-19T20:48:04.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 49.0 in stage 5.0 (TID 150). 6243 bytes result sent to driver
[2025-07-19T20:48:04.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 158) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 150) in 154 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:48:04.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 76.0 in stage 5.0 (TID 158)
[2025-07-19T20:48:04.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.1.delta.53989b39-07d6-4bee-a6b2-55c6988af894.TID155.tmp
[2025-07-19T20:48:04.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39602f9b
[2025-07-19T20:48:04.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70] for update
[2025-07-19T20:48:04.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.1.delta.c72c25c4-64ae-484e-b38e-dd5bf957da33.TID157.tmp
[2025-07-19T20:48:04.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.1.delta.6a7ee2ae-b083-435d-a408-8bb2272f227c.TID153.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta
[2025-07-19T20:48:04.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta
[2025-07-19T20:48:04.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 153, attempt 0, stage 5.0)
[2025-07-19T20:48:04.327+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 55 (task 153, attempt 0, stage 5.0)
[2025-07-19T20:48:04.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7068c712
[2025-07-19T20:48:04.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.1.delta.54f4d3a6-0008-443b-a5ef-3aaff307f018.TID152.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta
[2025-07-19T20:48:04.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta
[2025-07-19T20:48:04.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76] for update
[2025-07-19T20:48:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.1.delta.73c64e73-952e-4d97-9514-90ce4659ce92.TID156.tmp
[2025-07-19T20:48:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 152, attempt 0, stage 5.0)
[2025-07-19T20:48:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 55.0 in stage 5.0 (TID 153). 6243 bytes result sent to driver
[2025-07-19T20:48:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 159) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 153) in 118 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:48:04.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 80.0 in stage 5.0 (TID 159)
[2025-07-19T20:48:04.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.1.delta.ce8683d1-6849-4adc-a20f-eacb4eee20b1.TID151.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta
[2025-07-19T20:48:04.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta
[2025-07-19T20:48:04.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 151, attempt 0, stage 5.0)
[2025-07-19T20:48:04.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 54 (task 152, attempt 0, stage 5.0)
[2025-07-19T20:48:04.336+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 54.0 in stage 5.0 (TID 152). 6243 bytes result sent to driver
[2025-07-19T20:48:04.336+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.1.delta.bd689093-734d-4bab-93e4-b65dc08a65cf.TID154.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta
[2025-07-19T20:48:04.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta
[2025-07-19T20:48:04.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 154, attempt 0, stage 5.0)
[2025-07-19T20:48:04.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 160) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 81.0 in stage 5.0 (TID 160)
[2025-07-19T20:48:04.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 152) in 140 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:48:04.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:04.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 50 (task 151, attempt 0, stage 5.0)
[2025-07-19T20:48:04.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 61 (task 154, attempt 0, stage 5.0)
[2025-07-19T20:48:04.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 61.0 in stage 5.0 (TID 154). 6243 bytes result sent to driver
[2025-07-19T20:48:04.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 50.0 in stage 5.0 (TID 151). 6243 bytes result sent to driver
[2025-07-19T20:48:04.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 154) in 118 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:48:04.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 161) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 162) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f9a7789
[2025-07-19T20:48:04.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 84.0 in stage 5.0 (TID 161)
[2025-07-19T20:48:04.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 88.0 in stage 5.0 (TID 162)
[2025-07-19T20:48:04.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80] for update
[2025-07-19T20:48:04.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:04.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 151) in 158 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:48:04.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.1.delta.53989b39-07d6-4bee-a6b2-55c6988af894.TID155.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta
[2025-07-19T20:48:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta
[2025-07-19T20:48:04.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T20:48:04.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 155, attempt 0, stage 5.0)
[2025-07-19T20:48:04.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.1.delta.c72c25c4-64ae-484e-b38e-dd5bf957da33.TID157.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta
[2025-07-19T20:48:04.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta
[2025-07-19T20:48:04.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 157, attempt 0, stage 5.0)
[2025-07-19T20:48:04.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.1.delta.92bfc8eb-44b3-44bc-a9ed-9abf770b9ba3.TID158.tmp
[2025-07-19T20:48:04.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@117c4788
[2025-07-19T20:48:04.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84] for update
[2025-07-19T20:48:04.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.1.delta.7a3c2793-001a-4790-9eef-7bbdfb701a4b.TID159.tmp
[2025-07-19T20:48:04.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 67 (task 155, attempt 0, stage 5.0)
[2025-07-19T20:48:04.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 67.0 in stage 5.0 (TID 155). 6243 bytes result sent to driver
[2025-07-19T20:48:04.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 163) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.1.delta.73c64e73-952e-4d97-9514-90ce4659ce92.TID156.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta
[2025-07-19T20:48:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta
[2025-07-19T20:48:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 90.0 in stage 5.0 (TID 163)
[2025-07-19T20:48:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7aae5ec3
[2025-07-19T20:48:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 156, attempt 0, stage 5.0)
[2025-07-19T20:48:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 74 (task 157, attempt 0, stage 5.0)
[2025-07-19T20:48:04.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:04.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 70 (task 156, attempt 0, stage 5.0)
[2025-07-19T20:48:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 155) in 122 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:48:04.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 74.0 in stage 5.0 (TID 157). 6200 bytes result sent to driver
[2025-07-19T20:48:04.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 70.0 in stage 5.0 (TID 156). 6243 bytes result sent to driver
[2025-07-19T20:48:04.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81] for update
[2025-07-19T20:48:04.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 164) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 156) in 121 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:48:04.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 157) in 106 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:48:04.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 165) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 91.0 in stage 5.0 (TID 164)
[2025-07-19T20:48:04.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 93.0 in stage 5.0 (TID 165)
[2025-07-19T20:48:04.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.1.delta.aa937d00-8a17-455f-a6fa-15cc90e1cc27.TID161.tmp
[2025-07-19T20:48:04.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a07e764
[2025-07-19T20:48:04.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90] for update
[2025-07-19T20:48:04.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:04.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cefc059
[2025-07-19T20:48:04.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88] for update
[2025-07-19T20:48:04.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55036893
[2025-07-19T20:48:04.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.1.delta.92bfc8eb-44b3-44bc-a9ed-9abf770b9ba3.TID158.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta
[2025-07-19T20:48:04.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta
[2025-07-19T20:48:04.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 158, attempt 0, stage 5.0)
[2025-07-19T20:48:04.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93] for update
[2025-07-19T20:48:04.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e43e7a8
[2025-07-19T20:48:04.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 76 (task 158, attempt 0, stage 5.0)
[2025-07-19T20:48:04.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 76.0 in stage 5.0 (TID 158). 6286 bytes result sent to driver
[2025-07-19T20:48:04.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91] for update
[2025-07-19T20:48:04.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 101.0 in stage 5.0 (TID 166) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 158) in 130 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:48:04.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 101.0 in stage 5.0 (TID 166)
[2025-07-19T20:48:04.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.1.delta.99984088-0746-4477-a378-c17897c474b7.TID160.tmp
[2025-07-19T20:48:04.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.1.delta.c55a110c-ea92-44dd-8b3b-080216bb74c2.TID165.tmp
[2025-07-19T20:48:04.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.1.delta.a3f8995c-e489-4a81-9bcb-a5a2e353994a.TID163.tmp
[2025-07-19T20:48:04.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fff6494
[2025-07-19T20:48:04.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101] for update
[2025-07-19T20:48:04.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.1.delta.5e961ccb-3822-4a69-b954-1b4bd6adc1ee.TID162.tmp
[2025-07-19T20:48:04.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.1.delta.bb759703-61e5-4688-800a-e7c9d99f559b.TID164.tmp
[2025-07-19T20:48:04.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.1.delta.7a3c2793-001a-4790-9eef-7bbdfb701a4b.TID159.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta
[2025-07-19T20:48:04.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta
[2025-07-19T20:48:04.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.1.delta.aa937d00-8a17-455f-a6fa-15cc90e1cc27.TID161.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta
[2025-07-19T20:48:04.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta
[2025-07-19T20:48:04.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 159, attempt 0, stage 5.0)
[2025-07-19T20:48:04.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 161, attempt 0, stage 5.0)
[2025-07-19T20:48:04.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 84 (task 161, attempt 0, stage 5.0)
[2025-07-19T20:48:04.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 80 (task 159, attempt 0, stage 5.0)
[2025-07-19T20:48:04.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 84.0 in stage 5.0 (TID 161). 6243 bytes result sent to driver
[2025-07-19T20:48:04.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 103.0 in stage 5.0 (TID 167) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 103.0 in stage 5.0 (TID 167)
[2025-07-19T20:48:04.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 161) in 111 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:48:04.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 80.0 in stage 5.0 (TID 159). 6243 bytes result sent to driver
[2025-07-19T20:48:04.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 108.0 in stage 5.0 (TID 168) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 159) in 134 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:48:04.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 108.0 in stage 5.0 (TID 168)
[2025-07-19T20:48:04.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.1.delta.6b489c50-3058-4e2a-a1f1-ed5d2149e693.TID166.tmp
[2025-07-19T20:48:04.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b9f5731
[2025-07-19T20:48:04.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103] for update
[2025-07-19T20:48:04.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.1.delta.c55a110c-ea92-44dd-8b3b-080216bb74c2.TID165.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta
[2025-07-19T20:48:04.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta
[2025-07-19T20:48:04.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 165, attempt 0, stage 5.0)
[2025-07-19T20:48:04.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 93 (task 165, attempt 0, stage 5.0)
[2025-07-19T20:48:04.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 93.0 in stage 5.0 (TID 165). 6243 bytes result sent to driver
[2025-07-19T20:48:04.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 112.0 in stage 5.0 (TID 169) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fd04483
[2025-07-19T20:48:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108] for update
[2025-07-19T20:48:04.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 165) in 95 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:48:04.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 112.0 in stage 5.0 (TID 169)
[2025-07-19T20:48:04.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.1.delta.9b849121-273e-46b4-bb05-8a56aa9f8cd8.TID167.tmp
[2025-07-19T20:48:04.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:04.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.1.delta.99984088-0746-4477-a378-c17897c474b7.TID160.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta
[2025-07-19T20:48:04.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta
[2025-07-19T20:48:04.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 160, attempt 0, stage 5.0)
[2025-07-19T20:48:04.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.1.delta.a3f8995c-e489-4a81-9bcb-a5a2e353994a.TID163.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta
[2025-07-19T20:48:04.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta
[2025-07-19T20:48:04.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 163, attempt 0, stage 5.0)
[2025-07-19T20:48:04.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.1.delta.5e961ccb-3822-4a69-b954-1b4bd6adc1ee.TID162.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta
[2025-07-19T20:48:04.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta
[2025-07-19T20:48:04.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.1.delta.a2d4fa43-e3bb-46c2-b005-17ad55455a2d.TID168.tmp
[2025-07-19T20:48:04.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 81 (task 160, attempt 0, stage 5.0)
[2025-07-19T20:48:04.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@322e497
[2025-07-19T20:48:04.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 162, attempt 0, stage 5.0)
[2025-07-19T20:48:04.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112] for update
[2025-07-19T20:48:04.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 90 (task 163, attempt 0, stage 5.0)
[2025-07-19T20:48:04.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 81.0 in stage 5.0 (TID 160). 6243 bytes result sent to driver
[2025-07-19T20:48:04.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 114.0 in stage 5.0 (TID 170) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 114.0 in stage 5.0 (TID 170)
[2025-07-19T20:48:04.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 90.0 in stage 5.0 (TID 163). 6286 bytes result sent to driver
[2025-07-19T20:48:04.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 160) in 166 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:48:04.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 115.0 in stage 5.0 (TID 171) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 163) in 132 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:48:04.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 115.0 in stage 5.0 (TID 171)
[2025-07-19T20:48:04.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:04.536+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 88 (task 162, attempt 0, stage 5.0)
[2025-07-19T20:48:04.536+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.1.delta.bb759703-61e5-4688-800a-e7c9d99f559b.TID164.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta
[2025-07-19T20:48:04.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta
[2025-07-19T20:48:04.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 164, attempt 0, stage 5.0)
[2025-07-19T20:48:04.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.1.delta.6b489c50-3058-4e2a-a1f1-ed5d2149e693.TID166.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta
[2025-07-19T20:48:04.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta
[2025-07-19T20:48:04.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 166, attempt 0, stage 5.0)
[2025-07-19T20:48:04.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 88.0 in stage 5.0 (TID 162). 6243 bytes result sent to driver
[2025-07-19T20:48:04.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:04.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24f1fb30
[2025-07-19T20:48:04.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 91 (task 164, attempt 0, stage 5.0)
[2025-07-19T20:48:04.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 116.0 in stage 5.0 (TID 172) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 91.0 in stage 5.0 (TID 164). 6243 bytes result sent to driver
[2025-07-19T20:48:04.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 162) in 171 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:48:04.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 124.0 in stage 5.0 (TID 173) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.1.delta.a5653900-d798-4994-b35f-498a10b4fed5.TID169.tmp
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 164) in 136 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 116.0 in stage 5.0 (TID 172)
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 124.0 in stage 5.0 (TID 173)
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114] for update
[2025-07-19T20:48:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 101 (task 166, attempt 0, stage 5.0)
[2025-07-19T20:48:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 101.0 in stage 5.0 (TID 166). 6200 bytes result sent to driver
[2025-07-19T20:48:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:48:04.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 125.0 in stage 5.0 (TID 174) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 125.0 in stage 5.0 (TID 174)
[2025-07-19T20:48:04.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 101.0 in stage 5.0 (TID 166) in 107 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:48:04.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c72dd07
[2025-07-19T20:48:04.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124] for update
[2025-07-19T20:48:04.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.1.delta.9b849121-273e-46b4-bb05-8a56aa9f8cd8.TID167.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta
[2025-07-19T20:48:04.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta
[2025-07-19T20:48:04.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 167, attempt 0, stage 5.0)
[2025-07-19T20:48:04.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.1.delta.ca9e1327-2bfc-4c27-a14c-5df406df28a7.TID170.tmp
[2025-07-19T20:48:04.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e7ffa76
[2025-07-19T20:48:04.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 103 (task 167, attempt 0, stage 5.0)
[2025-07-19T20:48:04.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115] for update
[2025-07-19T20:48:04.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.1.delta.9e252035-c974-44d8-8d79-2a2220b51ff6.TID173.tmp
[2025-07-19T20:48:04.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 103.0 in stage 5.0 (TID 167). 6286 bytes result sent to driver
[2025-07-19T20:48:04.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.1.delta.a2d4fa43-e3bb-46c2-b005-17ad55455a2d.TID168.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta
[2025-07-19T20:48:04.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta
[2025-07-19T20:48:04.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 126.0 in stage 5.0 (TID 175) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 168, attempt 0, stage 5.0)
[2025-07-19T20:48:04.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@292fccfb
[2025-07-19T20:48:04.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 103.0 in stage 5.0 (TID 167) in 110 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:48:04.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 126.0 in stage 5.0 (TID 175)
[2025-07-19T20:48:04.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125] for update
[2025-07-19T20:48:04.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 108 (task 168, attempt 0, stage 5.0)
[2025-07-19T20:48:04.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 108.0 in stage 5.0 (TID 168). 6243 bytes result sent to driver
[2025-07-19T20:48:04.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 132.0 in stage 5.0 (TID 176) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 108.0 in stage 5.0 (TID 168) in 112 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:48:04.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 132.0 in stage 5.0 (TID 176)
[2025-07-19T20:48:04.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5135c43e
[2025-07-19T20:48:04.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116] for update
[2025-07-19T20:48:04.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.1.delta.3d04f651-560a-43e8-abe5-046761075843.TID171.tmp
[2025-07-19T20:48:04.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.1.delta.a5653900-d798-4994-b35f-498a10b4fed5.TID169.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta
[2025-07-19T20:48:04.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta
[2025-07-19T20:48:04.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 169, attempt 0, stage 5.0)
[2025-07-19T20:48:04.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@85765b3
[2025-07-19T20:48:04.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132] for update
[2025-07-19T20:48:04.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.1.delta.889b4b8f-e300-434c-8d88-13a67631cfe0.TID174.tmp
[2025-07-19T20:48:04.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.1.delta.70f40d6d-a70c-4ff4-952a-5846de14b6bf.TID172.tmp
[2025-07-19T20:48:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ddd642c
[2025-07-19T20:48:04.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126] for update
[2025-07-19T20:48:04.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 112 (task 169, attempt 0, stage 5.0)
[2025-07-19T20:48:04.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 112.0 in stage 5.0 (TID 169). 6243 bytes result sent to driver
[2025-07-19T20:48:04.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 134.0 in stage 5.0 (TID 177) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 112.0 in stage 5.0 (TID 169) in 124 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:48:04.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.1.delta.f546c8fd-f2b7-4667-aacf-6b805533e78f.TID176.tmp
[2025-07-19T20:48:04.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 134.0 in stage 5.0 (TID 177)
[2025-07-19T20:48:04.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.1.delta.ca9e1327-2bfc-4c27-a14c-5df406df28a7.TID170.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta
[2025-07-19T20:48:04.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta
[2025-07-19T20:48:04.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 170, attempt 0, stage 5.0)
[2025-07-19T20:48:04.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.1.delta.0419f2a7-b63c-4fba-b507-abec86c16b6e.TID175.tmp
[2025-07-19T20:48:04.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 114 (task 170, attempt 0, stage 5.0)
[2025-07-19T20:48:04.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10019b57
[2025-07-19T20:48:04.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 114.0 in stage 5.0 (TID 170). 6243 bytes result sent to driver
[2025-07-19T20:48:04.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 141.0 in stage 5.0 (TID 178) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 114.0 in stage 5.0 (TID 170) in 115 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:48:04.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 141.0 in stage 5.0 (TID 178)
[2025-07-19T20:48:04.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134] for update
[2025-07-19T20:48:04.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.1.delta.9e252035-c974-44d8-8d79-2a2220b51ff6.TID173.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta
[2025-07-19T20:48:04.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta
[2025-07-19T20:48:04.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 173, attempt 0, stage 5.0)
[2025-07-19T20:48:04.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6752f329
[2025-07-19T20:48:04.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141] for update
[2025-07-19T20:48:04.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.1.delta.3d04f651-560a-43e8-abe5-046761075843.TID171.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta
[2025-07-19T20:48:04.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta
[2025-07-19T20:48:04.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 171, attempt 0, stage 5.0)
[2025-07-19T20:48:04.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 124 (task 173, attempt 0, stage 5.0)
[2025-07-19T20:48:04.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 124.0 in stage 5.0 (TID 173). 6243 bytes result sent to driver
[2025-07-19T20:48:04.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 115 (task 171, attempt 0, stage 5.0)
[2025-07-19T20:48:04.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 115.0 in stage 5.0 (TID 171). 6243 bytes result sent to driver
[2025-07-19T20:48:04.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 142.0 in stage 5.0 (TID 179) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.1.delta.bb0a3ecb-ebd4-4e67-97b0-6f360c3c45a9.TID177.tmp
[2025-07-19T20:48:04.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 143.0 in stage 5.0 (TID 180) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 124.0 in stage 5.0 (TID 173) in 119 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:48:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 115.0 in stage 5.0 (TID 171) in 133 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:48:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 142.0 in stage 5.0 (TID 179)
[2025-07-19T20:48:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 143.0 in stage 5.0 (TID 180)
[2025-07-19T20:48:04.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.1.delta.187fda37-d95d-43ca-8194-a8934952050f.TID178.tmp
[2025-07-19T20:48:04.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.1.delta.70f40d6d-a70c-4ff4-952a-5846de14b6bf.TID172.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta
[2025-07-19T20:48:04.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta
[2025-07-19T20:48:04.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.1.delta.889b4b8f-e300-434c-8d88-13a67631cfe0.TID174.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta
[2025-07-19T20:48:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta
[2025-07-19T20:48:04.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 172, attempt 0, stage 5.0)
[2025-07-19T20:48:04.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b6af37e
[2025-07-19T20:48:04.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 174, attempt 0, stage 5.0)
[2025-07-19T20:48:04.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142] for update
[2025-07-19T20:48:04.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.1.delta.f546c8fd-f2b7-4667-aacf-6b805533e78f.TID176.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta
[2025-07-19T20:48:04.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta
[2025-07-19T20:48:04.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 176, attempt 0, stage 5.0)
[2025-07-19T20:48:04.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.1.delta.0419f2a7-b63c-4fba-b507-abec86c16b6e.TID175.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta
[2025-07-19T20:48:04.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta
[2025-07-19T20:48:04.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 175, attempt 0, stage 5.0)
[2025-07-19T20:48:04.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 132 (task 176, attempt 0, stage 5.0)
[2025-07-19T20:48:04.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 116 (task 172, attempt 0, stage 5.0)
[2025-07-19T20:48:04.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 132.0 in stage 5.0 (TID 176). 6243 bytes result sent to driver
[2025-07-19T20:48:04.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 116.0 in stage 5.0 (TID 172). 6243 bytes result sent to driver
[2025-07-19T20:48:04.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 146.0 in stage 5.0 (TID 181) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 147.0 in stage 5.0 (TID 182) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 146.0 in stage 5.0 (TID 181)
[2025-07-19T20:48:04.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 132.0 in stage 5.0 (TID 176) in 98 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:48:04.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 116.0 in stage 5.0 (TID 172) in 154 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:48:04.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 125 (task 174, attempt 0, stage 5.0)
[2025-07-19T20:48:04.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 125.0 in stage 5.0 (TID 174). 6243 bytes result sent to driver
[2025-07-19T20:48:04.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38612226
[2025-07-19T20:48:04.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 147.0 in stage 5.0 (TID 182)
[2025-07-19T20:48:04.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.1.delta.2253baa9-80da-4ab0-99e3-3091f4dd5584.TID179.tmp
[2025-07-19T20:48:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 148.0 in stage 5.0 (TID 183) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143] for update
[2025-07-19T20:48:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 125.0 in stage 5.0 (TID 174) in 144 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 148.0 in stage 5.0 (TID 183)
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 126 (task 175, attempt 0, stage 5.0)
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 126.0 in stage 5.0 (TID 175). 6243 bytes result sent to driver
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 151.0 in stage 5.0 (TID 184) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 151.0 in stage 5.0 (TID 184)
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 126.0 in stage 5.0 (TID 175) in 117 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d51639c
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147] for update
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.1.delta.bb0a3ecb-ebd4-4e67-97b0-6f360c3c45a9.TID177.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta
[2025-07-19T20:48:04.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta
[2025-07-19T20:48:04.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.1.delta.187fda37-d95d-43ca-8194-a8934952050f.TID178.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta
[2025-07-19T20:48:04.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta
[2025-07-19T20:48:04.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 177, attempt 0, stage 5.0)
[2025-07-19T20:48:04.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 178, attempt 0, stage 5.0)
[2025-07-19T20:48:04.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51266bc
[2025-07-19T20:48:04.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148] for update
[2025-07-19T20:48:04.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 134 (task 177, attempt 0, stage 5.0)
[2025-07-19T20:48:04.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.1.delta.ad4c16f2-4cba-4810-bb83-acf7f01c92f5.TID182.tmp
[2025-07-19T20:48:04.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.1.delta.7af454a9-3555-4a30-bc1d-7a69c2922b8b.TID180.tmp
[2025-07-19T20:48:04.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 141 (task 178, attempt 0, stage 5.0)
[2025-07-19T20:48:04.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 134.0 in stage 5.0 (TID 177). 6243 bytes result sent to driver
[2025-07-19T20:48:04.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 141.0 in stage 5.0 (TID 178). 6243 bytes result sent to driver
[2025-07-19T20:48:04.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 152.0 in stage 5.0 (TID 185) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 156.0 in stage 5.0 (TID 186) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 156.0 in stage 5.0 (TID 186)
[2025-07-19T20:48:04.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 134.0 in stage 5.0 (TID 177) in 99 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:48:04.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 141.0 in stage 5.0 (TID 178) in 85 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:48:04.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 152.0 in stage 5.0 (TID 185)
[2025-07-19T20:48:04.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2013439e
[2025-07-19T20:48:04.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146] for update
[2025-07-19T20:48:04.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.1.delta.58a3db84-ddeb-4488-b07e-c4c5273a05d4.TID183.tmp
[2025-07-19T20:48:04.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.1.delta.2253baa9-80da-4ab0-99e3-3091f4dd5584.TID179.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta
[2025-07-19T20:48:04.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta
[2025-07-19T20:48:04.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 179, attempt 0, stage 5.0)
[2025-07-19T20:48:04.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ae1eb59
[2025-07-19T20:48:04.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152] for update
[2025-07-19T20:48:04.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 142 (task 179, attempt 0, stage 5.0)
[2025-07-19T20:48:04.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 142.0 in stage 5.0 (TID 179). 6243 bytes result sent to driver
[2025-07-19T20:48:04.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 157.0 in stage 5.0 (TID 187) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 157.0 in stage 5.0 (TID 187)
[2025-07-19T20:48:04.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 142.0 in stage 5.0 (TID 179) in 99 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:48:04.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.1.delta.daab4450-483e-4e05-9380-d24ea3378a9f.TID181.tmp
[2025-07-19T20:48:04.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55cce987
[2025-07-19T20:48:04.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.746+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156] for update
[2025-07-19T20:48:04.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.1.delta.320f6ce3-6ce4-4830-9d9a-f9fe08926638.TID185.tmp
[2025-07-19T20:48:04.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@197102ae
[2025-07-19T20:48:04.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.1.delta.ad4c16f2-4cba-4810-bb83-acf7f01c92f5.TID182.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta
[2025-07-19T20:48:04.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta
[2025-07-19T20:48:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151] for update
[2025-07-19T20:48:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.1.delta.7af454a9-3555-4a30-bc1d-7a69c2922b8b.TID180.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta
[2025-07-19T20:48:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta
[2025-07-19T20:48:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 182, attempt 0, stage 5.0)
[2025-07-19T20:48:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 180, attempt 0, stage 5.0)
[2025-07-19T20:48:04.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.1.delta.5fa28dd0-61ca-40ea-9897-91a2fdc233a9.TID186.tmp
[2025-07-19T20:48:04.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 147 (task 182, attempt 0, stage 5.0)
[2025-07-19T20:48:04.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 147.0 in stage 5.0 (TID 182). 6243 bytes result sent to driver
[2025-07-19T20:48:04.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 164.0 in stage 5.0 (TID 188) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 147.0 in stage 5.0 (TID 182) in 102 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:48:04.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 164.0 in stage 5.0 (TID 188)
[2025-07-19T20:48:04.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 143 (task 180, attempt 0, stage 5.0)
[2025-07-19T20:48:04.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45d24fad
[2025-07-19T20:48:04.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157] for update
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 143.0 in stage 5.0 (TID 180). 6243 bytes result sent to driver
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 166.0 in stage 5.0 (TID 189) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 166.0 in stage 5.0 (TID 189)
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 143.0 in stage 5.0 (TID 180) in 136 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e98e7b5
[2025-07-19T20:48:04.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164] for update
[2025-07-19T20:48:04.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.1.delta.58a3db84-ddeb-4488-b07e-c4c5273a05d4.TID183.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta
[2025-07-19T20:48:04.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta
[2025-07-19T20:48:04.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.1.delta.0cfedc57-b6fd-4f92-a20d-28b9db2f5249.TID184.tmp
[2025-07-19T20:48:04.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 183, attempt 0, stage 5.0)
[2025-07-19T20:48:04.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@358f28af
[2025-07-19T20:48:04.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166] for update
[2025-07-19T20:48:04.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.1.delta.df28f0b1-9a50-45e9-8888-182d2a16e963.TID187.tmp
[2025-07-19T20:48:04.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 148 (task 183, attempt 0, stage 5.0)
[2025-07-19T20:48:04.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 148.0 in stage 5.0 (TID 183). 6243 bytes result sent to driver
[2025-07-19T20:48:04.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 167.0 in stage 5.0 (TID 190) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 167.0 in stage 5.0 (TID 190)
[2025-07-19T20:48:04.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 148.0 in stage 5.0 (TID 183) in 127 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:48:04.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.1.delta.b4a4fc56-9702-4e37-92dd-a59039d5a51e.TID188.tmp
[2025-07-19T20:48:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.1.delta.c5b62f50-3af9-42b0-a596-a75acbb7d089.TID189.tmp
[2025-07-19T20:48:04.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.1.delta.daab4450-483e-4e05-9380-d24ea3378a9f.TID181.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta
[2025-07-19T20:48:04.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta
[2025-07-19T20:48:04.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 181, attempt 0, stage 5.0)
[2025-07-19T20:48:04.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61cd27a7
[2025-07-19T20:48:04.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.1.delta.320f6ce3-6ce4-4830-9d9a-f9fe08926638.TID185.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta
[2025-07-19T20:48:04.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167] for update
[2025-07-19T20:48:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta
[2025-07-19T20:48:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 185, attempt 0, stage 5.0)
[2025-07-19T20:48:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 146 (task 181, attempt 0, stage 5.0)
[2025-07-19T20:48:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 146.0 in stage 5.0 (TID 181). 6243 bytes result sent to driver
[2025-07-19T20:48:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 168.0 in stage 5.0 (TID 191) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 146.0 in stage 5.0 (TID 181) in 161 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:48:04.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 168.0 in stage 5.0 (TID 191)
[2025-07-19T20:48:04.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.1.delta.5fa28dd0-61ca-40ea-9897-91a2fdc233a9.TID186.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta
[2025-07-19T20:48:04.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta
[2025-07-19T20:48:04.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 152 (task 185, attempt 0, stage 5.0)
[2025-07-19T20:48:04.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 152.0 in stage 5.0 (TID 185). 6243 bytes result sent to driver
[2025-07-19T20:48:04.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 186, attempt 0, stage 5.0)
[2025-07-19T20:48:04.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 171.0 in stage 5.0 (TID 192) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 152.0 in stage 5.0 (TID 185) in 139 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:48:04.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 156 (task 186, attempt 0, stage 5.0)
[2025-07-19T20:48:04.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 156.0 in stage 5.0 (TID 186). 6243 bytes result sent to driver
[2025-07-19T20:48:04.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 173.0 in stage 5.0 (TID 193) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 156.0 in stage 5.0 (TID 186) in 141 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:48:04.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 171.0 in stage 5.0 (TID 192)
[2025-07-19T20:48:04.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 173.0 in stage 5.0 (TID 193)
[2025-07-19T20:48:04.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.1.delta.c7a48f0e-8509-4ebb-ac00-571ea34151c0.TID190.tmp
[2025-07-19T20:48:04.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:04.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6390632
[2025-07-19T20:48:04.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168] for update
[2025-07-19T20:48:04.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.1.delta.0cfedc57-b6fd-4f92-a20d-28b9db2f5249.TID184.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta
[2025-07-19T20:48:04.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta
[2025-07-19T20:48:04.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19fdeb87
[2025-07-19T20:48:04.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 184, attempt 0, stage 5.0)
[2025-07-19T20:48:04.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.1.delta.df28f0b1-9a50-45e9-8888-182d2a16e963.TID187.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta
[2025-07-19T20:48:04.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta
[2025-07-19T20:48:04.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171] for update
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 187, attempt 0, stage 5.0)
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.1.delta.b4a4fc56-9702-4e37-92dd-a59039d5a51e.TID188.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 151 (task 184, attempt 0, stage 5.0)
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 188, attempt 0, stage 5.0)
[2025-07-19T20:48:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 157 (task 187, attempt 0, stage 5.0)
[2025-07-19T20:48:04.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.1.delta.c01c1670-f94d-4841-8c03-a992bf285c72.TID191.tmp
[2025-07-19T20:48:04.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@125611a8
[2025-07-19T20:48:04.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 151.0 in stage 5.0 (TID 184). 6286 bytes result sent to driver
[2025-07-19T20:48:04.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 157.0 in stage 5.0 (TID 187). 6286 bytes result sent to driver
[2025-07-19T20:48:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 176.0 in stage 5.0 (TID 194) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173] for update
[2025-07-19T20:48:04.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 184.0 in stage 5.0 (TID 195) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 176.0 in stage 5.0 (TID 194)
[2025-07-19T20:48:04.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 164 (task 188, attempt 0, stage 5.0)
[2025-07-19T20:48:04.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 184.0 in stage 5.0 (TID 195)
[2025-07-19T20:48:04.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.1.delta.c5b62f50-3af9-42b0-a596-a75acbb7d089.TID189.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta
[2025-07-19T20:48:04.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta
[2025-07-19T20:48:04.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 151.0 in stage 5.0 (TID 184) in 204 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:48:04.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 164.0 in stage 5.0 (TID 188). 6243 bytes result sent to driver
[2025-07-19T20:48:04.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 189, attempt 0, stage 5.0)
[2025-07-19T20:48:04.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 157.0 in stage 5.0 (TID 187) in 155 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:48:04.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.1.delta.3cb57de5-673f-413a-a385-a9d1a7dd3fe8.TID192.tmp
[2025-07-19T20:48:04.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 189.0 in stage 5.0 (TID 196) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 164.0 in stage 5.0 (TID 188) in 124 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:48:04.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 189.0 in stage 5.0 (TID 196)
[2025-07-19T20:48:04.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 166 (task 189, attempt 0, stage 5.0)
[2025-07-19T20:48:04.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 166.0 in stage 5.0 (TID 189). 6243 bytes result sent to driver
[2025-07-19T20:48:04.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 191.0 in stage 5.0 (TID 197) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 166.0 in stage 5.0 (TID 189) in 127 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:48:04.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27f416fe
[2025-07-19T20:48:04.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 191.0 in stage 5.0 (TID 197)
[2025-07-19T20:48:04.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176] for update
[2025-07-19T20:48:04.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.1.delta.1b587419-4056-4e2f-ac4c-d2942967d38f.TID193.tmp
[2025-07-19T20:48:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.1.delta.c7a48f0e-8509-4ebb-ac00-571ea34151c0.TID190.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta
[2025-07-19T20:48:04.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta
[2025-07-19T20:48:04.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 190, attempt 0, stage 5.0)
[2025-07-19T20:48:04.930+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:48:04.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7db632af
[2025-07-19T20:48:04.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189] for update
[2025-07-19T20:48:04.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 167 (task 190, attempt 0, stage 5.0)
[2025-07-19T20:48:04.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 167.0 in stage 5.0 (TID 190). 6243 bytes result sent to driver
[2025-07-19T20:48:04.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 193.0 in stage 5.0 (TID 198) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 167.0 in stage 5.0 (TID 190) in 124 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:48:04.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 193.0 in stage 5.0 (TID 198)
[2025-07-19T20:48:04.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d7dfe30
[2025-07-19T20:48:04.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191] for update
[2025-07-19T20:48:04.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.1.delta.a5e12079-efc0-4d1b-9539-9eb43c7db0ac.TID194.tmp
[2025-07-19T20:48:04.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:04.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60289f6b
[2025-07-19T20:48:04.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184] for update
[2025-07-19T20:48:04.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.1.delta.a8645aeb-8873-48d1-9461-d5b6281d5cd0.TID196.tmp
[2025-07-19T20:48:04.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.1.delta.36999fd3-b6d8-444e-9cb8-851d4b879e30.TID197.tmp
[2025-07-19T20:48:04.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.1.delta.c01c1670-f94d-4841-8c03-a992bf285c72.TID191.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta
[2025-07-19T20:48:04.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta
[2025-07-19T20:48:04.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 191, attempt 0, stage 5.0)
[2025-07-19T20:48:04.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10e142
[2025-07-19T20:48:04.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:04.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193] for update
[2025-07-19T20:48:04.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.1.delta.ae35f750-9a28-4e9b-b9e2-1dc2a567e320.TID195.tmp
[2025-07-19T20:48:04.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:04.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 168 (task 191, attempt 0, stage 5.0)
[2025-07-19T20:48:04.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 168.0 in stage 5.0 (TID 191). 6286 bytes result sent to driver
[2025-07-19T20:48:04.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.1.delta.3cb57de5-673f-413a-a385-a9d1a7dd3fe8.TID192.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta
[2025-07-19T20:48:04.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta
[2025-07-19T20:48:04.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 194.0 in stage 5.0 (TID 199) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:04.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 192, attempt 0, stage 5.0)
[2025-07-19T20:48:04.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 168.0 in stage 5.0 (TID 191) in 142 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:48:04.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 194.0 in stage 5.0 (TID 199)
[2025-07-19T20:48:04.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.1.delta.1b587419-4056-4e2f-ac4c-d2942967d38f.TID193.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta
[2025-07-19T20:48:04.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta
[2025-07-19T20:48:04.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 193, attempt 0, stage 5.0)
[2025-07-19T20:48:04.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:04.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 171 (task 192, attempt 0, stage 5.0)
[2025-07-19T20:48:04.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 171.0 in stage 5.0 (TID 192). 6243 bytes result sent to driver
[2025-07-19T20:48:04.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:05.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO DataWritingSparkTask: Committed partition 173 (task 193, attempt 0, stage 5.0)
[2025-07-19T20:48:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 196.0 in stage 5.0 (TID 200) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.1.delta.33798c30-770a-45aa-8174-048392fa4e58.TID198.tmp
[2025-07-19T20:48:05.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Running task 196.0 in stage 5.0 (TID 200)
[2025-07-19T20:48:05.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 171.0 in stage 5.0 (TID 192) in 156 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:48:05.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO Executor: Finished task 173.0 in stage 5.0 (TID 193). 6243 bytes result sent to driver
[2025-07-19T20:48:05.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Starting task 197.0 in stage 5.0 (TID 201) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO TaskSetManager: Finished task 173.0 in stage 5.0 (TID 193) in 156 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:48:05.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d0ce1c1
[2025-07-19T20:48:05.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:05.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194] for update
[2025-07-19T20:48:05.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 197.0 in stage 5.0 (TID 201)
[2025-07-19T20:48:05.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.1.delta.a5e12079-efc0-4d1b-9539-9eb43c7db0ac.TID194.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta
[2025-07-19T20:48:05.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta
[2025-07-19T20:48:05.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50b4e2a9
[2025-07-19T20:48:05.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:05.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196] for update
[2025-07-19T20:48:05.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.1.delta.36999fd3-b6d8-444e-9cb8-851d4b879e30.TID197.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta
[2025-07-19T20:48:05.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta
[2025-07-19T20:48:05.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 194, attempt 0, stage 5.0)
[2025-07-19T20:48:05.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 197, attempt 0, stage 5.0)
[2025-07-19T20:48:05.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c333349
[2025-07-19T20:48:05.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.1.delta.a8645aeb-8873-48d1-9461-d5b6281d5cd0.TID196.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta
[2025-07-19T20:48:05.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta
[2025-07-19T20:48:05.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:05.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197] for update
[2025-07-19T20:48:05.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 196, attempt 0, stage 5.0)
[2025-07-19T20:48:05.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 191 (task 197, attempt 0, stage 5.0)
[2025-07-19T20:48:05.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 176 (task 194, attempt 0, stage 5.0)
[2025-07-19T20:48:05.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 191.0 in stage 5.0 (TID 197). 6243 bytes result sent to driver
[2025-07-19T20:48:05.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 176.0 in stage 5.0 (TID 194). 6243 bytes result sent to driver
[2025-07-19T20:48:05.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 198.0 in stage 5.0 (TID 202) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.1.delta.a9dae308-847c-47fa-8e3b-bc995e23e85d.TID199.tmp
[2025-07-19T20:48:05.057+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 189 (task 196, attempt 0, stage 5.0)
[2025-07-19T20:48:05.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 176.0 in stage 5.0 (TID 194) in 153 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:48:05.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 198.0 in stage 5.0 (TID 202)
[2025-07-19T20:48:05.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.1.delta.f1e06463-77e5-4995-bb98-882c38703cad.TID200.tmp
[2025-07-19T20:48:05.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 203) (8b44f3d35cfa, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 189.0 in stage 5.0 (TID 196). 6243 bytes result sent to driver
[2025-07-19T20:48:05.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 203)
[2025-07-19T20:48:05.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 204) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 191.0 in stage 5.0 (TID 197) in 140 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:48:05.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 204)
[2025-07-19T20:48:05.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.1.delta.ae35f750-9a28-4e9b-b9e2-1dc2a567e320.TID195.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta
[2025-07-19T20:48:05.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 189.0 in stage 5.0 (TID 196) in 147 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:48:05.073+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta
[2025-07-19T20:48:05.074+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 195, attempt 0, stage 5.0)
[2025-07-19T20:48:05.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 184 (task 195, attempt 0, stage 5.0)
[2025-07-19T20:48:05.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@798f7a3c
[2025-07-19T20:48:05.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 184.0 in stage 5.0 (TID 195). 6243 bytes result sent to driver
[2025-07-19T20:48:05.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.1.delta.0c32030b-cdaa-4f60-b9f1-8ff14f64cc38.TID201.tmp
[2025-07-19T20:48:05.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.1.delta.33798c30-770a-45aa-8174-048392fa4e58.TID198.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta
[2025-07-19T20:48:05.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta
[2025-07-19T20:48:05.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 198, attempt 0, stage 5.0)
[2025-07-19T20:48:05.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],7dcfafb9-36e9-4e63-be5e-96bcfd822de6) is active
[2025-07-19T20:48:05.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198] for update
[2025-07-19T20:48:05.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 205) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 184.0 in stage 5.0 (TID 195) in 173 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:48:05.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 2.0 in stage 1.0 (TID 205)
[2025-07-19T20:48:05.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 193 (task 198, attempt 0, stage 5.0)
[2025-07-19T20:48:05.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 193.0 in stage 5.0 (TID 198). 6243 bytes result sent to driver
[2025-07-19T20:48:05.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 206) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 3.0 in stage 1.0 (TID 206)
[2025-07-19T20:48:05.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 193.0 in stage 5.0 (TID 198) in 144 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:48:05.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.1.delta.0379dbff-0f96-45bf-b88e-6efc9838f73c.TID202.tmp
[2025-07-19T20:48:05.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.1.delta.a9dae308-847c-47fa-8e3b-bc995e23e85d.TID199.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta
[2025-07-19T20:48:05.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta
[2025-07-19T20:48:05.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 199, attempt 0, stage 5.0)
[2025-07-19T20:48:05.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/.schema.74ee1fbe-55aa-49a7-a71e-1200f10a9495.TID203.tmp
[2025-07-19T20:48:05.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.1.delta.f1e06463-77e5-4995-bb98-882c38703cad.TID200.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta
[2025-07-19T20:48:05.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta
[2025-07-19T20:48:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 200, attempt 0, stage 5.0)
[2025-07-19T20:48:05.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 194 (task 199, attempt 0, stage 5.0)
[2025-07-19T20:48:05.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 194.0 in stage 5.0 (TID 199). 6200 bytes result sent to driver
[2025-07-19T20:48:05.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 207) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 194.0 in stage 5.0 (TID 199) in 133 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:48:05.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 4.0 in stage 1.0 (TID 207)
[2025-07-19T20:48:05.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 196 (task 200, attempt 0, stage 5.0)
[2025-07-19T20:48:05.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 196.0 in stage 5.0 (TID 200). 6200 bytes result sent to driver
[2025-07-19T20:48:05.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 208) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 7.0 in stage 1.0 (TID 208)
[2025-07-19T20:48:05.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 196.0 in stage 5.0 (TID 200) in 121 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:48:05.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.1.delta.0c32030b-cdaa-4f60-b9f1-8ff14f64cc38.TID201.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta
[2025-07-19T20:48:05.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta
[2025-07-19T20:48:05.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 201, attempt 0, stage 5.0)
[2025-07-19T20:48:05.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 197 (task 201, attempt 0, stage 5.0)
[2025-07-19T20:48:05.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 197.0 in stage 5.0 (TID 201). 6200 bytes result sent to driver
[2025-07-19T20:48:05.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 209) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 197.0 in stage 5.0 (TID 201) in 131 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:48:05.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 8.0 in stage 1.0 (TID 209)
[2025-07-19T20:48:05.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.1.delta.0379dbff-0f96-45bf-b88e-6efc9838f73c.TID202.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta
[2025-07-19T20:48:05.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta
[2025-07-19T20:48:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 202, attempt 0, stage 5.0)
[2025-07-19T20:48:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 198 (task 202, attempt 0, stage 5.0)
[2025-07-19T20:48:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 198.0 in stage 5.0 (TID 202). 6200 bytes result sent to driver
[2025-07-19T20:48:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 210) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 198.0 in stage 5.0 (TID 202) in 107 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:48:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-19T20:48:05.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 9.0 in stage 1.0 (TID 210)
[2025-07-19T20:48:05.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DAGScheduler: ResultStage 5 (start at <unknown>:0) finished in 5.413 s
[2025-07-19T20:48:05.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/.schema.74ee1fbe-55aa-49a7-a71e-1200f10a9495.TID203.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/schema
[2025-07-19T20:48:05.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e9039e9
[2025-07-19T20:48:05.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0] for update
[2025-07-19T20:48:05.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e61b8f
[2025-07-19T20:48:05.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:48:05.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-19T20:48:05.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1] for update
[2025-07-19T20:48:05.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 6.799988 s
[2025-07-19T20:48:05.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] is committing.
[2025-07-19T20:48:05.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO SparkWrite: Committing epoch 0 for query 4ea6f76f-42e1-458f-8af4-e164e5eb522c in append mode
[2025-07-19T20:48:05.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f2dd1fd
[2025-07-19T20:48:05.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9] for update
[2025-07-19T20:48:05.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.1.delta.8d1ae721-bc89-4302-8554-dbd548c9cafd.TID203.tmp
[2025-07-19T20:48:05.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23c8581a
[2025-07-19T20:48:05.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.196+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8] for update
[2025-07-19T20:48:05.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.1.delta.cf3c6007-1e40-47e0-98d6-773b3a9ba206.TID204.tmp
[2025-07-19T20:48:05.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45fa3d94
[2025-07-19T20:48:05.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7] for update
[2025-07-19T20:48:05.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.1.delta.7a05262c-1b27-4bd8-a62d-309ea2c728ca.TID210.tmp
[2025-07-19T20:48:05.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.1.delta.ff029faa-cc4e-4679-9eb2-786e11974630.TID209.tmp
[2025-07-19T20:48:05.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10d4ec57
[2025-07-19T20:48:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4] for update
[2025-07-19T20:48:05.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c0866a1
[2025-07-19T20:48:05.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO SparkWrite: Committing streaming append with 131 new data files to table my_catalog.bronze.Reservations_raw
[2025-07-19T20:48:05.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3] for update
[2025-07-19T20:48:05.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.1.delta.1fb285ca-6a84-4e1a-a61b-bd3053fbedda.TID208.tmp
[2025-07-19T20:48:05.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@499391be
[2025-07-19T20:48:05.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2] for update
[2025-07-19T20:48:05.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.1.delta.8d1ae721-bc89-4302-8554-dbd548c9cafd.TID203.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta
[2025-07-19T20:48:05.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta
[2025-07-19T20:48:05.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 203, attempt 0, stage 1.0)
[2025-07-19T20:48:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.1.delta.250fbac2-6ebb-45cf-a8f4-6e7628582e8b.TID207.tmp
[2025-07-19T20:48:05.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 0 (task 203, attempt 0, stage 1.0)
[2025-07-19T20:48:05.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 203). 9156 bytes result sent to driver
[2025-07-19T20:48:05.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.1.delta.6eba49df-80e0-468a-af0e-24fab96ff8ae.TID206.tmp
[2025-07-19T20:48:05.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 211) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 203) in 273 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:48:05.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 10.0 in stage 1.0 (TID 211)
[2025-07-19T20:48:05.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.1.delta.f08ca30d-4c1f-4b72-ad57-cae0957a62da.TID205.tmp
[2025-07-19T20:48:05.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.1.delta.cf3c6007-1e40-47e0-98d6-773b3a9ba206.TID204.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta
[2025-07-19T20:48:05.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta
[2025-07-19T20:48:05.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 204, attempt 0, stage 1.0)
[2025-07-19T20:48:05.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ffa248b
[2025-07-19T20:48:05.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.1.delta.ff029faa-cc4e-4679-9eb2-786e11974630.TID209.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta
[2025-07-19T20:48:05.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta
[2025-07-19T20:48:05.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10] for update
[2025-07-19T20:48:05.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 209, attempt 0, stage 1.0)
[2025-07-19T20:48:05.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.1.delta.7a05262c-1b27-4bd8-a62d-309ea2c728ca.TID210.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta
[2025-07-19T20:48:05.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta
[2025-07-19T20:48:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 210, attempt 0, stage 1.0)
[2025-07-19T20:48:05.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 8 (task 209, attempt 0, stage 1.0)
[2025-07-19T20:48:05.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.1.delta.192fab89-11c0-47bf-afdc-ae39422c7928.TID211.tmp
[2025-07-19T20:48:05.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 8.0 in stage 1.0 (TID 209). 9156 bytes result sent to driver
[2025-07-19T20:48:05.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 212) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 11.0 in stage 1.0 (TID 212)
[2025-07-19T20:48:05.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 209) in 229 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:48:05.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.1.delta.1fb285ca-6a84-4e1a-a61b-bd3053fbedda.TID208.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta
[2025-07-19T20:48:05.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta
[2025-07-19T20:48:05.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:05.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 9 (task 210, attempt 0, stage 1.0)
[2025-07-19T20:48:05.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 208, attempt 0, stage 1.0)
[2025-07-19T20:48:05.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 9.0 in stage 1.0 (TID 210). 9173 bytes result sent to driver
[2025-07-19T20:48:05.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 213) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 12.0 in stage 1.0 (TID 213)
[2025-07-19T20:48:05.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 210) in 228 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:48:05.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.1.delta.250fbac2-6ebb-45cf-a8f4-6e7628582e8b.TID207.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta
[2025-07-19T20:48:05.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta
[2025-07-19T20:48:05.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 207, attempt 0, stage 1.0)
[2025-07-19T20:48:05.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@795525b8
[2025-07-19T20:48:05.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:05.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11] for update
[2025-07-19T20:48:05.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f6ed167
[2025-07-19T20:48:05.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12] for update
[2025-07-19T20:48:05.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 7 (task 208, attempt 0, stage 1.0)
[2025-07-19T20:48:05.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.1.delta.6eba49df-80e0-468a-af0e-24fab96ff8ae.TID206.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta
[2025-07-19T20:48:05.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta
[2025-07-19T20:48:05.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 1 (task 204, attempt 0, stage 1.0)
[2025-07-19T20:48:05.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 206, attempt 0, stage 1.0)
[2025-07-19T20:48:05.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 7.0 in stage 1.0 (TID 208). 9148 bytes result sent to driver
[2025-07-19T20:48:05.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 204). 9167 bytes result sent to driver
[2025-07-19T20:48:05.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.1.delta.5a64aa9f-fef4-440e-a5b3-e0e7e7420948.TID212.tmp
[2025-07-19T20:48:05.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.1.delta.f08ca30d-4c1f-4b72-ad57-cae0957a62da.TID205.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta
[2025-07-19T20:48:05.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta
[2025-07-19T20:48:05.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 214) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 205, attempt 0, stage 1.0)
[2025-07-19T20:48:05.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 215) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 14.0 in stage 1.0 (TID 215)
[2025-07-19T20:48:05.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 13.0 in stage 1.0 (TID 214)
[2025-07-19T20:48:05.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:05.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 204) in 355 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:48:05.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 208) in 300 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:48:05.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@419a4f18
[2025-07-19T20:48:05.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.1.delta.192fab89-11c0-47bf-afdc-ae39422c7928.TID211.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta
[2025-07-19T20:48:05.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta
[2025-07-19T20:48:05.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.1.delta.6a8e75be-e989-475f-8eaf-1991ed7ce5d2.TID213.tmp
[2025-07-19T20:48:05.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 211, attempt 0, stage 1.0)
[2025-07-19T20:48:05.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14] for update
[2025-07-19T20:48:05.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 3 (task 206, attempt 0, stage 1.0)
[2025-07-19T20:48:05.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 4 (task 207, attempt 0, stage 1.0)
[2025-07-19T20:48:05.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 4.0 in stage 1.0 (TID 207). 9201 bytes result sent to driver
[2025-07-19T20:48:05.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 216) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 2 (task 205, attempt 0, stage 1.0)
[2025-07-19T20:48:05.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 2.0 in stage 1.0 (TID 205). 9156 bytes result sent to driver
[2025-07-19T20:48:05.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 207) in 356 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:48:05.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 15.0 in stage 1.0 (TID 216)
[2025-07-19T20:48:05.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 217) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 205) in 407 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:48:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 16.0 in stage 1.0 (TID 217)
[2025-07-19T20:48:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 3.0 in stage 1.0 (TID 206). 9195 bytes result sent to driver
[2025-07-19T20:48:05.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 218) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 18.0 in stage 1.0 (TID 218)
[2025-07-19T20:48:05.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33015f59
[2025-07-19T20:48:05.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.1.delta.8f5efcc7-5520-4c1d-9629-36a8e8d2a1d9.TID215.tmp
[2025-07-19T20:48:05.476+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 206) in 404 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:48:05.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13] for update
[2025-07-19T20:48:05.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:05.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14f3b033
[2025-07-19T20:48:05.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16] for update
[2025-07-19T20:48:05.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 10 (task 211, attempt 0, stage 1.0)
[2025-07-19T20:48:05.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.1.delta.5a64aa9f-fef4-440e-a5b3-e0e7e7420948.TID212.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta
[2025-07-19T20:48:05.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.1.delta.ff954cea-6fb6-4057-ae93-26c290268424.TID214.tmp
[2025-07-19T20:48:05.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta
[2025-07-19T20:48:05.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@359e83d1
[2025-07-19T20:48:05.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 10.0 in stage 1.0 (TID 211). 9200 bytes result sent to driver
[2025-07-19T20:48:05.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 219) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15] for update
[2025-07-19T20:48:05.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 20.0 in stage 1.0 (TID 219)
[2025-07-19T20:48:05.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 211) in 198 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:48:05.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 212, attempt 0, stage 1.0)
[2025-07-19T20:48:05.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.1.delta.edde4258-56fc-4cad-90b7-ee603b968597.TID217.tmp
[2025-07-19T20:48:05.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59587df3
[2025-07-19T20:48:05.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.1.delta.6a8e75be-e989-475f-8eaf-1991ed7ce5d2.TID213.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta
[2025-07-19T20:48:05.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta
[2025-07-19T20:48:05.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 213, attempt 0, stage 1.0)
[2025-07-19T20:48:05.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18] for update
[2025-07-19T20:48:05.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@331a49fc
[2025-07-19T20:48:05.536+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.536+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20] for update
[2025-07-19T20:48:05.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.1.delta.dc712a19-8726-4aaf-afb2-5cb4754ba214.TID216.tmp
[2025-07-19T20:48:05.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.1.delta.f5b42c75-9a79-4e2d-bc99-2d22aa0c3cf5.TID219.tmp
[2025-07-19T20:48:05.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.1.delta.12a030ed-6476-4ac1-9afe-117825eb4c8a.TID218.tmp
[2025-07-19T20:48:05.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.1.delta.8f5efcc7-5520-4c1d-9629-36a8e8d2a1d9.TID215.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta
[2025-07-19T20:48:05.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta
[2025-07-19T20:48:05.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 215, attempt 0, stage 1.0)
[2025-07-19T20:48:05.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 11 (task 212, attempt 0, stage 1.0)
[2025-07-19T20:48:05.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 11.0 in stage 1.0 (TID 212). 9149 bytes result sent to driver
[2025-07-19T20:48:05.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 220) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 212) in 215 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:48:05.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 8b44f3d35cfa:46433 in memory (size: 19.6 KiB, free: 434.2 MiB)
[2025-07-19T20:48:05.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 22.0 in stage 1.0 (TID 220)
[2025-07-19T20:48:05.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 12 (task 213, attempt 0, stage 1.0)
[2025-07-19T20:48:05.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:05.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 12.0 in stage 1.0 (TID 213). 9170 bytes result sent to driver
[2025-07-19T20:48:05.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 221) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 213) in 212 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:48:05.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 23.0 in stage 1.0 (TID 221)
[2025-07-19T20:48:05.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 14 (task 215, attempt 0, stage 1.0)
[2025-07-19T20:48:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 14.0 in stage 1.0 (TID 215). 9150 bytes result sent to driver
[2025-07-19T20:48:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 222) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 215) in 194 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:48:05.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 26.0 in stage 1.0 (TID 222)
[2025-07-19T20:48:05.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.1.delta.edde4258-56fc-4cad-90b7-ee603b968597.TID217.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta
[2025-07-19T20:48:05.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:05.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta
[2025-07-19T20:48:05.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:05.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 217, attempt 0, stage 1.0)
[2025-07-19T20:48:05.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.1.delta.ff954cea-6fb6-4057-ae93-26c290268424.TID214.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta
[2025-07-19T20:48:05.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta
[2025-07-19T20:48:05.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 214, attempt 0, stage 1.0)
[2025-07-19T20:48:05.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73611391
[2025-07-19T20:48:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22] for update
[2025-07-19T20:48:05.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@542b45c6
[2025-07-19T20:48:05.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23] for update
[2025-07-19T20:48:05.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.1.delta.12a030ed-6476-4ac1-9afe-117825eb4c8a.TID218.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta
[2025-07-19T20:48:05.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta
[2025-07-19T20:48:05.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 218, attempt 0, stage 1.0)
[2025-07-19T20:48:05.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.1.delta.f5b42c75-9a79-4e2d-bc99-2d22aa0c3cf5.TID219.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta
[2025-07-19T20:48:05.635+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta
[2025-07-19T20:48:05.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.1.delta.dc712a19-8726-4aaf-afb2-5cb4754ba214.TID216.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta
[2025-07-19T20:48:05.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta
[2025-07-19T20:48:05.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 16 (task 217, attempt 0, stage 1.0)
[2025-07-19T20:48:05.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 219, attempt 0, stage 1.0)
[2025-07-19T20:48:05.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 216, attempt 0, stage 1.0)
[2025-07-19T20:48:05.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 16.0 in stage 1.0 (TID 217). 9141 bytes result sent to driver
[2025-07-19T20:48:05.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.1.delta.18e36196-e130-4df9-82a0-05654285eccf.TID221.tmp
[2025-07-19T20:48:05.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 223) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 217) in 175 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:48:05.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 27.0 in stage 1.0 (TID 223)
[2025-07-19T20:48:05.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c0e6434
[2025-07-19T20:48:05.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26] for update
[2025-07-19T20:48:05.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 13 (task 214, attempt 0, stage 1.0)
[2025-07-19T20:48:05.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 13.0 in stage 1.0 (TID 214). 9172 bytes result sent to driver
[2025-07-19T20:48:05.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 224) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 28.0 in stage 1.0 (TID 224)
[2025-07-19T20:48:05.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 214) in 259 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:48:05.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@723ff5de
[2025-07-19T20:48:05.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.1.delta.3c3f5e66-ebd3-4470-93ec-1ad0f12dce71.TID220.tmp
[2025-07-19T20:48:05.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27] for update
[2025-07-19T20:48:05.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.1.delta.95803d3e-2f2d-450f-b9a6-f5a68399ace1.TID222.tmp
[2025-07-19T20:48:05.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 18 (task 218, attempt 0, stage 1.0)
[2025-07-19T20:48:05.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 20 (task 219, attempt 0, stage 1.0)
[2025-07-19T20:48:05.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 18.0 in stage 1.0 (TID 218). 9113 bytes result sent to driver
[2025-07-19T20:48:05.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 20.0 in stage 1.0 (TID 219). 9109 bytes result sent to driver
[2025-07-19T20:48:05.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.1.delta.c47e8200-f740-4be9-a529-3e74897dc824.TID223.tmp
[2025-07-19T20:48:05.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 15 (task 216, attempt 0, stage 1.0)
[2025-07-19T20:48:05.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 15.0 in stage 1.0 (TID 216). 9114 bytes result sent to driver
[2025-07-19T20:48:05.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64338f58
[2025-07-19T20:48:05.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 225) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 226) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 30.0 in stage 1.0 (TID 225)
[2025-07-19T20:48:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 227) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 218) in 208 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:48:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 31.0 in stage 1.0 (TID 226)
[2025-07-19T20:48:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 219) in 174 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:48:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 216) in 221 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:48:05.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 33.0 in stage 1.0 (TID 227)
[2025-07-19T20:48:05.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28] for update
[2025-07-19T20:48:05.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b0eb804
[2025-07-19T20:48:05.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.1.delta.18e36196-e130-4df9-82a0-05654285eccf.TID221.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta
[2025-07-19T20:48:05.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta
[2025-07-19T20:48:05.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 221, attempt 0, stage 1.0)
[2025-07-19T20:48:05.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31] for update
[2025-07-19T20:48:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2036251f
[2025-07-19T20:48:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.1.delta.3c3f5e66-ebd3-4470-93ec-1ad0f12dce71.TID220.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta
[2025-07-19T20:48:05.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta
[2025-07-19T20:48:05.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30] for update
[2025-07-19T20:48:05.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 220, attempt 0, stage 1.0)
[2025-07-19T20:48:05.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.1.delta.2e2198e5-0bb2-47a9-bbe6-e490684f0b78.TID226.tmp
[2025-07-19T20:48:05.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.1.delta.8418d357-9d4e-4932-be69-a6bc914bdc93.TID224.tmp
[2025-07-19T20:48:05.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.1.delta.c47e8200-f740-4be9-a529-3e74897dc824.TID223.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta
[2025-07-19T20:48:05.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta
[2025-07-19T20:48:05.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 223, attempt 0, stage 1.0)
[2025-07-19T20:48:05.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 23 (task 221, attempt 0, stage 1.0)
[2025-07-19T20:48:05.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 23.0 in stage 1.0 (TID 221). 9128 bytes result sent to driver
[2025-07-19T20:48:05.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f8e3b0c
[2025-07-19T20:48:05.735+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 228) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 35.0 in stage 1.0 (TID 228)
[2025-07-19T20:48:05.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 221) in 153 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:48:05.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 22 (task 220, attempt 0, stage 1.0)
[2025-07-19T20:48:05.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.1.delta.9dcb6712-b6ce-4662-ae7b-4cf2d3ff434c.TID225.tmp
[2025-07-19T20:48:05.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 22.0 in stage 1.0 (TID 220). 9106 bytes result sent to driver
[2025-07-19T20:48:05.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33] for update
[2025-07-19T20:48:05.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 229) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 37.0 in stage 1.0 (TID 229)
[2025-07-19T20:48:05.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 220) in 178 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:48:05.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f8fec13
[2025-07-19T20:48:05.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35] for update
[2025-07-19T20:48:05.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.1.delta.9bc6da02-6daf-4ca6-a27e-a71d358ffc98.TID227.tmp
[2025-07-19T20:48:05.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 27 (task 223, attempt 0, stage 1.0)
[2025-07-19T20:48:05.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 27.0 in stage 1.0 (TID 223). 9113 bytes result sent to driver
[2025-07-19T20:48:05.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 230) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 223) in 121 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:48:05.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 38.0 in stage 1.0 (TID 230)
[2025-07-19T20:48:05.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ef2c263
[2025-07-19T20:48:05.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37] for update
[2025-07-19T20:48:05.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.1.delta.54071521-20b4-4e63-b7bc-e0e15509653c.TID228.tmp
[2025-07-19T20:48:05.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.1.delta.95803d3e-2f2d-450f-b9a6-f5a68399ace1.TID222.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta
[2025-07-19T20:48:05.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta
[2025-07-19T20:48:05.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 222, attempt 0, stage 1.0)
[2025-07-19T20:48:05.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d5e27a6
[2025-07-19T20:48:05.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.1.delta.8418d357-9d4e-4932-be69-a6bc914bdc93.TID224.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta
[2025-07-19T20:48:05.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta
[2025-07-19T20:48:05.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38] for update
[2025-07-19T20:48:05.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 224, attempt 0, stage 1.0)
[2025-07-19T20:48:05.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.1.delta.83ace134-3bd1-4bf8-bbc8-aba3ec1b4307.TID229.tmp
[2025-07-19T20:48:05.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.1.delta.5dd59da4-de96-49a9-b4dc-693282749e15.TID230.tmp
[2025-07-19T20:48:05.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.1.delta.2e2198e5-0bb2-47a9-bbe6-e490684f0b78.TID226.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta
[2025-07-19T20:48:05.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta
[2025-07-19T20:48:05.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 226, attempt 0, stage 1.0)
[2025-07-19T20:48:05.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.1.delta.9dcb6712-b6ce-4662-ae7b-4cf2d3ff434c.TID225.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta
[2025-07-19T20:48:05.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.1.delta.9bc6da02-6daf-4ca6-a27e-a71d358ffc98.TID227.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 225, attempt 0, stage 1.0)
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 227, attempt 0, stage 1.0)
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.1.delta.54071521-20b4-4e63-b7bc-e0e15509653c.TID228.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta
[2025-07-19T20:48:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 228, attempt 0, stage 1.0)
[2025-07-19T20:48:05.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 26 (task 222, attempt 0, stage 1.0)
[2025-07-19T20:48:05.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 28 (task 224, attempt 0, stage 1.0)
[2025-07-19T20:48:05.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 26.0 in stage 1.0 (TID 222). 9117 bytes result sent to driver
[2025-07-19T20:48:05.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 28.0 in stage 1.0 (TID 224). 9171 bytes result sent to driver
[2025-07-19T20:48:05.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 231) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 31 (task 226, attempt 0, stage 1.0)
[2025-07-19T20:48:05.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 222) in 257 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:48:05.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 39.0 in stage 1.0 (TID 231)
[2025-07-19T20:48:05.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 31.0 in stage 1.0 (TID 226). 9125 bytes result sent to driver
[2025-07-19T20:48:05.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 232) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 233) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 226) in 170 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:48:05.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 42.0 in stage 1.0 (TID 233)
[2025-07-19T20:48:05.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 224) in 202 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:48:05.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 35 (task 228, attempt 0, stage 1.0)
[2025-07-19T20:48:05.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 33 (task 227, attempt 0, stage 1.0)
[2025-07-19T20:48:05.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 30 (task 225, attempt 0, stage 1.0)
[2025-07-19T20:48:05.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.1.delta.83ace134-3bd1-4bf8-bbc8-aba3ec1b4307.TID229.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta
[2025-07-19T20:48:05.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta
[2025-07-19T20:48:05.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 30.0 in stage 1.0 (TID 225). 9120 bytes result sent to driver
[2025-07-19T20:48:05.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 41.0 in stage 1.0 (TID 232)
[2025-07-19T20:48:05.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 234) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 43.0 in stage 1.0 (TID 234)
[2025-07-19T20:48:05.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 35.0 in stage 1.0 (TID 228). 9105 bytes result sent to driver
[2025-07-19T20:48:05.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 33.0 in stage 1.0 (TID 227). 9157 bytes result sent to driver
[2025-07-19T20:48:05.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 225) in 186 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:48:05.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 229, attempt 0, stage 1.0)
[2025-07-19T20:48:05.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 235) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 236) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 46.0 in stage 1.0 (TID 236)
[2025-07-19T20:48:05.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 227) in 179 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:48:05.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 228) in 126 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:48:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d1919e5
[2025-07-19T20:48:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39] for update
[2025-07-19T20:48:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 45.0 in stage 1.0 (TID 235)
[2025-07-19T20:48:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:05.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c8460fe
[2025-07-19T20:48:05.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41] for update
[2025-07-19T20:48:05.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.1.delta.5dd59da4-de96-49a9-b4dc-693282749e15.TID230.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta
[2025-07-19T20:48:05.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta
[2025-07-19T20:48:05.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 230, attempt 0, stage 1.0)
[2025-07-19T20:48:05.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.1.delta.1f1a875e-8e78-4265-b8e1-cbc0ac609185.TID231.tmp
[2025-07-19T20:48:05.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.1.delta.c6c9bc2e-2b34-4fac-b8e8-304c4c94f8c7.TID232.tmp
[2025-07-19T20:48:05.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66ac65e7
[2025-07-19T20:48:05.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42] for update
[2025-07-19T20:48:05.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 37 (task 229, attempt 0, stage 1.0)
[2025-07-19T20:48:05.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 37.0 in stage 1.0 (TID 229). 9113 bytes result sent to driver
[2025-07-19T20:48:05.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 237) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 229) in 152 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:48:05.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 47.0 in stage 1.0 (TID 237)
[2025-07-19T20:48:05.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@120ca2d7
[2025-07-19T20:48:05.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43] for update
[2025-07-19T20:48:05.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 38 (task 230, attempt 0, stage 1.0)
[2025-07-19T20:48:05.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 38.0 in stage 1.0 (TID 230). 9119 bytes result sent to driver
[2025-07-19T20:48:05.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 238) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 48.0 in stage 1.0 (TID 238)
[2025-07-19T20:48:05.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 230) in 137 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:48:05.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d17a595
[2025-07-19T20:48:05.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45] for update
[2025-07-19T20:48:05.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.1.delta.2fad6361-bc9d-4ce5-87f2-db9658463a56.TID234.tmp
[2025-07-19T20:48:05.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1047a56a
[2025-07-19T20:48:05.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46] for update
[2025-07-19T20:48:05.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@202ebc60
[2025-07-19T20:48:05.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.1.delta.0d558e63-5974-4e39-ba56-326ae4fb0580.TID233.tmp
[2025-07-19T20:48:05.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47] for update
[2025-07-19T20:48:05.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.1.delta.6f3aa198-b446-48e3-b0f3-0fadc89c490d.TID236.tmp
[2025-07-19T20:48:05.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.1.delta.8b65dbca-22ea-405e-8115-1a9ef8d69c48.TID235.tmp
[2025-07-19T20:48:05.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b2a2105
[2025-07-19T20:48:05.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:05.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48] for update
[2025-07-19T20:48:05.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:05.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.1.delta.1f1a875e-8e78-4265-b8e1-cbc0ac609185.TID231.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta
[2025-07-19T20:48:05.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta
[2025-07-19T20:48:05.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 231, attempt 0, stage 1.0)
[2025-07-19T20:48:05.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.1.delta.c6c9bc2e-2b34-4fac-b8e8-304c4c94f8c7.TID232.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta
[2025-07-19T20:48:05.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.1.delta.d569712e-7e4a-4ae7-bddf-1a84b7a5c8c8.TID237.tmp
[2025-07-19T20:48:05.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta
[2025-07-19T20:48:05.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 232, attempt 0, stage 1.0)
[2025-07-19T20:48:05.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.1.delta.5366c2d2-516f-4ed3-b829-9c96153e0fba.TID238.tmp
[2025-07-19T20:48:05.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.1.delta.2fad6361-bc9d-4ce5-87f2-db9658463a56.TID234.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta
[2025-07-19T20:48:05.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta
[2025-07-19T20:48:05.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 234, attempt 0, stage 1.0)
[2025-07-19T20:48:05.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 39 (task 231, attempt 0, stage 1.0)
[2025-07-19T20:48:05.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 39.0 in stage 1.0 (TID 231). 9103 bytes result sent to driver
[2025-07-19T20:48:05.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 239) (8b44f3d35cfa, executor driver, partition 50, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:05.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Committed partition 41 (task 232, attempt 0, stage 1.0)
[2025-07-19T20:48:05.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 50.0 in stage 1.0 (TID 239)
[2025-07-19T20:48:05.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Finished task 41.0 in stage 1.0 (TID 232). 9130 bytes result sent to driver
[2025-07-19T20:48:05.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:05.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:05.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.1.delta.6f3aa198-b446-48e3-b0f3-0fadc89c490d.TID236.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta
[2025-07-19T20:48:05.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta
[2025-07-19T20:48:05.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 236, attempt 0, stage 1.0)
[2025-07-19T20:48:05.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.1.delta.0d558e63-5974-4e39-ba56-326ae4fb0580.TID233.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta
[2025-07-19T20:48:05.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta
[2025-07-19T20:48:05.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 233, attempt 0, stage 1.0)
[2025-07-19T20:48:05.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.1.delta.8b65dbca-22ea-405e-8115-1a9ef8d69c48.TID235.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta
[2025-07-19T20:48:05.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta
[2025-07-19T20:48:06.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 235, attempt 0, stage 1.0)
[2025-07-19T20:48:06.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 240) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 232) in 153 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:48:06.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO Executor: Running task 51.0 in stage 1.0 (TID 240)
[2025-07-19T20:48:06.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 231) in 156 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:48:06.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e122dcc
[2025-07-19T20:48:06.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50] for update
[2025-07-19T20:48:06.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.1.delta.d569712e-7e4a-4ae7-bddf-1a84b7a5c8c8.TID237.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta
[2025-07-19T20:48:06.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta
[2025-07-19T20:48:06.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 237, attempt 0, stage 1.0)
[2025-07-19T20:48:06.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b14efa6
[2025-07-19T20:48:06.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.1.delta.808f6bf7-cb16-4fcc-8396-6cfb11b2bb97.TID239.tmp
[2025-07-19T20:48:06.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51] for update
[2025-07-19T20:48:06.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.1.delta.5366c2d2-516f-4ed3-b829-9c96153e0fba.TID238.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta
[2025-07-19T20:48:06.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta
[2025-07-19T20:48:06.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 43 (task 234, attempt 0, stage 1.0)
[2025-07-19T20:48:06.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 238, attempt 0, stage 1.0)
[2025-07-19T20:48:06.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 43.0 in stage 1.0 (TID 234). 9094 bytes result sent to driver
[2025-07-19T20:48:06.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 46 (task 236, attempt 0, stage 1.0)
[2025-07-19T20:48:06.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 241) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 46.0 in stage 1.0 (TID 236). 9105 bytes result sent to driver
[2025-07-19T20:48:06.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 42 (task 233, attempt 0, stage 1.0)
[2025-07-19T20:48:06.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 42.0 in stage 1.0 (TID 233). 9117 bytes result sent to driver
[2025-07-19T20:48:06.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 242) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 243) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 54.0 in stage 1.0 (TID 242)
[2025-07-19T20:48:06.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 234) in 173 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:48:06.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 236) in 169 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:48:06.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 233) in 179 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:48:06.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 55.0 in stage 1.0 (TID 243)
[2025-07-19T20:48:06.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 52.0 in stage 1.0 (TID 241)
[2025-07-19T20:48:06.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.1.delta.36983428-22f0-4c83-803e-4d9b8ef1dcf2.TID240.tmp
[2025-07-19T20:48:06.073+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b4d7e8f
[2025-07-19T20:48:06.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54] for update
[2025-07-19T20:48:06.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 45 (task 235, attempt 0, stage 1.0)
[2025-07-19T20:48:06.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 45.0 in stage 1.0 (TID 235). 9105 bytes result sent to driver
[2025-07-19T20:48:06.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 244) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 235) in 201 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:48:06.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 56.0 in stage 1.0 (TID 244)
[2025-07-19T20:48:06.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 48 (task 238, attempt 0, stage 1.0)
[2025-07-19T20:48:06.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 47 (task 237, attempt 0, stage 1.0)
[2025-07-19T20:48:06.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 48.0 in stage 1.0 (TID 238). 9152 bytes result sent to driver
[2025-07-19T20:48:06.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 47.0 in stage 1.0 (TID 237). 9101 bytes result sent to driver
[2025-07-19T20:48:06.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 245) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 246) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 238) in 171 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:48:06.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 59.0 in stage 1.0 (TID 246)
[2025-07-19T20:48:06.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 58.0 in stage 1.0 (TID 245)
[2025-07-19T20:48:06.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 237) in 177 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:48:06.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@365946b4
[2025-07-19T20:48:06.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55] for update
[2025-07-19T20:48:06.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.1.delta.e6d5409a-c096-4eeb-af2e-dad1d3bc206a.TID242.tmp
[2025-07-19T20:48:06.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e79001c
[2025-07-19T20:48:06.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58] for update
[2025-07-19T20:48:06.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.1.delta.808f6bf7-cb16-4fcc-8396-6cfb11b2bb97.TID239.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta
[2025-07-19T20:48:06.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta
[2025-07-19T20:48:06.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 239, attempt 0, stage 1.0)
[2025-07-19T20:48:06.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.1.delta.e791c34b-257e-4394-8f45-2af0c7bf0398.TID243.tmp
[2025-07-19T20:48:06.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4094a67c
[2025-07-19T20:48:06.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59] for update
[2025-07-19T20:48:06.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.1.delta.36983428-22f0-4c83-803e-4d9b8ef1dcf2.TID240.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta
[2025-07-19T20:48:06.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta
[2025-07-19T20:48:06.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 240, attempt 0, stage 1.0)
[2025-07-19T20:48:06.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59a7738d
[2025-07-19T20:48:06.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52] for update
[2025-07-19T20:48:06.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.1.delta.83062544-fe5b-49fa-86f1-54e07ab926d9.TID245.tmp
[2025-07-19T20:48:06.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.1.delta.183fffa0-f81d-49ef-b886-2a80d7277f41.TID246.tmp
[2025-07-19T20:48:06.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 50 (task 239, attempt 0, stage 1.0)
[2025-07-19T20:48:06.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 50.0 in stage 1.0 (TID 239). 9160 bytes result sent to driver
[2025-07-19T20:48:06.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 239) in 186 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:48:06.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 247) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 60.0 in stage 1.0 (TID 247)
[2025-07-19T20:48:06.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 51 (task 240, attempt 0, stage 1.0)
[2025-07-19T20:48:06.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 51.0 in stage 1.0 (TID 240). 9150 bytes result sent to driver
[2025-07-19T20:48:06.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42584cf
[2025-07-19T20:48:06.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:06.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56] for update
[2025-07-19T20:48:06.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Reservations_raw/metadata/v61.metadata.json
[2025-07-19T20:48:06.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 248) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.1.delta.eeea9b55-b771-4a3c-a182-aa35f10d94be.TID241.tmp
[2025-07-19T20:48:06.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 240) in 191 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:48:06.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 62.0 in stage 1.0 (TID 248)
[2025-07-19T20:48:06.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:48:06.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.1.delta.e791c34b-257e-4394-8f45-2af0c7bf0398.TID243.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta
[2025-07-19T20:48:06.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta
[2025-07-19T20:48:06.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.1.delta.e6d5409a-c096-4eeb-af2e-dad1d3bc206a.TID242.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta
[2025-07-19T20:48:06.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta
[2025-07-19T20:48:06.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 243, attempt 0, stage 1.0)
[2025-07-19T20:48:06.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 242, attempt 0, stage 1.0)
[2025-07-19T20:48:06.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fc1956c
[2025-07-19T20:48:06.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.1.delta.a5fc52c8-5df2-4ee9-bc73-8dfe35050cd5.TID244.tmp
[2025-07-19T20:48:06.223+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60] for update
[2025-07-19T20:48:06.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.1.delta.83062544-fe5b-49fa-86f1-54e07ab926d9.TID245.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta
[2025-07-19T20:48:06.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta
[2025-07-19T20:48:06.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 245, attempt 0, stage 1.0)
[2025-07-19T20:48:06.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@437e9e1f
[2025-07-19T20:48:06.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62] for update
[2025-07-19T20:48:06.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.1.delta.b7b081dc-dafb-4fc5-8408-5cbde3e862a0.TID247.tmp
[2025-07-19T20:48:06.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 54 (task 242, attempt 0, stage 1.0)
[2025-07-19T20:48:06.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.1.delta.183fffa0-f81d-49ef-b886-2a80d7277f41.TID246.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta
[2025-07-19T20:48:06.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta
[2025-07-19T20:48:06.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 54.0 in stage 1.0 (TID 242). 9164 bytes result sent to driver
[2025-07-19T20:48:06.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 246, attempt 0, stage 1.0)
[2025-07-19T20:48:06.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 249) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 242) in 266 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:48:06.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 58 (task 245, attempt 0, stage 1.0)
[2025-07-19T20:48:06.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 63.0 in stage 1.0 (TID 249)
[2025-07-19T20:48:06.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 58.0 in stage 1.0 (TID 245). 9141 bytes result sent to driver
[2025-07-19T20:48:06.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 250) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 65.0 in stage 1.0 (TID 250)
[2025-07-19T20:48:06.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 245) in 236 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:48:06.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.1.delta.d04ee1b7-802a-429d-8b35-15532a7a7ce7.TID248.tmp
[2025-07-19T20:48:06.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2452a7ce
[2025-07-19T20:48:06.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 55 (task 243, attempt 0, stage 1.0)
[2025-07-19T20:48:06.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65] for update
[2025-07-19T20:48:06.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.1.delta.a5fc52c8-5df2-4ee9-bc73-8dfe35050cd5.TID244.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta
[2025-07-19T20:48:06.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta
[2025-07-19T20:48:06.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 59 (task 246, attempt 0, stage 1.0)
[2025-07-19T20:48:06.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 55.0 in stage 1.0 (TID 243). 9195 bytes result sent to driver
[2025-07-19T20:48:06.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 251) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42ca2de6
[2025-07-19T20:48:06.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 66.0 in stage 1.0 (TID 251)
[2025-07-19T20:48:06.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 243) in 301 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:48:06.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 244, attempt 0, stage 1.0)
[2025-07-19T20:48:06.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63] for update
[2025-07-19T20:48:06.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 59.0 in stage 1.0 (TID 246). 9162 bytes result sent to driver
[2025-07-19T20:48:06.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.336+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 252) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 67.0 in stage 1.0 (TID 252)
[2025-07-19T20:48:06.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 246) in 271 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:48:06.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.1.delta.610a5e2f-a06e-4229-8e15-284d46c0801c.TID250.tmp
[2025-07-19T20:48:06.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a70a9bc
[2025-07-19T20:48:06.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66] for update
[2025-07-19T20:48:06.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.1.delta.eeea9b55-b771-4a3c-a182-aa35f10d94be.TID241.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta
[2025-07-19T20:48:06.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta
[2025-07-19T20:48:06.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 241, attempt 0, stage 1.0)
[2025-07-19T20:48:06.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 56 (task 244, attempt 0, stage 1.0)
[2025-07-19T20:48:06.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 56.0 in stage 1.0 (TID 244). 9152 bytes result sent to driver
[2025-07-19T20:48:06.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 244) in 296 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:48:06.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 253) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 68.0 in stage 1.0 (TID 253)
[2025-07-19T20:48:06.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.1.delta.b7b081dc-dafb-4fc5-8408-5cbde3e862a0.TID247.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta
[2025-07-19T20:48:06.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta
[2025-07-19T20:48:06.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 247, attempt 0, stage 1.0)
[2025-07-19T20:48:06.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.1.delta.d04ee1b7-802a-429d-8b35-15532a7a7ce7.TID248.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta
[2025-07-19T20:48:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta
[2025-07-19T20:48:06.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 248, attempt 0, stage 1.0)
[2025-07-19T20:48:06.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@649bedd5
[2025-07-19T20:48:06.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.1.delta.fd1a7a93-77e2-4823-be3a-e81528e4ff45.TID249.tmp
[2025-07-19T20:48:06.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.1.delta.9a832128-ef20-4424-8ccb-7093c2102e4a.TID251.tmp
[2025-07-19T20:48:06.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO SnapshotProducer: Committed snapshot 4638335287598733553 (FastAppend)
[2025-07-19T20:48:06.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67] for update
[2025-07-19T20:48:06.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 60 (task 247, attempt 0, stage 1.0)
[2025-07-19T20:48:06.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 52 (task 241, attempt 0, stage 1.0)
[2025-07-19T20:48:06.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 52.0 in stage 1.0 (TID 241). 9160 bytes result sent to driver
[2025-07-19T20:48:06.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 62 (task 248, attempt 0, stage 1.0)
[2025-07-19T20:48:06.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 62.0 in stage 1.0 (TID 248). 9144 bytes result sent to driver
[2025-07-19T20:48:06.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 254) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 71.0 in stage 1.0 (TID 254)
[2025-07-19T20:48:06.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 60.0 in stage 1.0 (TID 247). 9170 bytes result sent to driver
[2025-07-19T20:48:06.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.1.delta.10422056-9002-418f-b8ad-7a1907428b01.TID252.tmp
[2025-07-19T20:48:06.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 255) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@135e769e
[2025-07-19T20:48:06.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 256) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.1.delta.610a5e2f-a06e-4229-8e15-284d46c0801c.TID250.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta
[2025-07-19T20:48:06.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta
[2025-07-19T20:48:06.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 241) in 376 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:48:06.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 247) in 233 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:48:06.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 248) in 225 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:48:06.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 72.0 in stage 1.0 (TID 255)
[2025-07-19T20:48:06.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 250, attempt 0, stage 1.0)
[2025-07-19T20:48:06.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68] for update
[2025-07-19T20:48:06.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:06.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 74.0 in stage 1.0 (TID 256)
[2025-07-19T20:48:06.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39ca8395
[2025-07-19T20:48:06.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71] for update
[2025-07-19T20:48:06.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.1.delta.fd1a7a93-77e2-4823-be3a-e81528e4ff45.TID249.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta
[2025-07-19T20:48:06.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta
[2025-07-19T20:48:06.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 249, attempt 0, stage 1.0)
[2025-07-19T20:48:06.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31e14984
[2025-07-19T20:48:06.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72] for update
[2025-07-19T20:48:06.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 65 (task 250, attempt 0, stage 1.0)
[2025-07-19T20:48:06.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 65.0 in stage 1.0 (TID 250). 9115 bytes result sent to driver
[2025-07-19T20:48:06.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 257) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 250) in 136 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:48:06.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 75.0 in stage 1.0 (TID 257)
[2025-07-19T20:48:06.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.1.delta.52eb5d11-d4e7-41ef-a0d9-03579276a28d.TID254.tmp
[2025-07-19T20:48:06.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.1.delta.47e0f909-70a2-4682-9bd7-67ab15f2437f.TID253.tmp
[2025-07-19T20:48:06.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47c9e911
[2025-07-19T20:48:06.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74] for update
[2025-07-19T20:48:06.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.1.delta.2598c83f-c9a8-43e0-afea-9c30d88e896b.TID255.tmp
[2025-07-19T20:48:06.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Reservations_raw, snapshotId=4638335287598733553, sequenceNumber=60, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT1.16858825S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=131}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5633}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=215}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=7819}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=392087}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=16785349}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958074309, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:48:06.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO SparkWrite: Committed in 1217 ms
[2025-07-19T20:48:06.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 63 (task 249, attempt 0, stage 1.0)
[2025-07-19T20:48:06.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 63.0 in stage 1.0 (TID 249). 9117 bytes result sent to driver
[2025-07-19T20:48:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] committed.
[2025-07-19T20:48:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 258) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36410b7e
[2025-07-19T20:48:06.477+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 76.0 in stage 1.0 (TID 258)
[2025-07-19T20:48:06.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 249) in 180 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:48:06.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75] for update
[2025-07-19T20:48:06.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:06.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.1.delta.8f01048b-0b96-45a3-80b5-d9b7a44a7591.TID256.tmp
[2025-07-19T20:48:06.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.1.delta.9a832128-ef20-4424-8ccb-7093c2102e4a.TID251.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta
[2025-07-19T20:48:06.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta
[2025-07-19T20:48:06.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 251, attempt 0, stage 1.0)
[2025-07-19T20:48:06.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c1bbd0a
[2025-07-19T20:48:06.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76] for update
[2025-07-19T20:48:06.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.1.delta.52eb5d11-d4e7-41ef-a0d9-03579276a28d.TID254.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta
[2025-07-19T20:48:06.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.1.delta.7e99ac79-e5da-41e3-b465-5744033d0e4c.TID257.tmp
[2025-07-19T20:48:06.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta
[2025-07-19T20:48:06.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.1.delta.10422056-9002-418f-b8ad-7a1907428b01.TID252.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta
[2025-07-19T20:48:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta
[2025-07-19T20:48:06.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 254, attempt 0, stage 1.0)
[2025-07-19T20:48:06.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/commits/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/commits/.0.174fa3e3-b072-4da5-a09a-d7e98fe86a76.tmp
[2025-07-19T20:48:06.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 252, attempt 0, stage 1.0)
[2025-07-19T20:48:06.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.1.delta.efb1afc8-f6f7-4d9a-83e3-d93c80e7f2f1.TID258.tmp
[2025-07-19T20:48:06.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.1.delta.2598c83f-c9a8-43e0-afea-9c30d88e896b.TID255.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta
[2025-07-19T20:48:06.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta
[2025-07-19T20:48:06.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 71 (task 254, attempt 0, stage 1.0)
[2025-07-19T20:48:06.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 255, attempt 0, stage 1.0)
[2025-07-19T20:48:06.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 66 (task 251, attempt 0, stage 1.0)
[2025-07-19T20:48:06.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 67 (task 252, attempt 0, stage 1.0)
[2025-07-19T20:48:06.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 71.0 in stage 1.0 (TID 254). 9165 bytes result sent to driver
[2025-07-19T20:48:06.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 259) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 67.0 in stage 1.0 (TID 252). 9117 bytes result sent to driver
[2025-07-19T20:48:06.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 260) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 252) in 202 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:48:06.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 254) in 147 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:48:06.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 77.0 in stage 1.0 (TID 259)
[2025-07-19T20:48:06.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 78.0 in stage 1.0 (TID 260)
[2025-07-19T20:48:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.1.delta.47e0f909-70a2-4682-9bd7-67ab15f2437f.TID253.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta
[2025-07-19T20:48:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta
[2025-07-19T20:48:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 66.0 in stage 1.0 (TID 251). 9099 bytes result sent to driver
[2025-07-19T20:48:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 72 (task 255, attempt 0, stage 1.0)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 72.0 in stage 1.0 (TID 255). 9119 bytes result sent to driver
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 261) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 262) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 251) in 226 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 255) in 159 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 79.0 in stage 1.0 (TID 261)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 253, attempt 0, stage 1.0)
[2025-07-19T20:48:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 80.0 in stage 1.0 (TID 262)
[2025-07-19T20:48:06.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.1.delta.8f01048b-0b96-45a3-80b5-d9b7a44a7591.TID256.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta
[2025-07-19T20:48:06.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta
[2025-07-19T20:48:06.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 256, attempt 0, stage 1.0)
[2025-07-19T20:48:06.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.1.delta.7e99ac79-e5da-41e3-b465-5744033d0e4c.TID257.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta
[2025-07-19T20:48:06.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta
[2025-07-19T20:48:06.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 257, attempt 0, stage 1.0)
[2025-07-19T20:48:06.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a1f790
[2025-07-19T20:48:06.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77] for update
[2025-07-19T20:48:06.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/commits/.0.174fa3e3-b072-4da5-a09a-d7e98fe86a76.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:44:00+00:00/commits/0
[2025-07-19T20:48:06.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13bee15a
[2025-07-19T20:48:06.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 75 (task 257, attempt 0, stage 1.0)
[2025-07-19T20:48:06.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80] for update
[2025-07-19T20:48:06.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 75.0 in stage 1.0 (TID 257). 9135 bytes result sent to driver
[2025-07-19T20:48:06.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 263) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 82.0 in stage 1.0 (TID 263)
[2025-07-19T20:48:06.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 74 (task 256, attempt 0, stage 1.0)
[2025-07-19T20:48:06.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 257) in 152 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:48:06.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.1.delta.71502a75-2af5-450b-b231-ed5ec3169b8b.TID259.tmp
[2025-07-19T20:48:06.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:06.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 74.0 in stage 1.0 (TID 256). 9113 bytes result sent to driver
[2025-07-19T20:48:06.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 264) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 83.0 in stage 1.0 (TID 264)
[2025-07-19T20:48:06.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 256) in 194 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:48:06.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 68 (task 253, attempt 0, stage 1.0)
[2025-07-19T20:48:06.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 68.0 in stage 1.0 (TID 253). 9119 bytes result sent to driver
[2025-07-19T20:48:06.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 265) (8b44f3d35cfa, executor driver, partition 84, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.1.delta.5337834f-dc12-49ed-a434-2a7c04f382a8.TID262.tmp
[2025-07-19T20:48:06.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 84.0 in stage 1.0 (TID 265)
[2025-07-19T20:48:06.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 253) in 247 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:48:06.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:06.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7eeb23a3
[2025-07-19T20:48:06.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79] for update
[2025-07-19T20:48:06.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24af9f17
[2025-07-19T20:48:06.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78] for update
[2025-07-19T20:48:06.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.1.delta.efb1afc8-f6f7-4d9a-83e3-d93c80e7f2f1.TID258.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta
[2025-07-19T20:48:06.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta
[2025-07-19T20:48:06.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f4fde5
[2025-07-19T20:48:06.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84] for update
[2025-07-19T20:48:06.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 258, attempt 0, stage 1.0)
[2025-07-19T20:48:06.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.1.delta.5fecb06c-dd00-4275-8ece-95fe726a53b6.TID261.tmp
[2025-07-19T20:48:06.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.1.delta.f214d7aa-da2d-40cd-8aef-168c58c6c182.TID260.tmp
[2025-07-19T20:48:06.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:48:06.632+0000] {subprocess.py:93} INFO -   "id" : "4ea6f76f-42e1-458f-8af4-e164e5eb522c",
[2025-07-19T20:48:06.633+0000] {subprocess.py:93} INFO -   "runId" : "7dcfafb9-36e9-4e63-be5e-96bcfd822de6",
[2025-07-19T20:48:06.636+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:48:06.639+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:47:56.606Z",
[2025-07-19T20:48:06.642+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T20:48:06.642+0000] {subprocess.py:93} INFO -   "numInputRows" : 222,
[2025-07-19T20:48:06.642+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:06.642+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 22.286918984037747,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "addBatch" : 8769,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "commitOffsets" : 91,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "getBatch" : 8,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "latestOffset" : 579,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "queryPlanning" : 442,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "triggerExecution" : 9960,
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "walCommit" : 44
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:48:06.643+0000] {subprocess.py:93} INFO -     "avg" : "1970-01-01T00:00:00.000Z",
[2025-07-19T20:48:06.644+0000] {subprocess.py:93} INFO -     "max" : "1970-01-01T00:00:00.000Z",
[2025-07-19T20:48:06.644+0000] {subprocess.py:93} INFO -     "min" : "1970-01-01T00:00:00.000Z",
[2025-07-19T20:48:06.644+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T20:48:06.644+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:06.644+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:48:06.645+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:48:06.645+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 215,
[2025-07-19T20:48:06.645+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 215,
[2025-07-19T20:48:06.645+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 6074,
[2025-07-19T20:48:06.645+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:48:06.645+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 345,
[2025-07-19T20:48:06.648+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 16469,
[2025-07-19T20:48:06.648+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 98040,
[2025-07-19T20:48:06.649+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:48:06.649+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:48:06.650+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:48:06.651+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:48:06.652+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T20:48:06.656+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:48:06.657+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 7,
[2025-07-19T20:48:06.658+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 69240
[2025-07-19T20:48:06.660+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:06.663+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:06.664+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:48:06.664+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[reservations]]",
[2025-07-19T20:48:06.664+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T20:48:06.665+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:48:06.666+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T20:48:06.666+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:06.667+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:06.668+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:06.669+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:48:06.669+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T20:48:06.669+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:06.669+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:06.670+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:06.671+0000] {subprocess.py:93} INFO -     "numInputRows" : 222,
[2025-07-19T20:48:06.671+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:06.671+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 22.286918984037747,
[2025-07-19T20:48:06.672+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:48:06.672+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:48:06.673+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:48:06.673+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:48:06.674+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:06.674+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:06.675+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:48:06.675+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Reservations_raw",
[2025-07-19T20:48:06.676+0000] {subprocess.py:93} INFO -     "numOutputRows" : 215
[2025-07-19T20:48:06.676+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:48:06.676+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:48:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.1.delta.475c237c-ceef-422e-b0a5-d055fe4efa17.TID265.tmp
[2025-07-19T20:48:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8ac9f57
[2025-07-19T20:48:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83] for update
[2025-07-19T20:48:06.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 76 (task 258, attempt 0, stage 1.0)
[2025-07-19T20:48:06.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 76.0 in stage 1.0 (TID 258). 9127 bytes result sent to driver
[2025-07-19T20:48:06.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 266) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 85.0 in stage 1.0 (TID 266)
[2025-07-19T20:48:06.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 258) in 177 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:48:06.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61584fcf
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82] for update
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.1.delta.c14d90bd-c6bb-4d78-84c2-4b6c9c6073c0.TID264.tmp
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.1.delta.5337834f-dc12-49ed-a434-2a7c04f382a8.TID262.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 262, attempt 0, stage 1.0)
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e79ba43
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85] for update
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.1.delta.71502a75-2af5-450b-b231-ed5ec3169b8b.TID259.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 259, attempt 0, stage 1.0)
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.1.delta.813fb9cb-8624-4841-85a4-d69b2b5ef737.TID263.tmp
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.1.delta.9deb2432-4ff3-42ef-a691-d9af18288cf3.TID266.tmp
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.1.delta.5fecb06c-dd00-4275-8ece-95fe726a53b6.TID261.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta
[2025-07-19T20:48:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 261, attempt 0, stage 1.0)
[2025-07-19T20:48:06.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 80 (task 262, attempt 0, stage 1.0)
[2025-07-19T20:48:06.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 80.0 in stage 1.0 (TID 262). 9119 bytes result sent to driver
[2025-07-19T20:48:06.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 267) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 87.0 in stage 1.0 (TID 267)
[2025-07-19T20:48:06.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 262) in 143 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:48:06.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.1.delta.f214d7aa-da2d-40cd-8aef-168c58c6c182.TID260.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta
[2025-07-19T20:48:06.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta
[2025-07-19T20:48:06.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 260, attempt 0, stage 1.0)
[2025-07-19T20:48:06.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3da6314b
[2025-07-19T20:48:06.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87] for update
[2025-07-19T20:48:06.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.1.delta.813fb9cb-8624-4841-85a4-d69b2b5ef737.TID263.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta
[2025-07-19T20:48:06.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta
[2025-07-19T20:48:06.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 79 (task 261, attempt 0, stage 1.0)
[2025-07-19T20:48:06.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.1.delta.475c237c-ceef-422e-b0a5-d055fe4efa17.TID265.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta
[2025-07-19T20:48:06.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta
[2025-07-19T20:48:06.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 263, attempt 0, stage 1.0)
[2025-07-19T20:48:06.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.1.delta.c14d90bd-c6bb-4d78-84c2-4b6c9c6073c0.TID264.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta
[2025-07-19T20:48:06.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta
[2025-07-19T20:48:06.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 79.0 in stage 1.0 (TID 261). 9109 bytes result sent to driver
[2025-07-19T20:48:06.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 264, attempt 0, stage 1.0)
[2025-07-19T20:48:06.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 268) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 265, attempt 0, stage 1.0)
[2025-07-19T20:48:06.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 77 (task 259, attempt 0, stage 1.0)
[2025-07-19T20:48:06.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 261) in 164 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:48:06.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 77.0 in stage 1.0 (TID 259). 9132 bytes result sent to driver
[2025-07-19T20:48:06.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.1.delta.9deb2432-4ff3-42ef-a691-d9af18288cf3.TID266.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta
[2025-07-19T20:48:06.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta
[2025-07-19T20:48:06.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 78 (task 260, attempt 0, stage 1.0)
[2025-07-19T20:48:06.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 266, attempt 0, stage 1.0)
[2025-07-19T20:48:06.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 78.0 in stage 1.0 (TID 260). 9129 bytes result sent to driver
[2025-07-19T20:48:06.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 88.0 in stage 1.0 (TID 268)
[2025-07-19T20:48:06.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 269) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 94.0 in stage 1.0 (TID 269)
[2025-07-19T20:48:06.735+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 270) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 95.0 in stage 1.0 (TID 270)
[2025-07-19T20:48:06.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.1.delta.3774d886-6040-42d8-8ca9-00d4daddfb30.TID267.tmp
[2025-07-19T20:48:06.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:06.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ee12467
[2025-07-19T20:48:06.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 83 (task 264, attempt 0, stage 1.0)
[2025-07-19T20:48:06.746+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94] for update
[2025-07-19T20:48:06.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 83.0 in stage 1.0 (TID 264). 9113 bytes result sent to driver
[2025-07-19T20:48:06.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 259) in 199 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:48:06.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 271) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 84 (task 265, attempt 0, stage 1.0)
[2025-07-19T20:48:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 260) in 203 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:48:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 264) in 153 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:48:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 84.0 in stage 1.0 (TID 265). 9111 bytes result sent to driver
[2025-07-19T20:48:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 272) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 85 (task 266, attempt 0, stage 1.0)
[2025-07-19T20:48:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 85.0 in stage 1.0 (TID 266). 9129 bytes result sent to driver
[2025-07-19T20:48:06.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 97.0 in stage 1.0 (TID 272)
[2025-07-19T20:48:06.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 82 (task 263, attempt 0, stage 1.0)
[2025-07-19T20:48:06.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 96.0 in stage 1.0 (TID 271)
[2025-07-19T20:48:06.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 82.0 in stage 1.0 (TID 263). 9105 bytes result sent to driver
[2025-07-19T20:48:06.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 265) in 152 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:48:06.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17901338
[2025-07-19T20:48:06.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 273) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 266) in 106 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:48:06.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 274) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95] for update
[2025-07-19T20:48:06.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 263) in 173 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:48:06.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.1.delta.03dd818e-dd10-43d9-b065-ec384050c145.TID269.tmp
[2025-07-19T20:48:06.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 99.0 in stage 1.0 (TID 273)
[2025-07-19T20:48:06.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 100.0 in stage 1.0 (TID 274)
[2025-07-19T20:48:06.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5876a214
[2025-07-19T20:48:06.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97] for update
[2025-07-19T20:48:06.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.1.delta.4565713f-420a-46cf-885f-96e6f8f51212.TID270.tmp
[2025-07-19T20:48:06.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@641aed9b
[2025-07-19T20:48:06.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88] for update
[2025-07-19T20:48:06.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.1.delta.3774d886-6040-42d8-8ca9-00d4daddfb30.TID267.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta
[2025-07-19T20:48:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta
[2025-07-19T20:48:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 267, attempt 0, stage 1.0)
[2025-07-19T20:48:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.1.delta.4b2e89bb-ee3c-4557-b250-fc68283eb7b5.TID272.tmp
[2025-07-19T20:48:06.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@addf093
[2025-07-19T20:48:06.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100] for update
[2025-07-19T20:48:06.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.1.delta.56293622-6746-4633-be42-98e3209d19b6.TID268.tmp
[2025-07-19T20:48:06.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.1.delta.ccb2b028-f508-4fc5-ae83-9eba9196c704.TID274.tmp
[2025-07-19T20:48:06.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e86abff
[2025-07-19T20:48:06.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99] for update
[2025-07-19T20:48:06.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.1.delta.03dd818e-dd10-43d9-b065-ec384050c145.TID269.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta
[2025-07-19T20:48:06.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta
[2025-07-19T20:48:06.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 269, attempt 0, stage 1.0)
[2025-07-19T20:48:06.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 87 (task 267, attempt 0, stage 1.0)
[2025-07-19T20:48:06.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 87.0 in stage 1.0 (TID 267). 9113 bytes result sent to driver
[2025-07-19T20:48:06.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.1.delta.4565713f-420a-46cf-885f-96e6f8f51212.TID270.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta
[2025-07-19T20:48:06.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta
[2025-07-19T20:48:06.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.1.delta.53cc148f-6f3a-4e41-9af1-eb675159bdfc.TID273.tmp
[2025-07-19T20:48:06.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c1bb33
[2025-07-19T20:48:06.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96] for update
[2025-07-19T20:48:06.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 270, attempt 0, stage 1.0)
[2025-07-19T20:48:06.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 275) (8b44f3d35cfa, executor driver, partition 101, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 267) in 117 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:48:06.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 101.0 in stage 1.0 (TID 275)
[2025-07-19T20:48:06.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.1.delta.be9f8fc0-1a08-436f-a390-1c68907e5f7d.TID271.tmp
[2025-07-19T20:48:06.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 94 (task 269, attempt 0, stage 1.0)
[2025-07-19T20:48:06.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 94.0 in stage 1.0 (TID 269). 9120 bytes result sent to driver
[2025-07-19T20:48:06.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 269) in 97 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:48:06.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 276) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.1.delta.4b2e89bb-ee3c-4557-b250-fc68283eb7b5.TID272.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta
[2025-07-19T20:48:06.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta
[2025-07-19T20:48:06.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 103.0 in stage 1.0 (TID 276)
[2025-07-19T20:48:06.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 272, attempt 0, stage 1.0)
[2025-07-19T20:48:06.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.1.delta.56293622-6746-4633-be42-98e3209d19b6.TID268.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta
[2025-07-19T20:48:06.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta
[2025-07-19T20:48:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 95 (task 270, attempt 0, stage 1.0)
[2025-07-19T20:48:06.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 95.0 in stage 1.0 (TID 270). 9113 bytes result sent to driver
[2025-07-19T20:48:06.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 268, attempt 0, stage 1.0)
[2025-07-19T20:48:06.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 277) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 104.0 in stage 1.0 (TID 277)
[2025-07-19T20:48:06.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 270) in 110 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:48:06.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.1.delta.ccb2b028-f508-4fc5-ae83-9eba9196c704.TID274.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta
[2025-07-19T20:48:06.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta
[2025-07-19T20:48:06.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 274, attempt 0, stage 1.0)
[2025-07-19T20:48:06.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6749a938
[2025-07-19T20:48:06.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101] for update
[2025-07-19T20:48:06.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:06.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 88 (task 268, attempt 0, stage 1.0)
[2025-07-19T20:48:06.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 88.0 in stage 1.0 (TID 268). 9119 bytes result sent to driver
[2025-07-19T20:48:06.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2921cfc2
[2025-07-19T20:48:06.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 278) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 268) in 142 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:48:06.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104] for update
[2025-07-19T20:48:06.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.1.delta.53cc148f-6f3a-4e41-9af1-eb675159bdfc.TID273.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta
[2025-07-19T20:48:06.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 106.0 in stage 1.0 (TID 278)
[2025-07-19T20:48:06.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta
[2025-07-19T20:48:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.1.delta.fb7e2f82-4b24-49a8-964d-48498a26d6b6.TID275.tmp
[2025-07-19T20:48:06.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 273, attempt 0, stage 1.0)
[2025-07-19T20:48:06.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79158ea0
[2025-07-19T20:48:06.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103] for update
[2025-07-19T20:48:06.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 100 (task 274, attempt 0, stage 1.0)
[2025-07-19T20:48:06.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 97 (task 272, attempt 0, stage 1.0)
[2025-07-19T20:48:06.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 100.0 in stage 1.0 (TID 274). 9120 bytes result sent to driver
[2025-07-19T20:48:06.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 279) (8b44f3d35cfa, executor driver, partition 108, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.1.delta.be9f8fc0-1a08-436f-a390-1c68907e5f7d.TID271.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta
[2025-07-19T20:48:06.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta
[2025-07-19T20:48:06.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 108.0 in stage 1.0 (TID 279)
[2025-07-19T20:48:06.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 97.0 in stage 1.0 (TID 272). 9098 bytes result sent to driver
[2025-07-19T20:48:06.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.1.delta.c27689c7-71e1-4838-ab99-4d4e9810db34.TID277.tmp
[2025-07-19T20:48:06.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 280) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 271, attempt 0, stage 1.0)
[2025-07-19T20:48:06.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 274) in 132 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:48:06.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 272) in 142 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:48:06.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 110.0 in stage 1.0 (TID 280)
[2025-07-19T20:48:06.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4aebd7e4
[2025-07-19T20:48:06.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106] for update
[2025-07-19T20:48:06.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.1.delta.3e1ade2d-c950-4bc5-b2ca-88e6f370d6d4.TID276.tmp
[2025-07-19T20:48:06.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:06.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53fe892d
[2025-07-19T20:48:06.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108] for update
[2025-07-19T20:48:06.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c22f0a4
[2025-07-19T20:48:06.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110] for update
[2025-07-19T20:48:06.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.1.delta.d858e169-82aa-47be-8336-98c572c4485b.TID278.tmp
[2025-07-19T20:48:06.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 96 (task 271, attempt 0, stage 1.0)
[2025-07-19T20:48:06.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 96.0 in stage 1.0 (TID 271). 9127 bytes result sent to driver
[2025-07-19T20:48:06.930+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 99 (task 273, attempt 0, stage 1.0)
[2025-07-19T20:48:06.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 99.0 in stage 1.0 (TID 273). 9115 bytes result sent to driver
[2025-07-19T20:48:06.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 271) in 185 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:48:06.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 281) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 273) in 179 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:48:06.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 282) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.1.delta.fb7e2f82-4b24-49a8-964d-48498a26d6b6.TID275.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta
[2025-07-19T20:48:06.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta
[2025-07-19T20:48:06.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 112.0 in stage 1.0 (TID 282)
[2025-07-19T20:48:06.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 111.0 in stage 1.0 (TID 281)
[2025-07-19T20:48:06.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.1.delta.cb80278a-0b52-47f4-a773-efe6705e6313.TID279.tmp
[2025-07-19T20:48:06.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 275, attempt 0, stage 1.0)
[2025-07-19T20:48:06.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.1.delta.c27689c7-71e1-4838-ab99-4d4e9810db34.TID277.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta
[2025-07-19T20:48:06.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ea774c7
[2025-07-19T20:48:06.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta
[2025-07-19T20:48:06.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.1.delta.a07bfcad-de5d-4b86-9043-b5e193a5c8a9.TID280.tmp
[2025-07-19T20:48:06.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 277, attempt 0, stage 1.0)
[2025-07-19T20:48:06.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111] for update
[2025-07-19T20:48:06.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Committed partition 101 (task 275, attempt 0, stage 1.0)
[2025-07-19T20:48:06.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41f13c8e
[2025-07-19T20:48:06.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Finished task 101.0 in stage 1.0 (TID 275). 9205 bytes result sent to driver
[2025-07-19T20:48:06.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112] for update
[2025-07-19T20:48:06.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 283) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:06.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO Executor: Running task 113.0 in stage 1.0 (TID 283)
[2025-07-19T20:48:06.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:06.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 275) in 170 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:48:06.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.1.delta.3e1ade2d-c950-4bc5-b2ca-88e6f370d6d4.TID276.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta
[2025-07-19T20:48:06.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta
[2025-07-19T20:48:06.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 276, attempt 0, stage 1.0)
[2025-07-19T20:48:06.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.1.delta.d858e169-82aa-47be-8336-98c572c4485b.TID278.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta
[2025-07-19T20:48:06.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta
[2025-07-19T20:48:06.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 278, attempt 0, stage 1.0)
[2025-07-19T20:48:06.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:06.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:06.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.1.delta.8e629eb7-83a1-4b33-8476-bb3ff0a36e3f.TID281.tmp
[2025-07-19T20:48:06.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a7373c8
[2025-07-19T20:48:06.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:06.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113] for update
[2025-07-19T20:48:07.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 104 (task 277, attempt 0, stage 1.0)
[2025-07-19T20:48:07.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 104.0 in stage 1.0 (TID 277). 9160 bytes result sent to driver
[2025-07-19T20:48:07.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.1.delta.1635f1a4-87cb-461d-b051-d55a6477e538.TID282.tmp
[2025-07-19T20:48:07.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.1.delta.cb80278a-0b52-47f4-a773-efe6705e6313.TID279.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta
[2025-07-19T20:48:07.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta
[2025-07-19T20:48:07.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 279, attempt 0, stage 1.0)
[2025-07-19T20:48:07.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 284) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.1.delta.7796089f-7be4-4f41-ab7f-c0cb7db90891.TID283.tmp
[2025-07-19T20:48:07.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 106 (task 278, attempt 0, stage 1.0)
[2025-07-19T20:48:07.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 106.0 in stage 1.0 (TID 278). 9156 bytes result sent to driver
[2025-07-19T20:48:07.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 103 (task 276, attempt 0, stage 1.0)
[2025-07-19T20:48:07.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 277) in 184 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:48:07.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 114.0 in stage 1.0 (TID 284)
[2025-07-19T20:48:07.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 103.0 in stage 1.0 (TID 276). 9148 bytes result sent to driver
[2025-07-19T20:48:07.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 285) (8b44f3d35cfa, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 286) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 117.0 in stage 1.0 (TID 286)
[2025-07-19T20:48:07.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 278) in 177 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:48:07.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 276) in 208 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:48:07.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 115.0 in stage 1.0 (TID 285)
[2025-07-19T20:48:07.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 108 (task 279, attempt 0, stage 1.0)
[2025-07-19T20:48:07.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22b91ad
[2025-07-19T20:48:07.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.1.delta.a07bfcad-de5d-4b86-9043-b5e193a5c8a9.TID280.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta
[2025-07-19T20:48:07.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta
[2025-07-19T20:48:07.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 108.0 in stage 1.0 (TID 279). 9183 bytes result sent to driver
[2025-07-19T20:48:07.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 287) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117] for update
[2025-07-19T20:48:07.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 118.0 in stage 1.0 (TID 287)
[2025-07-19T20:48:07.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 280, attempt 0, stage 1.0)
[2025-07-19T20:48:07.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 279) in 173 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:48:07.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.057+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:07.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.1.delta.8e629eb7-83a1-4b33-8476-bb3ff0a36e3f.TID281.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta
[2025-07-19T20:48:07.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta
[2025-07-19T20:48:07.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 281, attempt 0, stage 1.0)
[2025-07-19T20:48:07.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45d6a3e9
[2025-07-19T20:48:07.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.1.delta.13750d3d-06bf-48e5-b2b3-0f2db6235997.TID286.tmp
[2025-07-19T20:48:07.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 8b44f3d35cfa:46433 in memory (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T20:48:07.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115] for update
[2025-07-19T20:48:07.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.1.delta.7796089f-7be4-4f41-ab7f-c0cb7db90891.TID283.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta
[2025-07-19T20:48:07.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta
[2025-07-19T20:48:07.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 283, attempt 0, stage 1.0)
[2025-07-19T20:48:07.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 110 (task 280, attempt 0, stage 1.0)
[2025-07-19T20:48:07.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.1.delta.1635f1a4-87cb-461d-b051-d55a6477e538.TID282.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta
[2025-07-19T20:48:07.073+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta
[2025-07-19T20:48:07.074+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 282, attempt 0, stage 1.0)
[2025-07-19T20:48:07.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 110.0 in stage 1.0 (TID 280). 9156 bytes result sent to driver
[2025-07-19T20:48:07.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 288) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 119.0 in stage 1.0 (TID 288)
[2025-07-19T20:48:07.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 280) in 201 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:48:07.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@373e1b47
[2025-07-19T20:48:07.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114] for update
[2025-07-19T20:48:07.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 8b44f3d35cfa:46433 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T20:48:07.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.1.delta.1113927f-14d1-4df7-9fb3-b7d714b81bb3.TID285.tmp
[2025-07-19T20:48:07.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 111 (task 281, attempt 0, stage 1.0)
[2025-07-19T20:48:07.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cf1cd52
[2025-07-19T20:48:07.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118] for update
[2025-07-19T20:48:07.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 113 (task 283, attempt 0, stage 1.0)
[2025-07-19T20:48:07.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 113.0 in stage 1.0 (TID 283). 9115 bytes result sent to driver
[2025-07-19T20:48:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 289) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 120.0 in stage 1.0 (TID 289)
[2025-07-19T20:48:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 111.0 in stage 1.0 (TID 281). 9167 bytes result sent to driver
[2025-07-19T20:48:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 290) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 121.0 in stage 1.0 (TID 290)
[2025-07-19T20:48:07.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.1.delta.d2abb293-7165-495a-b287-2a0efd246197.TID284.tmp
[2025-07-19T20:48:07.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5add65b2
[2025-07-19T20:48:07.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119] for update
[2025-07-19T20:48:07.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 281) in 180 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:48:07.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 283) in 132 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:48:07.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:07.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 112 (task 282, attempt 0, stage 1.0)
[2025-07-19T20:48:07.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 112.0 in stage 1.0 (TID 282). 9166 bytes result sent to driver
[2025-07-19T20:48:07.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 291) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.1.delta.13750d3d-06bf-48e5-b2b3-0f2db6235997.TID286.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta
[2025-07-19T20:48:07.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta
[2025-07-19T20:48:07.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f689882
[2025-07-19T20:48:07.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 122.0 in stage 1.0 (TID 291)
[2025-07-19T20:48:07.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121] for update
[2025-07-19T20:48:07.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 282) in 189 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:48:07.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 286, attempt 0, stage 1.0)
[2025-07-19T20:48:07.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.1.delta.5a80e5f5-11b9-45ea-b7cb-1e7d3136a0ce.TID288.tmp
[2025-07-19T20:48:07.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.1.delta.b2dba28e-2390-4de3-88bb-a8c21227b13a.TID287.tmp
[2025-07-19T20:48:07.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e5d992
[2025-07-19T20:48:07.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120] for update
[2025-07-19T20:48:07.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.1.delta.591f1b15-22ee-4748-b7a6-63457201fb3d.TID290.tmp
[2025-07-19T20:48:07.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 117 (task 286, attempt 0, stage 1.0)
[2025-07-19T20:48:07.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 117.0 in stage 1.0 (TID 286). 9119 bytes result sent to driver
[2025-07-19T20:48:07.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8acc499
[2025-07-19T20:48:07.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 292) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 286) in 109 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:48:07.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 125.0 in stage 1.0 (TID 292)
[2025-07-19T20:48:07.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122] for update
[2025-07-19T20:48:07.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.1.delta.e7b34255-086f-4eda-b0d9-6e11f64110d5.TID289.tmp
[2025-07-19T20:48:07.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.1.delta.d2abb293-7165-495a-b287-2a0efd246197.TID284.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta
[2025-07-19T20:48:07.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta
[2025-07-19T20:48:07.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 284, attempt 0, stage 1.0)
[2025-07-19T20:48:07.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.1.delta.1113927f-14d1-4df7-9fb3-b7d714b81bb3.TID285.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta
[2025-07-19T20:48:07.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta
[2025-07-19T20:48:07.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 285, attempt 0, stage 1.0)
[2025-07-19T20:48:07.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37748dbf
[2025-07-19T20:48:07.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125] for update
[2025-07-19T20:48:07.158+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.1.delta.3db11c28-f99b-458d-bffc-bad1b85cf6bd.TID291.tmp
[2025-07-19T20:48:07.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 114 (task 284, attempt 0, stage 1.0)
[2025-07-19T20:48:07.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 114.0 in stage 1.0 (TID 284). 9125 bytes result sent to driver
[2025-07-19T20:48:07.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 293) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 128.0 in stage 1.0 (TID 293)
[2025-07-19T20:48:07.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 115 (task 285, attempt 0, stage 1.0)
[2025-07-19T20:48:07.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 284) in 160 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:48:07.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.1.delta.b2dba28e-2390-4de3-88bb-a8c21227b13a.TID287.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta
[2025-07-19T20:48:07.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta
[2025-07-19T20:48:07.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.1.delta.5a80e5f5-11b9-45ea-b7cb-1e7d3136a0ce.TID288.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta
[2025-07-19T20:48:07.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta
[2025-07-19T20:48:07.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 287, attempt 0, stage 1.0)
[2025-07-19T20:48:07.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:07.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 288, attempt 0, stage 1.0)
[2025-07-19T20:48:07.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 115.0 in stage 1.0 (TID 285). 9099 bytes result sent to driver
[2025-07-19T20:48:07.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 294) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 129.0 in stage 1.0 (TID 294)
[2025-07-19T20:48:07.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 285) in 151 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:48:07.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.1.delta.0e660d0d-fd5b-45ff-84c7-e8b7706f48d1.TID292.tmp
[2025-07-19T20:48:07.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d25e423
[2025-07-19T20:48:07.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128] for update
[2025-07-19T20:48:07.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.1.delta.e7b34255-086f-4eda-b0d9-6e11f64110d5.TID289.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta
[2025-07-19T20:48:07.195+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta
[2025-07-19T20:48:07.196+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 289, attempt 0, stage 1.0)
[2025-07-19T20:48:07.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.1.delta.591f1b15-22ee-4748-b7a6-63457201fb3d.TID290.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta
[2025-07-19T20:48:07.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta
[2025-07-19T20:48:07.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 290, attempt 0, stage 1.0)
[2025-07-19T20:48:07.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6880cf06
[2025-07-19T20:48:07.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129] for update
[2025-07-19T20:48:07.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.1.delta.87b4cc5e-4323-4e66-bd76-b9c18800d0bf.TID293.tmp
[2025-07-19T20:48:07.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.1.delta.3db11c28-f99b-458d-bffc-bad1b85cf6bd.TID291.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta
[2025-07-19T20:48:07.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta
[2025-07-19T20:48:07.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 291, attempt 0, stage 1.0)
[2025-07-19T20:48:07.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 118 (task 287, attempt 0, stage 1.0)
[2025-07-19T20:48:07.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 118.0 in stage 1.0 (TID 287). 9113 bytes result sent to driver
[2025-07-19T20:48:07.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 295) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 287) in 174 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:48:07.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.1.delta.f17c2ceb-886b-4c39-a4c1-e74a2742f649.TID294.tmp
[2025-07-19T20:48:07.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 130.0 in stage 1.0 (TID 295)
[2025-07-19T20:48:07.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.1.delta.0e660d0d-fd5b-45ff-84c7-e8b7706f48d1.TID292.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta
[2025-07-19T20:48:07.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta
[2025-07-19T20:48:07.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 292, attempt 0, stage 1.0)
[2025-07-19T20:48:07.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 119 (task 288, attempt 0, stage 1.0)
[2025-07-19T20:48:07.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 119.0 in stage 1.0 (TID 288). 9109 bytes result sent to driver
[2025-07-19T20:48:07.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 121 (task 290, attempt 0, stage 1.0)
[2025-07-19T20:48:07.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 121.0 in stage 1.0 (TID 290). 9109 bytes result sent to driver
[2025-07-19T20:48:07.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 296) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 297) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 290) in 141 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:48:07.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 288) in 162 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:48:07.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 131.0 in stage 1.0 (TID 296)
[2025-07-19T20:48:07.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 120 (task 289, attempt 0, stage 1.0)
[2025-07-19T20:48:07.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 120.0 in stage 1.0 (TID 289). 9126 bytes result sent to driver
[2025-07-19T20:48:07.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 289) in 149 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:48:07.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 298) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 133.0 in stage 1.0 (TID 297)
[2025-07-19T20:48:07.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 134.0 in stage 1.0 (TID 298)
[2025-07-19T20:48:07.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:07.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d46daf7
[2025-07-19T20:48:07.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:07.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130] for update
[2025-07-19T20:48:07.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 125 (task 292, attempt 0, stage 1.0)
[2025-07-19T20:48:07.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 125.0 in stage 1.0 (TID 292). 9115 bytes result sent to driver
[2025-07-19T20:48:07.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 122 (task 291, attempt 0, stage 1.0)
[2025-07-19T20:48:07.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 122.0 in stage 1.0 (TID 291). 9109 bytes result sent to driver
[2025-07-19T20:48:07.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50f5f621
[2025-07-19T20:48:07.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 299) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134] for update
[2025-07-19T20:48:07.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 300) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 135.0 in stage 1.0 (TID 299)
[2025-07-19T20:48:07.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 292) in 124 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:48:07.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 291) in 150 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:48:07.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 137.0 in stage 1.0 (TID 300)
[2025-07-19T20:48:07.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.1.delta.87b4cc5e-4323-4e66-bd76-b9c18800d0bf.TID293.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta
[2025-07-19T20:48:07.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta
[2025-07-19T20:48:07.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 293, attempt 0, stage 1.0)
[2025-07-19T20:48:07.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68661507
[2025-07-19T20:48:07.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131] for update
[2025-07-19T20:48:07.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.1.delta.89eaf422-0b15-44f8-895d-b20c7fecf3e1.TID295.tmp
[2025-07-19T20:48:07.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@500ec481
[2025-07-19T20:48:07.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 128 (task 293, attempt 0, stage 1.0)
[2025-07-19T20:48:07.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133] for update
[2025-07-19T20:48:07.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 128.0 in stage 1.0 (TID 293). 9132 bytes result sent to driver
[2025-07-19T20:48:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 301) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 139.0 in stage 1.0 (TID 301)
[2025-07-19T20:48:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 293) in 120 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:48:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.1.delta.f17c2ceb-886b-4c39-a4c1-e74a2742f649.TID294.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta
[2025-07-19T20:48:07.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta
[2025-07-19T20:48:07.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 294, attempt 0, stage 1.0)
[2025-07-19T20:48:07.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.1.delta.90eae709-24ea-41d8-8906-af1e69ff75f7.TID298.tmp
[2025-07-19T20:48:07.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4765c2fa
[2025-07-19T20:48:07.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.1.delta.2a71ee07-a494-4059-9370-11f58ef37678.TID296.tmp
[2025-07-19T20:48:07.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137] for update
[2025-07-19T20:48:07.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.1.delta.fc2887df-3de5-48a2-ad59-ab0331a129fa.TID297.tmp
[2025-07-19T20:48:07.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54d1549b
[2025-07-19T20:48:07.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135] for update
[2025-07-19T20:48:07.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 129 (task 294, attempt 0, stage 1.0)
[2025-07-19T20:48:07.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 129.0 in stage 1.0 (TID 294). 9119 bytes result sent to driver
[2025-07-19T20:48:07.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 302) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 141.0 in stage 1.0 (TID 302)
[2025-07-19T20:48:07.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 294) in 138 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:48:07.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f8319c2
[2025-07-19T20:48:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.1.delta.981cd30a-6561-4820-873d-3c5d5f897d4a.TID300.tmp
[2025-07-19T20:48:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139] for update
[2025-07-19T20:48:07.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.1.delta.df80ae54-e6e7-4de4-b305-c8c667119313.TID299.tmp
[2025-07-19T20:48:07.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35416e5b
[2025-07-19T20:48:07.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141] for update
[2025-07-19T20:48:07.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.1.delta.90eae709-24ea-41d8-8906-af1e69ff75f7.TID298.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta
[2025-07-19T20:48:07.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta
[2025-07-19T20:48:07.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 298, attempt 0, stage 1.0)
[2025-07-19T20:48:07.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.1.delta.89eaf422-0b15-44f8-895d-b20c7fecf3e1.TID295.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta
[2025-07-19T20:48:07.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta
[2025-07-19T20:48:07.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 295, attempt 0, stage 1.0)
[2025-07-19T20:48:07.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.1.delta.87273b5b-b823-41fe-9c86-9ce01ecb76e2.TID302.tmp
[2025-07-19T20:48:07.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.1.delta.87dc2866-93fd-4393-802c-9b62f87d4cd7.TID301.tmp
[2025-07-19T20:48:07.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.1.delta.2a71ee07-a494-4059-9370-11f58ef37678.TID296.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta
[2025-07-19T20:48:07.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta
[2025-07-19T20:48:07.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 296, attempt 0, stage 1.0)
[2025-07-19T20:48:07.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.1.delta.fc2887df-3de5-48a2-ad59-ab0331a129fa.TID297.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta
[2025-07-19T20:48:07.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta
[2025-07-19T20:48:07.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 297, attempt 0, stage 1.0)
[2025-07-19T20:48:07.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.1.delta.981cd30a-6561-4820-873d-3c5d5f897d4a.TID300.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta
[2025-07-19T20:48:07.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta
[2025-07-19T20:48:07.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 300, attempt 0, stage 1.0)
[2025-07-19T20:48:07.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 130 (task 295, attempt 0, stage 1.0)
[2025-07-19T20:48:07.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 130.0 in stage 1.0 (TID 295). 9131 bytes result sent to driver
[2025-07-19T20:48:07.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 303) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 295) in 172 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:48:07.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 142.0 in stage 1.0 (TID 303)
[2025-07-19T20:48:07.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 131 (task 296, attempt 0, stage 1.0)
[2025-07-19T20:48:07.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 133 (task 297, attempt 0, stage 1.0)
[2025-07-19T20:48:07.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.1.delta.df80ae54-e6e7-4de4-b305-c8c667119313.TID299.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta
[2025-07-19T20:48:07.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta
[2025-07-19T20:48:07.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 299, attempt 0, stage 1.0)
[2025-07-19T20:48:07.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 131.0 in stage 1.0 (TID 296). 9109 bytes result sent to driver
[2025-07-19T20:48:07.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 133.0 in stage 1.0 (TID 297). 9117 bytes result sent to driver
[2025-07-19T20:48:07.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 304) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 296) in 159 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:48:07.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 143.0 in stage 1.0 (TID 304)
[2025-07-19T20:48:07.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 305) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 134 (task 298, attempt 0, stage 1.0)
[2025-07-19T20:48:07.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 144.0 in stage 1.0 (TID 305)
[2025-07-19T20:48:07.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28970e3a
[2025-07-19T20:48:07.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 297) in 167 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:48:07.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 134.0 in stage 1.0 (TID 298). 9119 bytes result sent to driver
[2025-07-19T20:48:07.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 306) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 145.0 in stage 1.0 (TID 306)
[2025-07-19T20:48:07.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142] for update
[2025-07-19T20:48:07.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.1.delta.87dc2866-93fd-4393-802c-9b62f87d4cd7.TID301.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta
[2025-07-19T20:48:07.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta
[2025-07-19T20:48:07.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.1.delta.87273b5b-b823-41fe-9c86-9ce01ecb76e2.TID302.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta
[2025-07-19T20:48:07.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta
[2025-07-19T20:48:07.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 302, attempt 0, stage 1.0)
[2025-07-19T20:48:07.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 301, attempt 0, stage 1.0)
[2025-07-19T20:48:07.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 298) in 169 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:48:07.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 135 (task 299, attempt 0, stage 1.0)
[2025-07-19T20:48:07.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ad03d63
[2025-07-19T20:48:07.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 135.0 in stage 1.0 (TID 299). 9121 bytes result sent to driver
[2025-07-19T20:48:07.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 137 (task 300, attempt 0, stage 1.0)
[2025-07-19T20:48:07.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 137.0 in stage 1.0 (TID 300). 9121 bytes result sent to driver
[2025-07-19T20:48:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 307) (8b44f3d35cfa, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 308) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 146.0 in stage 1.0 (TID 307)
[2025-07-19T20:48:07.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 300) in 157 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:48:07.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 147.0 in stage 1.0 (TID 308)
[2025-07-19T20:48:07.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 299) in 159 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:48:07.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144] for update
[2025-07-19T20:48:07.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53c5dc38
[2025-07-19T20:48:07.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143] for update
[2025-07-19T20:48:07.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.1.delta.11ace6f2-fd0a-4c1b-8787-9be2a59ed79b.TID303.tmp
[2025-07-19T20:48:07.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e0a0119
[2025-07-19T20:48:07.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146] for update
[2025-07-19T20:48:07.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.1.delta.cdd81d71-c856-4da3-a370-c9654e01bf37.TID305.tmp
[2025-07-19T20:48:07.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.1.delta.f92ef000-8613-4d63-8beb-73a69701a06c.TID304.tmp
[2025-07-19T20:48:07.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 141 (task 302, attempt 0, stage 1.0)
[2025-07-19T20:48:07.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 141.0 in stage 1.0 (TID 302). 9103 bytes result sent to driver
[2025-07-19T20:48:07.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 309) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 302) in 125 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:48:07.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 148.0 in stage 1.0 (TID 309)
[2025-07-19T20:48:07.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 139 (task 301, attempt 0, stage 1.0)
[2025-07-19T20:48:07.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 139.0 in stage 1.0 (TID 301). 9115 bytes result sent to driver
[2025-07-19T20:48:07.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 301) in 163 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:48:07.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 310) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 149.0 in stage 1.0 (TID 310)
[2025-07-19T20:48:07.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d4077ab
[2025-07-19T20:48:07.456+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.1.delta.c2dddf4b-5847-49c7-9ad9-4446c3ced776.TID307.tmp
[2025-07-19T20:48:07.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145] for update
[2025-07-19T20:48:07.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15097461
[2025-07-19T20:48:07.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149] for update
[2025-07-19T20:48:07.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.1.delta.6e2f89ed-c93c-4f2f-94f7-a7bfd999d0f5.TID306.tmp
[2025-07-19T20:48:07.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.1.delta.11ace6f2-fd0a-4c1b-8787-9be2a59ed79b.TID303.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta
[2025-07-19T20:48:07.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta
[2025-07-19T20:48:07.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 303, attempt 0, stage 1.0)
[2025-07-19T20:48:07.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.1.delta.4ba749f8-3d5b-4930-9c2a-1c824d6773d4.TID310.tmp
[2025-07-19T20:48:07.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1032bab6
[2025-07-19T20:48:07.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148] for update
[2025-07-19T20:48:07.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.1.delta.cdd81d71-c856-4da3-a370-c9654e01bf37.TID305.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta
[2025-07-19T20:48:07.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta
[2025-07-19T20:48:07.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 305, attempt 0, stage 1.0)
[2025-07-19T20:48:07.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 142 (task 303, attempt 0, stage 1.0)
[2025-07-19T20:48:07.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 142.0 in stage 1.0 (TID 303). 9121 bytes result sent to driver
[2025-07-19T20:48:07.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 311) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49575e9f
[2025-07-19T20:48:07.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 150.0 in stage 1.0 (TID 311)
[2025-07-19T20:48:07.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147] for update
[2025-07-19T20:48:07.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.1.delta.c2dddf4b-5847-49c7-9ad9-4446c3ced776.TID307.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta
[2025-07-19T20:48:07.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta
[2025-07-19T20:48:07.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 303) in 114 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:48:07.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 307, attempt 0, stage 1.0)
[2025-07-19T20:48:07.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.1.delta.f92ef000-8613-4d63-8beb-73a69701a06c.TID304.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta
[2025-07-19T20:48:07.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta
[2025-07-19T20:48:07.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 304, attempt 0, stage 1.0)
[2025-07-19T20:48:07.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 144 (task 305, attempt 0, stage 1.0)
[2025-07-19T20:48:07.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.1.delta.945f9f48-afee-4cb4-aee4-d1361a761959.TID309.tmp
[2025-07-19T20:48:07.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 144.0 in stage 1.0 (TID 305). 9094 bytes result sent to driver
[2025-07-19T20:48:07.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 312) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 305) in 116 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:48:07.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49492f49
[2025-07-19T20:48:07.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150] for update
[2025-07-19T20:48:07.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 151.0 in stage 1.0 (TID 312)
[2025-07-19T20:48:07.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.1.delta.6e2f89ed-c93c-4f2f-94f7-a7bfd999d0f5.TID306.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta
[2025-07-19T20:48:07.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta
[2025-07-19T20:48:07.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 306, attempt 0, stage 1.0)
[2025-07-19T20:48:07.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.1.delta.1fc64a0c-8982-4b7e-b0a7-720aa834593c.TID308.tmp
[2025-07-19T20:48:07.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:07.555+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 146 (task 307, attempt 0, stage 1.0)
[2025-07-19T20:48:07.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 146.0 in stage 1.0 (TID 307). 9103 bytes result sent to driver
[2025-07-19T20:48:07.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 313) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 153.0 in stage 1.0 (TID 313)
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 307) in 124 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.1.delta.5d8e599b-9786-4029-b750-f76c47d25162.TID311.tmp
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49c6075a
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151] for update
[2025-07-19T20:48:07.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 143 (task 304, attempt 0, stage 1.0)
[2025-07-19T20:48:07.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 145 (task 306, attempt 0, stage 1.0)
[2025-07-19T20:48:07.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 143.0 in stage 1.0 (TID 304). 9121 bytes result sent to driver
[2025-07-19T20:48:07.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 314) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@674a08b
[2025-07-19T20:48:07.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 154.0 in stage 1.0 (TID 314)
[2025-07-19T20:48:07.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 304) in 164 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:48:07.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153] for update
[2025-07-19T20:48:07.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 145.0 in stage 1.0 (TID 306). 9167 bytes result sent to driver
[2025-07-19T20:48:07.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 315) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.1.delta.49e72183-3e61-409c-b07a-d001169aef16.TID313.tmp
[2025-07-19T20:48:07.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 156.0 in stage 1.0 (TID 315)
[2025-07-19T20:48:07.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:07.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.1.delta.4ba749f8-3d5b-4930-9c2a-1c824d6773d4.TID310.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta
[2025-07-19T20:48:07.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta
[2025-07-19T20:48:07.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.1.delta.cfb12c8e-9ca6-4ba3-9702-3d99d5ef1225.TID312.tmp
[2025-07-19T20:48:07.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 306) in 165 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:48:07.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 310, attempt 0, stage 1.0)
[2025-07-19T20:48:07.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.1.delta.945f9f48-afee-4cb4-aee4-d1361a761959.TID309.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta
[2025-07-19T20:48:07.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta
[2025-07-19T20:48:07.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 309, attempt 0, stage 1.0)
[2025-07-19T20:48:07.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41c1fd19
[2025-07-19T20:48:07.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154] for update
[2025-07-19T20:48:07.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.1.delta.1fc64a0c-8982-4b7e-b0a7-720aa834593c.TID308.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta
[2025-07-19T20:48:07.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta
[2025-07-19T20:48:07.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 308, attempt 0, stage 1.0)
[2025-07-19T20:48:07.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 149 (task 310, attempt 0, stage 1.0)
[2025-07-19T20:48:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 149.0 in stage 1.0 (TID 310). 9111 bytes result sent to driver
[2025-07-19T20:48:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 316) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1eb53ec3
[2025-07-19T20:48:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 148 (task 309, attempt 0, stage 1.0)
[2025-07-19T20:48:07.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 157.0 in stage 1.0 (TID 316)
[2025-07-19T20:48:07.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156] for update
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 148.0 in stage 1.0 (TID 309). 9117 bytes result sent to driver
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.1.delta.5d8e599b-9786-4029-b750-f76c47d25162.TID311.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 317) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 309) in 161 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 158.0 in stage 1.0 (TID 317)
[2025-07-19T20:48:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 310) in 152 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:48:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 147 (task 308, attempt 0, stage 1.0)
[2025-07-19T20:48:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 311, attempt 0, stage 1.0)
[2025-07-19T20:48:07.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.1.delta.decd3d8e-40e0-47c9-9a3f-9724402d246e.TID314.tmp
[2025-07-19T20:48:07.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 147.0 in stage 1.0 (TID 308). 9197 bytes result sent to driver
[2025-07-19T20:48:07.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 318) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 308) in 199 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:48:07.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 159.0 in stage 1.0 (TID 318)
[2025-07-19T20:48:07.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a2f5a9c
[2025-07-19T20:48:07.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157] for update
[2025-07-19T20:48:07.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 150 (task 311, attempt 0, stage 1.0)
[2025-07-19T20:48:07.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 150.0 in stage 1.0 (TID 311). 9175 bytes result sent to driver
[2025-07-19T20:48:07.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.1.delta.7ef65af0-67f4-4d0f-b70e-7a7aff79874c.TID315.tmp
[2025-07-19T20:48:07.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 311) in 137 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:48:07.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 319) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.1.delta.cfb12c8e-9ca6-4ba3-9702-3d99d5ef1225.TID312.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta
[2025-07-19T20:48:07.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta
[2025-07-19T20:48:07.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 162.0 in stage 1.0 (TID 319)
[2025-07-19T20:48:07.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32ad50ee
[2025-07-19T20:48:07.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 312, attempt 0, stage 1.0)
[2025-07-19T20:48:07.635+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.1.delta.fa1107f1-b575-4d95-ad4f-20698678fcbb.TID316.tmp
[2025-07-19T20:48:07.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159] for update
[2025-07-19T20:48:07.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:07.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e8c6016
[2025-07-19T20:48:07.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158] for update
[2025-07-19T20:48:07.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.1.delta.49e72183-3e61-409c-b07a-d001169aef16.TID313.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta
[2025-07-19T20:48:07.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta
[2025-07-19T20:48:07.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 313, attempt 0, stage 1.0)
[2025-07-19T20:48:07.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5258a6a
[2025-07-19T20:48:07.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.1.delta.1363bd70-162a-453a-aa0a-28835cc42211.TID318.tmp
[2025-07-19T20:48:07.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162] for update
[2025-07-19T20:48:07.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 151 (task 312, attempt 0, stage 1.0)
[2025-07-19T20:48:07.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 151.0 in stage 1.0 (TID 312). 9148 bytes result sent to driver
[2025-07-19T20:48:07.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 153 (task 313, attempt 0, stage 1.0)
[2025-07-19T20:48:07.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 153.0 in stage 1.0 (TID 313). 9166 bytes result sent to driver
[2025-07-19T20:48:07.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.1.delta.6db74a4f-fcfe-4da0-a69b-8fd161e67d7d.TID317.tmp
[2025-07-19T20:48:07.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 320) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 321) (8b44f3d35cfa, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 167.0 in stage 1.0 (TID 321)
[2025-07-19T20:48:07.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.1.delta.decd3d8e-40e0-47c9-9a3f-9724402d246e.TID314.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta
[2025-07-19T20:48:07.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta
[2025-07-19T20:48:07.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 312) in 153 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:48:07.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 165.0 in stage 1.0 (TID 320)
[2025-07-19T20:48:07.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:07.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 313) in 129 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:48:07.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 314, attempt 0, stage 1.0)
[2025-07-19T20:48:07.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.1.delta.7af3eb07-1c2b-4c69-9a10-599af4f65d37.TID319.tmp
[2025-07-19T20:48:07.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb76133
[2025-07-19T20:48:07.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167] for update
[2025-07-19T20:48:07.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.1.delta.7ef65af0-67f4-4d0f-b70e-7a7aff79874c.TID315.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta
[2025-07-19T20:48:07.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta
[2025-07-19T20:48:07.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 315, attempt 0, stage 1.0)
[2025-07-19T20:48:07.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43415604
[2025-07-19T20:48:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165] for update
[2025-07-19T20:48:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.1.delta.fa1107f1-b575-4d95-ad4f-20698678fcbb.TID316.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta
[2025-07-19T20:48:07.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta
[2025-07-19T20:48:07.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 154 (task 314, attempt 0, stage 1.0)
[2025-07-19T20:48:07.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 316, attempt 0, stage 1.0)
[2025-07-19T20:48:07.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 154.0 in stage 1.0 (TID 314). 9160 bytes result sent to driver
[2025-07-19T20:48:07.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 322) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 168.0 in stage 1.0 (TID 322)
[2025-07-19T20:48:07.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.1.delta.f89617b6-3e65-44de-970e-2421cba0ce05.TID321.tmp
[2025-07-19T20:48:07.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 314) in 146 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:48:07.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.1.delta.1e4d968e-4dbc-427c-ac07-3debf1292611.TID320.tmp
[2025-07-19T20:48:07.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.1.delta.1363bd70-162a-453a-aa0a-28835cc42211.TID318.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta
[2025-07-19T20:48:07.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta
[2025-07-19T20:48:07.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 318, attempt 0, stage 1.0)
[2025-07-19T20:48:07.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ffd7355
[2025-07-19T20:48:07.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168] for update
[2025-07-19T20:48:07.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.1.delta.6db74a4f-fcfe-4da0-a69b-8fd161e67d7d.TID317.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta
[2025-07-19T20:48:07.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta
[2025-07-19T20:48:07.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 317, attempt 0, stage 1.0)
[2025-07-19T20:48:07.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 156 (task 315, attempt 0, stage 1.0)
[2025-07-19T20:48:07.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 156.0 in stage 1.0 (TID 315). 9166 bytes result sent to driver
[2025-07-19T20:48:07.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.1.delta.389dafab-649d-44ca-8958-3db9324a3a54.TID322.tmp
[2025-07-19T20:48:07.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 323) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 169.0 in stage 1.0 (TID 323)
[2025-07-19T20:48:07.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 315) in 164 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:48:07.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 157 (task 316, attempt 0, stage 1.0)
[2025-07-19T20:48:07.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.1.delta.7af3eb07-1c2b-4c69-9a10-599af4f65d37.TID319.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta
[2025-07-19T20:48:07.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta
[2025-07-19T20:48:07.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 319, attempt 0, stage 1.0)
[2025-07-19T20:48:07.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 157.0 in stage 1.0 (TID 316). 9167 bytes result sent to driver
[2025-07-19T20:48:07.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 324) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:07.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 170.0 in stage 1.0 (TID 324)
[2025-07-19T20:48:07.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 316) in 146 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:48:07.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.1.delta.f89617b6-3e65-44de-970e-2421cba0ce05.TID321.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta
[2025-07-19T20:48:07.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta
[2025-07-19T20:48:07.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 321, attempt 0, stage 1.0)
[2025-07-19T20:48:07.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b8ef8a5
[2025-07-19T20:48:07.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 159 (task 318, attempt 0, stage 1.0)
[2025-07-19T20:48:07.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 159.0 in stage 1.0 (TID 318). 9165 bytes result sent to driver
[2025-07-19T20:48:07.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 325) (8b44f3d35cfa, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 171.0 in stage 1.0 (TID 325)
[2025-07-19T20:48:07.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.1.delta.1e4d968e-4dbc-427c-ac07-3debf1292611.TID320.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta
[2025-07-19T20:48:07.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta
[2025-07-19T20:48:07.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 318) in 156 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:48:07.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169] for update
[2025-07-19T20:48:07.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 320, attempt 0, stage 1.0)
[2025-07-19T20:48:07.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 158 (task 317, attempt 0, stage 1.0)
[2025-07-19T20:48:07.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:07.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 158.0 in stage 1.0 (TID 317). 9165 bytes result sent to driver
[2025-07-19T20:48:07.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.1.delta.389dafab-649d-44ca-8958-3db9324a3a54.TID322.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta
[2025-07-19T20:48:07.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.1.delta.2e41ca5d-a364-4bf4-816e-b8aeb6da17a6.TID323.tmp
[2025-07-19T20:48:07.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45c5894b
[2025-07-19T20:48:07.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta
[2025-07-19T20:48:07.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 326) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170] for update
[2025-07-19T20:48:07.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 172.0 in stage 1.0 (TID 326)
[2025-07-19T20:48:07.803+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 317) in 204 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:48:07.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@604cc0d8
[2025-07-19T20:48:07.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171] for update
[2025-07-19T20:48:07.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 322, attempt 0, stage 1.0)
[2025-07-19T20:48:07.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 165 (task 320, attempt 0, stage 1.0)
[2025-07-19T20:48:07.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 165.0 in stage 1.0 (TID 320). 9152 bytes result sent to driver
[2025-07-19T20:48:07.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 327) (8b44f3d35cfa, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 173.0 in stage 1.0 (TID 327)
[2025-07-19T20:48:07.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 320) in 164 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:48:07.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.1.delta.bf2a0aac-2ad3-43c1-978c-4e0718a2687d.TID324.tmp
[2025-07-19T20:48:07.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 162 (task 319, attempt 0, stage 1.0)
[2025-07-19T20:48:07.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 162.0 in stage 1.0 (TID 319). 9146 bytes result sent to driver
[2025-07-19T20:48:07.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 328) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 319) in 218 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:48:07.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 174.0 in stage 1.0 (TID 328)
[2025-07-19T20:48:07.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.1.delta.e4d942d0-f7e4-47ad-9f90-5709eea22888.TID325.tmp
[2025-07-19T20:48:07.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52b42420
[2025-07-19T20:48:07.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172] for update
[2025-07-19T20:48:07.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 168 (task 322, attempt 0, stage 1.0)
[2025-07-19T20:48:07.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 168.0 in stage 1.0 (TID 322). 9124 bytes result sent to driver
[2025-07-19T20:48:07.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 329) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 175.0 in stage 1.0 (TID 329)
[2025-07-19T20:48:07.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 167 (task 321, attempt 0, stage 1.0)
[2025-07-19T20:48:07.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 167.0 in stage 1.0 (TID 321). 9162 bytes result sent to driver
[2025-07-19T20:48:07.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 330) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 322) in 184 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:48:07.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 321) in 225 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:48:07.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 178.0 in stage 1.0 (TID 330)
[2025-07-19T20:48:07.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.1.delta.79bcde12-f531-4bc3-9eef-7c2bc2f1b1bd.TID326.tmp
[2025-07-19T20:48:07.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71c1dc4c
[2025-07-19T20:48:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174] for update
[2025-07-19T20:48:07.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:07.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@549b098e
[2025-07-19T20:48:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173] for update
[2025-07-19T20:48:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.1.delta.bf2a0aac-2ad3-43c1-978c-4e0718a2687d.TID324.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta
[2025-07-19T20:48:07.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta
[2025-07-19T20:48:07.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 324, attempt 0, stage 1.0)
[2025-07-19T20:48:07.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.1.delta.2e41ca5d-a364-4bf4-816e-b8aeb6da17a6.TID323.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta
[2025-07-19T20:48:07.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta
[2025-07-19T20:48:07.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 323, attempt 0, stage 1.0)
[2025-07-19T20:48:07.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.1.delta.a96e29e9-2d93-4090-a976-4a52ca216de1.TID327.tmp
[2025-07-19T20:48:07.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@477f4dc1
[2025-07-19T20:48:07.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178] for update
[2025-07-19T20:48:07.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@526a761a
[2025-07-19T20:48:07.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:07.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175] for update
[2025-07-19T20:48:07.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:07.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.1.delta.e4d942d0-f7e4-47ad-9f90-5709eea22888.TID325.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta
[2025-07-19T20:48:07.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta
[2025-07-19T20:48:07.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 325, attempt 0, stage 1.0)
[2025-07-19T20:48:07.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.1.delta.79bcde12-f531-4bc3-9eef-7c2bc2f1b1bd.TID326.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta
[2025-07-19T20:48:07.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta
[2025-07-19T20:48:07.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 326, attempt 0, stage 1.0)
[2025-07-19T20:48:07.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.1.delta.a9fb2610-8435-4bd9-bed1-dfba6a942701.TID330.tmp
[2025-07-19T20:48:07.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 169 (task 323, attempt 0, stage 1.0)
[2025-07-19T20:48:07.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 169.0 in stage 1.0 (TID 323). 9111 bytes result sent to driver
[2025-07-19T20:48:07.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 331) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:07.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.1.delta.437b3c43-b9cc-45a0-a4f4-10eb542a2c0d.TID328.tmp
[2025-07-19T20:48:07.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 179.0 in stage 1.0 (TID 331)
[2025-07-19T20:48:07.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 323) in 268 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:48:07.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:07.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.1.delta.9b11b21a-36e7-4061-891b-08728ac6e11d.TID329.tmp
[2025-07-19T20:48:07.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO DataWritingSparkTask: Committed partition 170 (task 324, attempt 0, stage 1.0)
[2025-07-19T20:48:08.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Finished task 170.0 in stage 1.0 (TID 324). 9111 bytes result sent to driver
[2025-07-19T20:48:08.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 332) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 324) in 266 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:48:08.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO Executor: Running task 180.0 in stage 1.0 (TID 332)
[2025-07-19T20:48:08.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@678c1527
[2025-07-19T20:48:08.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179] for update
[2025-07-19T20:48:08.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2872a7c8
[2025-07-19T20:48:08.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180] for update
[2025-07-19T20:48:08.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 171 (task 325, attempt 0, stage 1.0)
[2025-07-19T20:48:08.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 171.0 in stage 1.0 (TID 325). 9109 bytes result sent to driver
[2025-07-19T20:48:08.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 333) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 181.0 in stage 1.0 (TID 333)
[2025-07-19T20:48:08.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 325) in 264 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:48:08.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 172 (task 326, attempt 0, stage 1.0)
[2025-07-19T20:48:08.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 172.0 in stage 1.0 (TID 326). 9110 bytes result sent to driver
[2025-07-19T20:48:08.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 334) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 326) in 236 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:48:08.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.1.delta.a96e29e9-2d93-4090-a976-4a52ca216de1.TID327.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta
[2025-07-19T20:48:08.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta
[2025-07-19T20:48:08.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.1.delta.5e9c9271-bdeb-47ce-8ac8-b2940cdfa7f3.TID331.tmp
[2025-07-19T20:48:08.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 182.0 in stage 1.0 (TID 334)
[2025-07-19T20:48:08.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 327, attempt 0, stage 1.0)
[2025-07-19T20:48:08.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50bdf287
[2025-07-19T20:48:08.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.1.delta.311eb7bd-8ca3-4f51-a357-b919cd001872.TID332.tmp
[2025-07-19T20:48:08.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181] for update
[2025-07-19T20:48:08.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.1.delta.a9fb2610-8435-4bd9-bed1-dfba6a942701.TID330.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta
[2025-07-19T20:48:08.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta
[2025-07-19T20:48:08.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 330, attempt 0, stage 1.0)
[2025-07-19T20:48:08.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7da5cdfd
[2025-07-19T20:48:08.057+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.1.delta.437b3c43-b9cc-45a0-a4f4-10eb542a2c0d.TID328.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta
[2025-07-19T20:48:08.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta
[2025-07-19T20:48:08.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182] for update
[2025-07-19T20:48:08.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 328, attempt 0, stage 1.0)
[2025-07-19T20:48:08.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 173 (task 327, attempt 0, stage 1.0)
[2025-07-19T20:48:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.1.delta.2a60139b-00fa-44a1-b670-4007569ac4c9.TID333.tmp
[2025-07-19T20:48:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 173.0 in stage 1.0 (TID 327). 9115 bytes result sent to driver
[2025-07-19T20:48:08.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 335) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.1.delta.9b11b21a-36e7-4061-891b-08728ac6e11d.TID329.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta
[2025-07-19T20:48:08.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta
[2025-07-19T20:48:08.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 327) in 250 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:48:08.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 329, attempt 0, stage 1.0)
[2025-07-19T20:48:08.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 183.0 in stage 1.0 (TID 335)
[2025-07-19T20:48:08.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 178 (task 330, attempt 0, stage 1.0)
[2025-07-19T20:48:08.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 178.0 in stage 1.0 (TID 330). 9113 bytes result sent to driver
[2025-07-19T20:48:08.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 330) in 193 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:48:08.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 336) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.1.delta.8d623a5b-b63f-4acb-a187-9b0fcaeac8f0.TID334.tmp
[2025-07-19T20:48:08.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.1.delta.5e9c9271-bdeb-47ce-8ac8-b2940cdfa7f3.TID331.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta
[2025-07-19T20:48:08.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta
[2025-07-19T20:48:08.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 184.0 in stage 1.0 (TID 336)
[2025-07-19T20:48:08.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18c475fa
[2025-07-19T20:48:08.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 331, attempt 0, stage 1.0)
[2025-07-19T20:48:08.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183] for update
[2025-07-19T20:48:08.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 174 (task 328, attempt 0, stage 1.0)
[2025-07-19T20:48:08.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 174.0 in stage 1.0 (TID 328). 9101 bytes result sent to driver
[2025-07-19T20:48:08.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 337) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 328) in 245 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:48:08.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 185.0 in stage 1.0 (TID 337)
[2025-07-19T20:48:08.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:08.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 175 (task 329, attempt 0, stage 1.0)
[2025-07-19T20:48:08.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 175.0 in stage 1.0 (TID 329). 9109 bytes result sent to driver
[2025-07-19T20:48:08.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 338) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 187.0 in stage 1.0 (TID 338)
[2025-07-19T20:48:08.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 329) in 227 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:48:08.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.1.delta.311eb7bd-8ca3-4f51-a357-b919cd001872.TID332.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta
[2025-07-19T20:48:08.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta
[2025-07-19T20:48:08.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 332, attempt 0, stage 1.0)
[2025-07-19T20:48:08.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 179 (task 331, attempt 0, stage 1.0)
[2025-07-19T20:48:08.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 179.0 in stage 1.0 (TID 331). 9107 bytes result sent to driver
[2025-07-19T20:48:08.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 339) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 188.0 in stage 1.0 (TID 339)
[2025-07-19T20:48:08.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 331) in 124 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:48:08.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dfbf9a2
[2025-07-19T20:48:08.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184] for update
[2025-07-19T20:48:08.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55220224
[2025-07-19T20:48:08.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.1.delta.fc5020fd-0d31-49b9-80cd-350865f753fe.TID335.tmp
[2025-07-19T20:48:08.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188] for update
[2025-07-19T20:48:08.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.1.delta.2a60139b-00fa-44a1-b670-4007569ac4c9.TID333.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta
[2025-07-19T20:48:08.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta
[2025-07-19T20:48:08.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 333, attempt 0, stage 1.0)
[2025-07-19T20:48:08.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 180 (task 332, attempt 0, stage 1.0)
[2025-07-19T20:48:08.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 180.0 in stage 1.0 (TID 332). 9107 bytes result sent to driver
[2025-07-19T20:48:08.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 340) (8b44f3d35cfa, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 189.0 in stage 1.0 (TID 340)
[2025-07-19T20:48:08.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 332) in 140 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:48:08.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.1.delta.039fb1a6-9e1b-43d0-a558-c8810da99d0e.TID336.tmp
[2025-07-19T20:48:08.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c673d7e
[2025-07-19T20:48:08.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187] for update
[2025-07-19T20:48:08.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.1.delta.70fc9c81-f550-45eb-b6a2-76f4082be6c0.TID339.tmp
[2025-07-19T20:48:08.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 181 (task 333, attempt 0, stage 1.0)
[2025-07-19T20:48:08.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 181.0 in stage 1.0 (TID 333). 9113 bytes result sent to driver
[2025-07-19T20:48:08.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 333) in 128 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:48:08.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 341) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 192.0 in stage 1.0 (TID 341)
[2025-07-19T20:48:08.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6667a2fc
[2025-07-19T20:48:08.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185] for update
[2025-07-19T20:48:08.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.1.delta.8d623a5b-b63f-4acb-a187-9b0fcaeac8f0.TID334.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta
[2025-07-19T20:48:08.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta
[2025-07-19T20:48:08.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 334, attempt 0, stage 1.0)
[2025-07-19T20:48:08.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.1.delta.7217c877-bdf6-43e5-ac21-808d531fe810.TID338.tmp
[2025-07-19T20:48:08.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d5362ff
[2025-07-19T20:48:08.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192] for update
[2025-07-19T20:48:08.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.1.delta.73350088-8dcd-453d-a574-1c42ccf80cd5.TID337.tmp
[2025-07-19T20:48:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28efde39
[2025-07-19T20:48:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189] for update
[2025-07-19T20:48:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.1.delta.63215de1-d7bf-4b46-8b03-48f2bf684688.TID341.tmp
[2025-07-19T20:48:08.196+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.1.delta.efd5097b-4332-40d8-9bf3-9086ff5ed272.TID340.tmp
[2025-07-19T20:48:08.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 182 (task 334, attempt 0, stage 1.0)
[2025-07-19T20:48:08.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 182.0 in stage 1.0 (TID 334). 9118 bytes result sent to driver
[2025-07-19T20:48:08.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.1.delta.fc5020fd-0d31-49b9-80cd-350865f753fe.TID335.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta
[2025-07-19T20:48:08.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta
[2025-07-19T20:48:08.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 342) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 335, attempt 0, stage 1.0)
[2025-07-19T20:48:08.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 334) in 180 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:48:08.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 194.0 in stage 1.0 (TID 342)
[2025-07-19T20:48:08.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.1.delta.039fb1a6-9e1b-43d0-a558-c8810da99d0e.TID336.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta
[2025-07-19T20:48:08.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta
[2025-07-19T20:48:08.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 336, attempt 0, stage 1.0)
[2025-07-19T20:48:08.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.1.delta.70fc9c81-f550-45eb-b6a2-76f4082be6c0.TID339.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta
[2025-07-19T20:48:08.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta
[2025-07-19T20:48:08.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 339, attempt 0, stage 1.0)
[2025-07-19T20:48:08.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.1.delta.7217c877-bdf6-43e5-ac21-808d531fe810.TID338.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta
[2025-07-19T20:48:08.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta
[2025-07-19T20:48:08.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 338, attempt 0, stage 1.0)
[2025-07-19T20:48:08.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 183 (task 335, attempt 0, stage 1.0)
[2025-07-19T20:48:08.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d676773
[2025-07-19T20:48:08.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.1.delta.73350088-8dcd-453d-a574-1c42ccf80cd5.TID337.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta
[2025-07-19T20:48:08.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta
[2025-07-19T20:48:08.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194] for update
[2025-07-19T20:48:08.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 337, attempt 0, stage 1.0)
[2025-07-19T20:48:08.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 183.0 in stage 1.0 (TID 335). 9141 bytes result sent to driver
[2025-07-19T20:48:08.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 188 (task 339, attempt 0, stage 1.0)
[2025-07-19T20:48:08.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 343) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 188.0 in stage 1.0 (TID 339). 9120 bytes result sent to driver
[2025-07-19T20:48:08.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 184 (task 336, attempt 0, stage 1.0)
[2025-07-19T20:48:08.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 184.0 in stage 1.0 (TID 336). 9107 bytes result sent to driver
[2025-07-19T20:48:08.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 344) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 196.0 in stage 1.0 (TID 343)
[2025-07-19T20:48:08.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 345) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 335) in 179 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:48:08.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 336) in 168 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:48:08.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 199.0 in stage 1.0 (TID 345)
[2025-07-19T20:48:08.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 197.0 in stage 1.0 (TID 344)
[2025-07-19T20:48:08.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 339) in 140 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:48:08.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 187 (task 338, attempt 0, stage 1.0)
[2025-07-19T20:48:08.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 187.0 in stage 1.0 (TID 338). 9128 bytes result sent to driver
[2025-07-19T20:48:08.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59cabeb1
[2025-07-19T20:48:08.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.1.delta.a7340600-0eeb-4730-b9bc-5e1d2d3a4043.TID342.tmp
[2025-07-19T20:48:08.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197] for update
[2025-07-19T20:48:08.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 346) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 338) in 159 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:48:08.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 5.0 in stage 1.0 (TID 346)
[2025-07-19T20:48:08.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.1.delta.efd5097b-4332-40d8-9bf3-9086ff5ed272.TID340.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta
[2025-07-19T20:48:08.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta
[2025-07-19T20:48:08.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.1.delta.63215de1-d7bf-4b46-8b03-48f2bf684688.TID341.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta
[2025-07-19T20:48:08.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta
[2025-07-19T20:48:08.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 341, attempt 0, stage 1.0)
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 340, attempt 0, stage 1.0)
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22802bad
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196] for update
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.1.delta.5094efc0-cf62-4f34-8dd1-af04544a5c28.TID344.tmp
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 185 (task 337, attempt 0, stage 1.0)
[2025-07-19T20:48:08.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 185.0 in stage 1.0 (TID 337). 9113 bytes result sent to driver
[2025-07-19T20:48:08.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 347) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 6.0 in stage 1.0 (TID 347)
[2025-07-19T20:48:08.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 337) in 194 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:48:08.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 192 (task 341, attempt 0, stage 1.0)
[2025-07-19T20:48:08.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d3810a6
[2025-07-19T20:48:08.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.1.delta.26b5a2af-8298-4d3f-bfde-636c61681039.TID343.tmp
[2025-07-19T20:48:08.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 192.0 in stage 1.0 (TID 341). 9107 bytes result sent to driver
[2025-07-19T20:48:08.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199] for update
[2025-07-19T20:48:08.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 348) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 17.0 in stage 1.0 (TID 348)
[2025-07-19T20:48:08.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 341) in 146 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:48:08.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 189 (task 340, attempt 0, stage 1.0)
[2025-07-19T20:48:08.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 189.0 in stage 1.0 (TID 340). 9115 bytes result sent to driver
[2025-07-19T20:48:08.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 349) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 19.0 in stage 1.0 (TID 349)
[2025-07-19T20:48:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@164e890f
[2025-07-19T20:48:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6] for update
[2025-07-19T20:48:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 340) in 167 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:48:08.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ddff1eb
[2025-07-19T20:48:08.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.1.delta.421f1f4c-68ad-4b81-a882-3d6b53d2ed58.TID345.tmp
[2025-07-19T20:48:08.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5] for update
[2025-07-19T20:48:08.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.1.delta.45c4f4be-e026-474d-b86e-78cda015873c.TID347.tmp
[2025-07-19T20:48:08.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f886f4e
[2025-07-19T20:48:08.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.1.delta.9054c9e7-7afc-4a04-953b-3fc7925b0ed8.TID346.tmp
[2025-07-19T20:48:08.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.1.delta.5094efc0-cf62-4f34-8dd1-af04544a5c28.TID344.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta
[2025-07-19T20:48:08.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta
[2025-07-19T20:48:08.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19] for update
[2025-07-19T20:48:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.1.delta.a7340600-0eeb-4730-b9bc-5e1d2d3a4043.TID342.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta
[2025-07-19T20:48:08.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta
[2025-07-19T20:48:08.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 344, attempt 0, stage 1.0)
[2025-07-19T20:48:08.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 342, attempt 0, stage 1.0)
[2025-07-19T20:48:08.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f792729
[2025-07-19T20:48:08.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17] for update
[2025-07-19T20:48:08.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.1.delta.9eeda11b-801d-45c6-81bc-bf3b4d39277c.TID349.tmp
[2025-07-19T20:48:08.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.1.delta.8377bcdc-6986-42a8-af4e-1046476eb0fc.TID348.tmp
[2025-07-19T20:48:08.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.1.delta.26b5a2af-8298-4d3f-bfde-636c61681039.TID343.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta
[2025-07-19T20:48:08.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta
[2025-07-19T20:48:08.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 343, attempt 0, stage 1.0)
[2025-07-19T20:48:08.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 197 (task 344, attempt 0, stage 1.0)
[2025-07-19T20:48:08.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.1.delta.421f1f4c-68ad-4b81-a882-3d6b53d2ed58.TID345.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta
[2025-07-19T20:48:08.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta
[2025-07-19T20:48:08.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 197.0 in stage 1.0 (TID 344). 9113 bytes result sent to driver
[2025-07-19T20:48:08.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 194 (task 342, attempt 0, stage 1.0)
[2025-07-19T20:48:08.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 194.0 in stage 1.0 (TID 342). 9124 bytes result sent to driver
[2025-07-19T20:48:08.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 345, attempt 0, stage 1.0)
[2025-07-19T20:48:08.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 350) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 351) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 344) in 114 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:48:08.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 342) in 148 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:48:08.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 24.0 in stage 1.0 (TID 351)
[2025-07-19T20:48:08.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 21.0 in stage 1.0 (TID 350)
[2025-07-19T20:48:08.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.1.delta.45c4f4be-e026-474d-b86e-78cda015873c.TID347.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta
[2025-07-19T20:48:08.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta
[2025-07-19T20:48:08.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2be68039
[2025-07-19T20:48:08.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 347, attempt 0, stage 1.0)
[2025-07-19T20:48:08.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 196 (task 343, attempt 0, stage 1.0)
[2025-07-19T20:48:08.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 196.0 in stage 1.0 (TID 343). 9107 bytes result sent to driver
[2025-07-19T20:48:08.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 343) in 133 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:48:08.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.1.delta.9054c9e7-7afc-4a04-953b-3fc7925b0ed8.TID346.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta
[2025-07-19T20:48:08.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 352) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta
[2025-07-19T20:48:08.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 6 (task 347, attempt 0, stage 1.0)
[2025-07-19T20:48:08.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24] for update
[2025-07-19T20:48:08.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 25.0 in stage 1.0 (TID 352)
[2025-07-19T20:48:08.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 199 (task 345, attempt 0, stage 1.0)
[2025-07-19T20:48:08.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 199.0 in stage 1.0 (TID 345). 9111 bytes result sent to driver
[2025-07-19T20:48:08.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 346, attempt 0, stage 1.0)
[2025-07-19T20:48:08.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 6.0 in stage 1.0 (TID 347). 6200 bytes result sent to driver
[2025-07-19T20:48:08.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 353) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 354) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 32.0 in stage 1.0 (TID 354)
[2025-07-19T20:48:08.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 345) in 137 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:48:08.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 29.0 in stage 1.0 (TID 353)
[2025-07-19T20:48:08.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e33097d
[2025-07-19T20:48:08.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21] for update
[2025-07-19T20:48:08.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 347) in 100 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:48:08.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 5 (task 346, attempt 0, stage 1.0)
[2025-07-19T20:48:08.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.1.delta.9eeda11b-801d-45c6-81bc-bf3b4d39277c.TID349.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta
[2025-07-19T20:48:08.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta
[2025-07-19T20:48:08.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 349, attempt 0, stage 1.0)
[2025-07-19T20:48:08.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 5.0 in stage 1.0 (TID 346). 6243 bytes result sent to driver
[2025-07-19T20:48:08.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 355) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45cd80d8
[2025-07-19T20:48:08.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32] for update
[2025-07-19T20:48:08.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 19 (task 349, attempt 0, stage 1.0)
[2025-07-19T20:48:08.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 19.0 in stage 1.0 (TID 349). 6200 bytes result sent to driver
[2025-07-19T20:48:08.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 356) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 36.0 in stage 1.0 (TID 356)
[2025-07-19T20:48:08.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 349) in 91 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:48:08.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 34.0 in stage 1.0 (TID 355)
[2025-07-19T20:48:08.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 346) in 130 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:48:08.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.1.delta.8377bcdc-6986-42a8-af4e-1046476eb0fc.TID348.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 348, attempt 0, stage 1.0)
[2025-07-19T20:48:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.1.delta.8e595877-7020-4a2a-af2b-505272082ec6.TID351.tmp
[2025-07-19T20:48:08.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71c8014d
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.1.delta.2e1ab915-d75e-42bf-9be7-2f29e188e425.TID350.tmp
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25] for update
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 17 (task 348, attempt 0, stage 1.0)
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 17.0 in stage 1.0 (TID 348). 6200 bytes result sent to driver
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.1.delta.2ac31182-9349-4d5a-945f-7e6e968fdc63.TID354.tmp
[2025-07-19T20:48:08.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 357) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 348) in 109 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:48:08.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 40.0 in stage 1.0 (TID 357)
[2025-07-19T20:48:08.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@365b7f7c
[2025-07-19T20:48:08.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34] for update
[2025-07-19T20:48:08.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:48:08.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18b27e8a
[2025-07-19T20:48:08.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36] for update
[2025-07-19T20:48:08.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.1.delta.203ea736-a09a-40d1-9c37-3536d3ee4a78.TID352.tmp
[2025-07-19T20:48:08.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.1.delta.378e89f4-4713-4d6e-b3a5-c4a19ba347d4.TID355.tmp
[2025-07-19T20:48:08.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49c36d2c
[2025-07-19T20:48:08.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29] for update
[2025-07-19T20:48:08.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3062be43
[2025-07-19T20:48:08.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.1.delta.402394e5-57b4-44f8-a506-d7580758cf74.TID353.tmp
[2025-07-19T20:48:08.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40] for update
[2025-07-19T20:48:08.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.1.delta.2ac31182-9349-4d5a-945f-7e6e968fdc63.TID354.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta
[2025-07-19T20:48:08.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta
[2025-07-19T20:48:08.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.1.delta.1414fdbc-e7ee-4994-b29f-844a098539cb.TID356.tmp
[2025-07-19T20:48:08.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 354, attempt 0, stage 1.0)
[2025-07-19T20:48:08.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.1.delta.2e1ab915-d75e-42bf-9be7-2f29e188e425.TID350.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta
[2025-07-19T20:48:08.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta
[2025-07-19T20:48:08.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.1.delta.8e595877-7020-4a2a-af2b-505272082ec6.TID351.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta
[2025-07-19T20:48:08.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta
[2025-07-19T20:48:08.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 350, attempt 0, stage 1.0)
[2025-07-19T20:48:08.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 351, attempt 0, stage 1.0)
[2025-07-19T20:48:08.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 32 (task 354, attempt 0, stage 1.0)
[2025-07-19T20:48:08.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 32.0 in stage 1.0 (TID 354). 6243 bytes result sent to driver
[2025-07-19T20:48:08.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 21 (task 350, attempt 0, stage 1.0)
[2025-07-19T20:48:08.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 358) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 354) in 115 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:48:08.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 21.0 in stage 1.0 (TID 350). 6243 bytes result sent to driver
[2025-07-19T20:48:08.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 359) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 49.0 in stage 1.0 (TID 359)
[2025-07-19T20:48:08.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 350) in 142 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:48:08.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 24 (task 351, attempt 0, stage 1.0)
[2025-07-19T20:48:08.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 24.0 in stage 1.0 (TID 351). 6243 bytes result sent to driver
[2025-07-19T20:48:08.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 44.0 in stage 1.0 (TID 358)
[2025-07-19T20:48:08.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 360) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 351) in 149 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:48:08.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.1.delta.203ea736-a09a-40d1-9c37-3536d3ee4a78.TID352.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta
[2025-07-19T20:48:08.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta
[2025-07-19T20:48:08.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 53.0 in stage 1.0 (TID 360)
[2025-07-19T20:48:08.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 352, attempt 0, stage 1.0)
[2025-07-19T20:48:08.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.1.delta.ade69b22-6923-4af3-b0f5-c1b411dca4cc.TID357.tmp
[2025-07-19T20:48:08.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 25 (task 352, attempt 0, stage 1.0)
[2025-07-19T20:48:08.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.1.delta.378e89f4-4713-4d6e-b3a5-c4a19ba347d4.TID355.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta
[2025-07-19T20:48:08.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta
[2025-07-19T20:48:08.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 355, attempt 0, stage 1.0)
[2025-07-19T20:48:08.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b6db1e3
[2025-07-19T20:48:08.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 25.0 in stage 1.0 (TID 352). 6286 bytes result sent to driver
[2025-07-19T20:48:08.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 361) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 352) in 144 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:48:08.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 57.0 in stage 1.0 (TID 361)
[2025-07-19T20:48:08.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49] for update
[2025-07-19T20:48:08.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 34 (task 355, attempt 0, stage 1.0)
[2025-07-19T20:48:08.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 34.0 in stage 1.0 (TID 355). 6243 bytes result sent to driver
[2025-07-19T20:48:08.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 362) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 355) in 139 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:48:08.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.1.delta.402394e5-57b4-44f8-a506-d7580758cf74.TID353.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta
[2025-07-19T20:48:08.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta
[2025-07-19T20:48:08.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 353, attempt 0, stage 1.0)
[2025-07-19T20:48:08.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 61.0 in stage 1.0 (TID 362)
[2025-07-19T20:48:08.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 29 (task 353, attempt 0, stage 1.0)
[2025-07-19T20:48:08.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 29.0 in stage 1.0 (TID 353). 6243 bytes result sent to driver
[2025-07-19T20:48:08.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 363) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 353) in 155 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:48:08.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e95c0cf
[2025-07-19T20:48:08.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 64.0 in stage 1.0 (TID 363)
[2025-07-19T20:48:08.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.555+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53] for update
[2025-07-19T20:48:08.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.1.delta.a901470d-6a94-4e8b-9c6e-0782c9c4e197.TID359.tmp
[2025-07-19T20:48:08.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71744769
[2025-07-19T20:48:08.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44] for update
[2025-07-19T20:48:08.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33c32b9a
[2025-07-19T20:48:08.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64] for update
[2025-07-19T20:48:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.1.delta.e94d170b-94d4-4bfc-afd8-f226158a5253.TID360.tmp
[2025-07-19T20:48:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.1.delta.cb4e4203-be5a-47fb-8624-293d6732f221.TID358.tmp
[2025-07-19T20:48:08.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.1.delta.1414fdbc-e7ee-4994-b29f-844a098539cb.TID356.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta
[2025-07-19T20:48:08.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta
[2025-07-19T20:48:08.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@450f5f41
[2025-07-19T20:48:08.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 356, attempt 0, stage 1.0)
[2025-07-19T20:48:08.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61] for update
[2025-07-19T20:48:08.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 36 (task 356, attempt 0, stage 1.0)
[2025-07-19T20:48:08.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 36.0 in stage 1.0 (TID 356). 6243 bytes result sent to driver
[2025-07-19T20:48:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4914fc1c
[2025-07-19T20:48:08.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.1.delta.ade69b22-6923-4af3-b0f5-c1b411dca4cc.TID357.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta
[2025-07-19T20:48:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta
[2025-07-19T20:48:08.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57] for update
[2025-07-19T20:48:08.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 364) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 356) in 181 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:48:08.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 357, attempt 0, stage 1.0)
[2025-07-19T20:48:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.1.delta.d3487e6a-2b4b-4d5d-bbf8-6078070a8435.TID363.tmp
[2025-07-19T20:48:08.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 69.0 in stage 1.0 (TID 364)
[2025-07-19T20:48:08.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 40 (task 357, attempt 0, stage 1.0)
[2025-07-19T20:48:08.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.1.delta.4a58dfb4-db5e-4dd9-8eba-425785292cd9.TID362.tmp
[2025-07-19T20:48:08.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 40.0 in stage 1.0 (TID 357). 6243 bytes result sent to driver
[2025-07-19T20:48:08.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 365) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 357) in 187 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:48:08.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 70.0 in stage 1.0 (TID 365)
[2025-07-19T20:48:08.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39e72363
[2025-07-19T20:48:08.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69] for update
[2025-07-19T20:48:08.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.1.delta.a901470d-6a94-4e8b-9c6e-0782c9c4e197.TID359.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta
[2025-07-19T20:48:08.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta
[2025-07-19T20:48:08.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 359, attempt 0, stage 1.0)
[2025-07-19T20:48:08.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.1.delta.f29526e0-ff56-431a-a870-f39ad0cc30f8.TID361.tmp
[2025-07-19T20:48:08.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 49 (task 359, attempt 0, stage 1.0)
[2025-07-19T20:48:08.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 49.0 in stage 1.0 (TID 359). 6200 bytes result sent to driver
[2025-07-19T20:48:08.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:48:08.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 366) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 359) in 110 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:48:08.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 73.0 in stage 1.0 (TID 366)
[2025-07-19T20:48:08.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.1.delta.e94d170b-94d4-4bfc-afd8-f226158a5253.TID360.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta
[2025-07-19T20:48:08.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta
[2025-07-19T20:48:08.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 360, attempt 0, stage 1.0)
[2025-07-19T20:48:08.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ae50e69
[2025-07-19T20:48:08.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70] for update
[2025-07-19T20:48:08.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.1.delta.cb4e4203-be5a-47fb-8624-293d6732f221.TID358.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta
[2025-07-19T20:48:08.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta
[2025-07-19T20:48:08.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 358, attempt 0, stage 1.0)
[2025-07-19T20:48:08.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 53 (task 360, attempt 0, stage 1.0)
[2025-07-19T20:48:08.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 53.0 in stage 1.0 (TID 360). 6200 bytes result sent to driver
[2025-07-19T20:48:08.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.1.delta.d3487e6a-2b4b-4d5d-bbf8-6078070a8435.TID363.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta
[2025-07-19T20:48:08.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta
[2025-07-19T20:48:08.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 367) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 363, attempt 0, stage 1.0)
[2025-07-19T20:48:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.1.delta.991a4be2-354d-4bb7-b088-7886c36a6512.TID364.tmp
[2025-07-19T20:48:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 44 (task 358, attempt 0, stage 1.0)
[2025-07-19T20:48:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28788baa
[2025-07-19T20:48:08.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 81.0 in stage 1.0 (TID 367)
[2025-07-19T20:48:08.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 360) in 128 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:48:08.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73] for update
[2025-07-19T20:48:08.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 64 (task 363, attempt 0, stage 1.0)
[2025-07-19T20:48:08.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 64.0 in stage 1.0 (TID 363). 6200 bytes result sent to driver
[2025-07-19T20:48:08.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 44.0 in stage 1.0 (TID 358). 6200 bytes result sent to driver
[2025-07-19T20:48:08.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 368) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 369) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 363) in 104 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:48:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 358) in 144 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:48:08.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 86.0 in stage 1.0 (TID 368)
[2025-07-19T20:48:08.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.1.delta.4a58dfb4-db5e-4dd9-8eba-425785292cd9.TID362.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta
[2025-07-19T20:48:08.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta
[2025-07-19T20:48:08.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 89.0 in stage 1.0 (TID 369)
[2025-07-19T20:48:08.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 362, attempt 0, stage 1.0)
[2025-07-19T20:48:08.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 61 (task 362, attempt 0, stage 1.0)
[2025-07-19T20:48:08.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.1.delta.e2150755-dfc9-4788-9523-e488e3db5e4e.TID365.tmp
[2025-07-19T20:48:08.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 61.0 in stage 1.0 (TID 362). 6200 bytes result sent to driver
[2025-07-19T20:48:08.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@615d8a84
[2025-07-19T20:48:08.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 370) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81] for update
[2025-07-19T20:48:08.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 362) in 121 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:48:08.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.1.delta.25a9eadb-c31f-43c9-b9ea-cd7c170de6f3.TID366.tmp
[2025-07-19T20:48:08.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 90.0 in stage 1.0 (TID 370)
[2025-07-19T20:48:08.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.1.delta.f29526e0-ff56-431a-a870-f39ad0cc30f8.TID361.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta
[2025-07-19T20:48:08.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta
[2025-07-19T20:48:08.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 361, attempt 0, stage 1.0)
[2025-07-19T20:48:08.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@327fbf7f
[2025-07-19T20:48:08.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89] for update
[2025-07-19T20:48:08.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 57 (task 361, attempt 0, stage 1.0)
[2025-07-19T20:48:08.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 57.0 in stage 1.0 (TID 361). 6243 bytes result sent to driver
[2025-07-19T20:48:08.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 371) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 91.0 in stage 1.0 (TID 371)
[2025-07-19T20:48:08.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 361) in 144 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:48:08.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d07bd97
[2025-07-19T20:48:08.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86] for update
[2025-07-19T20:48:08.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.1.delta.abc3b227-7f59-45e8-90d1-66b5828e90ab.TID367.tmp
[2025-07-19T20:48:08.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ba1821b
[2025-07-19T20:48:08.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90] for update
[2025-07-19T20:48:08.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd648e9
[2025-07-19T20:48:08.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91] for update
[2025-07-19T20:48:08.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.1.delta.0cdd6385-2ffb-4798-ae96-3f0170d773c5.TID368.tmp
[2025-07-19T20:48:08.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.1.delta.65f40b9a-2aa2-4f76-940b-1a9da2c752ac.TID369.tmp
[2025-07-19T20:48:08.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.1.delta.25a9eadb-c31f-43c9-b9ea-cd7c170de6f3.TID366.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta
[2025-07-19T20:48:08.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta
[2025-07-19T20:48:08.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 366, attempt 0, stage 1.0)
[2025-07-19T20:48:08.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.1.delta.991a4be2-354d-4bb7-b088-7886c36a6512.TID364.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta
[2025-07-19T20:48:08.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta
[2025-07-19T20:48:08.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 364, attempt 0, stage 1.0)
[2025-07-19T20:48:08.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 73 (task 366, attempt 0, stage 1.0)
[2025-07-19T20:48:08.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 73.0 in stage 1.0 (TID 366). 6200 bytes result sent to driver
[2025-07-19T20:48:08.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 372) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 366) in 102 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:48:08.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 92.0 in stage 1.0 (TID 372)
[2025-07-19T20:48:08.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.1.delta.eadf8f8a-9d0b-4b42-93a5-a3ce27ad2097.TID371.tmp
[2025-07-19T20:48:08.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.1.delta.e2150755-dfc9-4788-9523-e488e3db5e4e.TID365.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta
[2025-07-19T20:48:08.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta
[2025-07-19T20:48:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.1.delta.963d7526-6897-47d0-9949-67a22fe7f1e8.TID370.tmp
[2025-07-19T20:48:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 365, attempt 0, stage 1.0)
[2025-07-19T20:48:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 69 (task 364, attempt 0, stage 1.0)
[2025-07-19T20:48:08.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 69.0 in stage 1.0 (TID 364). 6200 bytes result sent to driver
[2025-07-19T20:48:08.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 373) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 364) in 143 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:48:08.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 93.0 in stage 1.0 (TID 373)
[2025-07-19T20:48:08.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 70 (task 365, attempt 0, stage 1.0)
[2025-07-19T20:48:08.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 70.0 in stage 1.0 (TID 365). 6200 bytes result sent to driver
[2025-07-19T20:48:08.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 374) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 98.0 in stage 1.0 (TID 374)
[2025-07-19T20:48:08.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 365) in 129 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:48:08.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53a711a9
[2025-07-19T20:48:08.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92] for update
[2025-07-19T20:48:08.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.1.delta.abc3b227-7f59-45e8-90d1-66b5828e90ab.TID367.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta
[2025-07-19T20:48:08.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta
[2025-07-19T20:48:08.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 367, attempt 0, stage 1.0)
[2025-07-19T20:48:08.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 81 (task 367, attempt 0, stage 1.0)
[2025-07-19T20:48:08.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 81.0 in stage 1.0 (TID 367). 6200 bytes result sent to driver
[2025-07-19T20:48:08.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 375) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 102.0 in stage 1.0 (TID 375)
[2025-07-19T20:48:08.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 367) in 107 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:48:08.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c9664a0
[2025-07-19T20:48:08.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.1.delta.65f40b9a-2aa2-4f76-940b-1a9da2c752ac.TID369.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta
[2025-07-19T20:48:08.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta
[2025-07-19T20:48:08.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98] for update
[2025-07-19T20:48:08.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 369, attempt 0, stage 1.0)
[2025-07-19T20:48:08.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.1.delta.0cdd6385-2ffb-4798-ae96-3f0170d773c5.TID368.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta
[2025-07-19T20:48:08.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta
[2025-07-19T20:48:08.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 368, attempt 0, stage 1.0)
[2025-07-19T20:48:08.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 89 (task 369, attempt 0, stage 1.0)
[2025-07-19T20:48:08.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 89.0 in stage 1.0 (TID 369). 6200 bytes result sent to driver
[2025-07-19T20:48:08.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.1.delta.e09f0398-ad0a-47c8-b95d-258bf97fa946.TID372.tmp
[2025-07-19T20:48:08.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 376) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@445860f0
[2025-07-19T20:48:08.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 105.0 in stage 1.0 (TID 376)
[2025-07-19T20:48:08.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 369) in 113 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:48:08.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93] for update
[2025-07-19T20:48:08.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 86 (task 368, attempt 0, stage 1.0)
[2025-07-19T20:48:08.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 86.0 in stage 1.0 (TID 368). 6200 bytes result sent to driver
[2025-07-19T20:48:08.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 377) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 368) in 119 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:48:08.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 107.0 in stage 1.0 (TID 377)
[2025-07-19T20:48:08.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5112b613
[2025-07-19T20:48:08.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102] for update
[2025-07-19T20:48:08.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.1.delta.93a1d22f-dba0-48b0-87bd-94f595ee1dc3.TID374.tmp
[2025-07-19T20:48:08.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.1.delta.eadf8f8a-9d0b-4b42-93a5-a3ce27ad2097.TID371.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta
[2025-07-19T20:48:08.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta
[2025-07-19T20:48:08.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.1.delta.963d7526-6897-47d0-9949-67a22fe7f1e8.TID370.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta
[2025-07-19T20:48:08.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta
[2025-07-19T20:48:08.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.1.delta.0d67628c-1910-4756-9e97-5a23f5a44bef.TID373.tmp
[2025-07-19T20:48:08.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 371, attempt 0, stage 1.0)
[2025-07-19T20:48:08.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 370, attempt 0, stage 1.0)
[2025-07-19T20:48:08.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1de35af1
[2025-07-19T20:48:08.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107] for update
[2025-07-19T20:48:08.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 90 (task 370, attempt 0, stage 1.0)
[2025-07-19T20:48:08.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.1.delta.a73c0ce0-b499-4fac-961a-9d316e30fb1e.TID375.tmp
[2025-07-19T20:48:08.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 90.0 in stage 1.0 (TID 370). 6200 bytes result sent to driver
[2025-07-19T20:48:08.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 91 (task 371, attempt 0, stage 1.0)
[2025-07-19T20:48:08.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 378) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 109.0 in stage 1.0 (TID 378)
[2025-07-19T20:48:08.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 370) in 129 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:48:08.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 91.0 in stage 1.0 (TID 371). 6200 bytes result sent to driver
[2025-07-19T20:48:08.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 379) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 116.0 in stage 1.0 (TID 379)
[2025-07-19T20:48:08.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 371) in 116 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:48:08.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25790af4
[2025-07-19T20:48:08.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105] for update
[2025-07-19T20:48:08.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.1.delta.9d495ee9-9e32-431f-a94a-f3626c78590a.TID377.tmp
[2025-07-19T20:48:08.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3205e92a
[2025-07-19T20:48:08.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116] for update
[2025-07-19T20:48:08.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.1.delta.e09f0398-ad0a-47c8-b95d-258bf97fa946.TID372.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta
[2025-07-19T20:48:08.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta
[2025-07-19T20:48:08.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 372, attempt 0, stage 1.0)
[2025-07-19T20:48:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2df5274c
[2025-07-19T20:48:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109] for update
[2025-07-19T20:48:08.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.1.delta.93a1d22f-dba0-48b0-87bd-94f595ee1dc3.TID374.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta
[2025-07-19T20:48:08.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta
[2025-07-19T20:48:08.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.1.delta.2470e121-0fe4-41d8-87a3-938ba800cdad.TID376.tmp
[2025-07-19T20:48:08.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 374, attempt 0, stage 1.0)
[2025-07-19T20:48:08.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.1.delta.95d889f3-6321-4b0a-a7ce-5ff00b1c254d.TID379.tmp
[2025-07-19T20:48:08.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 92 (task 372, attempt 0, stage 1.0)
[2025-07-19T20:48:08.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 92.0 in stage 1.0 (TID 372). 6200 bytes result sent to driver
[2025-07-19T20:48:08.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 380) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 372) in 102 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:48:08.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 123.0 in stage 1.0 (TID 380)
[2025-07-19T20:48:08.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 98 (task 374, attempt 0, stage 1.0)
[2025-07-19T20:48:08.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 98.0 in stage 1.0 (TID 374). 6200 bytes result sent to driver
[2025-07-19T20:48:08.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 381) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 124.0 in stage 1.0 (TID 381)
[2025-07-19T20:48:08.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 374) in 98 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:48:08.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.1.delta.0d67628c-1910-4756-9e97-5a23f5a44bef.TID373.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta
[2025-07-19T20:48:08.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta
[2025-07-19T20:48:08.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.1.delta.7019b209-474c-40e9-b3f1-ee3ffea6a800.TID378.tmp
[2025-07-19T20:48:08.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50d198
[2025-07-19T20:48:08.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 373, attempt 0, stage 1.0)
[2025-07-19T20:48:08.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123] for update
[2025-07-19T20:48:08.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 93 (task 373, attempt 0, stage 1.0)
[2025-07-19T20:48:08.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 93.0 in stage 1.0 (TID 373). 6200 bytes result sent to driver
[2025-07-19T20:48:08.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@603bc778
[2025-07-19T20:48:08.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124] for update
[2025-07-19T20:48:08.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 382) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 373) in 119 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:48:08.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 126.0 in stage 1.0 (TID 382)
[2025-07-19T20:48:08.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.1.delta.a73c0ce0-b499-4fac-961a-9d316e30fb1e.TID375.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta
[2025-07-19T20:48:08.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta
[2025-07-19T20:48:08.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 375, attempt 0, stage 1.0)
[2025-07-19T20:48:08.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.1.delta.9d495ee9-9e32-431f-a94a-f3626c78590a.TID377.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta
[2025-07-19T20:48:08.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta
[2025-07-19T20:48:08.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 377, attempt 0, stage 1.0)
[2025-07-19T20:48:08.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.1.delta.70c19065-0bcd-4cec-ba06-e7bc6b183667.TID380.tmp
[2025-07-19T20:48:08.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 107 (task 377, attempt 0, stage 1.0)
[2025-07-19T20:48:08.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.1.delta.45fe73e1-ee75-4203-8c13-6e5b7f962d89.TID381.tmp
[2025-07-19T20:48:08.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 107.0 in stage 1.0 (TID 377). 6200 bytes result sent to driver
[2025-07-19T20:48:08.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 383) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 377) in 91 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:48:08.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 102 (task 375, attempt 0, stage 1.0)
[2025-07-19T20:48:08.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 102.0 in stage 1.0 (TID 375). 6200 bytes result sent to driver
[2025-07-19T20:48:08.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 384) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 132.0 in stage 1.0 (TID 384)
[2025-07-19T20:48:08.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 375) in 113 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:48:08.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 127.0 in stage 1.0 (TID 383)
[2025-07-19T20:48:08.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.1.delta.2470e121-0fe4-41d8-87a3-938ba800cdad.TID376.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta
[2025-07-19T20:48:08.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta
[2025-07-19T20:48:08.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 376, attempt 0, stage 1.0)
[2025-07-19T20:48:08.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47b15427
[2025-07-19T20:48:08.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126] for update
[2025-07-19T20:48:08.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 105 (task 376, attempt 0, stage 1.0)
[2025-07-19T20:48:08.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 105.0 in stage 1.0 (TID 376). 6200 bytes result sent to driver
[2025-07-19T20:48:08.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 385) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 136.0 in stage 1.0 (TID 385)
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 376) in 106 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3195fc88
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132] for update
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.1.delta.7019b209-474c-40e9-b3f1-ee3ffea6a800.TID378.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta
[2025-07-19T20:48:08.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 378, attempt 0, stage 1.0)
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.1.delta.95d889f3-6321-4b0a-a7ce-5ff00b1c254d.TID379.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 109 (task 378, attempt 0, stage 1.0)
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 109.0 in stage 1.0 (TID 378). 6200 bytes result sent to driver
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 379, attempt 0, stage 1.0)
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 386) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 378) in 92 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:48:08.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 138.0 in stage 1.0 (TID 386)
[2025-07-19T20:48:08.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4906ec02
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127] for update
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 116 (task 379, attempt 0, stage 1.0)
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.1.delta.50542dd4-c236-4422-b6f9-66e95e09dd91.TID382.tmp
[2025-07-19T20:48:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.1.delta.9b3c774d-084c-481a-b7cc-44f21e9faf4e.TID384.tmp
[2025-07-19T20:48:08.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 116.0 in stage 1.0 (TID 379). 6200 bytes result sent to driver
[2025-07-19T20:48:08.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 387) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 140.0 in stage 1.0 (TID 387)
[2025-07-19T20:48:08.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 379) in 99 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:48:08.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ff57473
[2025-07-19T20:48:08.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136] for update
[2025-07-19T20:48:08.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@701a8066
[2025-07-19T20:48:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138] for update
[2025-07-19T20:48:08.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.1.delta.2a184281-f7de-4b00-a014-5567c51e492e.TID385.tmp
[2025-07-19T20:48:08.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.1.delta.45fe73e1-ee75-4203-8c13-6e5b7f962d89.TID381.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta
[2025-07-19T20:48:08.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta
[2025-07-19T20:48:08.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.1.delta.a9c28458-29d5-443a-b740-b24bb9798180.TID383.tmp
[2025-07-19T20:48:08.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 381, attempt 0, stage 1.0)
[2025-07-19T20:48:08.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19f933c8
[2025-07-19T20:48:08.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140] for update
[2025-07-19T20:48:08.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.1.delta.70c19065-0bcd-4cec-ba06-e7bc6b183667.TID380.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta
[2025-07-19T20:48:08.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta
[2025-07-19T20:48:08.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 380, attempt 0, stage 1.0)
[2025-07-19T20:48:08.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 124 (task 381, attempt 0, stage 1.0)
[2025-07-19T20:48:08.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 124.0 in stage 1.0 (TID 381). 6200 bytes result sent to driver
[2025-07-19T20:48:08.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 388) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 152.0 in stage 1.0 (TID 388)
[2025-07-19T20:48:08.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 381) in 87 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:48:08.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fa61e71
[2025-07-19T20:48:08.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152] for update
[2025-07-19T20:48:08.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.1.delta.50542dd4-c236-4422-b6f9-66e95e09dd91.TID382.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta
[2025-07-19T20:48:08.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta
[2025-07-19T20:48:08.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 382, attempt 0, stage 1.0)
[2025-07-19T20:48:08.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 126 (task 382, attempt 0, stage 1.0)
[2025-07-19T20:48:08.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 126.0 in stage 1.0 (TID 382). 6200 bytes result sent to driver
[2025-07-19T20:48:08.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 389) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.1.delta.50dc3636-4a11-41ee-9c42-ac2906886ae3.TID387.tmp
[2025-07-19T20:48:08.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 155.0 in stage 1.0 (TID 389)
[2025-07-19T20:48:08.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 382) in 90 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:48:08.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.1.delta.94023564-7d28-4082-b577-9247057ee12c.TID386.tmp
[2025-07-19T20:48:08.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.1.delta.9b3c774d-084c-481a-b7cc-44f21e9faf4e.TID384.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta
[2025-07-19T20:48:08.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta
[2025-07-19T20:48:08.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 384, attempt 0, stage 1.0)
[2025-07-19T20:48:08.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 132 (task 384, attempt 0, stage 1.0)
[2025-07-19T20:48:08.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 123 (task 380, attempt 0, stage 1.0)
[2025-07-19T20:48:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 123.0 in stage 1.0 (TID 380). 6200 bytes result sent to driver
[2025-07-19T20:48:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 132.0 in stage 1.0 (TID 384). 6200 bytes result sent to driver
[2025-07-19T20:48:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 390) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 380) in 126 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:48:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 160.0 in stage 1.0 (TID 390)
[2025-07-19T20:48:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.1.delta.7cd583d9-5ce6-478b-8856-4a6e25dc8a7c.TID388.tmp
[2025-07-19T20:48:08.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c746eb1
[2025-07-19T20:48:08.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 391) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 384) in 91 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:48:08.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 161.0 in stage 1.0 (TID 391)
[2025-07-19T20:48:08.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155] for update
[2025-07-19T20:48:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.1.delta.a9c28458-29d5-443a-b740-b24bb9798180.TID383.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta
[2025-07-19T20:48:08.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta
[2025-07-19T20:48:08.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 383, attempt 0, stage 1.0)
[2025-07-19T20:48:08.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8e92cb2
[2025-07-19T20:48:08.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160] for update
[2025-07-19T20:48:08.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.1.delta.2a184281-f7de-4b00-a014-5567c51e492e.TID385.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta
[2025-07-19T20:48:08.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta
[2025-07-19T20:48:08.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 385, attempt 0, stage 1.0)
[2025-07-19T20:48:08.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 136 (task 385, attempt 0, stage 1.0)
[2025-07-19T20:48:08.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 136.0 in stage 1.0 (TID 385). 6200 bytes result sent to driver
[2025-07-19T20:48:08.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 127 (task 383, attempt 0, stage 1.0)
[2025-07-19T20:48:08.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 392) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 127.0 in stage 1.0 (TID 383). 6200 bytes result sent to driver
[2025-07-19T20:48:08.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 163.0 in stage 1.0 (TID 392)
[2025-07-19T20:48:08.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 393) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 385) in 103 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:48:08.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 383) in 114 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:48:08.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 164.0 in stage 1.0 (TID 393)
[2025-07-19T20:48:08.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:08.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c1aa1eb
[2025-07-19T20:48:08.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161] for update
[2025-07-19T20:48:08.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.1.delta.fb132d13-2f5b-41f8-b514-444256c7322b.TID389.tmp
[2025-07-19T20:48:08.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.1.delta.7b64540d-3c50-4305-a9d7-464867a69380.TID390.tmp
[2025-07-19T20:48:08.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@435b4285
[2025-07-19T20:48:08.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164] for update
[2025-07-19T20:48:08.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.1.delta.979f2634-fa09-4b99-a658-84caa4ebad3b.TID391.tmp
[2025-07-19T20:48:08.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.1.delta.50dc3636-4a11-41ee-9c42-ac2906886ae3.TID387.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta
[2025-07-19T20:48:08.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta
[2025-07-19T20:48:08.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 387, attempt 0, stage 1.0)
[2025-07-19T20:48:08.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c28abe2
[2025-07-19T20:48:08.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.1.delta.7cd583d9-5ce6-478b-8856-4a6e25dc8a7c.TID388.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta
[2025-07-19T20:48:08.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta
[2025-07-19T20:48:08.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 388, attempt 0, stage 1.0)
[2025-07-19T20:48:08.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:08.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163] for update
[2025-07-19T20:48:08.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:08.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 140 (task 387, attempt 0, stage 1.0)
[2025-07-19T20:48:08.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 140.0 in stage 1.0 (TID 387). 6200 bytes result sent to driver
[2025-07-19T20:48:08.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.1.delta.a990b4a0-f6c8-42e0-ad98-fe8c75941233.TID393.tmp
[2025-07-19T20:48:08.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 394) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 152 (task 388, attempt 0, stage 1.0)
[2025-07-19T20:48:08.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 387) in 118 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:48:08.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Finished task 152.0 in stage 1.0 (TID 388). 6200 bytes result sent to driver
[2025-07-19T20:48:08.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.1.delta.94023564-7d28-4082-b577-9247057ee12c.TID386.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 395) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 386, attempt 0, stage 1.0)
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 166.0 in stage 1.0 (TID 394)
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 388) in 94 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO Executor: Running task 176.0 in stage 1.0 (TID 395)
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:08.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:09.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:09.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:08 INFO DataWritingSparkTask: Committed partition 138 (task 386, attempt 0, stage 1.0)
[2025-07-19T20:48:09.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d36ac1a
[2025-07-19T20:48:09.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 138.0 in stage 1.0 (TID 386). 6286 bytes result sent to driver
[2025-07-19T20:48:09.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.1.delta.a209f836-a9da-4905-a1f8-8dd85924c1e2.TID392.tmp
[2025-07-19T20:48:09.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176] for update
[2025-07-19T20:48:09.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 396) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 386) in 144 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:48:09.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 177.0 in stage 1.0 (TID 396)
[2025-07-19T20:48:09.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48974974
[2025-07-19T20:48:09.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166] for update
[2025-07-19T20:48:09.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.1.delta.fb132d13-2f5b-41f8-b514-444256c7322b.TID389.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta
[2025-07-19T20:48:09.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta
[2025-07-19T20:48:09.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.1.delta.7b64540d-3c50-4305-a9d7-464867a69380.TID390.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 389, attempt 0, stage 1.0)
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 390, attempt 0, stage 1.0)
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5eded59
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177] for update
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 155 (task 389, attempt 0, stage 1.0)
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 155.0 in stage 1.0 (TID 389). 6243 bytes result sent to driver
[2025-07-19T20:48:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 160 (task 390, attempt 0, stage 1.0)
[2025-07-19T20:48:09.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 397) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 389) in 109 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:48:09.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 160.0 in stage 1.0 (TID 390). 6243 bytes result sent to driver
[2025-07-19T20:48:09.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.1.delta.5d8aea62-8aec-49e6-8ad1-340e10b0bc7e.TID395.tmp
[2025-07-19T20:48:09.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 186.0 in stage 1.0 (TID 397)
[2025-07-19T20:48:09.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 398) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.1.delta.94e2e73d-ac6c-4451-a6f1-6495fca0c816.TID394.tmp
[2025-07-19T20:48:09.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 390) in 101 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:48:09.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 190.0 in stage 1.0 (TID 398)
[2025-07-19T20:48:09.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.1.delta.979f2634-fa09-4b99-a658-84caa4ebad3b.TID391.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta
[2025-07-19T20:48:09.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta
[2025-07-19T20:48:09.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 391, attempt 0, stage 1.0)
[2025-07-19T20:48:09.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.1.delta.75a0b501-d61b-4e99-8cbc-e6f434ba4ec0.TID396.tmp
[2025-07-19T20:48:09.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39796da4
[2025-07-19T20:48:09.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186] for update
[2025-07-19T20:48:09.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 161 (task 391, attempt 0, stage 1.0)
[2025-07-19T20:48:09.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.1.delta.a990b4a0-f6c8-42e0-ad98-fe8c75941233.TID393.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta
[2025-07-19T20:48:09.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta
[2025-07-19T20:48:09.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 161.0 in stage 1.0 (TID 391). 6243 bytes result sent to driver
[2025-07-19T20:48:09.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 393, attempt 0, stage 1.0)
[2025-07-19T20:48:09.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 399) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 391) in 114 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:48:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 191.0 in stage 1.0 (TID 399)
[2025-07-19T20:48:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 164 (task 393, attempt 0, stage 1.0)
[2025-07-19T20:48:09.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 164.0 in stage 1.0 (TID 393). 6200 bytes result sent to driver
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 400) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 193.0 in stage 1.0 (TID 400)
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 393) in 98 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3888a0eb
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190] for update
[2025-07-19T20:48:09.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.1.delta.a209f836-a9da-4905-a1f8-8dd85924c1e2.TID392.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta
[2025-07-19T20:48:09.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta
[2025-07-19T20:48:09.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 392, attempt 0, stage 1.0)
[2025-07-19T20:48:09.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.1.delta.48338c9a-1aa0-4470-b7f3-bf1ea6f5a2bc.TID397.tmp
[2025-07-19T20:48:09.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7328d71a
[2025-07-19T20:48:09.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.074+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191] for update
[2025-07-19T20:48:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 163 (task 392, attempt 0, stage 1.0)
[2025-07-19T20:48:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.1.delta.40cc9738-5164-4e4b-ad68-d18a47cd550c.TID398.tmp
[2025-07-19T20:48:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 163.0 in stage 1.0 (TID 392). 6243 bytes result sent to driver
[2025-07-19T20:48:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 401) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.1.delta.5d8aea62-8aec-49e6-8ad1-340e10b0bc7e.TID395.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta
[2025-07-19T20:48:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta
[2025-07-19T20:48:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 195.0 in stage 1.0 (TID 401)
[2025-07-19T20:48:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@627777f0
[2025-07-19T20:48:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 395, attempt 0, stage 1.0)
[2025-07-19T20:48:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193] for update
[2025-07-19T20:48:09.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 392) in 121 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:48:09.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 176 (task 395, attempt 0, stage 1.0)
[2025-07-19T20:48:09.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 176.0 in stage 1.0 (TID 395). 6200 bytes result sent to driver
[2025-07-19T20:48:09.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 402) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 395) in 92 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:48:09.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 198.0 in stage 1.0 (TID 402)
[2025-07-19T20:48:09.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.1.delta.94e2e73d-ac6c-4451-a6f1-6495fca0c816.TID394.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta
[2025-07-19T20:48:09.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta
[2025-07-19T20:48:09.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 394, attempt 0, stage 1.0)
[2025-07-19T20:48:09.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.1.delta.85e31c53-f9cd-466b-ac6a-338c4f12ccf8.TID399.tmp
[2025-07-19T20:48:09.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fb38458
[2025-07-19T20:48:09.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195] for update
[2025-07-19T20:48:09.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.1.delta.c5aa114f-f7a9-4726-ae07-891dcf009a87.TID400.tmp
[2025-07-19T20:48:09.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 166 (task 394, attempt 0, stage 1.0)
[2025-07-19T20:48:09.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 166.0 in stage 1.0 (TID 394). 6243 bytes result sent to driver
[2025-07-19T20:48:09.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.1.delta.75a0b501-d61b-4e99-8cbc-e6f434ba4ec0.TID396.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta
[2025-07-19T20:48:09.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta
[2025-07-19T20:48:09.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9e4a958
[2025-07-19T20:48:09.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:09.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198] for update
[2025-07-19T20:48:09.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 396, attempt 0, stage 1.0)
[2025-07-19T20:48:09.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.1.delta.d805a657-4256-405f-b61c-976fc019cb29.TID401.tmp
[2025-07-19T20:48:09.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 403) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 1.0 in stage 3.0 (TID 403)
[2025-07-19T20:48:09.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 394) in 121 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:48:09.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.1.delta.40cc9738-5164-4e4b-ad68-d18a47cd550c.TID398.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta
[2025-07-19T20:48:09.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta
[2025-07-19T20:48:09.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 398, attempt 0, stage 1.0)
[2025-07-19T20:48:09.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.1.delta.48338c9a-1aa0-4470-b7f3-bf1ea6f5a2bc.TID397.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta
[2025-07-19T20:48:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta
[2025-07-19T20:48:09.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 177 (task 396, attempt 0, stage 1.0)
[2025-07-19T20:48:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 397, attempt 0, stage 1.0)
[2025-07-19T20:48:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 177.0 in stage 1.0 (TID 396). 6243 bytes result sent to driver
[2025-07-19T20:48:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 404) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 190 (task 398, attempt 0, stage 1.0)
[2025-07-19T20:48:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 2.0 in stage 3.0 (TID 404)
[2025-07-19T20:48:09.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 396) in 116 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:48:09.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 186 (task 397, attempt 0, stage 1.0)
[2025-07-19T20:48:09.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 186.0 in stage 1.0 (TID 397). 6243 bytes result sent to driver
[2025-07-19T20:48:09.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 397) in 99 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:48:09.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 190.0 in stage 1.0 (TID 398). 6243 bytes result sent to driver
[2025-07-19T20:48:09.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 405) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 5.0 in stage 3.0 (TID 405)
[2025-07-19T20:48:09.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 406) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 398) in 98 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:48:09.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 6.0 in stage 3.0 (TID 406)
[2025-07-19T20:48:09.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.1.delta.61bf2a30-de58-41ad-820d-d6d8c199dd80.TID402.tmp
[2025-07-19T20:48:09.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.1.delta.85e31c53-f9cd-466b-ac6a-338c4f12ccf8.TID399.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta
[2025-07-19T20:48:09.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta
[2025-07-19T20:48:09.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 399, attempt 0, stage 1.0)
[2025-07-19T20:48:09.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cefcc20
[2025-07-19T20:48:09.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.1.delta.c5aa114f-f7a9-4726-ae07-891dcf009a87.TID400.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta
[2025-07-19T20:48:09.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta
[2025-07-19T20:48:09.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 400, attempt 0, stage 1.0)
[2025-07-19T20:48:09.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1] for update
[2025-07-19T20:48:09.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 191 (task 399, attempt 0, stage 1.0)
[2025-07-19T20:48:09.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 191.0 in stage 1.0 (TID 399). 6243 bytes result sent to driver
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 407) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 7.0 in stage 3.0 (TID 407)
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cdc6cfd
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 399) in 109 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6] for update
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 193 (task 400, attempt 0, stage 1.0)
[2025-07-19T20:48:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 193.0 in stage 1.0 (TID 400). 6243 bytes result sent to driver
[2025-07-19T20:48:09.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 408) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 400) in 108 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:48:09.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 8.0 in stage 3.0 (TID 408)
[2025-07-19T20:48:09.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a0ad15b
[2025-07-19T20:48:09.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5] for update
[2025-07-19T20:48:09.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.1.delta.d805a657-4256-405f-b61c-976fc019cb29.TID401.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta
[2025-07-19T20:48:09.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta
[2025-07-19T20:48:09.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18697b47
[2025-07-19T20:48:09.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 401, attempt 0, stage 1.0)
[2025-07-19T20:48:09.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2] for update
[2025-07-19T20:48:09.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodeGenerator: Code generated in 23.369208 ms
[2025-07-19T20:48:09.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 195 (task 401, attempt 0, stage 1.0)
[2025-07-19T20:48:09.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3942f14c
[2025-07-19T20:48:09.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 195.0 in stage 1.0 (TID 401). 6243 bytes result sent to driver
[2025-07-19T20:48:09.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8] for update
[2025-07-19T20:48:09.196+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 409) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 401) in 109 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:48:09.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 10.0 in stage 3.0 (TID 409)
[2025-07-19T20:48:09.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodeGenerator: Code generated in 6.008958 ms
[2025-07-19T20:48:09.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.1.delta.61bf2a30-de58-41ad-820d-d6d8c199dd80.TID402.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta
[2025-07-19T20:48:09.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta
[2025-07-19T20:48:09.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 402, attempt 0, stage 1.0)
[2025-07-19T20:48:09.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 198 (task 402, attempt 0, stage 1.0)
[2025-07-19T20:48:09.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 198.0 in stage 1.0 (TID 402). 6200 bytes result sent to driver
[2025-07-19T20:48:09.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 410) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 402) in 106 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:48:09.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-19T20:48:09.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7df7648d
[2025-07-19T20:48:09.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 9.278 s
[2025-07-19T20:48:09.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:48:09.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-19T20:48:09.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 11.0 in stage 3.0 (TID 410)
[2025-07-19T20:48:09.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 10.834647 s
[2025-07-19T20:48:09.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T20:48:09.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO SparkWrite: Committing epoch 0 for query b0ea99b8-5ad6-454d-8c07-6fb91d8182de in append mode
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7] for update
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e0749e6
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11] for update
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO SparkWrite: Committing streaming append with 143 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2460af85
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.1.delta.8be8b5d5-feee-4407-bce5-5e301467f828.TID403.tmp
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.1.delta.3410d320-85db-47ee-a002-f32a36dd4aca.TID408.tmp
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10] for update
[2025-07-19T20:48:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.1.delta.d0b85acd-98ea-4fb7-a8f3-d33f0bff68c3.TID406.tmp
[2025-07-19T20:48:09.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.1.delta.d0412e69-381c-4187-980b-3499e004599e.TID404.tmp
[2025-07-19T20:48:09.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.1.delta.7a5f5b4e-23d3-42e5-bebb-48364f38f943.TID410.tmp
[2025-07-19T20:48:09.256+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.1.delta.c4882581-6734-4bd8-b343-bc1fb6780190.TID407.tmp
[2025-07-19T20:48:09.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.1.delta.607d14aa-fc8b-480d-b302-5ca9f885f60a.TID405.tmp
[2025-07-19T20:48:09.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.1.delta.82c90770-dc60-40a1-9e75-5bb1098cfd54.TID409.tmp
[2025-07-19T20:48:09.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.1.delta.d0412e69-381c-4187-980b-3499e004599e.TID404.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta
[2025-07-19T20:48:09.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/1.delta
[2025-07-19T20:48:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 404, attempt 0, stage 3.0)
[2025-07-19T20:48:09.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.1.delta.8be8b5d5-feee-4407-bce5-5e301467f828.TID403.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta
[2025-07-19T20:48:09.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/1.delta
[2025-07-19T20:48:09.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 403, attempt 0, stage 3.0)
[2025-07-19T20:48:09.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.1.delta.d0b85acd-98ea-4fb7-a8f3-d33f0bff68c3.TID406.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta
[2025-07-19T20:48:09.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/1.delta
[2025-07-19T20:48:09.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 406, attempt 0, stage 3.0)
[2025-07-19T20:48:09.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.1.delta.3410d320-85db-47ee-a002-f32a36dd4aca.TID408.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta
[2025-07-19T20:48:09.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/1.delta
[2025-07-19T20:48:09.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 408, attempt 0, stage 3.0)
[2025-07-19T20:48:09.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.1.delta.7a5f5b4e-23d3-42e5-bebb-48364f38f943.TID410.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta
[2025-07-19T20:48:09.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/1.delta
[2025-07-19T20:48:09.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 410, attempt 0, stage 3.0)
[2025-07-19T20:48:09.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.1.delta.607d14aa-fc8b-480d-b302-5ca9f885f60a.TID405.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta
[2025-07-19T20:48:09.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/1.delta
[2025-07-19T20:48:09.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 405, attempt 0, stage 3.0)
[2025-07-19T20:48:09.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.1.delta.c4882581-6734-4bd8-b343-bc1fb6780190.TID407.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta
[2025-07-19T20:48:09.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/1.delta
[2025-07-19T20:48:09.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.1.delta.82c90770-dc60-40a1-9e75-5bb1098cfd54.TID409.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta
[2025-07-19T20:48:09.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/1.delta
[2025-07-19T20:48:09.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 1 (task 403, attempt 0, stage 3.0)
[2025-07-19T20:48:09.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 407, attempt 0, stage 3.0)
[2025-07-19T20:48:09.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 1.0 in stage 3.0 (TID 403). 9244 bytes result sent to driver
[2025-07-19T20:48:09.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 411) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 409, attempt 0, stage 3.0)
[2025-07-19T20:48:09.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 12.0 in stage 3.0 (TID 411)
[2025-07-19T20:48:09.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 403) in 246 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:48:09.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 2 (task 404, attempt 0, stage 3.0)
[2025-07-19T20:48:09.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 2.0 in stage 3.0 (TID 404). 9260 bytes result sent to driver
[2025-07-19T20:48:09.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 6 (task 406, attempt 0, stage 3.0)
[2025-07-19T20:48:09.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 6.0 in stage 3.0 (TID 406). 9246 bytes result sent to driver
[2025-07-19T20:48:09.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 412) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 13.0 in stage 3.0 (TID 412)
[2025-07-19T20:48:09.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 413) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 406) in 243 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:48:09.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 404) in 248 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:48:09.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 14.0 in stage 3.0 (TID 413)
[2025-07-19T20:48:09.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38fa872f
[2025-07-19T20:48:09.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12] for update
[2025-07-19T20:48:09.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f01b4a5
[2025-07-19T20:48:09.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13] for update
[2025-07-19T20:48:09.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 7 (task 407, attempt 0, stage 3.0)
[2025-07-19T20:48:09.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 11 (task 410, attempt 0, stage 3.0)
[2025-07-19T20:48:09.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 8 (task 408, attempt 0, stage 3.0)
[2025-07-19T20:48:09.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 10 (task 409, attempt 0, stage 3.0)
[2025-07-19T20:48:09.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 11.0 in stage 3.0 (TID 410). 9250 bytes result sent to driver
[2025-07-19T20:48:09.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 10.0 in stage 3.0 (TID 409). 9246 bytes result sent to driver
[2025-07-19T20:48:09.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 414) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 8.0 in stage 3.0 (TID 408). 9250 bytes result sent to driver
[2025-07-19T20:48:09.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 15.0 in stage 3.0 (TID 414)
[2025-07-19T20:48:09.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 415) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 416) (8b44f3d35cfa, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 7.0 in stage 3.0 (TID 407). 9296 bytes result sent to driver
[2025-07-19T20:48:09.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 16.0 in stage 3.0 (TID 415)
[2025-07-19T20:48:09.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 417) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 18.0 in stage 3.0 (TID 417)
[2025-07-19T20:48:09.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 410) in 217 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:48:09.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.1.delta.aeefdd2b-f383-426e-91ba-1c9a74a815ae.TID411.tmp
[2025-07-19T20:48:09.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 17.0 in stage 3.0 (TID 416)
[2025-07-19T20:48:09.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 407) in 251 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:48:09.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 409) in 233 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:48:09.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 408) in 256 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:48:09.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.1.delta.e1519550-a70c-41b7-8a71-ac9d10d7d16d.TID412.tmp
[2025-07-19T20:48:09.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5467084e
[2025-07-19T20:48:09.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14] for update
[2025-07-19T20:48:09.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 5 (task 405, attempt 0, stage 3.0)
[2025-07-19T20:48:09.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 5.0 in stage 3.0 (TID 405). 9235 bytes result sent to driver
[2025-07-19T20:48:09.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 418) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 405) in 299 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:48:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36dbd0f6
[2025-07-19T20:48:09.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15] for update
[2025-07-19T20:48:09.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.1.delta.a6fa398e-e6dd-4754-b6ca-bd709a907712.TID413.tmp
[2025-07-19T20:48:09.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7997f217
[2025-07-19T20:48:09.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17] for update
[2025-07-19T20:48:09.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.1.delta.8ffc1e36-c394-4420-a3e8-f6e9aefa342c.TID414.tmp
[2025-07-19T20:48:09.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 19.0 in stage 3.0 (TID 418)
[2025-07-19T20:48:09.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14d5a150
[2025-07-19T20:48:09.456+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.1.delta.aeefdd2b-f383-426e-91ba-1c9a74a815ae.TID411.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta
[2025-07-19T20:48:09.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/1.delta
[2025-07-19T20:48:09.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16] for update
[2025-07-19T20:48:09.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 411, attempt 0, stage 3.0)
[2025-07-19T20:48:09.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.1.delta.4c02e28b-ce6c-426e-a6da-bd7aa72315ab.TID416.tmp
[2025-07-19T20:48:09.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71686aaf
[2025-07-19T20:48:09.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.1.delta.e1519550-a70c-41b7-8a71-ac9d10d7d16d.TID412.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta
[2025-07-19T20:48:09.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/1.delta
[2025-07-19T20:48:09.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 412, attempt 0, stage 3.0)
[2025-07-19T20:48:09.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18] for update
[2025-07-19T20:48:09.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.477+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.1.delta.a6fa398e-e6dd-4754-b6ca-bd709a907712.TID413.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta
[2025-07-19T20:48:09.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/1.delta
[2025-07-19T20:48:09.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 413, attempt 0, stage 3.0)
[2025-07-19T20:48:09.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.1.delta.85d52d7a-7138-45d3-997b-df550154338b.TID415.tmp
[2025-07-19T20:48:09.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.1.delta.4680dc34-153c-4afc-a40e-354347eb7a97.TID417.tmp
[2025-07-19T20:48:09.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 22 ms
[2025-07-19T20:48:09.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@212b9680
[2025-07-19T20:48:09.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.1.delta.8ffc1e36-c394-4420-a3e8-f6e9aefa342c.TID414.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta
[2025-07-19T20:48:09.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/1.delta
[2025-07-19T20:48:09.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19] for update
[2025-07-19T20:48:09.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 414, attempt 0, stage 3.0)
[2025-07-19T20:48:09.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 12 (task 411, attempt 0, stage 3.0)
[2025-07-19T20:48:09.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 12.0 in stage 3.0 (TID 411). 9258 bytes result sent to driver
[2025-07-19T20:48:09.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 14 (task 413, attempt 0, stage 3.0)
[2025-07-19T20:48:09.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 14.0 in stage 3.0 (TID 413). 9250 bytes result sent to driver
[2025-07-19T20:48:09.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 419) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 20.0 in stage 3.0 (TID 419)
[2025-07-19T20:48:09.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 420) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 22.0 in stage 3.0 (TID 420)
[2025-07-19T20:48:09.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 413) in 144 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:48:09.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 411) in 160 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:48:09.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:09.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.1.delta.09374624-df39-49df-909c-aae288050f29.TID418.tmp
[2025-07-19T20:48:09.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22b3f793
[2025-07-19T20:48:09.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20] for update
[2025-07-19T20:48:09.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 13 (task 412, attempt 0, stage 3.0)
[2025-07-19T20:48:09.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 13.0 in stage 3.0 (TID 412). 9248 bytes result sent to driver
[2025-07-19T20:48:09.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 421) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 24.0 in stage 3.0 (TID 421)
[2025-07-19T20:48:09.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 412) in 161 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:48:09.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61988096
[2025-07-19T20:48:09.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22] for update
[2025-07-19T20:48:09.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e98015
[2025-07-19T20:48:09.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24] for update
[2025-07-19T20:48:09.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 15 (task 414, attempt 0, stage 3.0)
[2025-07-19T20:48:09.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.1.delta.85d52d7a-7138-45d3-997b-df550154338b.TID415.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta
[2025-07-19T20:48:09.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/1.delta
[2025-07-19T20:48:09.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.1.delta.4c02e28b-ce6c-426e-a6da-bd7aa72315ab.TID416.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta
[2025-07-19T20:48:09.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/1.delta
[2025-07-19T20:48:09.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 416, attempt 0, stage 3.0)
[2025-07-19T20:48:09.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 15.0 in stage 3.0 (TID 414). 9263 bytes result sent to driver
[2025-07-19T20:48:09.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 415, attempt 0, stage 3.0)
[2025-07-19T20:48:09.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 422) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 414) in 151 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:48:09.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 26.0 in stage 3.0 (TID 422)
[2025-07-19T20:48:09.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.1.delta.8682b65b-841a-4272-a7be-f4961f62c4b8.TID420.tmp
[2025-07-19T20:48:09.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16d05dd8
[2025-07-19T20:48:09.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.1.delta.4680dc34-153c-4afc-a40e-354347eb7a97.TID417.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta
[2025-07-19T20:48:09.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/1.delta
[2025-07-19T20:48:09.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 417, attempt 0, stage 3.0)
[2025-07-19T20:48:09.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26] for update
[2025-07-19T20:48:09.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.1.delta.ba97bcee-238a-4c2f-8f34-6b9ef409c330.TID421.tmp
[2025-07-19T20:48:09.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.1.delta.3c590b6e-3b82-48ad-b2e0-94339a8acc44.TID419.tmp
[2025-07-19T20:48:09.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 16 (task 415, attempt 0, stage 3.0)
[2025-07-19T20:48:09.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 17 (task 416, attempt 0, stage 3.0)
[2025-07-19T20:48:09.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 16.0 in stage 3.0 (TID 415). 9261 bytes result sent to driver
[2025-07-19T20:48:09.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 17.0 in stage 3.0 (TID 416). 9252 bytes result sent to driver
[2025-07-19T20:48:09.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 423) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 424) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 415) in 172 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:48:09.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 27.0 in stage 3.0 (TID 423)
[2025-07-19T20:48:09.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 416) in 172 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:48:09.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 28.0 in stage 3.0 (TID 424)
[2025-07-19T20:48:09.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:09.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 18 (task 417, attempt 0, stage 3.0)
[2025-07-19T20:48:09.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.1.delta.fcf4c0c5-c924-431c-beef-1c652651423c.TID422.tmp
[2025-07-19T20:48:09.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 18.0 in stage 3.0 (TID 417). 9245 bytes result sent to driver
[2025-07-19T20:48:09.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 425) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 29.0 in stage 3.0 (TID 425)
[2025-07-19T20:48:09.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.1.delta.09374624-df39-49df-909c-aae288050f29.TID418.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta
[2025-07-19T20:48:09.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/1.delta
[2025-07-19T20:48:09.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33641ce5
[2025-07-19T20:48:09.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 417) in 187 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:48:09.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v120.metadata.json
[2025-07-19T20:48:09.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 418, attempt 0, stage 3.0)
[2025-07-19T20:48:09.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28] for update
[2025-07-19T20:48:09.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fa430c9
[2025-07-19T20:48:09.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27] for update
[2025-07-19T20:48:09.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10d64f1e
[2025-07-19T20:48:09.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.1.delta.5d261aff-833a-4ed8-a52c-d9049b58dda5.TID424.tmp
[2025-07-19T20:48:09.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29] for update
[2025-07-19T20:48:09.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 19 (task 418, attempt 0, stage 3.0)
[2025-07-19T20:48:09.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 19.0 in stage 3.0 (TID 418). 9261 bytes result sent to driver
[2025-07-19T20:48:09.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 426) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 30.0 in stage 3.0 (TID 426)
[2025-07-19T20:48:09.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 418) in 205 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:48:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.1.delta.8682b65b-841a-4272-a7be-f4961f62c4b8.TID420.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta
[2025-07-19T20:48:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/1.delta
[2025-07-19T20:48:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 420, attempt 0, stage 3.0)
[2025-07-19T20:48:09.635+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.1.delta.5e358d63-0ae6-40c9-b7fd-c3d7d73d5bd5.TID423.tmp
[2025-07-19T20:48:09.635+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.1.delta.3c590b6e-3b82-48ad-b2e0-94339a8acc44.TID419.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta
[2025-07-19T20:48:09.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/1.delta
[2025-07-19T20:48:09.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 419, attempt 0, stage 3.0)
[2025-07-19T20:48:09.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d90734f
[2025-07-19T20:48:09.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30] for update
[2025-07-19T20:48:09.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.1.delta.ba97bcee-238a-4c2f-8f34-6b9ef409c330.TID421.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta
[2025-07-19T20:48:09.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/1.delta
[2025-07-19T20:48:09.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 421, attempt 0, stage 3.0)
[2025-07-19T20:48:09.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 22 (task 420, attempt 0, stage 3.0)
[2025-07-19T20:48:09.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 22.0 in stage 3.0 (TID 420). 9252 bytes result sent to driver
[2025-07-19T20:48:09.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO SnapshotProducer: Committed snapshot 4906269819275254266 (FastAppend)
[2025-07-19T20:48:09.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 427) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 31.0 in stage 3.0 (TID 427)
[2025-07-19T20:48:09.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 420) in 147 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:48:09.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 20 (task 419, attempt 0, stage 3.0)
[2025-07-19T20:48:09.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 20.0 in stage 3.0 (TID 419). 9229 bytes result sent to driver
[2025-07-19T20:48:09.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.1.delta.fcf4c0c5-c924-431c-beef-1c652651423c.TID422.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta
[2025-07-19T20:48:09.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/1.delta
[2025-07-19T20:48:09.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 428) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 419) in 152 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:48:09.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 422, attempt 0, stage 3.0)
[2025-07-19T20:48:09.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 32.0 in stage 3.0 (TID 428)
[2025-07-19T20:48:09.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.1.delta.780bdb5a-792a-4f9b-97c2-47f2ee23970d.TID425.tmp
[2025-07-19T20:48:09.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6da5e08c
[2025-07-19T20:48:09.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31] for update
[2025-07-19T20:48:09.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 24 (task 421, attempt 0, stage 3.0)
[2025-07-19T20:48:09.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 24.0 in stage 3.0 (TID 421). 9250 bytes result sent to driver
[2025-07-19T20:48:09.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.1.delta.7d3cc4b3-9531-4d72-92c3-fc643e6936ff.TID426.tmp
[2025-07-19T20:48:09.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 429) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35906583
[2025-07-19T20:48:09.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32] for update
[2025-07-19T20:48:09.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 421) in 155 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:48:09.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 33.0 in stage 3.0 (TID 429)
[2025-07-19T20:48:09.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.1.delta.f76307bb-1de2-4a13-9ac7-2553f8aa17f3.TID427.tmp
[2025-07-19T20:48:09.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 26 (task 422, attempt 0, stage 3.0)
[2025-07-19T20:48:09.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.1.delta.7ed0afbb-ab2d-4eaf-9375-fa6b2d0b4029.TID428.tmp
[2025-07-19T20:48:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.1.delta.5d261aff-833a-4ed8-a52c-d9049b58dda5.TID424.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta
[2025-07-19T20:48:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/1.delta
[2025-07-19T20:48:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 26.0 in stage 3.0 (TID 422). 9251 bytes result sent to driver
[2025-07-19T20:48:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 430) (8b44f3d35cfa, executor driver, partition 34, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 422) in 148 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:48:09.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 34.0 in stage 3.0 (TID 430)
[2025-07-19T20:48:09.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 424, attempt 0, stage 3.0)
[2025-07-19T20:48:09.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:09.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e24788b
[2025-07-19T20:48:09.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.1.delta.5e358d63-0ae6-40c9-b7fd-c3d7d73d5bd5.TID423.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta
[2025-07-19T20:48:09.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/1.delta
[2025-07-19T20:48:09.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33] for update
[2025-07-19T20:48:09.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 423, attempt 0, stage 3.0)
[2025-07-19T20:48:09.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@324eeaaf
[2025-07-19T20:48:09.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34] for update
[2025-07-19T20:48:09.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 28 (task 424, attempt 0, stage 3.0)
[2025-07-19T20:48:09.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.1.delta.3c8a7aab-c1cc-4d2a-a643-d68fd4d5a9be.TID429.tmp
[2025-07-19T20:48:09.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 28.0 in stage 3.0 (TID 424). 9270 bytes result sent to driver
[2025-07-19T20:48:09.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 431) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 27 (task 423, attempt 0, stage 3.0)
[2025-07-19T20:48:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 424) in 155 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:48:09.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 35.0 in stage 3.0 (TID 431)
[2025-07-19T20:48:09.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 27.0 in stage 3.0 (TID 423). 9259 bytes result sent to driver
[2025-07-19T20:48:09.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 432) (8b44f3d35cfa, executor driver, partition 36, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 36.0 in stage 3.0 (TID 432)
[2025-07-19T20:48:09.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 423) in 159 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:48:09.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.1.delta.a053049f-8c05-46b7-9323-74cfc3eedbce.TID430.tmp
[2025-07-19T20:48:09.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.1.delta.7d3cc4b3-9531-4d72-92c3-fc643e6936ff.TID426.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta
[2025-07-19T20:48:09.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/1.delta
[2025-07-19T20:48:09.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 426, attempt 0, stage 3.0)
[2025-07-19T20:48:09.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bf5bf12
[2025-07-19T20:48:09.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35] for update
[2025-07-19T20:48:09.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=4906269819275254266, sequenceNumber=119, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.53662675S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=143}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5828}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=222}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8010}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=414165}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=16788812}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958074309, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:48:09.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO SparkWrite: Committed in 537 ms
[2025-07-19T20:48:09.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T20:48:09.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752785268000 ms
[2025-07-19T20:48:09.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.1.delta.780bdb5a-792a-4f9b-97c2-47f2ee23970d.TID425.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta
[2025-07-19T20:48:09.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/1.delta
[2025-07-19T20:48:09.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 425, attempt 0, stage 3.0)
[2025-07-19T20:48:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.1.delta.7ed0afbb-ab2d-4eaf-9375-fa6b2d0b4029.TID428.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta
[2025-07-19T20:48:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/1.delta
[2025-07-19T20:48:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 30 (task 426, attempt 0, stage 3.0)
[2025-07-19T20:48:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 428, attempt 0, stage 3.0)
[2025-07-19T20:48:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 30.0 in stage 3.0 (TID 426). 9244 bytes result sent to driver
[2025-07-19T20:48:09.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f5f927d
[2025-07-19T20:48:09.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.1.delta.f76307bb-1de2-4a13-9ac7-2553f8aa17f3.TID427.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta
[2025-07-19T20:48:09.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/1.delta
[2025-07-19T20:48:09.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 427, attempt 0, stage 3.0)
[2025-07-19T20:48:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36] for update
[2025-07-19T20:48:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 433) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/.0.0d5bd8cb-ddaf-455e-a896-00795603f6cf.tmp
[2025-07-19T20:48:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 426) in 163 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:48:09.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.1.delta.3facc660-181f-4f63-bff6-4f1cdf08d8d3.TID431.tmp
[2025-07-19T20:48:09.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 39.0 in stage 3.0 (TID 433)
[2025-07-19T20:48:09.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 32 (task 428, attempt 0, stage 3.0)
[2025-07-19T20:48:09.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 31 (task 427, attempt 0, stage 3.0)
[2025-07-19T20:48:09.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 31.0 in stage 3.0 (TID 427). 9279 bytes result sent to driver
[2025-07-19T20:48:09.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.1.delta.a053049f-8c05-46b7-9323-74cfc3eedbce.TID430.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta
[2025-07-19T20:48:09.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/1.delta
[2025-07-19T20:48:09.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 32.0 in stage 3.0 (TID 428). 9293 bytes result sent to driver
[2025-07-19T20:48:09.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42ad37bd
[2025-07-19T20:48:09.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 430, attempt 0, stage 3.0)
[2025-07-19T20:48:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 434) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39] for update
[2025-07-19T20:48:09.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 40.0 in stage 3.0 (TID 434)
[2025-07-19T20:48:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 435) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 29 (task 425, attempt 0, stage 3.0)
[2025-07-19T20:48:09.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 428) in 159 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:48:09.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 427) in 168 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:48:09.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 41.0 in stage 3.0 (TID 435)
[2025-07-19T20:48:09.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@414b5659
[2025-07-19T20:48:09.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 29.0 in stage 3.0 (TID 425). 9289 bytes result sent to driver
[2025-07-19T20:48:09.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 34 (task 430, attempt 0, stage 3.0)
[2025-07-19T20:48:09.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 436) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 425) in 244 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:48:09.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40] for update
[2025-07-19T20:48:09.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.1.delta.f8c46686-77e5-4e8e-a11b-25fa966fe73a.TID432.tmp
[2025-07-19T20:48:09.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 42.0 in stage 3.0 (TID 436)
[2025-07-19T20:48:09.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 34.0 in stage 3.0 (TID 430). 9336 bytes result sent to driver
[2025-07-19T20:48:09.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 437) (8b44f3d35cfa, executor driver, partition 44, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 44.0 in stage 3.0 (TID 437)
[2025-07-19T20:48:09.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 430) in 150 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:48:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62ad76
[2025-07-19T20:48:09.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.1.delta.646662e5-ecf7-41e3-bb01-78b80a3d5903.TID433.tmp
[2025-07-19T20:48:09.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41] for update
[2025-07-19T20:48:09.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T20:48:09.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.1.delta.3c8a7aab-c1cc-4d2a-a643-d68fd4d5a9be.TID429.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta
[2025-07-19T20:48:09.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/1.delta
[2025-07-19T20:48:09.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:09.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 429, attempt 0, stage 3.0)
[2025-07-19T20:48:09.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d9697dd
[2025-07-19T20:48:09.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42] for update
[2025-07-19T20:48:09.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.1.delta.08498f94-c4e5-4552-b2b5-ec7a9cb59044.TID434.tmp
[2025-07-19T20:48:09.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.1.delta.76955326-bbb0-48f4-9a48-ea2f2cd4e76e.TID435.tmp
[2025-07-19T20:48:09.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.1.delta.3facc660-181f-4f63-bff6-4f1cdf08d8d3.TID431.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta
[2025-07-19T20:48:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/1.delta
[2025-07-19T20:48:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 431, attempt 0, stage 3.0)
[2025-07-19T20:48:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 33 (task 429, attempt 0, stage 3.0)
[2025-07-19T20:48:09.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f55218d
[2025-07-19T20:48:09.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 33.0 in stage 3.0 (TID 429). 9289 bytes result sent to driver
[2025-07-19T20:48:09.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44] for update
[2025-07-19T20:48:09.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 438) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 46.0 in stage 3.0 (TID 438)
[2025-07-19T20:48:09.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 429) in 205 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:48:09.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:09.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/.0.0d5bd8cb-ddaf-455e-a896-00795603f6cf.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/0
[2025-07-19T20:48:09.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:48:09.904+0000] {subprocess.py:93} INFO -   "id" : "b0ea99b8-5ad6-454d-8c07-6fb91d8182de",
[2025-07-19T20:48:09.905+0000] {subprocess.py:93} INFO -   "runId" : "1de00c25-9d15-45b4-834f-e4fa238248c8",
[2025-07-19T20:48:09.905+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:48:09.906+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:47:56.973Z",
[2025-07-19T20:48:09.906+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T20:48:09.907+0000] {subprocess.py:93} INFO -   "numInputRows" : 222,
[2025-07-19T20:48:09.907+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:09.908+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 17.191977077363898,
[2025-07-19T20:48:09.908+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:48:09.908+0000] {subprocess.py:93} INFO -     "addBatch" : 12057,
[2025-07-19T20:48:09.909+0000] {subprocess.py:93} INFO -     "commitOffsets" : 125,
[2025-07-19T20:48:09.910+0000] {subprocess.py:93} INFO -     "getBatch" : 9,
[2025-07-19T20:48:09.911+0000] {subprocess.py:93} INFO -     "latestOffset" : 219,
[2025-07-19T20:48:09.912+0000] {subprocess.py:93} INFO -     "queryPlanning" : 442,
[2025-07-19T20:48:09.913+0000] {subprocess.py:93} INFO -     "triggerExecution" : 12913,
[2025-07-19T20:48:09.914+0000] {subprocess.py:93} INFO -     "walCommit" : 42
[2025-07-19T20:48:09.917+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:09.917+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:48:09.917+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T19:09:26.202Z",
[2025-07-19T20:48:09.918+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T20:47:48.000Z",
[2025-07-19T20:48:09.919+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T18:00:01.000Z",
[2025-07-19T20:48:09.920+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T20:48:09.921+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:09.923+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:48:09.924+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:48:09.925+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 222,
[2025-07-19T20:48:09.927+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 222,
[2025-07-19T20:48:09.928+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 3320,
[2025-07-19T20:48:09.929+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:48:09.929+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 157,
[2025-07-19T20:48:09.929+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 13973,
[2025-07-19T20:48:09.930+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 100288,
[2025-07-19T20:48:09.930+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:48:09.930+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:48:09.930+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:48:09.930+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:48:09.930+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T20:48:09.931+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:48:09.931+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:48:09.931+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 71488
[2025-07-19T20:48:09.931+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:09.932+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:09.932+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:48:09.933+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T20:48:09.934+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T20:48:09.934+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:48:09.935+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:48:09.937+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:09.938+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:09.939+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:09.939+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:48:09.940+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:48:09.940+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:09.941+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:09.941+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:09.942+0000] {subprocess.py:93} INFO -     "numInputRows" : 222,
[2025-07-19T20:48:09.942+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:09.942+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 17.191977077363898,
[2025-07-19T20:48:09.943+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:48:09.943+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -     "numOutputRows" : 222
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:48:09.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.1.delta.9b3842df-a945-431c-8a62-dff99de1100c.TID436.tmp
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a112c40
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46] for update
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8b44f3d35cfa:46433 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.1.delta.f8c46686-77e5-4e8e-a11b-25fa966fe73a.TID432.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/1.delta
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 432, attempt 0, stage 3.0)
[2025-07-19T20:48:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.1.delta.02e269d2-4e73-4531-92a8-002a3f09b193.TID437.tmp
[2025-07-19T20:48:09.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8b44f3d35cfa:46433 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T20:48:09.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 35 (task 431, attempt 0, stage 3.0)
[2025-07-19T20:48:09.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.1.delta.db07bc09-5dfd-4666-8e6f-1ee2be1c7a67.TID438.tmp
[2025-07-19T20:48:09.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 35.0 in stage 3.0 (TID 431). 9290 bytes result sent to driver
[2025-07-19T20:48:09.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 439) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 431) in 202 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:48:09.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 36 (task 432, attempt 0, stage 3.0)
[2025-07-19T20:48:09.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 36.0 in stage 3.0 (TID 432). 9273 bytes result sent to driver
[2025-07-19T20:48:09.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 440) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 432) in 200 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:48:09.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 48.0 in stage 3.0 (TID 440)
[2025-07-19T20:48:09.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 47.0 in stage 3.0 (TID 439)
[2025-07-19T20:48:09.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.956+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.1.delta.646662e5-ecf7-41e3-bb01-78b80a3d5903.TID433.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta
[2025-07-19T20:48:09.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/1.delta
[2025-07-19T20:48:09.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 433, attempt 0, stage 3.0)
[2025-07-19T20:48:09.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@274c8251
[2025-07-19T20:48:09.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48] for update
[2025-07-19T20:48:09.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.1.delta.08498f94-c4e5-4552-b2b5-ec7a9cb59044.TID434.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta
[2025-07-19T20:48:09.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/1.delta
[2025-07-19T20:48:09.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 434, attempt 0, stage 3.0)
[2025-07-19T20:48:09.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19d1cfb9
[2025-07-19T20:48:09.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 8b44f3d35cfa:46433 in memory (size: 19.3 KiB, free: 434.3 MiB)
[2025-07-19T20:48:09.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47] for update
[2025-07-19T20:48:09.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.1.delta.76955326-bbb0-48f4-9a48-ea2f2cd4e76e.TID435.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta
[2025-07-19T20:48:09.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/1.delta
[2025-07-19T20:48:09.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/.1.6ad9f7ce-b68c-422f-aa70-9200155b748e.tmp
[2025-07-19T20:48:09.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 435, attempt 0, stage 3.0)
[2025-07-19T20:48:09.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.1.delta.91a05b3b-af97-4de7-8027-d133b607d353.TID440.tmp
[2025-07-19T20:48:09.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.1.delta.9b3842df-a945-431c-8a62-dff99de1100c.TID436.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta
[2025-07-19T20:48:09.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/1.delta
[2025-07-19T20:48:09.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 39 (task 433, attempt 0, stage 3.0)
[2025-07-19T20:48:09.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 436, attempt 0, stage 3.0)
[2025-07-19T20:48:09.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 39.0 in stage 3.0 (TID 433). 9270 bytes result sent to driver
[2025-07-19T20:48:09.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 441) (8b44f3d35cfa, executor driver, partition 49, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.1.delta.92decc98-1bf4-47f2-93ce-0ff26573e31c.TID439.tmp
[2025-07-19T20:48:09.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 433) in 188 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:48:09.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 49.0 in stage 3.0 (TID 441)
[2025-07-19T20:48:09.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 40 (task 434, attempt 0, stage 3.0)
[2025-07-19T20:48:09.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 40.0 in stage 3.0 (TID 434). 9261 bytes result sent to driver
[2025-07-19T20:48:09.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 442) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 51.0 in stage 3.0 (TID 442)
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 434) in 168 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 41 (task 435, attempt 0, stage 3.0)
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 41.0 in stage 3.0 (TID 435). 9246 bytes result sent to driver
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 443) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 54.0 in stage 3.0 (TID 443)
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cae6e19
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 435) in 168 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49] for update
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.1.delta.02e269d2-4e73-4531-92a8-002a3f09b193.TID437.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta
[2025-07-19T20:48:09.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/1.delta
[2025-07-19T20:48:09.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30ab2cad
[2025-07-19T20:48:09.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:09.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51] for update
[2025-07-19T20:48:09.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 437, attempt 0, stage 3.0)
[2025-07-19T20:48:09.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO DataWritingSparkTask: Committed partition 42 (task 436, attempt 0, stage 3.0)
[2025-07-19T20:48:09.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:09.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Finished task 42.0 in stage 3.0 (TID 436). 9252 bytes result sent to driver
[2025-07-19T20:48:10.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 444) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO Executor: Running task 55.0 in stage 3.0 (TID 444)
[2025-07-19T20:48:10.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 436) in 163 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:48:10.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.1.delta.912005f8-c6a0-413c-ab9e-365460f174d3.TID441.tmp
[2025-07-19T20:48:10.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fbeff01
[2025-07-19T20:48:10.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.1.delta.db07bc09-5dfd-4666-8e6f-1ee2be1c7a67.TID438.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta
[2025-07-19T20:48:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/1.delta
[2025-07-19T20:48:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54] for update
[2025-07-19T20:48:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 438, attempt 0, stage 3.0)
[2025-07-19T20:48:10.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.1.delta.d10ded8c-06b7-4f69-8eb3-836d08b83732.TID442.tmp
[2025-07-19T20:48:10.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 44 (task 437, attempt 0, stage 3.0)
[2025-07-19T20:48:10.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@500a4a76
[2025-07-19T20:48:10.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55] for update
[2025-07-19T20:48:10.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 44.0 in stage 3.0 (TID 437). 9259 bytes result sent to driver
[2025-07-19T20:48:10.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 445) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.1.delta.92decc98-1bf4-47f2-93ce-0ff26573e31c.TID439.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta
[2025-07-19T20:48:10.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/1.delta
[2025-07-19T20:48:10.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 439, attempt 0, stage 3.0)
[2025-07-19T20:48:10.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 437) in 186 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:48:10.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 57.0 in stage 3.0 (TID 445)
[2025-07-19T20:48:10.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.1.delta.91a05b3b-af97-4de7-8027-d133b607d353.TID440.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta
[2025-07-19T20:48:10.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/1.delta
[2025-07-19T20:48:10.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 440, attempt 0, stage 3.0)
[2025-07-19T20:48:10.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.1.delta.0205fe62-e374-45ae-b998-f14d18d3a5e2.TID443.tmp
[2025-07-19T20:48:10.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 46 (task 438, attempt 0, stage 3.0)
[2025-07-19T20:48:10.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 46.0 in stage 3.0 (TID 438). 9244 bytes result sent to driver
[2025-07-19T20:48:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 438) in 155 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:48:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 446) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.043+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/.1.6ad9f7ce-b68c-422f-aa70-9200155b748e.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/offsets/1
[2025-07-19T20:48:10.043+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752785268000,1752958089917,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:48:10.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 58.0 in stage 3.0 (TID 446)
[2025-07-19T20:48:10.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 47 (task 439, attempt 0, stage 3.0)
[2025-07-19T20:48:10.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.1.delta.d8891578-760d-4274-8d34-93ff88f3c5e7.TID444.tmp
[2025-07-19T20:48:10.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 47.0 in stage 3.0 (TID 439). 9276 bytes result sent to driver
[2025-07-19T20:48:10.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:10.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 447) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 60.0 in stage 3.0 (TID 447)
[2025-07-19T20:48:10.057+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.1.delta.912005f8-c6a0-413c-ab9e-365460f174d3.TID441.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta
[2025-07-19T20:48:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/1.delta
[2025-07-19T20:48:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 439) in 132 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:48:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.1.delta.d10ded8c-06b7-4f69-8eb3-836d08b83732.TID442.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta
[2025-07-19T20:48:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/1.delta
[2025-07-19T20:48:10.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 441, attempt 0, stage 3.0)
[2025-07-19T20:48:10.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13746bbc
[2025-07-19T20:48:10.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58] for update
[2025-07-19T20:48:10.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 442, attempt 0, stage 3.0)
[2025-07-19T20:48:10.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 48 (task 440, attempt 0, stage 3.0)
[2025-07-19T20:48:10.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11304f58
[2025-07-19T20:48:10.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57] for update
[2025-07-19T20:48:10.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 48.0 in stage 3.0 (TID 440). 9266 bytes result sent to driver
[2025-07-19T20:48:10.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 448) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 62.0 in stage 3.0 (TID 448)
[2025-07-19T20:48:10.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 440) in 145 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:48:10.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c66c719
[2025-07-19T20:48:10.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:10.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60] for update
[2025-07-19T20:48:10.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.1.delta.43a86fb7-747c-4344-ac8b-ec1b1d04b363.TID446.tmp
[2025-07-19T20:48:10.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.1.delta.0205fe62-e374-45ae-b998-f14d18d3a5e2.TID443.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta
[2025-07-19T20:48:10.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/1.delta
[2025-07-19T20:48:10.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 443, attempt 0, stage 3.0)
[2025-07-19T20:48:10.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.1.delta.3dc23a4a-47f9-471d-a4ad-86a4f61de1bc.TID445.tmp
[2025-07-19T20:48:10.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22986f31
[2025-07-19T20:48:10.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62] for update
[2025-07-19T20:48:10.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 51 (task 442, attempt 0, stage 3.0)
[2025-07-19T20:48:10.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 51.0 in stage 3.0 (TID 442). 9269 bytes result sent to driver
[2025-07-19T20:48:10.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 449) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 63.0 in stage 3.0 (TID 449)
[2025-07-19T20:48:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 442) in 127 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:48:10.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 54 (task 443, attempt 0, stage 3.0)
[2025-07-19T20:48:10.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:10.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 54.0 in stage 3.0 (TID 443). 9259 bytes result sent to driver
[2025-07-19T20:48:10.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.1.delta.6a6ef116-4e2d-4e98-b256-1db1eb513b92.TID447.tmp
[2025-07-19T20:48:10.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.1.delta.d8891578-760d-4274-8d34-93ff88f3c5e7.TID444.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta
[2025-07-19T20:48:10.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/1.delta
[2025-07-19T20:48:10.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.1.delta.bd73e820-3f83-4a68-a25b-24f430ec6f0e.TID448.tmp
[2025-07-19T20:48:10.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 450) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 64.0 in stage 3.0 (TID 450)
[2025-07-19T20:48:10.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 443) in 125 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:48:10.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 444, attempt 0, stage 3.0)
[2025-07-19T20:48:10.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@205fa1d8
[2025-07-19T20:48:10.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63] for update
[2025-07-19T20:48:10.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63e65ad2
[2025-07-19T20:48:10.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64] for update
[2025-07-19T20:48:10.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.1.delta.973986b2-453a-4c90-9bf6-a9ea2a8c18b8.TID449.tmp
[2025-07-19T20:48:10.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 49 (task 441, attempt 0, stage 3.0)
[2025-07-19T20:48:10.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 49.0 in stage 3.0 (TID 441). 9269 bytes result sent to driver
[2025-07-19T20:48:10.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 451) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 66.0 in stage 3.0 (TID 451)
[2025-07-19T20:48:10.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.1.delta.b8d7c418-2751-4432-8629-c9d0b26bab11.TID450.tmp
[2025-07-19T20:48:10.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 441) in 160 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:48:10.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.1.delta.43a86fb7-747c-4344-ac8b-ec1b1d04b363.TID446.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta
[2025-07-19T20:48:10.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/1.delta
[2025-07-19T20:48:10.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 446, attempt 0, stage 3.0)
[2025-07-19T20:48:10.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.1.delta.6a6ef116-4e2d-4e98-b256-1db1eb513b92.TID447.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta
[2025-07-19T20:48:10.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T20:48:10.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/1.delta
[2025-07-19T20:48:10.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.1.delta.3dc23a4a-47f9-471d-a4ad-86a4f61de1bc.TID445.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta
[2025-07-19T20:48:10.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/1.delta
[2025-07-19T20:48:10.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 55 (task 444, attempt 0, stage 3.0)
[2025-07-19T20:48:10.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 55.0 in stage 3.0 (TID 444). 9241 bytes result sent to driver
[2025-07-19T20:48:10.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 452) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 445, attempt 0, stage 3.0)
[2025-07-19T20:48:10.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 68.0 in stage 3.0 (TID 452)
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 58 (task 446, attempt 0, stage 3.0)
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 447, attempt 0, stage 3.0)
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 58.0 in stage 3.0 (TID 446). 9246 bytes result sent to driver
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 453) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 444) in 162 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:48:10.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 446) in 116 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:48:10.158+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 71.0 in stage 3.0 (TID 453)
[2025-07-19T20:48:10.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.1.delta.bd73e820-3f83-4a68-a25b-24f430ec6f0e.TID448.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta
[2025-07-19T20:48:10.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/1.delta
[2025-07-19T20:48:10.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.1.delta.973986b2-453a-4c90-9bf6-a9ea2a8c18b8.TID449.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta
[2025-07-19T20:48:10.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/1.delta
[2025-07-19T20:48:10.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@271b53e9
[2025-07-19T20:48:10.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 448, attempt 0, stage 3.0)
[2025-07-19T20:48:10.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66] for update
[2025-07-19T20:48:10.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 449, attempt 0, stage 3.0)
[2025-07-19T20:48:10.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@692df495
[2025-07-19T20:48:10.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71] for update
[2025-07-19T20:48:10.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 60 (task 447, attempt 0, stage 3.0)
[2025-07-19T20:48:10.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 60.0 in stage 3.0 (TID 447). 9252 bytes result sent to driver
[2025-07-19T20:48:10.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.1.delta.aebb9d9a-e8c9-4908-a08d-7df07e11db1b.TID451.tmp
[2025-07-19T20:48:10.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 454) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 73.0 in stage 3.0 (TID 454)
[2025-07-19T20:48:10.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 447) in 157 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:48:10.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.1.delta.b8d7c418-2751-4432-8629-c9d0b26bab11.TID450.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta
[2025-07-19T20:48:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/1.delta
[2025-07-19T20:48:10.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 450, attempt 0, stage 3.0)
[2025-07-19T20:48:10.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:10.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bd4017d
[2025-07-19T20:48:10.235+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.1.delta.36bf2562-123a-4146-8e3c-a487402cfa3e.TID453.tmp
[2025-07-19T20:48:10.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68] for update
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 57 (task 445, attempt 0, stage 3.0)
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 57.0 in stage 3.0 (TID 445). 9244 bytes result sent to driver
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 455) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 63 (task 449, attempt 0, stage 3.0)
[2025-07-19T20:48:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 74.0 in stage 3.0 (TID 455)
[2025-07-19T20:48:10.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 63.0 in stage 3.0 (TID 449). 9248 bytes result sent to driver
[2025-07-19T20:48:10.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 445) in 207 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:48:10.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 456) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 75.0 in stage 3.0 (TID 456)
[2025-07-19T20:48:10.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 449) in 134 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:48:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 62 (task 448, attempt 0, stage 3.0)
[2025-07-19T20:48:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3540e84e
[2025-07-19T20:48:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 62.0 in stage 3.0 (TID 448). 9252 bytes result sent to driver
[2025-07-19T20:48:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73] for update
[2025-07-19T20:48:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 457) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 448) in 168 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:48:10.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 76.0 in stage 3.0 (TID 457)
[2025-07-19T20:48:10.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.1.delta.1f8a1740-ebd8-4d24-8a79-9dfdab3c67b0.TID452.tmp
[2025-07-19T20:48:10.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 64 (task 450, attempt 0, stage 3.0)
[2025-07-19T20:48:10.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 64.0 in stage 3.0 (TID 450). 9270 bytes result sent to driver
[2025-07-19T20:48:10.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.1.delta.983f1235-56f5-4a56-a416-c243f6926044.TID454.tmp
[2025-07-19T20:48:10.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 458) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54e9424a
[2025-07-19T20:48:10.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74] for update
[2025-07-19T20:48:10.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 77.0 in stage 3.0 (TID 458)
[2025-07-19T20:48:10.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 450) in 145 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:48:10.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57a04a3a
[2025-07-19T20:48:10.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75] for update
[2025-07-19T20:48:10.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.1.delta.7a773da1-e482-47c0-ac86-4bec0ba1d47a.TID455.tmp
[2025-07-19T20:48:10.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d86c9d5
[2025-07-19T20:48:10.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76] for update
[2025-07-19T20:48:10.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T20:48:10.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@144033a1
[2025-07-19T20:48:10.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.1.delta.36bf2562-123a-4146-8e3c-a487402cfa3e.TID453.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta
[2025-07-19T20:48:10.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/1.delta
[2025-07-19T20:48:10.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.1.delta.9eba8cfd-46ee-4f00-810f-900cebb460e2.TID456.tmp
[2025-07-19T20:48:10.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 453, attempt 0, stage 3.0)
[2025-07-19T20:48:10.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77] for update
[2025-07-19T20:48:10.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.1.delta.aebb9d9a-e8c9-4908-a08d-7df07e11db1b.TID451.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta
[2025-07-19T20:48:10.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/1.delta
[2025-07-19T20:48:10.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 451, attempt 0, stage 3.0)
[2025-07-19T20:48:10.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.8 MiB)
[2025-07-19T20:48:10.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 8b44f3d35cfa:46433 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:48:10.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkContext: Created broadcast 12 from start at <unknown>:0
[2025-07-19T20:48:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.1.delta.cc1ab1da-b036-48bf-9c81-44266d9d09c6.TID457.tmp
[2025-07-19T20:48:10.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.1.delta.9dd1414b-3cac-4113-b9be-326679c7343d.TID458.tmp
[2025-07-19T20:48:10.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.1.delta.1f8a1740-ebd8-4d24-8a79-9dfdab3c67b0.TID452.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta
[2025-07-19T20:48:10.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/1.delta
[2025-07-19T20:48:10.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 452, attempt 0, stage 3.0)
[2025-07-19T20:48:10.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 433.8 MiB)
[2025-07-19T20:48:10.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.1.delta.983f1235-56f5-4a56-a416-c243f6926044.TID454.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta
[2025-07-19T20:48:10.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/1.delta
[2025-07-19T20:48:10.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 454, attempt 0, stage 3.0)
[2025-07-19T20:48:10.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.7 MiB)
[2025-07-19T20:48:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 8b44f3d35cfa:46433 (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T20:48:10.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkContext: Created broadcast 13 from start at <unknown>:0
[2025-07-19T20:48:10.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:48:10.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 68 (task 452, attempt 0, stage 3.0)
[2025-07-19T20:48:10.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 68.0 in stage 3.0 (TID 452). 9264 bytes result sent to driver
[2025-07-19T20:48:10.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:48:10.327+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Registering RDD 27 (start at <unknown>:0) as input to shuffle 3
[2025-07-19T20:48:10.327+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Got job 3 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:48:10.327+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Final stage: ResultStage 7 (start at <unknown>:0)
[2025-07-19T20:48:10.327+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 66 (task 451, attempt 0, stage 3.0)
[2025-07-19T20:48:10.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-19T20:48:10.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 459) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Missing parents: List()
[2025-07-19T20:48:10.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 79.0 in stage 3.0 (TID 459)
[2025-07-19T20:48:10.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 66.0 in stage 3.0 (TID 451). 9270 bytes result sent to driver
[2025-07-19T20:48:10.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 451) in 204 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:48:10.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 460) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 71 (task 453, attempt 0, stage 3.0)
[2025-07-19T20:48:10.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 80.0 in stage 3.0 (TID 460)
[2025-07-19T20:48:10.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 71.0 in stage 3.0 (TID 453). 9258 bytes result sent to driver
[2025-07-19T20:48:10.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 452) in 179 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:48:10.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Submitting ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:48:10.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.1.delta.7a773da1-e482-47c0-ac86-4bec0ba1d47a.TID455.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta
[2025-07-19T20:48:10.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/1.delta
[2025-07-19T20:48:10.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.1.delta.9eba8cfd-46ee-4f00-810f-900cebb460e2.TID456.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta
[2025-07-19T20:48:10.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/1.delta
[2025-07-19T20:48:10.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 461) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 455, attempt 0, stage 3.0)
[2025-07-19T20:48:10.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 456, attempt 0, stage 3.0)
[2025-07-19T20:48:10.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ee41172
[2025-07-19T20:48:10.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80] for update
[2025-07-19T20:48:10.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 82.0 in stage 3.0 (TID 461)
[2025-07-19T20:48:10.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 73 (task 454, attempt 0, stage 3.0)
[2025-07-19T20:48:10.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 73.0 in stage 3.0 (TID 454). 9270 bytes result sent to driver
[2025-07-19T20:48:10.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 453) in 193 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:48:10.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 462) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.1.delta.cc1ab1da-b036-48bf-9c81-44266d9d09c6.TID457.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta
[2025-07-19T20:48:10.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/1.delta
[2025-07-19T20:48:10.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 457, attempt 0, stage 3.0)
[2025-07-19T20:48:10.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 454) in 152 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:48:10.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 83.0 in stage 3.0 (TID 462)
[2025-07-19T20:48:10.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17ec573
[2025-07-19T20:48:10.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:10.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.1.delta.bdb0c335-cb28-46cd-bf2a-57dc1bf30c40.TID460.tmp
[2025-07-19T20:48:10.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82] for update
[2025-07-19T20:48:10.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (717.0 B) non-empty blocks including 1 (717.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 75 (task 456, attempt 0, stage 3.0)
[2025-07-19T20:48:10.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 75.0 in stage 3.0 (TID 456). 9252 bytes result sent to driver
[2025-07-19T20:48:10.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.1.delta.d64ee3cc-9a1b-4e26-b189-3449427e3a80.TID461.tmp
[2025-07-19T20:48:10.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 463) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 86.0 in stage 3.0 (TID 463)
[2025-07-19T20:48:10.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.1.delta.9dd1414b-3cac-4113-b9be-326679c7343d.TID458.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta
[2025-07-19T20:48:10.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/1.delta
[2025-07-19T20:48:10.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 456) in 141 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:48:10.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 74 (task 455, attempt 0, stage 3.0)
[2025-07-19T20:48:10.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 74.0 in stage 3.0 (TID 455). 9262 bytes result sent to driver
[2025-07-19T20:48:10.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 458, attempt 0, stage 3.0)
[2025-07-19T20:48:10.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 464) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 87.0 in stage 3.0 (TID 464)
[2025-07-19T20:48:10.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@564de5f6
[2025-07-19T20:48:10.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 455) in 152 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:48:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79] for update
[2025-07-19T20:48:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bc6f186
[2025-07-19T20:48:10.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87] for update
[2025-07-19T20:48:10.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 77 (task 458, attempt 0, stage 3.0)
[2025-07-19T20:48:10.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 76 (task 457, attempt 0, stage 3.0)
[2025-07-19T20:48:10.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 76.0 in stage 3.0 (TID 457). 9267 bytes result sent to driver
[2025-07-19T20:48:10.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 77.0 in stage 3.0 (TID 458). 9250 bytes result sent to driver
[2025-07-19T20:48:10.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 465) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 466) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 88.0 in stage 3.0 (TID 465)
[2025-07-19T20:48:10.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 457) in 157 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:48:10.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 458) in 146 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:48:10.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 90.0 in stage 3.0 (TID 466)
[2025-07-19T20:48:10.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.1.delta.c292125d-ac6b-4940-9c86-d20d1cd8960a.TID459.tmp
[2025-07-19T20:48:10.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75e6dfa2
[2025-07-19T20:48:10.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83] for update
[2025-07-19T20:48:10.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:10.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 31.7 KiB, free 433.7 MiB)
[2025-07-19T20:48:10.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.1.delta.dea0af49-4efb-42c4-abce-272de75b22a2.TID464.tmp
[2025-07-19T20:48:10.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.7 MiB)
[2025-07-19T20:48:10.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.1.delta.bdb0c335-cb28-46cd-bf2a-57dc1bf30c40.TID460.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta
[2025-07-19T20:48:10.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/1.delta
[2025-07-19T20:48:10.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 8b44f3d35cfa:46433 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T20:48:10.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29bafb4e
[2025-07-19T20:48:10.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 460, attempt 0, stage 3.0)
[2025-07-19T20:48:10.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88] for update
[2025-07-19T20:48:10.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:48:10.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:48:10.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-19T20:48:10.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d579e00
[2025-07-19T20:48:10.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 80 (task 460, attempt 0, stage 3.0)
[2025-07-19T20:48:10.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86] for update
[2025-07-19T20:48:10.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 80.0 in stage 3.0 (TID 460). 9307 bytes result sent to driver
[2025-07-19T20:48:10.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 467) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 460) in 112 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:48:10.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.1.delta.497f42ea-ed61-4cce-b952-7b38bcc30278.TID465.tmp
[2025-07-19T20:48:10.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 92.0 in stage 3.0 (TID 467)
[2025-07-19T20:48:10.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.1.delta.d64ee3cc-9a1b-4e26-b189-3449427e3a80.TID461.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta
[2025-07-19T20:48:10.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/1.delta
[2025-07-19T20:48:10.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fc0d225
[2025-07-19T20:48:10.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.1.delta.3cf93974-f9ba-4d3b-aafb-88a544425015.TID462.tmp
[2025-07-19T20:48:10.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90] for update
[2025-07-19T20:48:10.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 461, attempt 0, stage 3.0)
[2025-07-19T20:48:10.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.1.delta.c292125d-ac6b-4940-9c86-d20d1cd8960a.TID459.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta
[2025-07-19T20:48:10.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/1.delta
[2025-07-19T20:48:10.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 459, attempt 0, stage 3.0)
[2025-07-19T20:48:10.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.1.delta.dea0af49-4efb-42c4-abce-272de75b22a2.TID464.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta
[2025-07-19T20:48:10.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/1.delta
[2025-07-19T20:48:10.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dca3a38
[2025-07-19T20:48:10.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 464, attempt 0, stage 3.0)
[2025-07-19T20:48:10.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92] for update
[2025-07-19T20:48:10.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.1.delta.22f48e36-ed72-46be-a808-c9ccd9ace378.TID463.tmp
[2025-07-19T20:48:10.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 82 (task 461, attempt 0, stage 3.0)
[2025-07-19T20:48:10.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 82.0 in stage 3.0 (TID 461). 9309 bytes result sent to driver
[2025-07-19T20:48:10.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 468) (8b44f3d35cfa, executor driver, partition 93, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.1.delta.574442a2-0e41-4088-b7aa-01f8502812d3.TID466.tmp
[2025-07-19T20:48:10.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 461) in 155 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:48:10.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 93.0 in stage 3.0 (TID 468)
[2025-07-19T20:48:10.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55fc28c1
[2025-07-19T20:48:10.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93] for update
[2025-07-19T20:48:10.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.1.delta.719327d7-1091-4258-88b4-6d610e566889.TID467.tmp
[2025-07-19T20:48:10.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 79 (task 459, attempt 0, stage 3.0)
[2025-07-19T20:48:10.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.1.delta.3cf93974-f9ba-4d3b-aafb-88a544425015.TID462.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta
[2025-07-19T20:48:10.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/1.delta
[2025-07-19T20:48:10.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 79.0 in stage 3.0 (TID 459). 9296 bytes result sent to driver
[2025-07-19T20:48:10.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 462, attempt 0, stage 3.0)
[2025-07-19T20:48:10.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 469) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 96.0 in stage 3.0 (TID 469)
[2025-07-19T20:48:10.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 459) in 198 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:48:10.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 87 (task 464, attempt 0, stage 3.0)
[2025-07-19T20:48:10.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 87.0 in stage 3.0 (TID 464). 9311 bytes result sent to driver
[2025-07-19T20:48:10.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.1.delta.429e93f7-289b-48d1-b1d2-2328ad8331e2.TID468.tmp
[2025-07-19T20:48:10.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 464) in 165 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:48:10.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 470) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 97.0 in stage 3.0 (TID 470)
[2025-07-19T20:48:10.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.1.delta.497f42ea-ed61-4cce-b952-7b38bcc30278.TID465.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta
[2025-07-19T20:48:10.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/1.delta
[2025-07-19T20:48:10.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 465, attempt 0, stage 3.0)
[2025-07-19T20:48:10.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a00a464
[2025-07-19T20:48:10.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96] for update
[2025-07-19T20:48:10.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.1.delta.22f48e36-ed72-46be-a808-c9ccd9ace378.TID463.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta
[2025-07-19T20:48:10.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/1.delta
[2025-07-19T20:48:10.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 463, attempt 0, stage 3.0)
[2025-07-19T20:48:10.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60af1ada
[2025-07-19T20:48:10.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97] for update
[2025-07-19T20:48:10.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.1.delta.574442a2-0e41-4088-b7aa-01f8502812d3.TID466.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta
[2025-07-19T20:48:10.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/1.delta
[2025-07-19T20:48:10.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.1.delta.965dcdbe-7fb7-4c24-9cd1-0fd4e5990300.TID469.tmp
[2025-07-19T20:48:10.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 83 (task 462, attempt 0, stage 3.0)
[2025-07-19T20:48:10.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 83.0 in stage 3.0 (TID 462). 9309 bytes result sent to driver
[2025-07-19T20:48:10.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 466, attempt 0, stage 3.0)
[2025-07-19T20:48:10.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 471) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 462) in 236 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:48:10.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 99.0 in stage 3.0 (TID 471)
[2025-07-19T20:48:10.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.1.delta.719327d7-1091-4258-88b4-6d610e566889.TID467.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta
[2025-07-19T20:48:10.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/1.delta
[2025-07-19T20:48:10.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 467, attempt 0, stage 3.0)
[2025-07-19T20:48:10.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.1.delta.74e2d299-8102-4bf5-80b7-5ba91cc78d04.TID470.tmp
[2025-07-19T20:48:10.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 88 (task 465, attempt 0, stage 3.0)
[2025-07-19T20:48:10.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 88.0 in stage 3.0 (TID 465). 9305 bytes result sent to driver
[2025-07-19T20:48:10.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 472) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 465) in 200 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:48:10.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 100.0 in stage 3.0 (TID 472)
[2025-07-19T20:48:10.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 86 (task 463, attempt 0, stage 3.0)
[2025-07-19T20:48:10.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 86.0 in stage 3.0 (TID 463). 9316 bytes result sent to driver
[2025-07-19T20:48:10.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 473) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 102.0 in stage 3.0 (TID 473)
[2025-07-19T20:48:10.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 463) in 229 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:48:10.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:10.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14010f86
[2025-07-19T20:48:10.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:10.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99] for update
[2025-07-19T20:48:10.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 92 (task 467, attempt 0, stage 3.0)
[2025-07-19T20:48:10.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 92.0 in stage 3.0 (TID 467). 9282 bytes result sent to driver
[2025-07-19T20:48:10.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a3a384d
[2025-07-19T20:48:10.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 90 (task 466, attempt 0, stage 3.0)
[2025-07-19T20:48:10.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 467) in 171 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:48:10.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 90.0 in stage 3.0 (TID 466). 9302 bytes result sent to driver
[2025-07-19T20:48:10.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 474) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102] for update
[2025-07-19T20:48:10.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 103.0 in stage 3.0 (TID 474)
[2025-07-19T20:48:10.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 475) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 466) in 220 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:48:10.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.1.delta.429e93f7-289b-48d1-b1d2-2328ad8331e2.TID468.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta
[2025-07-19T20:48:10.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/1.delta
[2025-07-19T20:48:10.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 468, attempt 0, stage 3.0)
[2025-07-19T20:48:10.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 105.0 in stage 3.0 (TID 475)
[2025-07-19T20:48:10.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:10.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.1.delta.e6cd3a5e-842a-420a-adc5-a0d3db1a8271.TID471.tmp
[2025-07-19T20:48:10.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b920675
[2025-07-19T20:48:10.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100] for update
[2025-07-19T20:48:10.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.1.delta.056cb92f-68df-4e8c-8391-63ba9820c8a9.TID473.tmp
[2025-07-19T20:48:10.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 93 (task 468, attempt 0, stage 3.0)
[2025-07-19T20:48:10.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@226447de
[2025-07-19T20:48:10.635+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 93.0 in stage 3.0 (TID 468). 9270 bytes result sent to driver
[2025-07-19T20:48:10.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 476) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105] for update
[2025-07-19T20:48:10.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 106.0 in stage 3.0 (TID 476)
[2025-07-19T20:48:10.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 468) in 145 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:48:10.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.1.delta.965dcdbe-7fb7-4c24-9cd1-0fd4e5990300.TID469.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta
[2025-07-19T20:48:10.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/1.delta
[2025-07-19T20:48:10.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 469, attempt 0, stage 3.0)
[2025-07-19T20:48:10.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.1.delta.8a61dd1c-77fa-4cd1-aa25-793909599e41.TID472.tmp
[2025-07-19T20:48:10.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a6208f4
[2025-07-19T20:48:10.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103] for update
[2025-07-19T20:48:10.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1456e645
[2025-07-19T20:48:10.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.1.delta.a8522ce0-3045-4ae1-9eda-e18589c969c1.TID475.tmp
[2025-07-19T20:48:10.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.1.delta.74e2d299-8102-4bf5-80b7-5ba91cc78d04.TID470.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta
[2025-07-19T20:48:10.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/1.delta
[2025-07-19T20:48:10.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106] for update
[2025-07-19T20:48:10.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 470, attempt 0, stage 3.0)
[2025-07-19T20:48:10.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 96 (task 469, attempt 0, stage 3.0)
[2025-07-19T20:48:10.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 96.0 in stage 3.0 (TID 469). 9281 bytes result sent to driver
[2025-07-19T20:48:10.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.1.delta.bb7cba03-9f0c-4e67-a08a-34310cfa91f1.TID474.tmp
[2025-07-19T20:48:10.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 477) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 469) in 138 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:48:10.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 109.0 in stage 3.0 (TID 477)
[2025-07-19T20:48:10.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.1.delta.5fbc1181-fa62-497a-a54c-f10c40371d99.TID476.tmp
[2025-07-19T20:48:10.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.1.delta.e6cd3a5e-842a-420a-adc5-a0d3db1a8271.TID471.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta
[2025-07-19T20:48:10.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/1.delta
[2025-07-19T20:48:10.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 471, attempt 0, stage 3.0)
[2025-07-19T20:48:10.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7806a34b
[2025-07-19T20:48:10.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109] for update
[2025-07-19T20:48:10.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 97 (task 470, attempt 0, stage 3.0)
[2025-07-19T20:48:10.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 97.0 in stage 3.0 (TID 470). 9264 bytes result sent to driver
[2025-07-19T20:48:10.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 478) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 110.0 in stage 3.0 (TID 478)
[2025-07-19T20:48:10.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 470) in 150 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:48:10.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.1.delta.056cb92f-68df-4e8c-8391-63ba9820c8a9.TID473.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta
[2025-07-19T20:48:10.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/1.delta
[2025-07-19T20:48:10.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 473, attempt 0, stage 3.0)
[2025-07-19T20:48:10.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 99 (task 471, attempt 0, stage 3.0)
[2025-07-19T20:48:10.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.1.delta.c1ac7013-cd1a-42cc-9962-b42bfb68f237.TID477.tmp
[2025-07-19T20:48:10.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 99.0 in stage 3.0 (TID 471). 9278 bytes result sent to driver
[2025-07-19T20:48:10.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.1.delta.8a61dd1c-77fa-4cd1-aa25-793909599e41.TID472.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta
[2025-07-19T20:48:10.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/1.delta
[2025-07-19T20:48:10.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 472, attempt 0, stage 3.0)
[2025-07-19T20:48:10.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 479) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 471) in 130 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:48:10.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3383455f
[2025-07-19T20:48:10.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110] for update
[2025-07-19T20:48:10.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 111.0 in stage 3.0 (TID 479)
[2025-07-19T20:48:10.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:10.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.1.delta.a8522ce0-3045-4ae1-9eda-e18589c969c1.TID475.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta
[2025-07-19T20:48:10.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/1.delta
[2025-07-19T20:48:10.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 475, attempt 0, stage 3.0)
[2025-07-19T20:48:10.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 102 (task 473, attempt 0, stage 3.0)
[2025-07-19T20:48:10.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 102.0 in stage 3.0 (TID 473). 9244 bytes result sent to driver
[2025-07-19T20:48:10.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 480) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 473) in 139 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:48:10.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 112.0 in stage 3.0 (TID 480)
[2025-07-19T20:48:10.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 100 (task 472, attempt 0, stage 3.0)
[2025-07-19T20:48:10.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 100.0 in stage 3.0 (TID 472). 9251 bytes result sent to driver
[2025-07-19T20:48:10.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 481) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 472) in 149 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:48:10.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 113.0 in stage 3.0 (TID 481)
[2025-07-19T20:48:10.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.1.delta.bb7cba03-9f0c-4e67-a08a-34310cfa91f1.TID474.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta
[2025-07-19T20:48:10.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/1.delta
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 474, attempt 0, stage 3.0)
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.1.delta.58061e54-7ab2-4326-9f17-bc6849aad910.TID478.tmp
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ed6b3f6
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 105 (task 475, attempt 0, stage 3.0)
[2025-07-19T20:48:10.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111] for update
[2025-07-19T20:48:10.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 105.0 in stage 3.0 (TID 475). 9252 bytes result sent to driver
[2025-07-19T20:48:10.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:10.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 482) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 475) in 140 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:48:10.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 114.0 in stage 3.0 (TID 482)
[2025-07-19T20:48:10.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@275a340d
[2025-07-19T20:48:10.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112] for update
[2025-07-19T20:48:10.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.1.delta.5fbc1181-fa62-497a-a54c-f10c40371d99.TID476.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta
[2025-07-19T20:48:10.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/1.delta
[2025-07-19T20:48:10.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 476, attempt 0, stage 3.0)
[2025-07-19T20:48:10.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 103 (task 474, attempt 0, stage 3.0)
[2025-07-19T20:48:10.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 103.0 in stage 3.0 (TID 474). 9304 bytes result sent to driver
[2025-07-19T20:48:10.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 483) (8b44f3d35cfa, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 116.0 in stage 3.0 (TID 483)
[2025-07-19T20:48:10.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 474) in 153 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:48:10.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5333036a
[2025-07-19T20:48:10.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113] for update
[2025-07-19T20:48:10.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.1.delta.85b838fe-61a9-4a53-85a9-d6133d9fb7f5.TID479.tmp
[2025-07-19T20:48:10.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.1.delta.af45584c-6118-4f83-9a4e-efcf455a46d9.TID480.tmp
[2025-07-19T20:48:10.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 106 (task 476, attempt 0, stage 3.0)
[2025-07-19T20:48:10.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 106.0 in stage 3.0 (TID 476). 9248 bytes result sent to driver
[2025-07-19T20:48:10.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 476) in 141 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:48:10.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 484) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 117.0 in stage 3.0 (TID 484)
[2025-07-19T20:48:10.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.1.delta.c1ac7013-cd1a-42cc-9962-b42bfb68f237.TID477.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta
[2025-07-19T20:48:10.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/1.delta
[2025-07-19T20:48:10.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 477, attempt 0, stage 3.0)
[2025-07-19T20:48:10.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ce593ae
[2025-07-19T20:48:10.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116] for update
[2025-07-19T20:48:10.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.1.delta.c0d3a737-a9c3-4b65-8618-f9f0fe70b9af.TID481.tmp
[2025-07-19T20:48:10.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41df47a9
[2025-07-19T20:48:10.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114] for update
[2025-07-19T20:48:10.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@346c756c
[2025-07-19T20:48:10.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117] for update
[2025-07-19T20:48:10.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.1.delta.0522a427-67e1-40f1-aea6-d656a8981150.TID483.tmp
[2025-07-19T20:48:10.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.1.delta.58061e54-7ab2-4326-9f17-bc6849aad910.TID478.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta
[2025-07-19T20:48:10.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/1.delta
[2025-07-19T20:48:10.803+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 478, attempt 0, stage 3.0)
[2025-07-19T20:48:10.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.1.delta.ae9438c4-5b47-4972-a20d-7882e56e3b75.TID482.tmp
[2025-07-19T20:48:10.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 109 (task 477, attempt 0, stage 3.0)
[2025-07-19T20:48:10.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 109.0 in stage 3.0 (TID 477). 9271 bytes result sent to driver
[2025-07-19T20:48:10.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 485) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 477) in 152 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:48:10.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 118.0 in stage 3.0 (TID 485)
[2025-07-19T20:48:10.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.1.delta.af45584c-6118-4f83-9a4e-efcf455a46d9.TID480.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta
[2025-07-19T20:48:10.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/1.delta
[2025-07-19T20:48:10.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.1.delta.63b52e15-6745-4098-a3af-f7fb3ec93585.TID484.tmp
[2025-07-19T20:48:10.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 480, attempt 0, stage 3.0)
[2025-07-19T20:48:10.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.1.delta.85b838fe-61a9-4a53-85a9-d6133d9fb7f5.TID479.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta
[2025-07-19T20:48:10.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/1.delta
[2025-07-19T20:48:10.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 479, attempt 0, stage 3.0)
[2025-07-19T20:48:10.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:48:10.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 110 (task 478, attempt 0, stage 3.0)
[2025-07-19T20:48:10.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 110.0 in stage 3.0 (TID 478). 9263 bytes result sent to driver
[2025-07-19T20:48:10.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 486) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 478) in 144 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:48:10.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 119.0 in stage 3.0 (TID 486)
[2025-07-19T20:48:10.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.1.delta.c0d3a737-a9c3-4b65-8618-f9f0fe70b9af.TID481.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta
[2025-07-19T20:48:10.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/1.delta
[2025-07-19T20:48:10.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 481, attempt 0, stage 3.0)
[2025-07-19T20:48:10.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56e97fc9
[2025-07-19T20:48:10.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118] for update
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 111 (task 479, attempt 0, stage 3.0)
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 111.0 in stage 3.0 (TID 479). 9268 bytes result sent to driver
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 487) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 120.0 in stage 3.0 (TID 487)
[2025-07-19T20:48:10.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 479) in 136 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:48:10.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 112 (task 480, attempt 0, stage 3.0)
[2025-07-19T20:48:10.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 112.0 in stage 3.0 (TID 480). 9257 bytes result sent to driver
[2025-07-19T20:48:10.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 488) (8b44f3d35cfa, executor driver, partition 124, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 124.0 in stage 3.0 (TID 488)
[2025-07-19T20:48:10.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 480) in 115 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:48:10.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.1.delta.0522a427-67e1-40f1-aea6-d656a8981150.TID483.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta
[2025-07-19T20:48:10.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/1.delta
[2025-07-19T20:48:10.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.1.delta.ae9438c4-5b47-4972-a20d-7882e56e3b75.TID482.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta
[2025-07-19T20:48:10.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/1.delta
[2025-07-19T20:48:10.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.1.delta.e2860e53-d708-4c1e-8515-6202572dfd85.TID485.tmp
[2025-07-19T20:48:10.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 113 (task 481, attempt 0, stage 3.0)
[2025-07-19T20:48:10.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 113.0 in stage 3.0 (TID 481). 9242 bytes result sent to driver
[2025-07-19T20:48:10.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 482, attempt 0, stage 3.0)
[2025-07-19T20:48:10.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 489) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 483, attempt 0, stage 3.0)
[2025-07-19T20:48:10.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 481) in 118 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:48:10.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 125.0 in stage 3.0 (TID 489)
[2025-07-19T20:48:10.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c2473a6
[2025-07-19T20:48:10.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119] for update
[2025-07-19T20:48:10.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f9e085e
[2025-07-19T20:48:10.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125] for update
[2025-07-19T20:48:10.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 116 (task 483, attempt 0, stage 3.0)
[2025-07-19T20:48:10.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 116.0 in stage 3.0 (TID 483). 9279 bytes result sent to driver
[2025-07-19T20:48:10.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 114 (task 482, attempt 0, stage 3.0)
[2025-07-19T20:48:10.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 114.0 in stage 3.0 (TID 482). 9257 bytes result sent to driver
[2025-07-19T20:48:10.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 490) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 483) in 121 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:48:10.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 491) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 127.0 in stage 3.0 (TID 491)
[2025-07-19T20:48:10.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 126.0 in stage 3.0 (TID 490)
[2025-07-19T20:48:10.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 482) in 135 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:48:10.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.1.delta.8d11d53d-ad65-40b5-a507-a31e40d7929e.TID489.tmp
[2025-07-19T20:48:10.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9da750b
[2025-07-19T20:48:10.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124] for update
[2025-07-19T20:48:10.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.1.delta.63b52e15-6745-4098-a3af-f7fb3ec93585.TID484.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta
[2025-07-19T20:48:10.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/1.delta
[2025-07-19T20:48:10.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 484, attempt 0, stage 3.0)
[2025-07-19T20:48:10.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.1.delta.418d4799-dd6e-453c-9439-869425b6c850.TID486.tmp
[2025-07-19T20:48:10.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c021324
[2025-07-19T20:48:10.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120] for update
[2025-07-19T20:48:10.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.1.delta.9a7341c1-0e1e-4b8d-87dd-cb5de11ed983.TID488.tmp
[2025-07-19T20:48:10.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e7dabb
[2025-07-19T20:48:10.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127] for update
[2025-07-19T20:48:10.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.1.delta.c693870d-6820-4818-8f53-3d81383a0abc.TID487.tmp
[2025-07-19T20:48:10.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 117 (task 484, attempt 0, stage 3.0)
[2025-07-19T20:48:10.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 117.0 in stage 3.0 (TID 484). 9280 bytes result sent to driver
[2025-07-19T20:48:10.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25c58cfc
[2025-07-19T20:48:10.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 492) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 128.0 in stage 3.0 (TID 492)
[2025-07-19T20:48:10.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126] for update
[2025-07-19T20:48:10.930+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.930+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.1.delta.e2860e53-d708-4c1e-8515-6202572dfd85.TID485.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta
[2025-07-19T20:48:10.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/1.delta
[2025-07-19T20:48:10.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 485, attempt 0, stage 3.0)
[2025-07-19T20:48:10.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 484) in 155 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:48:10.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.1.delta.1fd305e9-0c33-4e05-bcda-9db2f73ce88f.TID491.tmp
[2025-07-19T20:48:10.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.1.delta.8d11d53d-ad65-40b5-a507-a31e40d7929e.TID489.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta
[2025-07-19T20:48:10.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/1.delta
[2025-07-19T20:48:10.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.1.delta.7acbd6c1-5292-40a5-a8cc-3471c511e9bf.TID490.tmp
[2025-07-19T20:48:10.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 489, attempt 0, stage 3.0)
[2025-07-19T20:48:10.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cbf70a1
[2025-07-19T20:48:10.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:10.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128] for update
[2025-07-19T20:48:10.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.1.delta.418d4799-dd6e-453c-9439-869425b6c850.TID486.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta
[2025-07-19T20:48:10.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/1.delta
[2025-07-19T20:48:10.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 486, attempt 0, stage 3.0)
[2025-07-19T20:48:10.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:10.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.1.delta.9a7341c1-0e1e-4b8d-87dd-cb5de11ed983.TID488.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta
[2025-07-19T20:48:10.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/1.delta
[2025-07-19T20:48:10.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 488, attempt 0, stage 3.0)
[2025-07-19T20:48:10.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 118 (task 485, attempt 0, stage 3.0)
[2025-07-19T20:48:10.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 118.0 in stage 3.0 (TID 485). 9219 bytes result sent to driver
[2025-07-19T20:48:10.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.1.delta.760400b2-a684-49de-a2c4-61d0dac8f722.TID492.tmp
[2025-07-19T20:48:10.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 493) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:10.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Running task 130.0 in stage 3.0 (TID 493)
[2025-07-19T20:48:10.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 485) in 161 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:48:10.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:10.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:10.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5aa10c90
[2025-07-19T20:48:10.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130] for update
[2025-07-19T20:48:11.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.1.delta.c693870d-6820-4818-8f53-3d81383a0abc.TID487.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta
[2025-07-19T20:48:11.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/1.delta
[2025-07-19T20:48:11.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 487, attempt 0, stage 3.0)
[2025-07-19T20:48:11.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO DataWritingSparkTask: Committed partition 125 (task 489, attempt 0, stage 3.0)
[2025-07-19T20:48:11.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:10 INFO Executor: Finished task 125.0 in stage 3.0 (TID 489). 9250 bytes result sent to driver
[2025-07-19T20:48:11.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 494) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 489) in 147 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:48:11.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 119 (task 486, attempt 0, stage 3.0)
[2025-07-19T20:48:11.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 119.0 in stage 3.0 (TID 486). 9244 bytes result sent to driver
[2025-07-19T20:48:11.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 495) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 486) in 186 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:48:11.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 134.0 in stage 3.0 (TID 495)
[2025-07-19T20:48:11.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 131.0 in stage 3.0 (TID 494)
[2025-07-19T20:48:11.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.1.delta.1fd305e9-0c33-4e05-bcda-9db2f73ce88f.TID491.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta
[2025-07-19T20:48:11.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/1.delta
[2025-07-19T20:48:11.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 491, attempt 0, stage 3.0)
[2025-07-19T20:48:11.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.1.delta.f27c7e01-039e-4cdb-b173-d509be6e2daa.TID493.tmp
[2025-07-19T20:48:11.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 124 (task 488, attempt 0, stage 3.0)
[2025-07-19T20:48:11.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66b10d7e
[2025-07-19T20:48:11.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.1.delta.760400b2-a684-49de-a2c4-61d0dac8f722.TID492.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta
[2025-07-19T20:48:11.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134] for update
[2025-07-19T20:48:11.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/1.delta
[2025-07-19T20:48:11.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 492, attempt 0, stage 3.0)
[2025-07-19T20:48:11.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 120 (task 487, attempt 0, stage 3.0)
[2025-07-19T20:48:11.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 124.0 in stage 3.0 (TID 488). 9300 bytes result sent to driver
[2025-07-19T20:48:11.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 127 (task 491, attempt 0, stage 3.0)
[2025-07-19T20:48:11.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 127.0 in stage 3.0 (TID 491). 9243 bytes result sent to driver
[2025-07-19T20:48:11.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 496) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36141898
[2025-07-19T20:48:11.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 497) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 135.0 in stage 3.0 (TID 496)
[2025-07-19T20:48:11.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 120.0 in stage 3.0 (TID 487). 9307 bytes result sent to driver
[2025-07-19T20:48:11.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 498) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 137.0 in stage 3.0 (TID 498)
[2025-07-19T20:48:11.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131] for update
[2025-07-19T20:48:11.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 136.0 in stage 3.0 (TID 497)
[2025-07-19T20:48:11.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 487) in 313 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:48:11.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 491) in 272 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:48:11.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.1.delta.7acbd6c1-5292-40a5-a8cc-3471c511e9bf.TID490.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta
[2025-07-19T20:48:11.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/1.delta
[2025-07-19T20:48:11.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 490, attempt 0, stage 3.0)
[2025-07-19T20:48:11.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 488) in 326 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:48:11.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 128 (task 492, attempt 0, stage 3.0)
[2025-07-19T20:48:11.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 128.0 in stage 3.0 (TID 492). 9233 bytes result sent to driver
[2025-07-19T20:48:11.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 499) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 492) in 275 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:48:11.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 140.0 in stage 3.0 (TID 499)
[2025-07-19T20:48:11.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@194c4909
[2025-07-19T20:48:11.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.1.delta.d661fad1-e9de-4941-80b6-5a582c760f8a.TID494.tmp
[2025-07-19T20:48:11.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.1.delta.404f9323-a0e6-4986-b08f-accf56e94ef6.TID495.tmp
[2025-07-19T20:48:11.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136] for update
[2025-07-19T20:48:11.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19be9c4
[2025-07-19T20:48:11.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137] for update
[2025-07-19T20:48:11.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@400a8173
[2025-07-19T20:48:11.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.1.delta.d2e23142-58e8-4f6c-823b-306697fe6ee1.TID497.tmp
[2025-07-19T20:48:11.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135] for update
[2025-07-19T20:48:11.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.1.delta.f27c7e01-039e-4cdb-b173-d509be6e2daa.TID493.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta
[2025-07-19T20:48:11.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/1.delta
[2025-07-19T20:48:11.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 493, attempt 0, stage 3.0)
[2025-07-19T20:48:11.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 126 (task 490, attempt 0, stage 3.0)
[2025-07-19T20:48:11.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 126.0 in stage 3.0 (TID 490). 9239 bytes result sent to driver
[2025-07-19T20:48:11.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 500) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 141.0 in stage 3.0 (TID 500)
[2025-07-19T20:48:11.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 490) in 373 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:48:11.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.1.delta.147f4b52-a44f-4c89-b189-7969a75f2680.TID498.tmp
[2025-07-19T20:48:11.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75167b48
[2025-07-19T20:48:11.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.1.delta.b3d57652-7b16-49cc-b8f2-c89f1e63041f.TID496.tmp
[2025-07-19T20:48:11.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140] for update
[2025-07-19T20:48:11.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 130 (task 493, attempt 0, stage 3.0)
[2025-07-19T20:48:11.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 130.0 in stage 3.0 (TID 493). 9248 bytes result sent to driver
[2025-07-19T20:48:11.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 501) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 493) in 306 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:48:11.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 142.0 in stage 3.0 (TID 501)
[2025-07-19T20:48:11.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2be3d155
[2025-07-19T20:48:11.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141] for update
[2025-07-19T20:48:11.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fe694cf
[2025-07-19T20:48:11.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.1.delta.4340ca6c-e96f-4c3b-9b58-d2c4b7a46b29.TID499.tmp
[2025-07-19T20:48:11.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142] for update
[2025-07-19T20:48:11.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.1.delta.404f9323-a0e6-4986-b08f-accf56e94ef6.TID495.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta
[2025-07-19T20:48:11.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/1.delta
[2025-07-19T20:48:11.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 495, attempt 0, stage 3.0)
[2025-07-19T20:48:11.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.1.delta.d661fad1-e9de-4941-80b6-5a582c760f8a.TID494.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta
[2025-07-19T20:48:11.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/1.delta
[2025-07-19T20:48:11.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 494, attempt 0, stage 3.0)
[2025-07-19T20:48:11.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.1.delta.6ed151a3-447b-4768-8a1d-5775538920b6.TID500.tmp
[2025-07-19T20:48:11.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.1.delta.d2e23142-58e8-4f6c-823b-306697fe6ee1.TID497.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta
[2025-07-19T20:48:11.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/1.delta
[2025-07-19T20:48:11.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 497, attempt 0, stage 3.0)
[2025-07-19T20:48:11.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.1.delta.74c2308e-bd1b-45bb-b4c8-7a4051bbd9f2.TID501.tmp
[2025-07-19T20:48:11.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.1.delta.b3d57652-7b16-49cc-b8f2-c89f1e63041f.TID496.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta
[2025-07-19T20:48:11.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/1.delta
[2025-07-19T20:48:11.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 134 (task 495, attempt 0, stage 3.0)
[2025-07-19T20:48:11.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 496, attempt 0, stage 3.0)
[2025-07-19T20:48:11.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 134.0 in stage 3.0 (TID 495). 9248 bytes result sent to driver
[2025-07-19T20:48:11.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 502) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 495) in 314 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:48:11.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 131 (task 494, attempt 0, stage 3.0)
[2025-07-19T20:48:11.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 136 (task 497, attempt 0, stage 3.0)
[2025-07-19T20:48:11.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 144.0 in stage 3.0 (TID 502)
[2025-07-19T20:48:11.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 131.0 in stage 3.0 (TID 494). 9343 bytes result sent to driver
[2025-07-19T20:48:11.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 503) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 136.0 in stage 3.0 (TID 497). 9349 bytes result sent to driver
[2025-07-19T20:48:11.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 145.0 in stage 3.0 (TID 503)
[2025-07-19T20:48:11.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 494) in 339 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:48:11.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 504) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 497) in 204 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:48:11.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.1.delta.147f4b52-a44f-4c89-b189-7969a75f2680.TID498.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta
[2025-07-19T20:48:11.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/1.delta
[2025-07-19T20:48:11.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 147.0 in stage 3.0 (TID 504)
[2025-07-19T20:48:11.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 498, attempt 0, stage 3.0)
[2025-07-19T20:48:11.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:11.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.1.delta.4340ca6c-e96f-4c3b-9b58-d2c4b7a46b29.TID499.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta
[2025-07-19T20:48:11.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/1.delta
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 499, attempt 0, stage 3.0)
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4be48c53
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144] for update
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.1.delta.6ed151a3-447b-4768-8a1d-5775538920b6.TID500.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/1.delta
[2025-07-19T20:48:11.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 500, attempt 0, stage 3.0)
[2025-07-19T20:48:11.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:11.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 135 (task 496, attempt 0, stage 3.0)
[2025-07-19T20:48:11.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 135.0 in stage 3.0 (TID 496). 9300 bytes result sent to driver
[2025-07-19T20:48:11.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 505) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ec645df
[2025-07-19T20:48:11.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 496) in 243 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:48:11.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 148.0 in stage 3.0 (TID 505)
[2025-07-19T20:48:11.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 137 (task 498, attempt 0, stage 3.0)
[2025-07-19T20:48:11.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145] for update
[2025-07-19T20:48:11.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 137.0 in stage 3.0 (TID 498). 9345 bytes result sent to driver
[2025-07-19T20:48:11.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.1.delta.157561fa-2ab4-4cae-b90e-c54eb7c7be1d.TID502.tmp
[2025-07-19T20:48:11.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 140 (task 499, attempt 0, stage 3.0)
[2025-07-19T20:48:11.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40096c9f
[2025-07-19T20:48:11.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 140.0 in stage 3.0 (TID 499). 9270 bytes result sent to driver
[2025-07-19T20:48:11.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 506) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.1.delta.74c2308e-bd1b-45bb-b4c8-7a4051bbd9f2.TID501.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta
[2025-07-19T20:48:11.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/1.delta
[2025-07-19T20:48:11.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147] for update
[2025-07-19T20:48:11.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 141 (task 500, attempt 0, stage 3.0)
[2025-07-19T20:48:11.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 149.0 in stage 3.0 (TID 506)
[2025-07-19T20:48:11.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 501, attempt 0, stage 3.0)
[2025-07-19T20:48:11.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 141.0 in stage 3.0 (TID 500). 9309 bytes result sent to driver
[2025-07-19T20:48:11.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 507) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.1.delta.cf30ae60-dc00-41d0-978b-22849e93bde4.TID503.tmp
[2025-07-19T20:48:11.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 151.0 in stage 3.0 (TID 507)
[2025-07-19T20:48:11.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15c5b850
[2025-07-19T20:48:11.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148] for update
[2025-07-19T20:48:11.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 508) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 498) in 265 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:48:11.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 152.0 in stage 3.0 (TID 508)
[2025-07-19T20:48:11.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 500) in 165 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:48:11.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 499) in 225 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:48:11.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:11.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 142 (task 501, attempt 0, stage 3.0)
[2025-07-19T20:48:11.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 142.0 in stage 3.0 (TID 501). 9290 bytes result sent to driver
[2025-07-19T20:48:11.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.1.delta.3ae3b1dc-b74d-4778-8b0c-185014a922d8.TID505.tmp
[2025-07-19T20:48:11.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 509) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42744296
[2025-07-19T20:48:11.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.1.delta.cacaf92d-6ea3-4224-94a1-875779e2cc43.TID504.tmp
[2025-07-19T20:48:11.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152] for update
[2025-07-19T20:48:11.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 501) in 173 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:48:11.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 153.0 in stage 3.0 (TID 509)
[2025-07-19T20:48:11.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17a16820
[2025-07-19T20:48:11.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151] for update
[2025-07-19T20:48:11.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
[2025-07-19T20:48:11.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.1.delta.6a320760-4017-41d4-ac33-3bb87e77f1fd.TID508.tmp
[2025-07-19T20:48:11.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2616f051
[2025-07-19T20:48:11.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149] for update
[2025-07-19T20:48:11.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@234e56aa
[2025-07-19T20:48:11.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153] for update
[2025-07-19T20:48:11.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.1.delta.157561fa-2ab4-4cae-b90e-c54eb7c7be1d.TID502.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta
[2025-07-19T20:48:11.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/1.delta
[2025-07-19T20:48:11.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 502, attempt 0, stage 3.0)
[2025-07-19T20:48:11.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.1.delta.cf30ae60-dc00-41d0-978b-22849e93bde4.TID503.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta
[2025-07-19T20:48:11.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/1.delta
[2025-07-19T20:48:11.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.1.delta.45105998-a245-48f9-9f1b-391e3e0f6e5a.TID507.tmp
[2025-07-19T20:48:11.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.1.delta.b41b804b-3985-4104-9108-ab5a61c87239.TID509.tmp
[2025-07-19T20:48:11.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 503, attempt 0, stage 3.0)
[2025-07-19T20:48:11.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.1.delta.3ae3b1dc-b74d-4778-8b0c-185014a922d8.TID505.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta
[2025-07-19T20:48:11.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/1.delta
[2025-07-19T20:48:11.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 505, attempt 0, stage 3.0)
[2025-07-19T20:48:11.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.1.delta.cacaf92d-6ea3-4224-94a1-875779e2cc43.TID504.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta
[2025-07-19T20:48:11.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/1.delta
[2025-07-19T20:48:11.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 504, attempt 0, stage 3.0)
[2025-07-19T20:48:11.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.1.delta.b924a1c5-5fd9-421a-ad4e-2a8de37ba81c.TID506.tmp
[2025-07-19T20:48:11.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 144 (task 502, attempt 0, stage 3.0)
[2025-07-19T20:48:11.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 144.0 in stage 3.0 (TID 502). 9313 bytes result sent to driver
[2025-07-19T20:48:11.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 145 (task 503, attempt 0, stage 3.0)
[2025-07-19T20:48:11.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 145.0 in stage 3.0 (TID 503). 9295 bytes result sent to driver
[2025-07-19T20:48:11.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 510) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 511) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.1.delta.6a320760-4017-41d4-ac33-3bb87e77f1fd.TID508.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta
[2025-07-19T20:48:11.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/1.delta
[2025-07-19T20:48:11.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 155.0 in stage 3.0 (TID 510)
[2025-07-19T20:48:11.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 502) in 243 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:48:11.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 508, attempt 0, stage 3.0)
[2025-07-19T20:48:11.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 147 (task 504, attempt 0, stage 3.0)
[2025-07-19T20:48:11.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 148 (task 505, attempt 0, stage 3.0)
[2025-07-19T20:48:11.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 148.0 in stage 3.0 (TID 505). 9263 bytes result sent to driver
[2025-07-19T20:48:11.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 512) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 147.0 in stage 3.0 (TID 504). 9282 bytes result sent to driver
[2025-07-19T20:48:11.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 156.0 in stage 3.0 (TID 511)
[2025-07-19T20:48:11.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 157.0 in stage 3.0 (TID 512)
[2025-07-19T20:48:11.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 513) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 503) in 239 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:48:11.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 504) in 237 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:48:11.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 505) in 202 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:48:11.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 159.0 in stage 3.0 (TID 513)
[2025-07-19T20:48:11.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cb1c8f7
[2025-07-19T20:48:11.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157] for update
[2025-07-19T20:48:11.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.1.delta.b41b804b-3985-4104-9108-ab5a61c87239.TID509.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta
[2025-07-19T20:48:11.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/1.delta
[2025-07-19T20:48:11.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 509, attempt 0, stage 3.0)
[2025-07-19T20:48:11.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 152 (task 508, attempt 0, stage 3.0)
[2025-07-19T20:48:11.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 152.0 in stage 3.0 (TID 508). 9259 bytes result sent to driver
[2025-07-19T20:48:11.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 514) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31162808
[2025-07-19T20:48:11.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 160.0 in stage 3.0 (TID 514)
[2025-07-19T20:48:11.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 508) in 206 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:48:11.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159] for update
[2025-07-19T20:48:11.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20b038c9
[2025-07-19T20:48:11.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.1.delta.45105998-a245-48f9-9f1b-391e3e0f6e5a.TID507.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta
[2025-07-19T20:48:11.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/1.delta
[2025-07-19T20:48:11.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 507, attempt 0, stage 3.0)
[2025-07-19T20:48:11.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155] for update
[2025-07-19T20:48:11.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.1.delta.84d0c5c0-1738-49c8-ad9a-9d3becc5f102.TID512.tmp
[2025-07-19T20:48:11.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 153 (task 509, attempt 0, stage 3.0)
[2025-07-19T20:48:11.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.1.delta.0ce975be-a727-4999-8de9-c65c7247392f.TID513.tmp
[2025-07-19T20:48:11.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7071a572
[2025-07-19T20:48:11.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156] for update
[2025-07-19T20:48:11.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 153.0 in stage 3.0 (TID 509). 9308 bytes result sent to driver
[2025-07-19T20:48:11.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 515) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 162.0 in stage 3.0 (TID 515)
[2025-07-19T20:48:11.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.1.delta.b924a1c5-5fd9-421a-ad4e-2a8de37ba81c.TID506.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta
[2025-07-19T20:48:11.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/1.delta
[2025-07-19T20:48:11.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 506, attempt 0, stage 3.0)
[2025-07-19T20:48:11.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 509) in 251 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:48:11.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 151 (task 507, attempt 0, stage 3.0)
[2025-07-19T20:48:11.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 151.0 in stage 3.0 (TID 507). 9259 bytes result sent to driver
[2025-07-19T20:48:11.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 507) in 299 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:48:11.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.1.delta.ec913149-7362-4d6e-acce-4b2398375219.TID510.tmp
[2025-07-19T20:48:11.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 516) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 165.0 in stage 3.0 (TID 516)
[2025-07-19T20:48:11.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eaa740a
[2025-07-19T20:48:11.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160] for update
[2025-07-19T20:48:11.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.1.delta.83204847-b8da-4030-9be8-93a6a771f861.TID511.tmp
[2025-07-19T20:48:11.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 149 (task 506, attempt 0, stage 3.0)
[2025-07-19T20:48:11.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 149.0 in stage 3.0 (TID 506). 9264 bytes result sent to driver
[2025-07-19T20:48:11.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e999752
[2025-07-19T20:48:11.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162] for update
[2025-07-19T20:48:11.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 517) (8b44f3d35cfa, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 506) in 325 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:48:11.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 166.0 in stage 3.0 (TID 517)
[2025-07-19T20:48:11.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.1.delta.f7c6d473-551d-464f-a62c-22958b726c45.TID514.tmp
[2025-07-19T20:48:11.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af5852f
[2025-07-19T20:48:11.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165] for update
[2025-07-19T20:48:11.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.1.delta.3e985fa2-ce63-4c3e-bceb-c881a556d52b.TID515.tmp
[2025-07-19T20:48:11.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.1.delta.84d0c5c0-1738-49c8-ad9a-9d3becc5f102.TID512.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta
[2025-07-19T20:48:11.735+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/1.delta
[2025-07-19T20:48:11.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 512, attempt 0, stage 3.0)
[2025-07-19T20:48:11.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.1.delta.0ce975be-a727-4999-8de9-c65c7247392f.TID513.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta
[2025-07-19T20:48:11.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/1.delta
[2025-07-19T20:48:11.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.1.delta.ec913149-7362-4d6e-acce-4b2398375219.TID510.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta
[2025-07-19T20:48:11.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/1.delta
[2025-07-19T20:48:11.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 510, attempt 0, stage 3.0)
[2025-07-19T20:48:11.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 513, attempt 0, stage 3.0)
[2025-07-19T20:48:11.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.1.delta.b9ae2e1e-8445-4bde-af65-2e022bb35772.TID516.tmp
[2025-07-19T20:48:11.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26a27fbe
[2025-07-19T20:48:11.768+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166] for update
[2025-07-19T20:48:11.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 157 (task 512, attempt 0, stage 3.0)
[2025-07-19T20:48:11.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 157.0 in stage 3.0 (TID 512). 9245 bytes result sent to driver
[2025-07-19T20:48:11.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 518) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 168.0 in stage 3.0 (TID 518)
[2025-07-19T20:48:11.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 512) in 197 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:48:11.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 155 (task 510, attempt 0, stage 3.0)
[2025-07-19T20:48:11.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 155.0 in stage 3.0 (TID 510). 9233 bytes result sent to driver
[2025-07-19T20:48:11.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.1.delta.83204847-b8da-4030-9be8-93a6a771f861.TID511.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta
[2025-07-19T20:48:11.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/1.delta
[2025-07-19T20:48:11.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 519) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 169.0 in stage 3.0 (TID 519)
[2025-07-19T20:48:11.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 511, attempt 0, stage 3.0)
[2025-07-19T20:48:11.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 510) in 214 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:48:11.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 159 (task 513, attempt 0, stage 3.0)
[2025-07-19T20:48:11.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 159.0 in stage 3.0 (TID 513). 9257 bytes result sent to driver
[2025-07-19T20:48:11.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 520) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 174.0 in stage 3.0 (TID 520)
[2025-07-19T20:48:11.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 513) in 208 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:48:11.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bf3983c
[2025-07-19T20:48:11.798+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168] for update
[2025-07-19T20:48:11.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.1.delta.d55bfc59-42c5-48d7-ae38-c0224605dfc7.TID517.tmp
[2025-07-19T20:48:11.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 156 (task 511, attempt 0, stage 3.0)
[2025-07-19T20:48:11.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 156.0 in stage 3.0 (TID 511). 9262 bytes result sent to driver
[2025-07-19T20:48:11.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 521) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 511) in 244 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:48:11.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 175.0 in stage 3.0 (TID 521)
[2025-07-19T20:48:11.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.1.delta.f7c6d473-551d-464f-a62c-22958b726c45.TID514.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta
[2025-07-19T20:48:11.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/1.delta
[2025-07-19T20:48:11.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 514, attempt 0, stage 3.0)
[2025-07-19T20:48:11.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f2be5de
[2025-07-19T20:48:11.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174] for update
[2025-07-19T20:48:11.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:11.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e07bf0
[2025-07-19T20:48:11.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169] for update
[2025-07-19T20:48:11.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.1.delta.0d22cd24-4e6b-40f5-84f1-bdaec66a8e69.TID518.tmp
[2025-07-19T20:48:11.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.1.delta.3e985fa2-ce63-4c3e-bceb-c881a556d52b.TID515.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta
[2025-07-19T20:48:11.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/1.delta
[2025-07-19T20:48:11.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.1.delta.73ae7161-24e1-4cb2-9e8c-5449c9fa3a0e.TID520.tmp
[2025-07-19T20:48:11.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 515, attempt 0, stage 3.0)
[2025-07-19T20:48:11.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ed29ed0
[2025-07-19T20:48:11.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175] for update
[2025-07-19T20:48:11.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.1.delta.1f153eed-cd6d-4670-a8eb-be038f52f4b0.TID519.tmp
[2025-07-19T20:48:11.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 160 (task 514, attempt 0, stage 3.0)
[2025-07-19T20:48:11.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 160.0 in stage 3.0 (TID 514). 9274 bytes result sent to driver
[2025-07-19T20:48:11.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 522) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.1.delta.b9ae2e1e-8445-4bde-af65-2e022bb35772.TID516.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta
[2025-07-19T20:48:11.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/1.delta
[2025-07-19T20:48:11.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 176.0 in stage 3.0 (TID 522)
[2025-07-19T20:48:11.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 514) in 236 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:48:11.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:11.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 516, attempt 0, stage 3.0)
[2025-07-19T20:48:11.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.1.delta.958e8005-1e2e-42da-a602-b44ed291c5c0.TID521.tmp
[2025-07-19T20:48:11.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.1.delta.d55bfc59-42c5-48d7-ae38-c0224605dfc7.TID517.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta
[2025-07-19T20:48:11.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/1.delta
[2025-07-19T20:48:11.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 517, attempt 0, stage 3.0)
[2025-07-19T20:48:11.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@553438b
[2025-07-19T20:48:11.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 162 (task 515, attempt 0, stage 3.0)
[2025-07-19T20:48:11.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176] for update
[2025-07-19T20:48:11.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 165 (task 516, attempt 0, stage 3.0)
[2025-07-19T20:48:11.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 162.0 in stage 3.0 (TID 515). 9267 bytes result sent to driver
[2025-07-19T20:48:11.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.1.delta.0d22cd24-4e6b-40f5-84f1-bdaec66a8e69.TID518.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta
[2025-07-19T20:48:11.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/1.delta
[2025-07-19T20:48:11.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 165.0 in stage 3.0 (TID 516). 9300 bytes result sent to driver
[2025-07-19T20:48:11.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 523) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 524) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 179.0 in stage 3.0 (TID 524)
[2025-07-19T20:48:11.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 178.0 in stage 3.0 (TID 523)
[2025-07-19T20:48:11.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 516) in 177 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:48:11.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.1.delta.73ae7161-24e1-4cb2-9e8c-5449c9fa3a0e.TID520.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta
[2025-07-19T20:48:11.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/1.delta
[2025-07-19T20:48:11.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 518, attempt 0, stage 3.0)
[2025-07-19T20:48:11.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 520, attempt 0, stage 3.0)
[2025-07-19T20:48:11.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 515) in 192 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:48:11.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 166 (task 517, attempt 0, stage 3.0)
[2025-07-19T20:48:11.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 166.0 in stage 3.0 (TID 517). 9264 bytes result sent to driver
[2025-07-19T20:48:11.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:11.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@760ff43a
[2025-07-19T20:48:11.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.1.delta.7b5d9029-4a19-4a3d-8c5c-1d6d1c2145b9.TID522.tmp
[2025-07-19T20:48:11.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 525) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178] for update
[2025-07-19T20:48:11.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 182.0 in stage 3.0 (TID 525)
[2025-07-19T20:48:11.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 517) in 170 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:48:11.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 168 (task 518, attempt 0, stage 3.0)
[2025-07-19T20:48:11.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10f229a5
[2025-07-19T20:48:11.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 168.0 in stage 3.0 (TID 518). 9251 bytes result sent to driver
[2025-07-19T20:48:11.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 526) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 518) in 121 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:48:11.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 183.0 in stage 3.0 (TID 526)
[2025-07-19T20:48:11.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179] for update
[2025-07-19T20:48:11.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 174 (task 520, attempt 0, stage 3.0)
[2025-07-19T20:48:11.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 174.0 in stage 3.0 (TID 520). 9262 bytes result sent to driver
[2025-07-19T20:48:11.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 527) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 184.0 in stage 3.0 (TID 527)
[2025-07-19T20:48:11.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 520) in 111 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:48:11.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f93db32
[2025-07-19T20:48:11.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.1.delta.1f153eed-cd6d-4670-a8eb-be038f52f4b0.TID519.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta
[2025-07-19T20:48:11.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/1.delta
[2025-07-19T20:48:11.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 519, attempt 0, stage 3.0)
[2025-07-19T20:48:11.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182] for update
[2025-07-19T20:48:11.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.1.delta.dec7d412-94fb-47dc-b995-067fa85f6832.TID523.tmp
[2025-07-19T20:48:11.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.1.delta.58db7017-1d9f-485c-a915-15fda1abf513.TID524.tmp
[2025-07-19T20:48:11.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 169 (task 519, attempt 0, stage 3.0)
[2025-07-19T20:48:11.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@165123d9
[2025-07-19T20:48:11.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 169.0 in stage 3.0 (TID 519). 9257 bytes result sent to driver
[2025-07-19T20:48:11.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183] for update
[2025-07-19T20:48:11.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.1.delta.958e8005-1e2e-42da-a602-b44ed291c5c0.TID521.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/1.delta
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 528) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 519) in 137 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 185.0 in stage 3.0 (TID 528)
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 521, attempt 0, stage 3.0)
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.1.delta.caf836b6-9481-4b35-8447-a58ebd3e2a5a.TID525.tmp
[2025-07-19T20:48:11.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ea23ca5
[2025-07-19T20:48:11.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184] for update
[2025-07-19T20:48:11.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.1.delta.f80e4fbf-12fa-47b0-b5de-4a79ce7c4693.TID526.tmp
[2025-07-19T20:48:11.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 175 (task 521, attempt 0, stage 3.0)
[2025-07-19T20:48:11.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 175.0 in stage 3.0 (TID 521). 9244 bytes result sent to driver
[2025-07-19T20:48:11.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 529) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 187.0 in stage 3.0 (TID 529)
[2025-07-19T20:48:11.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 521) in 123 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:48:11.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e6019ff
[2025-07-19T20:48:11.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185] for update
[2025-07-19T20:48:11.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:11.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.1.delta.f6357aed-403e-4619-a02c-22ba365e3f77.TID527.tmp
[2025-07-19T20:48:11.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.1.delta.7b5d9029-4a19-4a3d-8c5c-1d6d1c2145b9.TID522.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta
[2025-07-19T20:48:11.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/1.delta
[2025-07-19T20:48:11.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 522, attempt 0, stage 3.0)
[2025-07-19T20:48:11.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.1.delta.8f3be044-e2d2-476a-8d68-8fa222fb3223.TID528.tmp
[2025-07-19T20:48:11.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.1.delta.dec7d412-94fb-47dc-b995-067fa85f6832.TID523.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta
[2025-07-19T20:48:11.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/1.delta
[2025-07-19T20:48:11.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 523, attempt 0, stage 3.0)
[2025-07-19T20:48:11.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b4ba6ea
[2025-07-19T20:48:11.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187] for update
[2025-07-19T20:48:11.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.1.delta.caf836b6-9481-4b35-8447-a58ebd3e2a5a.TID525.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta
[2025-07-19T20:48:11.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/1.delta
[2025-07-19T20:48:11.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 525, attempt 0, stage 3.0)
[2025-07-19T20:48:11.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 176 (task 522, attempt 0, stage 3.0)
[2025-07-19T20:48:11.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.1.delta.58db7017-1d9f-485c-a915-15fda1abf513.TID524.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta
[2025-07-19T20:48:11.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/1.delta
[2025-07-19T20:48:11.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 176.0 in stage 3.0 (TID 522). 9303 bytes result sent to driver
[2025-07-19T20:48:11.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 530) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 524, attempt 0, stage 3.0)
[2025-07-19T20:48:11.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 188.0 in stage 3.0 (TID 530)
[2025-07-19T20:48:11.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 522) in 124 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:48:11.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 178 (task 523, attempt 0, stage 3.0)
[2025-07-19T20:48:11.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 178.0 in stage 3.0 (TID 523). 9264 bytes result sent to driver
[2025-07-19T20:48:11.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 531) (8b44f3d35cfa, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 191.0 in stage 3.0 (TID 531)
[2025-07-19T20:48:11.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 523) in 104 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:48:11.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.1.delta.9e120b88-7e44-4342-9350-ce570c78b25e.TID529.tmp
[2025-07-19T20:48:11.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ab027ff
[2025-07-19T20:48:11.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188] for update
[2025-07-19T20:48:11.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 182 (task 525, attempt 0, stage 3.0)
[2025-07-19T20:48:11.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 182.0 in stage 3.0 (TID 525). 9263 bytes result sent to driver
[2025-07-19T20:48:11.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 532) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:11.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 194.0 in stage 3.0 (TID 532)
[2025-07-19T20:48:11.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 525) in 99 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:48:11.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:11.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:11.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1597678d
[2025-07-19T20:48:11.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:11.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191] for update
[2025-07-19T20:48:11.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.1.delta.208b9034-90a5-470f-bcc1-0b22c1e89385.TID530.tmp
[2025-07-19T20:48:11.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:11.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.1.delta.f6357aed-403e-4619-a02c-22ba365e3f77.TID527.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta
[2025-07-19T20:48:11.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/1.delta
[2025-07-19T20:48:11.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6466d5a0
[2025-07-19T20:48:11.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Committed partition 179 (task 524, attempt 0, stage 3.0)
[2025-07-19T20:48:12.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 527, attempt 0, stage 3.0)
[2025-07-19T20:48:12.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Finished task 179.0 in stage 3.0 (TID 524). 9261 bytes result sent to driver
[2025-07-19T20:48:12.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194] for update
[2025-07-19T20:48:12.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 533) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO Executor: Running task 196.0 in stage 3.0 (TID 533)
[2025-07-19T20:48:12.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.1.delta.8f3be044-e2d2-476a-8d68-8fa222fb3223.TID528.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta
[2025-07-19T20:48:12.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 524) in 131 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:48:12.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:11 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/1.delta
[2025-07-19T20:48:12.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 528, attempt 0, stage 3.0)
[2025-07-19T20:48:12.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.1.delta.ecfab274-ca8b-4320-a252-0ee9dd0578fe.TID531.tmp
[2025-07-19T20:48:12.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.1.delta.f80e4fbf-12fa-47b0-b5de-4a79ce7c4693.TID526.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta
[2025-07-19T20:48:12.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/1.delta
[2025-07-19T20:48:12.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 184 (task 527, attempt 0, stage 3.0)
[2025-07-19T20:48:12.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@132704d1
[2025-07-19T20:48:12.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 526, attempt 0, stage 3.0)
[2025-07-19T20:48:12.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196] for update
[2025-07-19T20:48:12.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 184.0 in stage 3.0 (TID 527). 9248 bytes result sent to driver
[2025-07-19T20:48:12.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 534) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 197.0 in stage 3.0 (TID 534)
[2025-07-19T20:48:12.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.1.delta.5b0f57b7-09c7-44c5-a498-5d574b1d9d3b.TID532.tmp
[2025-07-19T20:48:12.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 527) in 120 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:48:12.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 185 (task 528, attempt 0, stage 3.0)
[2025-07-19T20:48:12.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 185.0 in stage 3.0 (TID 528). 9257 bytes result sent to driver
[2025-07-19T20:48:12.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 535) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 198.0 in stage 3.0 (TID 535)
[2025-07-19T20:48:12.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 528) in 112 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:48:12.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:12.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 183 (task 526, attempt 0, stage 3.0)
[2025-07-19T20:48:12.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5286c2b5
[2025-07-19T20:48:12.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 183.0 in stage 3.0 (TID 526). 9248 bytes result sent to driver
[2025-07-19T20:48:12.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197] for update
[2025-07-19T20:48:12.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 536) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 199.0 in stage 3.0 (TID 536)
[2025-07-19T20:48:12.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 526) in 147 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:48:12.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.1.delta.767a498b-48f8-4fb7-bb46-97c51e550abe.TID533.tmp
[2025-07-19T20:48:12.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@625219cc
[2025-07-19T20:48:12.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198] for update
[2025-07-19T20:48:12.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.1.delta.9e120b88-7e44-4342-9350-ce570c78b25e.TID529.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta
[2025-07-19T20:48:12.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/1.delta
[2025-07-19T20:48:12.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 529, attempt 0, stage 3.0)
[2025-07-19T20:48:12.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@297fac6f
[2025-07-19T20:48:12.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.1.delta.ecfab274-ca8b-4320-a252-0ee9dd0578fe.TID531.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta
[2025-07-19T20:48:12.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/1.delta
[2025-07-19T20:48:12.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199] for update
[2025-07-19T20:48:12.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 531, attempt 0, stage 3.0)
[2025-07-19T20:48:12.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.1.delta.208b9034-90a5-470f-bcc1-0b22c1e89385.TID530.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta
[2025-07-19T20:48:12.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/1.delta
[2025-07-19T20:48:12.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 530, attempt 0, stage 3.0)
[2025-07-19T20:48:12.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.1.delta.e13d2801-5848-475f-964c-25ba2bf2f819.TID534.tmp
[2025-07-19T20:48:12.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.1.delta.398c4f91-ed68-49a2-9a15-0fa072856129.TID535.tmp
[2025-07-19T20:48:12.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 187 (task 529, attempt 0, stage 3.0)
[2025-07-19T20:48:12.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.1.delta.5b0f57b7-09c7-44c5-a498-5d574b1d9d3b.TID532.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta
[2025-07-19T20:48:12.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/1.delta
[2025-07-19T20:48:12.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 532, attempt 0, stage 3.0)
[2025-07-19T20:48:12.073+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 187.0 in stage 3.0 (TID 529). 9343 bytes result sent to driver
[2025-07-19T20:48:12.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 537) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 537)
[2025-07-19T20:48:12.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.1.delta.1f4987f3-f14f-4a4f-815d-77621372c518.TID536.tmp
[2025-07-19T20:48:12.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 529) in 147 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:48:12.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 188 (task 530, attempt 0, stage 3.0)
[2025-07-19T20:48:12.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 188.0 in stage 3.0 (TID 530). 9300 bytes result sent to driver
[2025-07-19T20:48:12.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 538) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 3.0 in stage 3.0 (TID 538)
[2025-07-19T20:48:12.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 191 (task 531, attempt 0, stage 3.0)
[2025-07-19T20:48:12.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 191.0 in stage 3.0 (TID 531). 9306 bytes result sent to driver
[2025-07-19T20:48:12.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 539) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 4.0 in stage 3.0 (TID 539)
[2025-07-19T20:48:12.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 530) in 117 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:48:12.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 531) in 110 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:48:12.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 194 (task 532, attempt 0, stage 3.0)
[2025-07-19T20:48:12.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 194.0 in stage 3.0 (TID 532). 9336 bytes result sent to driver
[2025-07-19T20:48:12.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 540) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 9.0 in stage 3.0 (TID 540)
[2025-07-19T20:48:12.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 532) in 112 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:48:12.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.1.delta.767a498b-48f8-4fb7-bb46-97c51e550abe.TID533.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta
[2025-07-19T20:48:12.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/1.delta
[2025-07-19T20:48:12.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 533, attempt 0, stage 3.0)
[2025-07-19T20:48:12.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/.schema.a4a3dfa8-de46-49ec-a86f-11de854b371e.TID537.tmp
[2025-07-19T20:48:12.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.1.delta.e13d2801-5848-475f-964c-25ba2bf2f819.TID534.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta
[2025-07-19T20:48:12.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/1.delta
[2025-07-19T20:48:12.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 534, attempt 0, stage 3.0)
[2025-07-19T20:48:12.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 196 (task 533, attempt 0, stage 3.0)
[2025-07-19T20:48:12.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.1.delta.398c4f91-ed68-49a2-9a15-0fa072856129.TID535.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta
[2025-07-19T20:48:12.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/1.delta
[2025-07-19T20:48:12.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 196.0 in stage 3.0 (TID 533). 9300 bytes result sent to driver
[2025-07-19T20:48:12.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 535, attempt 0, stage 3.0)
[2025-07-19T20:48:12.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 541) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 21.0 in stage 3.0 (TID 541)
[2025-07-19T20:48:12.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 533) in 110 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:48:12.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.1.delta.1f4987f3-f14f-4a4f-815d-77621372c518.TID536.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta
[2025-07-19T20:48:12.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/1.delta
[2025-07-19T20:48:12.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 536, attempt 0, stage 3.0)
[2025-07-19T20:48:12.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 197 (task 534, attempt 0, stage 3.0)
[2025-07-19T20:48:12.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:12.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 197.0 in stage 3.0 (TID 534). 9296 bytes result sent to driver
[2025-07-19T20:48:12.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 542) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 23.0 in stage 3.0 (TID 542)
[2025-07-19T20:48:12.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 534) in 106 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:48:12.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 198 (task 535, attempt 0, stage 3.0)
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/.schema.a4a3dfa8-de46-49ec-a86f-11de854b371e.TID537.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/_metadata/schema
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 198.0 in stage 3.0 (TID 535). 9302 bytes result sent to driver
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f46e3ac
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 543) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 25.0 in stage 3.0 (TID 543)
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0] for update
[2025-07-19T20:48:12.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 535) in 101 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:48:12.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 199 (task 536, attempt 0, stage 3.0)
[2025-07-19T20:48:12.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 199.0 in stage 3.0 (TID 536). 9320 bytes result sent to driver
[2025-07-19T20:48:12.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 544) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 536) in 96 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:48:12.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 37.0 in stage 3.0 (TID 544)
[2025-07-19T20:48:12.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49ad77ab
[2025-07-19T20:48:12.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23] for update
[2025-07-19T20:48:12.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.1.delta.503ccc76-8fc3-4ad3-bea8-0cf21d4fefb3.TID537.tmp
[2025-07-19T20:48:12.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b314fcb
[2025-07-19T20:48:12.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21] for update
[2025-07-19T20:48:12.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@455e7a87
[2025-07-19T20:48:12.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.1.delta.424ea4c9-3361-4d63-9e60-20a3c8604f5e.TID542.tmp
[2025-07-19T20:48:12.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9] for update
[2025-07-19T20:48:12.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a1131d
[2025-07-19T20:48:12.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4] for update
[2025-07-19T20:48:12.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.1.delta.a281f2d0-44dc-460f-85e9-a79ee5b85cf7.TID541.tmp
[2025-07-19T20:48:12.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.1.delta.830ee770-62ba-4a85-835f-b9b188e0231a.TID540.tmp
[2025-07-19T20:48:12.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46f919c3
[2025-07-19T20:48:12.158+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3] for update
[2025-07-19T20:48:12.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.1.delta.996e4441-a05e-4780-af3c-9c67322b5ca6.TID539.tmp
[2025-07-19T20:48:12.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41f797e2
[2025-07-19T20:48:12.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37] for update
[2025-07-19T20:48:12.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.1.delta.4054eab2-7784-4494-8991-5407da7fa694.TID538.tmp
[2025-07-19T20:48:12.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a02de98
[2025-07-19T20:48:12.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25] for update
[2025-07-19T20:48:12.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.1.delta.dda7d4de-55ed-418f-95a2-31250e413a35.TID544.tmp
[2025-07-19T20:48:12.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.1.delta.424ea4c9-3361-4d63-9e60-20a3c8604f5e.TID542.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta
[2025-07-19T20:48:12.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/1.delta
[2025-07-19T20:48:12.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 542, attempt 0, stage 3.0)
[2025-07-19T20:48:12.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.1.delta.503ccc76-8fc3-4ad3-bea8-0cf21d4fefb3.TID537.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta
[2025-07-19T20:48:12.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/1.delta
[2025-07-19T20:48:12.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 537, attempt 0, stage 3.0)
[2025-07-19T20:48:12.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 23 (task 542, attempt 0, stage 3.0)
[2025-07-19T20:48:12.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 23.0 in stage 3.0 (TID 542). 6243 bytes result sent to driver
[2025-07-19T20:48:12.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 545) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 0 (task 537, attempt 0, stage 3.0)
[2025-07-19T20:48:12.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 38.0 in stage 3.0 (TID 545)
[2025-07-19T20:48:12.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 537). 6243 bytes result sent to driver
[2025-07-19T20:48:12.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 542) in 67 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:48:12.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 546) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 537) in 117 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:48:12.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 43.0 in stage 3.0 (TID 546)
[2025-07-19T20:48:12.195+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.1.delta.a281f2d0-44dc-460f-85e9-a79ee5b85cf7.TID541.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta
[2025-07-19T20:48:12.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/1.delta
[2025-07-19T20:48:12.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 541, attempt 0, stage 3.0)
[2025-07-19T20:48:12.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bfa9c55
[2025-07-19T20:48:12.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:12.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38] for update
[2025-07-19T20:48:12.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.1.delta.ffc76139-42b2-40f8-a010-279f4b96cb69.TID543.tmp
[2025-07-19T20:48:12.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 21 (task 541, attempt 0, stage 3.0)
[2025-07-19T20:48:12.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.1.delta.830ee770-62ba-4a85-835f-b9b188e0231a.TID540.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta
[2025-07-19T20:48:12.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/1.delta
[2025-07-19T20:48:12.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 21.0 in stage 3.0 (TID 541). 6243 bytes result sent to driver
[2025-07-19T20:48:12.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 547) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 541) in 93 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:48:12.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 540, attempt 0, stage 3.0)
[2025-07-19T20:48:12.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 45.0 in stage 3.0 (TID 547)
[2025-07-19T20:48:12.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 9 (task 540, attempt 0, stage 3.0)
[2025-07-19T20:48:12.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 9.0 in stage 3.0 (TID 540). 6243 bytes result sent to driver
[2025-07-19T20:48:12.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 548) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69c42990
[2025-07-19T20:48:12.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 50.0 in stage 3.0 (TID 548)
[2025-07-19T20:48:12.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 540) in 119 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:48:12.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.1.delta.bd7f972a-1ec0-466b-a782-c00655643891.TID545.tmp
[2025-07-19T20:48:12.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43] for update
[2025-07-19T20:48:12.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23e879f1
[2025-07-19T20:48:12.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45] for update
[2025-07-19T20:48:12.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.1.delta.4054eab2-7784-4494-8991-5407da7fa694.TID538.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta
[2025-07-19T20:48:12.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/1.delta
[2025-07-19T20:48:12.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.1.delta.996e4441-a05e-4780-af3c-9c67322b5ca6.TID539.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta
[2025-07-19T20:48:12.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/1.delta
[2025-07-19T20:48:12.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 539, attempt 0, stage 3.0)
[2025-07-19T20:48:12.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 538, attempt 0, stage 3.0)
[2025-07-19T20:48:12.223+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 4 (task 539, attempt 0, stage 3.0)
[2025-07-19T20:48:12.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 4.0 in stage 3.0 (TID 539). 6243 bytes result sent to driver
[2025-07-19T20:48:12.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 549) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.1.delta.dda7d4de-55ed-418f-95a2-31250e413a35.TID544.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta
[2025-07-19T20:48:12.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/1.delta
[2025-07-19T20:48:12.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 544, attempt 0, stage 3.0)
[2025-07-19T20:48:12.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 3 (task 538, attempt 0, stage 3.0)
[2025-07-19T20:48:12.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 52.0 in stage 3.0 (TID 549)
[2025-07-19T20:48:12.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.1.delta.b6976a7e-f3d1-41a1-a740-dc9d368faa4f.TID546.tmp
[2025-07-19T20:48:12.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 539) in 148 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:48:12.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 3.0 in stage 3.0 (TID 538). 6243 bytes result sent to driver
[2025-07-19T20:48:12.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 550) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 53.0 in stage 3.0 (TID 550)
[2025-07-19T20:48:12.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.235+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.235+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 37 (task 544, attempt 0, stage 3.0)
[2025-07-19T20:48:12.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 538) in 155 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:48:12.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 37.0 in stage 3.0 (TID 544). 6200 bytes result sent to driver
[2025-07-19T20:48:12.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.1.delta.029d4ab8-4e51-448c-b470-adbbcc232590.TID547.tmp
[2025-07-19T20:48:12.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 551) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@337ab452
[2025-07-19T20:48:12.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 56.0 in stage 3.0 (TID 551)
[2025-07-19T20:48:12.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 544) in 106 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:48:12.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50] for update
[2025-07-19T20:48:12.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.1.delta.ffc76139-42b2-40f8-a010-279f4b96cb69.TID543.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta
[2025-07-19T20:48:12.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/1.delta
[2025-07-19T20:48:12.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 543, attempt 0, stage 3.0)
[2025-07-19T20:48:12.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b0a7977
[2025-07-19T20:48:12.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56] for update
[2025-07-19T20:48:12.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 25 (task 543, attempt 0, stage 3.0)
[2025-07-19T20:48:12.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 25.0 in stage 3.0 (TID 543). 6243 bytes result sent to driver
[2025-07-19T20:48:12.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71c70804
[2025-07-19T20:48:12.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.1.delta.c8171166-93f8-49f5-a262-c62876c60a4c.TID548.tmp
[2025-07-19T20:48:12.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 552) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 59.0 in stage 3.0 (TID 552)
[2025-07-19T20:48:12.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52] for update
[2025-07-19T20:48:12.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 543) in 128 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:48:12.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dcdd18e
[2025-07-19T20:48:12.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53] for update
[2025-07-19T20:48:12.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.1.delta.bd7f972a-1ec0-466b-a782-c00655643891.TID545.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta
[2025-07-19T20:48:12.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/1.delta
[2025-07-19T20:48:12.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 545, attempt 0, stage 3.0)
[2025-07-19T20:48:12.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.1.delta.3b4e5030-ccde-4775-99b6-250e484c5e33.TID551.tmp
[2025-07-19T20:48:12.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 38 (task 545, attempt 0, stage 3.0)
[2025-07-19T20:48:12.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 38.0 in stage 3.0 (TID 545). 6200 bytes result sent to driver
[2025-07-19T20:48:12.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 553) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 545) in 83 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:48:12.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 61.0 in stage 3.0 (TID 553)
[2025-07-19T20:48:12.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@90e717b
[2025-07-19T20:48:12.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59] for update
[2025-07-19T20:48:12.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:12.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.1.delta.ece10e6b-62d2-4c67-81b9-1300bf0bd88d.TID550.tmp
[2025-07-19T20:48:12.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.1.delta.924a7493-ce57-425a-a956-9cb171eeac12.TID549.tmp
[2025-07-19T20:48:12.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6450f349
[2025-07-19T20:48:12.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.1.delta.e72c3e7b-bfca-486d-a511-97f988414211.TID552.tmp
[2025-07-19T20:48:12.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61] for update
[2025-07-19T20:48:12.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.1.delta.029d4ab8-4e51-448c-b470-adbbcc232590.TID547.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta
[2025-07-19T20:48:12.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/1.delta
[2025-07-19T20:48:12.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 547, attempt 0, stage 3.0)
[2025-07-19T20:48:12.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.1.delta.b6976a7e-f3d1-41a1-a740-dc9d368faa4f.TID546.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta
[2025-07-19T20:48:12.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/1.delta
[2025-07-19T20:48:12.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 546, attempt 0, stage 3.0)
[2025-07-19T20:48:12.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 45 (task 547, attempt 0, stage 3.0)
[2025-07-19T20:48:12.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 45.0 in stage 3.0 (TID 547). 6200 bytes result sent to driver
[2025-07-19T20:48:12.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 43 (task 546, attempt 0, stage 3.0)
[2025-07-19T20:48:12.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 554) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 65.0 in stage 3.0 (TID 554)
[2025-07-19T20:48:12.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 547) in 94 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:48:12.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 43.0 in stage 3.0 (TID 546). 6200 bytes result sent to driver
[2025-07-19T20:48:12.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 555) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 546) in 109 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:48:12.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 67.0 in stage 3.0 (TID 555)
[2025-07-19T20:48:12.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.1.delta.d0e65478-51e0-4957-8f1d-d912cce22c98.TID553.tmp
[2025-07-19T20:48:12.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.1.delta.c8171166-93f8-49f5-a262-c62876c60a4c.TID548.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta
[2025-07-19T20:48:12.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/1.delta
[2025-07-19T20:48:12.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 548, attempt 0, stage 3.0)
[2025-07-19T20:48:12.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b714c82
[2025-07-19T20:48:12.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65] for update
[2025-07-19T20:48:12.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 50 (task 548, attempt 0, stage 3.0)
[2025-07-19T20:48:12.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 50.0 in stage 3.0 (TID 548). 6200 bytes result sent to driver
[2025-07-19T20:48:12.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 556) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 548) in 104 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:48:12.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 69.0 in stage 3.0 (TID 556)
[2025-07-19T20:48:12.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.1.delta.3b4e5030-ccde-4775-99b6-250e484c5e33.TID551.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta
[2025-07-19T20:48:12.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/1.delta
[2025-07-19T20:48:12.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 551, attempt 0, stage 3.0)
[2025-07-19T20:48:12.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64bc0bb
[2025-07-19T20:48:12.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67] for update
[2025-07-19T20:48:12.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.1.delta.aa696c83-00b5-4241-91fc-03303e734a2f.TID554.tmp
[2025-07-19T20:48:12.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.1.delta.924a7493-ce57-425a-a956-9cb171eeac12.TID549.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta
[2025-07-19T20:48:12.327+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/1.delta
[2025-07-19T20:48:12.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 549, attempt 0, stage 3.0)
[2025-07-19T20:48:12.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 52 (task 549, attempt 0, stage 3.0)
[2025-07-19T20:48:12.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 52.0 in stage 3.0 (TID 549). 6200 bytes result sent to driver
[2025-07-19T20:48:12.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@242c6fa0
[2025-07-19T20:48:12.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 557) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 56 (task 551, attempt 0, stage 3.0)
[2025-07-19T20:48:12.336+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 549) in 105 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:48:12.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 70.0 in stage 3.0 (TID 557)
[2025-07-19T20:48:12.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 56.0 in stage 3.0 (TID 551). 6200 bytes result sent to driver
[2025-07-19T20:48:12.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69] for update
[2025-07-19T20:48:12.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 558) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 72.0 in stage 3.0 (TID 558)
[2025-07-19T20:48:12.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 551) in 99 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:48:12.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.1.delta.e72c3e7b-bfca-486d-a511-97f988414211.TID552.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta
[2025-07-19T20:48:12.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/1.delta
[2025-07-19T20:48:12.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 552, attempt 0, stage 3.0)
[2025-07-19T20:48:12.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.1.delta.ece10e6b-62d2-4c67-81b9-1300bf0bd88d.TID550.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta
[2025-07-19T20:48:12.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/1.delta
[2025-07-19T20:48:12.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 550, attempt 0, stage 3.0)
[2025-07-19T20:48:12.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 59 (task 552, attempt 0, stage 3.0)
[2025-07-19T20:48:12.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 59.0 in stage 3.0 (TID 552). 6200 bytes result sent to driver
[2025-07-19T20:48:12.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 559) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 78.0 in stage 3.0 (TID 559)
[2025-07-19T20:48:12.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 552) in 97 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:48:12.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 53 (task 550, attempt 0, stage 3.0)
[2025-07-19T20:48:12.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 53.0 in stage 3.0 (TID 550). 6200 bytes result sent to driver
[2025-07-19T20:48:12.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.1.delta.94124b44-5dfe-4d3a-b891-946b73c099b9.TID555.tmp
[2025-07-19T20:48:12.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 560) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 81.0 in stage 3.0 (TID 560)
[2025-07-19T20:48:12.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 550) in 134 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:48:12.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66e08ac4
[2025-07-19T20:48:12.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70] for update
[2025-07-19T20:48:12.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.1.delta.b25f15e9-62ff-4b4e-9a27-364b30c5a49e.TID556.tmp
[2025-07-19T20:48:12.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72e82e2a
[2025-07-19T20:48:12.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78] for update
[2025-07-19T20:48:12.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.1.delta.d0e65478-51e0-4957-8f1d-d912cce22c98.TID553.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta
[2025-07-19T20:48:12.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/1.delta
[2025-07-19T20:48:12.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 553, attempt 0, stage 3.0)
[2025-07-19T20:48:12.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@234dd6ec
[2025-07-19T20:48:12.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.1.delta.aa696c83-00b5-4241-91fc-03303e734a2f.TID554.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta
[2025-07-19T20:48:12.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/1.delta
[2025-07-19T20:48:12.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72] for update
[2025-07-19T20:48:12.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 554, attempt 0, stage 3.0)
[2025-07-19T20:48:12.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 61 (task 553, attempt 0, stage 3.0)
[2025-07-19T20:48:12.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.1.delta.b35a25d3-cf4f-42ff-80b3-079da77e752f.TID557.tmp
[2025-07-19T20:48:12.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 61.0 in stage 3.0 (TID 553). 6200 bytes result sent to driver
[2025-07-19T20:48:12.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34829ce
[2025-07-19T20:48:12.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 561) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81] for update
[2025-07-19T20:48:12.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 84.0 in stage 3.0 (TID 561)
[2025-07-19T20:48:12.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 65 (task 554, attempt 0, stage 3.0)
[2025-07-19T20:48:12.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 553) in 147 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:48:12.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 65.0 in stage 3.0 (TID 554). 6200 bytes result sent to driver
[2025-07-19T20:48:12.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.1.delta.4e3cf37c-0324-4446-9d2f-4b9dfded9bb7.TID559.tmp
[2025-07-19T20:48:12.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 562) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 85.0 in stage 3.0 (TID 562)
[2025-07-19T20:48:12.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 554) in 129 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:48:12.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.1.delta.04be04a9-cd5a-42f7-8c19-2a37dc5bfca1.TID558.tmp
[2025-07-19T20:48:12.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7321ade3
[2025-07-19T20:48:12.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.1.delta.94124b44-5dfe-4d3a-b891-946b73c099b9.TID555.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta
[2025-07-19T20:48:12.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/1.delta
[2025-07-19T20:48:12.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 555, attempt 0, stage 3.0)
[2025-07-19T20:48:12.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84] for update
[2025-07-19T20:48:12.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.1.delta.90a2fad7-8fde-48ed-9040-6fc9656d4608.TID560.tmp
[2025-07-19T20:48:12.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 67 (task 555, attempt 0, stage 3.0)
[2025-07-19T20:48:12.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 67.0 in stage 3.0 (TID 555). 6243 bytes result sent to driver
[2025-07-19T20:48:12.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 563) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41a769c0
[2025-07-19T20:48:12.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 555) in 147 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:48:12.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85] for update
[2025-07-19T20:48:12.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 89.0 in stage 3.0 (TID 563)
[2025-07-19T20:48:12.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.1.delta.56737b57-9029-4aeb-a2b8-9966b8e5a838.TID561.tmp
[2025-07-19T20:48:12.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19789545
[2025-07-19T20:48:12.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89] for update
[2025-07-19T20:48:12.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.1.delta.c210ba52-ebc8-428c-9d49-7d326d7e0aba.TID562.tmp
[2025-07-19T20:48:12.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.1.delta.b25f15e9-62ff-4b4e-9a27-364b30c5a49e.TID556.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta
[2025-07-19T20:48:12.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/1.delta
[2025-07-19T20:48:12.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 556, attempt 0, stage 3.0)
[2025-07-19T20:48:12.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 69 (task 556, attempt 0, stage 3.0)
[2025-07-19T20:48:12.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.1.delta.b35a25d3-cf4f-42ff-80b3-079da77e752f.TID557.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta
[2025-07-19T20:48:12.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/1.delta
[2025-07-19T20:48:12.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 557, attempt 0, stage 3.0)
[2025-07-19T20:48:12.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 69.0 in stage 3.0 (TID 556). 6200 bytes result sent to driver
[2025-07-19T20:48:12.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.1.delta.91d2cecc-24b2-4f87-bd11-03d492c66aaf.TID563.tmp
[2025-07-19T20:48:12.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 564) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 91.0 in stage 3.0 (TID 564)
[2025-07-19T20:48:12.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.1.delta.4e3cf37c-0324-4446-9d2f-4b9dfded9bb7.TID559.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta
[2025-07-19T20:48:12.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/1.delta
[2025-07-19T20:48:12.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 559, attempt 0, stage 3.0)
[2025-07-19T20:48:12.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 556) in 162 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:48:12.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 78 (task 559, attempt 0, stage 3.0)
[2025-07-19T20:48:12.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 78.0 in stage 3.0 (TID 559). 6200 bytes result sent to driver
[2025-07-19T20:48:12.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 70 (task 557, attempt 0, stage 3.0)
[2025-07-19T20:48:12.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 565) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68e53164
[2025-07-19T20:48:12.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 94.0 in stage 3.0 (TID 565)
[2025-07-19T20:48:12.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.1.delta.90a2fad7-8fde-48ed-9040-6fc9656d4608.TID560.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta
[2025-07-19T20:48:12.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 70.0 in stage 3.0 (TID 557). 6243 bytes result sent to driver
[2025-07-19T20:48:12.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/1.delta
[2025-07-19T20:48:12.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91] for update
[2025-07-19T20:48:12.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.1.delta.04be04a9-cd5a-42f7-8c19-2a37dc5bfca1.TID558.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta
[2025-07-19T20:48:12.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/1.delta
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 559) in 138 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 560, attempt 0, stage 3.0)
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 558, attempt 0, stage 3.0)
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 566) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 557) in 161 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:48:12.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 95.0 in stage 3.0 (TID 566)
[2025-07-19T20:48:12.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 81 (task 560, attempt 0, stage 3.0)
[2025-07-19T20:48:12.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 72 (task 558, attempt 0, stage 3.0)
[2025-07-19T20:48:12.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 72.0 in stage 3.0 (TID 558). 6200 bytes result sent to driver
[2025-07-19T20:48:12.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 567) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 81.0 in stage 3.0 (TID 560). 6200 bytes result sent to driver
[2025-07-19T20:48:12.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 98.0 in stage 3.0 (TID 567)
[2025-07-19T20:48:12.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 568) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 101.0 in stage 3.0 (TID 568)
[2025-07-19T20:48:12.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 560) in 140 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:48:12.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 558) in 167 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:48:12.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e347879
[2025-07-19T20:48:12.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94] for update
[2025-07-19T20:48:12.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.1.delta.c210ba52-ebc8-428c-9d49-7d326d7e0aba.TID562.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta
[2025-07-19T20:48:12.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/1.delta
[2025-07-19T20:48:12.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 562, attempt 0, stage 3.0)
[2025-07-19T20:48:12.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 85 (task 562, attempt 0, stage 3.0)
[2025-07-19T20:48:12.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e4538e
[2025-07-19T20:48:12.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 85.0 in stage 3.0 (TID 562). 6200 bytes result sent to driver
[2025-07-19T20:48:12.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98] for update
[2025-07-19T20:48:12.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.1.delta.bfb7f04d-1c95-4db2-8d50-168f50094bac.TID564.tmp
[2025-07-19T20:48:12.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 569) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 562) in 105 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:48:12.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 104.0 in stage 3.0 (TID 569)
[2025-07-19T20:48:12.543+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.1.delta.56737b57-9029-4aeb-a2b8-9966b8e5a838.TID561.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta
[2025-07-19T20:48:12.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/1.delta
[2025-07-19T20:48:12.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.1.delta.44c6647e-1c9d-45fa-9583-2b3a1b982a90.TID565.tmp
[2025-07-19T20:48:12.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 561, attempt 0, stage 3.0)
[2025-07-19T20:48:12.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.1.delta.91d2cecc-24b2-4f87-bd11-03d492c66aaf.TID563.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta
[2025-07-19T20:48:12.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/1.delta
[2025-07-19T20:48:12.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ca739a
[2025-07-19T20:48:12.555+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 563, attempt 0, stage 3.0)
[2025-07-19T20:48:12.555+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 84 (task 561, attempt 0, stage 3.0)
[2025-07-19T20:48:12.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 89 (task 563, attempt 0, stage 3.0)
[2025-07-19T20:48:12.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.1.delta.d60b7aa8-7d8b-49e7-ada7-9833b7fb2fc0.TID567.tmp
[2025-07-19T20:48:12.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101] for update
[2025-07-19T20:48:12.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 89.0 in stage 3.0 (TID 563). 6243 bytes result sent to driver
[2025-07-19T20:48:12.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 84.0 in stage 3.0 (TID 561). 6200 bytes result sent to driver
[2025-07-19T20:48:12.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 570) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 107.0 in stage 3.0 (TID 570)
[2025-07-19T20:48:12.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 571) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 563) in 111 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:48:12.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 561) in 142 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:48:12.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 108.0 in stage 3.0 (TID 571)
[2025-07-19T20:48:12.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@708388
[2025-07-19T20:48:12.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95] for update
[2025-07-19T20:48:12.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.1.delta.c05e4550-0720-40b4-aa94-3a41602b9922.TID568.tmp
[2025-07-19T20:48:12.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1607162e
[2025-07-19T20:48:12.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107] for update
[2025-07-19T20:48:12.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45879e05
[2025-07-19T20:48:12.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108] for update
[2025-07-19T20:48:12.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.1.delta.52e69d01-f3f8-47d4-809f-93db8ab35886.TID570.tmp
[2025-07-19T20:48:12.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.1.delta.ca9e273a-7e12-4e75-98b0-74c1bce2efd2.TID566.tmp
[2025-07-19T20:48:12.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.1.delta.44c6647e-1c9d-45fa-9583-2b3a1b982a90.TID565.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta
[2025-07-19T20:48:12.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/1.delta
[2025-07-19T20:48:12.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 565, attempt 0, stage 3.0)
[2025-07-19T20:48:12.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2117b3ca
[2025-07-19T20:48:12.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104] for update
[2025-07-19T20:48:12.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 94 (task 565, attempt 0, stage 3.0)
[2025-07-19T20:48:12.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.1.delta.bfb7f04d-1c95-4db2-8d50-168f50094bac.TID564.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta
[2025-07-19T20:48:12.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/1.delta
[2025-07-19T20:48:12.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 94.0 in stage 3.0 (TID 565). 6200 bytes result sent to driver
[2025-07-19T20:48:12.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 572) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 115.0 in stage 3.0 (TID 572)
[2025-07-19T20:48:12.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 565) in 108 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:48:12.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 564, attempt 0, stage 3.0)
[2025-07-19T20:48:12.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.1.delta.8b71ac32-7e63-486e-a051-71739f240e15.TID571.tmp
[2025-07-19T20:48:12.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:12.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 91 (task 564, attempt 0, stage 3.0)
[2025-07-19T20:48:12.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 91.0 in stage 3.0 (TID 564). 6200 bytes result sent to driver
[2025-07-19T20:48:12.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 573) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 121.0 in stage 3.0 (TID 573)
[2025-07-19T20:48:12.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 564) in 121 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:48:12.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.1.delta.d60b7aa8-7d8b-49e7-ada7-9833b7fb2fc0.TID567.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta
[2025-07-19T20:48:12.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/1.delta
[2025-07-19T20:48:12.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 567, attempt 0, stage 3.0)
[2025-07-19T20:48:12.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.1.delta.1ebe0ac5-798a-40a3-921e-231eeebf44f9.TID569.tmp
[2025-07-19T20:48:12.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6384c6c3
[2025-07-19T20:48:12.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115] for update
[2025-07-19T20:48:12.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 98 (task 567, attempt 0, stage 3.0)
[2025-07-19T20:48:12.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54df9100
[2025-07-19T20:48:12.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121] for update
[2025-07-19T20:48:12.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 98.0 in stage 3.0 (TID 567). 6200 bytes result sent to driver
[2025-07-19T20:48:12.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 574) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.1.delta.045b4baf-f645-41b6-b539-8c15f5f7809a.TID572.tmp
[2025-07-19T20:48:12.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 567) in 120 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:48:12.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 122.0 in stage 3.0 (TID 574)
[2025-07-19T20:48:12.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.1.delta.c05e4550-0720-40b4-aa94-3a41602b9922.TID568.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta
[2025-07-19T20:48:12.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/1.delta
[2025-07-19T20:48:12.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 568, attempt 0, stage 3.0)
[2025-07-19T20:48:12.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.1.delta.300a337a-23c9-47b4-b91c-0a7e43a19271.TID573.tmp
[2025-07-19T20:48:12.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 101 (task 568, attempt 0, stage 3.0)
[2025-07-19T20:48:12.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9052800
[2025-07-19T20:48:12.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122] for update
[2025-07-19T20:48:12.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 101.0 in stage 3.0 (TID 568). 6200 bytes result sent to driver
[2025-07-19T20:48:12.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 575) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 568) in 135 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:48:12.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 123.0 in stage 3.0 (TID 575)
[2025-07-19T20:48:12.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.1.delta.52e69d01-f3f8-47d4-809f-93db8ab35886.TID570.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta
[2025-07-19T20:48:12.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/1.delta
[2025-07-19T20:48:12.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 570, attempt 0, stage 3.0)
[2025-07-19T20:48:12.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.1.delta.ca9e273a-7e12-4e75-98b0-74c1bce2efd2.TID566.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta
[2025-07-19T20:48:12.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/1.delta
[2025-07-19T20:48:12.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 566, attempt 0, stage 3.0)
[2025-07-19T20:48:12.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26224477
[2025-07-19T20:48:12.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.1.delta.b14e1d32-8739-4c79-bfb1-cf8f30494fd6.TID574.tmp
[2025-07-19T20:48:12.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.1.delta.8b71ac32-7e63-486e-a051-71739f240e15.TID571.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta
[2025-07-19T20:48:12.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/1.delta
[2025-07-19T20:48:12.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 571, attempt 0, stage 3.0)
[2025-07-19T20:48:12.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 107 (task 570, attempt 0, stage 3.0)
[2025-07-19T20:48:12.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 107.0 in stage 3.0 (TID 570). 6200 bytes result sent to driver
[2025-07-19T20:48:12.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.1.delta.1ebe0ac5-798a-40a3-921e-231eeebf44f9.TID569.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta
[2025-07-19T20:48:12.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/1.delta
[2025-07-19T20:48:12.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 95 (task 566, attempt 0, stage 3.0)
[2025-07-19T20:48:12.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 108 (task 571, attempt 0, stage 3.0)
[2025-07-19T20:48:12.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 95.0 in stage 3.0 (TID 566). 6200 bytes result sent to driver
[2025-07-19T20:48:12.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 576) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 108.0 in stage 3.0 (TID 571). 6200 bytes result sent to driver
[2025-07-19T20:48:12.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 569, attempt 0, stage 3.0)
[2025-07-19T20:48:12.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 570) in 104 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:48:12.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123] for update
[2025-07-19T20:48:12.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 577) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 578) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 566) in 163 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:48:12.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 133.0 in stage 3.0 (TID 578)
[2025-07-19T20:48:12.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 571) in 102 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:48:12.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 129.0 in stage 3.0 (TID 576)
[2025-07-19T20:48:12.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.1.delta.045b4baf-f645-41b6-b539-8c15f5f7809a.TID572.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/1.delta
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 132.0 in stage 3.0 (TID 577)
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 572, attempt 0, stage 3.0)
[2025-07-19T20:48:12.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8747ab5
[2025-07-19T20:48:12.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133] for update
[2025-07-19T20:48:12.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 115 (task 572, attempt 0, stage 3.0)
[2025-07-19T20:48:12.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 115.0 in stage 3.0 (TID 572). 6200 bytes result sent to driver
[2025-07-19T20:48:12.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 579) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 572) in 81 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:48:12.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 138.0 in stage 3.0 (TID 579)
[2025-07-19T20:48:12.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7abfda52
[2025-07-19T20:48:12.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132] for update
[2025-07-19T20:48:12.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 104 (task 569, attempt 0, stage 3.0)
[2025-07-19T20:48:12.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 104.0 in stage 3.0 (TID 569). 6200 bytes result sent to driver
[2025-07-19T20:48:12.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 580) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 569) in 156 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.1.delta.300a337a-23c9-47b4-b91c-0a7e43a19271.TID573.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/1.delta
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 573, attempt 0, stage 3.0)
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 139.0 in stage 3.0 (TID 580)
[2025-07-19T20:48:12.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.1.delta.358b3ff3-b8e3-4434-82f4-220b19ef4bcb.TID575.tmp
[2025-07-19T20:48:12.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.1.delta.bd88a5b6-55ea-47ef-be39-ebf0cb19f37c.TID578.tmp
[2025-07-19T20:48:12.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fccaa70
[2025-07-19T20:48:12.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.1.delta.b14e1d32-8739-4c79-bfb1-cf8f30494fd6.TID574.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta
[2025-07-19T20:48:12.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/1.delta
[2025-07-19T20:48:12.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129] for update
[2025-07-19T20:48:12.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.1.delta.931549ea-c7cc-48cd-a589-f1d8c610286b.TID577.tmp
[2025-07-19T20:48:12.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 574, attempt 0, stage 3.0)
[2025-07-19T20:48:12.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 122 (task 574, attempt 0, stage 3.0)
[2025-07-19T20:48:12.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 122.0 in stage 3.0 (TID 574). 6286 bytes result sent to driver
[2025-07-19T20:48:12.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 121 (task 573, attempt 0, stage 3.0)
[2025-07-19T20:48:12.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 121.0 in stage 3.0 (TID 573). 6243 bytes result sent to driver
[2025-07-19T20:48:12.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 581) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a05c0df
[2025-07-19T20:48:12.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 574) in 100 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:48:12.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 143.0 in stage 3.0 (TID 581)
[2025-07-19T20:48:12.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138] for update
[2025-07-19T20:48:12.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 573) in 124 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:48:12.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 582) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 146.0 in stage 3.0 (TID 582)
[2025-07-19T20:48:12.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.1.delta.827ce6c5-63a1-4833-b4e4-b4dfbad57d5d.TID576.tmp
[2025-07-19T20:48:12.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53971ff3
[2025-07-19T20:48:12.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139] for update
[2025-07-19T20:48:12.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.1.delta.4a12f763-d8c8-49f2-b77d-f34119b0898b.TID579.tmp
[2025-07-19T20:48:12.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.1.delta.358b3ff3-b8e3-4434-82f4-220b19ef4bcb.TID575.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta
[2025-07-19T20:48:12.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/1.delta
[2025-07-19T20:48:12.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 575, attempt 0, stage 3.0)
[2025-07-19T20:48:12.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.1.delta.103cbf18-499d-4132-af85-6b5938f6b574.TID580.tmp
[2025-07-19T20:48:12.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f45ed34
[2025-07-19T20:48:12.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143] for update
[2025-07-19T20:48:12.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.1.delta.bd88a5b6-55ea-47ef-be39-ebf0cb19f37c.TID578.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta
[2025-07-19T20:48:12.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/1.delta
[2025-07-19T20:48:12.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.1.delta.931549ea-c7cc-48cd-a589-f1d8c610286b.TID577.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta
[2025-07-19T20:48:12.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/1.delta
[2025-07-19T20:48:12.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@465081e9
[2025-07-19T20:48:12.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146] for update
[2025-07-19T20:48:12.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 578, attempt 0, stage 3.0)
[2025-07-19T20:48:12.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 577, attempt 0, stage 3.0)
[2025-07-19T20:48:12.800+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 123 (task 575, attempt 0, stage 3.0)
[2025-07-19T20:48:12.801+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 123.0 in stage 3.0 (TID 575). 6243 bytes result sent to driver
[2025-07-19T20:48:12.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 583) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 150.0 in stage 3.0 (TID 583)
[2025-07-19T20:48:12.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 575) in 173 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:48:12.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 133 (task 578, attempt 0, stage 3.0)
[2025-07-19T20:48:12.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 133.0 in stage 3.0 (TID 578). 6243 bytes result sent to driver
[2025-07-19T20:48:12.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 584) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.1.delta.ff93985e-1cda-41d3-ad19-249acfba7273.TID582.tmp
[2025-07-19T20:48:12.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 578) in 163 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:48:12.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:12.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 154.0 in stage 3.0 (TID 584)
[2025-07-19T20:48:12.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 132 (task 577, attempt 0, stage 3.0)
[2025-07-19T20:48:12.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 132.0 in stage 3.0 (TID 577). 6243 bytes result sent to driver
[2025-07-19T20:48:12.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 585) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 158.0 in stage 3.0 (TID 585)
[2025-07-19T20:48:12.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 577) in 169 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:48:12.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:12.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73ae310a
[2025-07-19T20:48:12.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.1.delta.cfff37ae-7207-45cf-a63b-728fad8c263b.TID581.tmp
[2025-07-19T20:48:12.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150] for update
[2025-07-19T20:48:12.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.1.delta.827ce6c5-63a1-4833-b4e4-b4dfbad57d5d.TID576.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta
[2025-07-19T20:48:12.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/1.delta
[2025-07-19T20:48:12.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.1.delta.4a12f763-d8c8-49f2-b77d-f34119b0898b.TID579.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta
[2025-07-19T20:48:12.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/1.delta
[2025-07-19T20:48:12.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 576, attempt 0, stage 3.0)
[2025-07-19T20:48:12.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 579, attempt 0, stage 3.0)
[2025-07-19T20:48:12.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b2b068a
[2025-07-19T20:48:12.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 138 (task 579, attempt 0, stage 3.0)
[2025-07-19T20:48:12.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 138.0 in stage 3.0 (TID 579). 6243 bytes result sent to driver
[2025-07-19T20:48:12.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 129 (task 576, attempt 0, stage 3.0)
[2025-07-19T20:48:12.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154] for update
[2025-07-19T20:48:12.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 129.0 in stage 3.0 (TID 576). 6243 bytes result sent to driver
[2025-07-19T20:48:12.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 586) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.1.delta.6b5bc7ba-3fa3-4033-a3d9-2758efb5e349.TID583.tmp
[2025-07-19T20:48:12.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 161.0 in stage 3.0 (TID 586)
[2025-07-19T20:48:12.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 587) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 576) in 212 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:48:12.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 579) in 197 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:48:12.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 163.0 in stage 3.0 (TID 587)
[2025-07-19T20:48:12.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.1.delta.103cbf18-499d-4132-af85-6b5938f6b574.TID580.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta
[2025-07-19T20:48:12.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/1.delta
[2025-07-19T20:48:12.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 580, attempt 0, stage 3.0)
[2025-07-19T20:48:12.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50df16be
[2025-07-19T20:48:12.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158] for update
[2025-07-19T20:48:12.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 139 (task 580, attempt 0, stage 3.0)
[2025-07-19T20:48:12.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 139.0 in stage 3.0 (TID 580). 6243 bytes result sent to driver
[2025-07-19T20:48:12.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 588) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 580) in 201 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:48:12.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 164.0 in stage 3.0 (TID 588)
[2025-07-19T20:48:12.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.1.delta.ff93985e-1cda-41d3-ad19-249acfba7273.TID582.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta
[2025-07-19T20:48:12.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/1.delta
[2025-07-19T20:48:12.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.1.delta.62617fc9-108b-4de1-85f7-b52e1357175f.TID584.tmp
[2025-07-19T20:48:12.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.1.delta.88f03795-2e56-41f9-b6f8-4bea3d34abe9.TID585.tmp
[2025-07-19T20:48:12.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 582, attempt 0, stage 3.0)
[2025-07-19T20:48:12.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c5568dd
[2025-07-19T20:48:12.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161] for update
[2025-07-19T20:48:12.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 146 (task 582, attempt 0, stage 3.0)
[2025-07-19T20:48:12.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 146.0 in stage 3.0 (TID 582). 6200 bytes result sent to driver
[2025-07-19T20:48:12.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 589) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58909795
[2025-07-19T20:48:12.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 167.0 in stage 3.0 (TID 589)
[2025-07-19T20:48:12.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 582) in 177 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:48:12.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163] for update
[2025-07-19T20:48:12.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.1.delta.cfff37ae-7207-45cf-a63b-728fad8c263b.TID581.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta
[2025-07-19T20:48:12.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/1.delta
[2025-07-19T20:48:12.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38e8e052
[2025-07-19T20:48:12.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 581, attempt 0, stage 3.0)
[2025-07-19T20:48:12.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 143 (task 581, attempt 0, stage 3.0)
[2025-07-19T20:48:12.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.1.delta.3d65486b-f001-4ef4-a1e0-6f5f24597ab0.TID587.tmp
[2025-07-19T20:48:12.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 143.0 in stage 3.0 (TID 581). 6200 bytes result sent to driver
[2025-07-19T20:48:12.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 590) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164] for update
[2025-07-19T20:48:12.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 581) in 204 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:48:12.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 170.0 in stage 3.0 (TID 590)
[2025-07-19T20:48:12.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@408bccb2
[2025-07-19T20:48:12.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167] for update
[2025-07-19T20:48:12.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.1.delta.ab90a426-4926-4046-81fe-5dbc2b14578e.TID586.tmp
[2025-07-19T20:48:12.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.1.delta.6b5bc7ba-3fa3-4033-a3d9-2758efb5e349.TID583.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta
[2025-07-19T20:48:12.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/1.delta
[2025-07-19T20:48:12.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 583, attempt 0, stage 3.0)
[2025-07-19T20:48:12.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 150 (task 583, attempt 0, stage 3.0)
[2025-07-19T20:48:12.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 150.0 in stage 3.0 (TID 583). 6200 bytes result sent to driver
[2025-07-19T20:48:12.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 591) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 583) in 123 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:48:12.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 171.0 in stage 3.0 (TID 591)
[2025-07-19T20:48:12.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3465de1a
[2025-07-19T20:48:12.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170] for update
[2025-07-19T20:48:12.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.1.delta.62617fc9-108b-4de1-85f7-b52e1357175f.TID584.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta
[2025-07-19T20:48:12.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/1.delta
[2025-07-19T20:48:12.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 584, attempt 0, stage 3.0)
[2025-07-19T20:48:12.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.1.delta.fb659cd0-bb9a-4121-9bec-73363b1bf73f.TID588.tmp
[2025-07-19T20:48:12.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 154 (task 584, attempt 0, stage 3.0)
[2025-07-19T20:48:12.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.1.delta.ca3abb31-8bce-46df-9c9a-5514f150841e.TID589.tmp
[2025-07-19T20:48:12.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 154.0 in stage 3.0 (TID 584). 6200 bytes result sent to driver
[2025-07-19T20:48:12.938+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12e217bf
[2025-07-19T20:48:12.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 592) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 172.0 in stage 3.0 (TID 592)
[2025-07-19T20:48:12.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171] for update
[2025-07-19T20:48:12.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 584) in 127 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:48:12.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.1.delta.88f03795-2e56-41f9-b6f8-4bea3d34abe9.TID585.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta
[2025-07-19T20:48:12.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/1.delta
[2025-07-19T20:48:12.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 585, attempt 0, stage 3.0)
[2025-07-19T20:48:12.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.1.delta.96416422-e301-4353-b340-b7d8c7f93dcf.TID590.tmp
[2025-07-19T20:48:12.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 158 (task 585, attempt 0, stage 3.0)
[2025-07-19T20:48:12.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 158.0 in stage 3.0 (TID 585). 6200 bytes result sent to driver
[2025-07-19T20:48:12.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 593) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 585) in 136 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:48:12.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.1.delta.ab90a426-4926-4046-81fe-5dbc2b14578e.TID586.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta
[2025-07-19T20:48:12.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/1.delta
[2025-07-19T20:48:12.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 586, attempt 0, stage 3.0)
[2025-07-19T20:48:12.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 173.0 in stage 3.0 (TID 593)
[2025-07-19T20:48:12.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:12.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a0efa06
[2025-07-19T20:48:12.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172] for update
[2025-07-19T20:48:12.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.1.delta.3d65486b-f001-4ef4-a1e0-6f5f24597ab0.TID587.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta
[2025-07-19T20:48:12.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/1.delta
[2025-07-19T20:48:12.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 161 (task 586, attempt 0, stage 3.0)
[2025-07-19T20:48:12.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 587, attempt 0, stage 3.0)
[2025-07-19T20:48:12.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 161.0 in stage 3.0 (TID 586). 6200 bytes result sent to driver
[2025-07-19T20:48:12.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 594) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 177.0 in stage 3.0 (TID 594)
[2025-07-19T20:48:12.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.1.delta.87b47891-a88f-4484-88a9-e965f00ec0cc.TID592.tmp
[2025-07-19T20:48:12.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 586) in 115 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:48:12.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79a49bc4
[2025-07-19T20:48:12.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.1.delta.d14cd97a-d51f-41f1-816a-fe46d44bd476.TID591.tmp
[2025-07-19T20:48:12.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:12.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173] for update
[2025-07-19T20:48:12.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:12.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:12.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:12.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Committed partition 163 (task 587, attempt 0, stage 3.0)
[2025-07-19T20:48:12.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Finished task 163.0 in stage 3.0 (TID 587). 6200 bytes result sent to driver
[2025-07-19T20:48:12.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 595) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:12.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 587) in 127 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:48:12.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO Executor: Running task 180.0 in stage 3.0 (TID 595)
[2025-07-19T20:48:12.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.1.delta.96416422-e301-4353-b340-b7d8c7f93dcf.TID590.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta
[2025-07-19T20:48:12.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/1.delta
[2025-07-19T20:48:12.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 590, attempt 0, stage 3.0)
[2025-07-19T20:48:12.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32f0f95d
[2025-07-19T20:48:12.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.1.delta.fb659cd0-bb9a-4121-9bec-73363b1bf73f.TID588.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta
[2025-07-19T20:48:12.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/1.delta
[2025-07-19T20:48:12.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177] for update
[2025-07-19T20:48:13.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 588, attempt 0, stage 3.0)
[2025-07-19T20:48:13.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:13.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:12 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.1.delta.ca3abb31-8bce-46df-9c9a-5514f150841e.TID589.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta
[2025-07-19T20:48:13.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/1.delta
[2025-07-19T20:48:13.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 589, attempt 0, stage 3.0)
[2025-07-19T20:48:13.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 164 (task 588, attempt 0, stage 3.0)
[2025-07-19T20:48:13.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 164.0 in stage 3.0 (TID 588). 6200 bytes result sent to driver
[2025-07-19T20:48:13.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 596) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 170 (task 590, attempt 0, stage 3.0)
[2025-07-19T20:48:13.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 588) in 131 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:48:13.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 181.0 in stage 3.0 (TID 596)
[2025-07-19T20:48:13.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.1.delta.01d82680-1669-4d0e-8e9b-a9899a978201.TID593.tmp
[2025-07-19T20:48:13.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 170.0 in stage 3.0 (TID 590). 6200 bytes result sent to driver
[2025-07-19T20:48:13.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 597) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 167 (task 589, attempt 0, stage 3.0)
[2025-07-19T20:48:13.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 167.0 in stage 3.0 (TID 589). 6200 bytes result sent to driver
[2025-07-19T20:48:13.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 186.0 in stage 3.0 (TID 597)
[2025-07-19T20:48:13.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 598) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c661467
[2025-07-19T20:48:13.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180] for update
[2025-07-19T20:48:13.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 589) in 118 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:48:13.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 590) in 105 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:48:13.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 189.0 in stage 3.0 (TID 598)
[2025-07-19T20:48:13.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.1.delta.fb03adf4-46e2-44f3-9bce-1c02e70b30f5.TID594.tmp
[2025-07-19T20:48:13.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:13.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48b238c3
[2025-07-19T20:48:13.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181] for update
[2025-07-19T20:48:13.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.1.delta.be26c3b5-5c9f-4db0-ba58-8f2d9a629005.TID595.tmp
[2025-07-19T20:48:13.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.1.delta.d14cd97a-d51f-41f1-816a-fe46d44bd476.TID591.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta
[2025-07-19T20:48:13.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/1.delta
[2025-07-19T20:48:13.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21a4aaa9
[2025-07-19T20:48:13.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 591, attempt 0, stage 3.0)
[2025-07-19T20:48:13.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.1.delta.87b47891-a88f-4484-88a9-e965f00ec0cc.TID592.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta
[2025-07-19T20:48:13.057+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/1.delta
[2025-07-19T20:48:13.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 592, attempt 0, stage 3.0)
[2025-07-19T20:48:13.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186] for update
[2025-07-19T20:48:13.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 171 (task 591, attempt 0, stage 3.0)
[2025-07-19T20:48:13.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.1.delta.932bf8dc-88ff-4f78-ba56-d359c5abd880.TID596.tmp
[2025-07-19T20:48:13.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 171.0 in stage 3.0 (TID 591). 6200 bytes result sent to driver
[2025-07-19T20:48:13.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 599) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 591) in 135 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:48:13.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 190.0 in stage 3.0 (TID 599)
[2025-07-19T20:48:13.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@442a67c6
[2025-07-19T20:48:13.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189] for update
[2025-07-19T20:48:13.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 172 (task 592, attempt 0, stage 3.0)
[2025-07-19T20:48:13.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 172.0 in stage 3.0 (TID 592). 6200 bytes result sent to driver
[2025-07-19T20:48:13.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2025-07-19T20:48:13.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.1.delta.f7b507df-ed6f-4ece-bf10-1f312eaf39bb.TID597.tmp
[2025-07-19T20:48:13.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.1.delta.01d82680-1669-4d0e-8e9b-a9899a978201.TID593.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta
[2025-07-19T20:48:13.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/1.delta
[2025-07-19T20:48:13.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 600) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 192.0 in stage 3.0 (TID 600)
[2025-07-19T20:48:13.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 592) in 143 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:48:13.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 593, attempt 0, stage 3.0)
[2025-07-19T20:48:13.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.1.delta.fb03adf4-46e2-44f3-9bce-1c02e70b30f5.TID594.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta
[2025-07-19T20:48:13.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/1.delta
[2025-07-19T20:48:13.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 594, attempt 0, stage 3.0)
[2025-07-19T20:48:13.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 177 (task 594, attempt 0, stage 3.0)
[2025-07-19T20:48:13.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5768afd3
[2025-07-19T20:48:13.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190] for update
[2025-07-19T20:48:13.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 173 (task 593, attempt 0, stage 3.0)
[2025-07-19T20:48:13.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 177.0 in stage 3.0 (TID 594). 6200 bytes result sent to driver
[2025-07-19T20:48:13.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 173.0 in stage 3.0 (TID 593). 6200 bytes result sent to driver
[2025-07-19T20:48:13.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 601) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 594) in 135 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:48:13.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2db55ce2
[2025-07-19T20:48:13.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 593) in 156 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:48:13.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 193.0 in stage 3.0 (TID 601)
[2025-07-19T20:48:13.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 602) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192] for update
[2025-07-19T20:48:13.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 195.0 in stage 3.0 (TID 602)
[2025-07-19T20:48:13.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.1.delta.4eacf27e-859d-428b-9a87-15fb2c54d58d.TID598.tmp
[2025-07-19T20:48:13.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.1.delta.f843f039-d742-4193-becd-9d5cf76c6e7e.TID599.tmp
[2025-07-19T20:48:13.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:13.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.1.delta.be26c3b5-5c9f-4db0-ba58-8f2d9a629005.TID595.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta
[2025-07-19T20:48:13.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/1.delta
[2025-07-19T20:48:13.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 595, attempt 0, stage 3.0)
[2025-07-19T20:48:13.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17262ce4
[2025-07-19T20:48:13.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195] for update
[2025-07-19T20:48:13.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 180 (task 595, attempt 0, stage 3.0)
[2025-07-19T20:48:13.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.1.delta.e44c39c7-a38d-4fcb-9e0c-80d094407ecf.TID600.tmp
[2025-07-19T20:48:13.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.1.delta.932bf8dc-88ff-4f78-ba56-d359c5abd880.TID596.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta
[2025-07-19T20:48:13.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/1.delta
[2025-07-19T20:48:13.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@691495f9
[2025-07-19T20:48:13.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.1.delta.f7b507df-ed6f-4ece-bf10-1f312eaf39bb.TID597.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta
[2025-07-19T20:48:13.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/1.delta
[2025-07-19T20:48:13.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 180.0 in stage 3.0 (TID 595). 6200 bytes result sent to driver
[2025-07-19T20:48:13.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 597, attempt 0, stage 3.0)
[2025-07-19T20:48:13.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 596, attempt 0, stage 3.0)
[2025-07-19T20:48:13.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 603) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:13.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 595) in 157 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:48:13.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 0.0 in stage 7.0 (TID 603)
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193] for update
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68746e5e
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0] for update
[2025-07-19T20:48:13.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 186 (task 597, attempt 0, stage 3.0)
[2025-07-19T20:48:13.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 186.0 in stage 3.0 (TID 597). 6200 bytes result sent to driver
[2025-07-19T20:48:13.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 181 (task 596, attempt 0, stage 3.0)
[2025-07-19T20:48:13.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 181.0 in stage 3.0 (TID 596). 6200 bytes result sent to driver
[2025-07-19T20:48:13.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 604) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 1.0 in stage 7.0 (TID 604)
[2025-07-19T20:48:13.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 605) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 596) in 147 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:48:13.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 597) in 143 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:48:13.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.158+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 2.0 in stage 7.0 (TID 605)
[2025-07-19T20:48:13.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@570a711d
[2025-07-19T20:48:13.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1] for update
[2025-07-19T20:48:13.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.1.delta.bad9639e-08a7-4230-b837-0633e201c20c.TID602.tmp
[2025-07-19T20:48:13.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodeGenerator: Code generated in 10.308333 ms
[2025-07-19T20:48:13.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20a62fbc
[2025-07-19T20:48:13.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2] for update
[2025-07-19T20:48:13.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.1.delta.285e1dd1-6b9e-417c-aa87-765353a745bf.TID601.tmp
[2025-07-19T20:48:13.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.2.delta.36fb61ff-a8e9-4b68-8285-d59258871451.TID603.tmp
[2025-07-19T20:48:13.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.2.delta.f2f083c1-7219-467c-8a9e-8f632722e11d.TID604.tmp
[2025-07-19T20:48:13.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.2.delta.34eb9a1e-9060-460b-b7e6-1469840a5f32.TID605.tmp
[2025-07-19T20:48:13.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.1.delta.4eacf27e-859d-428b-9a87-15fb2c54d58d.TID598.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta
[2025-07-19T20:48:13.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/1.delta
[2025-07-19T20:48:13.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 598, attempt 0, stage 3.0)
[2025-07-19T20:48:13.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.1.delta.f843f039-d742-4193-becd-9d5cf76c6e7e.TID599.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta
[2025-07-19T20:48:13.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/1.delta
[2025-07-19T20:48:13.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 599, attempt 0, stage 3.0)
[2025-07-19T20:48:13.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.1.delta.e44c39c7-a38d-4fcb-9e0c-80d094407ecf.TID600.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta
[2025-07-19T20:48:13.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/1.delta
[2025-07-19T20:48:13.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 600, attempt 0, stage 3.0)
[2025-07-19T20:48:13.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 189 (task 598, attempt 0, stage 3.0)
[2025-07-19T20:48:13.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 189.0 in stage 3.0 (TID 598). 6200 bytes result sent to driver
[2025-07-19T20:48:13.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 606) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 598) in 203 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:48:13.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 3.0 in stage 7.0 (TID 606)
[2025-07-19T20:48:13.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 192 (task 600, attempt 0, stage 3.0)
[2025-07-19T20:48:13.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:13.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 192.0 in stage 3.0 (TID 600). 6200 bytes result sent to driver
[2025-07-19T20:48:13.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 190 (task 599, attempt 0, stage 3.0)
[2025-07-19T20:48:13.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 190.0 in stage 3.0 (TID 599). 6200 bytes result sent to driver
[2025-07-19T20:48:13.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 607) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 608) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c72954
[2025-07-19T20:48:13.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 4.0 in stage 7.0 (TID 607)
[2025-07-19T20:48:13.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 600) in 150 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:48:13.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 5.0 in stage 7.0 (TID 608)
[2025-07-19T20:48:13.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 599) in 170 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:48:13.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3] for update
[2025-07-19T20:48:13.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.1.delta.bad9639e-08a7-4230-b837-0633e201c20c.TID602.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta
[2025-07-19T20:48:13.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/1.delta
[2025-07-19T20:48:13.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 602, attempt 0, stage 3.0)
[2025-07-19T20:48:13.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dd15396
[2025-07-19T20:48:13.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.256+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5] for update
[2025-07-19T20:48:13.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ffe14ef
[2025-07-19T20:48:13.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4] for update
[2025-07-19T20:48:13.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.2.delta.36fb61ff-a8e9-4b68-8285-d59258871451.TID603.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/2.delta
[2025-07-19T20:48:13.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/0/2.delta
[2025-07-19T20:48:13.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 195 (task 602, attempt 0, stage 3.0)
[2025-07-19T20:48:13.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T20:48:13.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 195.0 in stage 3.0 (TID 602). 6200 bytes result sent to driver
[2025-07-19T20:48:13.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.1.delta.285e1dd1-6b9e-417c-aa87-765353a745bf.TID601.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta
[2025-07-19T20:48:13.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/1.delta
[2025-07-19T20:48:13.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 601, attempt 0, stage 3.0)
[2025-07-19T20:48:13.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 609) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 6.0 in stage 7.0 (TID 609)
[2025-07-19T20:48:13.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 602) in 139 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:48:13.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.2.delta.1c5ee365-3fb8-4c0e-b472-877644fff4e6.TID606.tmp
[2025-07-19T20:48:13.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cdd7bc8
[2025-07-19T20:48:13.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6] for update
[2025-07-19T20:48:13.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.2.delta.0e085ce3-21b1-484b-8540-d56a0065f692.TID608.tmp
[2025-07-19T20:48:13.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T20:48:13.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 193 (task 601, attempt 0, stage 3.0)
[2025-07-19T20:48:13.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 0.0 in stage 7.0 (TID 603). 5829 bytes result sent to driver
[2025-07-19T20:48:13.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 610) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.2.delta.f2f083c1-7219-467c-8a9e-8f632722e11d.TID604.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/2.delta
[2025-07-19T20:48:13.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/1/2.delta
[2025-07-19T20:48:13.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 193.0 in stage 3.0 (TID 601). 6200 bytes result sent to driver
[2025-07-19T20:48:13.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 603) in 114 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:48:13.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 7.0 in stage 7.0 (TID 610)
[2025-07-19T20:48:13.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T20:48:13.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 611) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 8.0 in stage 7.0 (TID 611)
[2025-07-19T20:48:13.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 601) in 152 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:48:13.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-19T20:48:13.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:13.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.2.delta.34eb9a1e-9060-460b-b7e6-1469840a5f32.TID605.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/2.delta
[2025-07-19T20:48:13.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/2/2.delta
[2025-07-19T20:48:13.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DAGScheduler: ResultStage 3 (start at <unknown>:0) finished in 13.462 s
[2025-07-19T20:48:13.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33ee19c2
[2025-07-19T20:48:13.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:48:13.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-19T20:48:13.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T20:48:13.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7] for update
[2025-07-19T20:48:13.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DAGScheduler: Job 2 finished: start at <unknown>:0, took 14.909450 s
[2025-07-19T20:48:13.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T20:48:13.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Committing epoch 0 for query 302fc0f2-ecb3-4b30-9b45-e72bb5225779 in append mode
[2025-07-19T20:48:13.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78d67375
[2025-07-19T20:48:13.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.2.delta.598bb844-f1ff-4935-890d-0848275c4b0b.TID607.tmp
[2025-07-19T20:48:13.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8] for update
[2025-07-19T20:48:13.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.2.delta.51499f10-3d3e-4ee5-8376-668c4496752f.TID609.tmp
[2025-07-19T20:48:13.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T20:48:13.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 1.0 in stage 7.0 (TID 604). 5829 bytes result sent to driver
[2025-07-19T20:48:13.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T20:48:13.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 2.0 in stage 7.0 (TID 605). 5829 bytes result sent to driver
[2025-07-19T20:48:13.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 612) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 613) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 9.0 in stage 7.0 (TID 612)
[2025-07-19T20:48:13.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 604) in 125 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:48:13.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 605) in 125 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:48:13.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.2.delta.e55b7b5c-e770-47c8-9e2d-d8eb9e3d798c.TID611.tmp
[2025-07-19T20:48:13.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 10.0 in stage 7.0 (TID 613)
[2025-07-19T20:48:13.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@550ab1b
[2025-07-19T20:48:13.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9] for update
[2025-07-19T20:48:13.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@566a4083
[2025-07-19T20:48:13.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10] for update
[2025-07-19T20:48:13.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.2.delta.1103eda1-e145-48b3-999f-7bd54c4548f0.TID610.tmp
[2025-07-19T20:48:13.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Committing streaming append with 134 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.2.delta.dc7e09ba-4ec2-4e7c-bedf-2a69555dde24.TID612.tmp
[2025-07-19T20:48:13.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.2.delta.1c5ee365-3fb8-4c0e-b472-877644fff4e6.TID606.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/2.delta
[2025-07-19T20:48:13.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/3/2.delta
[2025-07-19T20:48:13.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.2.delta.8ead5310-f3fc-4323-b807-1a02ddeef806.TID613.tmp
[2025-07-19T20:48:13.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T20:48:13.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T20:48:13.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 3.0 in stage 7.0 (TID 606). 5829 bytes result sent to driver
[2025-07-19T20:48:13.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 614) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 606) in 102 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:48:13.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.2.delta.0e085ce3-21b1-484b-8540-d56a0065f692.TID608.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/2.delta
[2025-07-19T20:48:13.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/5/2.delta
[2025-07-19T20:48:13.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 11.0 in stage 7.0 (TID 614)
[2025-07-19T20:48:13.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T20:48:13.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17fb1590
[2025-07-19T20:48:13.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11] for update
[2025-07-19T20:48:13.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T20:48:13.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 5.0 in stage 7.0 (TID 608). 5829 bytes result sent to driver
[2025-07-19T20:48:13.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 615) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 12.0 in stage 7.0 (TID 615)
[2025-07-19T20:48:13.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 608) in 101 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:48:13.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.2.delta.598bb844-f1ff-4935-890d-0848275c4b0b.TID607.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/2.delta
[2025-07-19T20:48:13.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/4/2.delta
[2025-07-19T20:48:13.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@154f93ab
[2025-07-19T20:48:13.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T20:48:13.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12] for update
[2025-07-19T20:48:13.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.2.delta.e55b7b5c-e770-47c8-9e2d-d8eb9e3d798c.TID611.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/2.delta
[2025-07-19T20:48:13.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/8/2.delta
[2025-07-19T20:48:13.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.2.delta.23dc6618-98e3-457f-82ea-d9e75ed45ae4.TID614.tmp
[2025-07-19T20:48:13.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T20:48:13.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T20:48:13.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 4.0 in stage 7.0 (TID 607). 5829 bytes result sent to driver
[2025-07-19T20:48:13.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.2.delta.51499f10-3d3e-4ee5-8376-668c4496752f.TID609.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/2.delta
[2025-07-19T20:48:13.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/6/2.delta
[2025-07-19T20:48:13.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T20:48:13.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 616) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.357+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 8.0 in stage 7.0 (TID 611). 5786 bytes result sent to driver
[2025-07-19T20:48:13.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 617) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T20:48:13.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 607) in 122 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:48:13.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 14.0 in stage 7.0 (TID 617)
[2025-07-19T20:48:13.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 611) in 94 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59037697
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 13.0 in stage 7.0 (TID 616)
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14] for update
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.2.delta.1103eda1-e145-48b3-999f-7bd54c4548f0.TID610.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/2.delta
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/7/2.delta
[2025-07-19T20:48:13.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T20:48:13.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T20:48:13.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 6.0 in stage 7.0 (TID 609). 5915 bytes result sent to driver
[2025-07-19T20:48:13.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 618) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 15.0 in stage 7.0 (TID 618)
[2025-07-19T20:48:13.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T20:48:13.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:13.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 7.0 in stage 7.0 (TID 610). 5872 bytes result sent to driver
[2025-07-19T20:48:13.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 619) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 16.0 in stage 7.0 (TID 619)
[2025-07-19T20:48:13.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d0550da
[2025-07-19T20:48:13.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 609) in 126 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:48:13.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 610) in 119 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:48:13.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15] for update
[2025-07-19T20:48:13.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.2.delta.7e93348a-c75b-4c0d-aa59-34178cdd3e0c.TID617.tmp
[2025-07-19T20:48:13.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.2.delta.dc7e09ba-4ec2-4e7c-bedf-2a69555dde24.TID612.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/2.delta
[2025-07-19T20:48:13.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/9/2.delta
[2025-07-19T20:48:13.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.2.delta.3dbc1f5d-a4a0-4ddb-b3ee-e458e06c1bc6.TID615.tmp
[2025-07-19T20:48:13.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T20:48:13.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:13.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@373f222e
[2025-07-19T20:48:13.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13] for update
[2025-07-19T20:48:13.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T20:48:13.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 9.0 in stage 7.0 (TID 612). 5872 bytes result sent to driver
[2025-07-19T20:48:13.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 620) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 17.0 in stage 7.0 (TID 620)
[2025-07-19T20:48:13.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d90c165
[2025-07-19T20:48:13.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16] for update
[2025-07-19T20:48:13.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 612) in 117 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:48:13.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f6e6ff1
[2025-07-19T20:48:13.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.2.delta.dd161249-c87e-48ea-965d-8cdeb27bbbea.TID618.tmp
[2025-07-19T20:48:13.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17] for update
[2025-07-19T20:48:13.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.2.delta.8ead5310-f3fc-4323-b807-1a02ddeef806.TID613.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/2.delta
[2025-07-19T20:48:13.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/10/2.delta
[2025-07-19T20:48:13.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T20:48:13.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T20:48:13.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 10.0 in stage 7.0 (TID 613). 5872 bytes result sent to driver
[2025-07-19T20:48:13.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 621) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 613) in 133 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:48:13.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 18.0 in stage 7.0 (TID 621)
[2025-07-19T20:48:13.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.2.delta.d0a395e0-71ea-4cb0-a527-eaf42cd6553e.TID619.tmp
[2025-07-19T20:48:13.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.416+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:13.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.2.delta.d5c290d7-4964-4a9f-95de-6675d4c6e00c.TID616.tmp
[2025-07-19T20:48:13.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cf04ba8
[2025-07-19T20:48:13.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18] for update
[2025-07-19T20:48:13.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.2.delta.ef08dc9e-7f1b-42ab-804d-a06d4978f9ce.TID620.tmp
[2025-07-19T20:48:13.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.2.delta.23dc6618-98e3-457f-82ea-d9e75ed45ae4.TID614.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/2.delta
[2025-07-19T20:48:13.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/11/2.delta
[2025-07-19T20:48:13.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T20:48:13.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T20:48:13.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 11.0 in stage 7.0 (TID 614). 5872 bytes result sent to driver
[2025-07-19T20:48:13.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 622) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 19.0 in stage 7.0 (TID 622)
[2025-07-19T20:48:13.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 614) in 116 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:48:13.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.2.delta.379ab38a-8816-47ca-8886-4628b8ea12f3.TID621.tmp
[2025-07-19T20:48:13.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:13.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.2.delta.7e93348a-c75b-4c0d-aa59-34178cdd3e0c.TID617.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/2.delta
[2025-07-19T20:48:13.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/14/2.delta
[2025-07-19T20:48:13.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T20:48:13.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73a3a0f5
[2025-07-19T20:48:13.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.2.delta.3dbc1f5d-a4a0-4ddb-b3ee-e458e06c1bc6.TID615.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/2.delta
[2025-07-19T20:48:13.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/12/2.delta
[2025-07-19T20:48:13.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19] for update
[2025-07-19T20:48:13.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T20:48:13.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T20:48:13.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 14.0 in stage 7.0 (TID 617). 5872 bytes result sent to driver
[2025-07-19T20:48:13.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 623) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 20.0 in stage 7.0 (TID 623)
[2025-07-19T20:48:13.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 617) in 97 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:48:13.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T20:48:13.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 12.0 in stage 7.0 (TID 615). 5872 bytes result sent to driver
[2025-07-19T20:48:13.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.2.delta.e553580a-4a79-4d6c-a911-b520e1a157b9.TID622.tmp
[2025-07-19T20:48:13.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 624) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f7328cf
[2025-07-19T20:48:13.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 615) in 128 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:48:13.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 21.0 in stage 7.0 (TID 624)
[2025-07-19T20:48:13.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.2.delta.dd161249-c87e-48ea-965d-8cdeb27bbbea.TID618.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/2.delta
[2025-07-19T20:48:13.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/15/2.delta
[2025-07-19T20:48:13.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20] for update
[2025-07-19T20:48:13.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T20:48:13.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.2.delta.d0a395e0-71ea-4cb0-a527-eaf42cd6553e.TID619.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/2.delta
[2025-07-19T20:48:13.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/16/2.delta
[2025-07-19T20:48:13.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T20:48:13.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.2.delta.d5c290d7-4964-4a9f-95de-6675d4c6e00c.TID616.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/2.delta
[2025-07-19T20:48:13.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/13/2.delta
[2025-07-19T20:48:13.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dcafeb3
[2025-07-19T20:48:13.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T20:48:13.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T20:48:13.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T20:48:13.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21] for update
[2025-07-19T20:48:13.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 16.0 in stage 7.0 (TID 619). 5872 bytes result sent to driver
[2025-07-19T20:48:13.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 15.0 in stage 7.0 (TID 618). 5915 bytes result sent to driver
[2025-07-19T20:48:13.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 625) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.476+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 626) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.476+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 22.0 in stage 7.0 (TID 625)
[2025-07-19T20:48:13.477+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 23.0 in stage 7.0 (TID 626)
[2025-07-19T20:48:13.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 619) in 101 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:48:13.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 618) in 106 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:48:13.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T20:48:13.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 13.0 in stage 7.0 (TID 616). 5872 bytes result sent to driver
[2025-07-19T20:48:13.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 627) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 616) in 127 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:48:13.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 24.0 in stage 7.0 (TID 627)
[2025-07-19T20:48:13.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60eac7c9
[2025-07-19T20:48:13.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.2.delta.59581efd-710d-4184-9a71-92ac204c93b7.TID623.tmp
[2025-07-19T20:48:13.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.2.delta.ef08dc9e-7f1b-42ab-804d-a06d4978f9ce.TID620.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/2.delta
[2025-07-19T20:48:13.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/17/2.delta
[2025-07-19T20:48:13.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T20:48:13.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22] for update
[2025-07-19T20:48:13.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d1ef28
[2025-07-19T20:48:13.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.2.delta.b64e9c38-b9bc-4ea6-9d8b-bc871e65cabc.TID624.tmp
[2025-07-19T20:48:13.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.2.delta.379ab38a-8816-47ca-8886-4628b8ea12f3.TID621.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/2.delta
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/18/2.delta
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24] for update
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 17.0 in stage 7.0 (TID 620). 5872 bytes result sent to driver
[2025-07-19T20:48:13.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 628) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T20:48:13.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 25.0 in stage 7.0 (TID 628)
[2025-07-19T20:48:13.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 620) in 103 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:48:13.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3280d9d6
[2025-07-19T20:48:13.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23] for update
[2025-07-19T20:48:13.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b914782
[2025-07-19T20:48:13.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25] for update
[2025-07-19T20:48:13.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T20:48:13.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 18.0 in stage 7.0 (TID 621). 5872 bytes result sent to driver
[2025-07-19T20:48:13.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 629) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 26.0 in stage 7.0 (TID 629)
[2025-07-19T20:48:13.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 621) in 90 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:48:13.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.509+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@88de413
[2025-07-19T20:48:13.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26] for update
[2025-07-19T20:48:13.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.2.delta.bcb8c609-d3b7-403a-8170-9d39192ce0f6.TID627.tmp
[2025-07-19T20:48:13.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.2.delta.05942aff-4627-496d-b47e-7878d65ebb7c.TID625.tmp
[2025-07-19T20:48:13.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.2.delta.5faf880f-67d9-4989-8a2f-bba06bdb202b.TID626.tmp
[2025-07-19T20:48:13.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.2.delta.2ed1b3f9-973a-4b2d-bbb7-d0a8e17b677b.TID628.tmp
[2025-07-19T20:48:13.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.2.delta.e553580a-4a79-4d6c-a911-b520e1a157b9.TID622.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/2.delta
[2025-07-19T20:48:13.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/19/2.delta
[2025-07-19T20:48:13.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T20:48:13.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T20:48:13.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 19.0 in stage 7.0 (TID 622). 5872 bytes result sent to driver
[2025-07-19T20:48:13.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 630) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 27.0 in stage 7.0 (TID 630)
[2025-07-19T20:48:13.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.2.delta.10159c8c-6f0f-4909-8f07-a08a17ae8829.TID629.tmp
[2025-07-19T20:48:13.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.2.delta.59581efd-710d-4184-9a71-92ac204c93b7.TID623.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/2.delta
[2025-07-19T20:48:13.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/20/2.delta
[2025-07-19T20:48:13.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 622) in 97 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:48:13.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T20:48:13.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T20:48:13.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 20.0 in stage 7.0 (TID 623). 5829 bytes result sent to driver
[2025-07-19T20:48:13.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 631) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 623) in 84 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:48:13.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 28.0 in stage 7.0 (TID 631)
[2025-07-19T20:48:13.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b1e49b8
[2025-07-19T20:48:13.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27] for update
[2025-07-19T20:48:13.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ef020db
[2025-07-19T20:48:13.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28] for update
[2025-07-19T20:48:13.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.2.delta.3f495fbd-9fdd-4f92-b8a7-d0ef1639c0f1.TID630.tmp
[2025-07-19T20:48:13.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.2.delta.0b490ac4-5dbf-4e3a-8348-73805b755e12.TID631.tmp
[2025-07-19T20:48:13.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.2.delta.b64e9c38-b9bc-4ea6-9d8b-bc871e65cabc.TID624.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/2.delta
[2025-07-19T20:48:13.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/21/2.delta
[2025-07-19T20:48:13.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T20:48:13.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T20:48:13.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 21.0 in stage 7.0 (TID 624). 5829 bytes result sent to driver
[2025-07-19T20:48:13.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 632) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 624) in 101 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:48:13.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 29.0 in stage 7.0 (TID 632)
[2025-07-19T20:48:13.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@718bbac1
[2025-07-19T20:48:13.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.2.delta.2ed1b3f9-973a-4b2d-bbb7-d0a8e17b677b.TID628.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/2.delta
[2025-07-19T20:48:13.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/25/2.delta
[2025-07-19T20:48:13.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29] for update
[2025-07-19T20:48:13.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T20:48:13.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.2.delta.05942aff-4627-496d-b47e-7878d65ebb7c.TID625.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/2.delta
[2025-07-19T20:48:13.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/22/2.delta
[2025-07-19T20:48:13.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.2.delta.5faf880f-67d9-4989-8a2f-bba06bdb202b.TID626.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/2.delta
[2025-07-19T20:48:13.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/23/2.delta
[2025-07-19T20:48:13.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v120.metadata.json
[2025-07-19T20:48:13.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T20:48:13.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T20:48:13.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T20:48:13.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 25.0 in stage 7.0 (TID 628). 5829 bytes result sent to driver
[2025-07-19T20:48:13.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 633) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 628) in 82 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:48:13.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 30.0 in stage 7.0 (TID 633)
[2025-07-19T20:48:13.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a7091b8
[2025-07-19T20:48:13.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30] for update
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 23.0 in stage 7.0 (TID 626). 5829 bytes result sent to driver
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 634) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T20:48:13.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 22.0 in stage 7.0 (TID 625). 5829 bytes result sent to driver
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 635) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 31.0 in stage 7.0 (TID 634)
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.2.delta.7314f096-85e6-48a0-87fe-a65d31ed36d0.TID632.tmp
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.2.delta.10159c8c-6f0f-4909-8f07-a08a17ae8829.TID629.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/2.delta
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/26/2.delta
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 625) in 106 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T20:48:13.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@725f0a4e
[2025-07-19T20:48:13.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 626) in 107 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:48:13.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.2.delta.bcb8c609-d3b7-403a-8170-9d39192ce0f6.TID627.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/2.delta
[2025-07-19T20:48:13.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/24/2.delta
[2025-07-19T20:48:13.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 32.0 in stage 7.0 (TID 635)
[2025-07-19T20:48:13.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31] for update
[2025-07-19T20:48:13.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T20:48:13.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T20:48:13.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.2.delta.dcbe2cb7-efb0-4fe6-9ce2-d4a5c1b38767.TID633.tmp
[2025-07-19T20:48:13.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 26.0 in stage 7.0 (TID 629). 5829 bytes result sent to driver
[2025-07-19T20:48:13.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 636) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 629) in 94 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:48:13.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 33.0 in stage 7.0 (TID 636)
[2025-07-19T20:48:13.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b4a4d7f
[2025-07-19T20:48:13.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32] for update
[2025-07-19T20:48:13.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T20:48:13.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 24.0 in stage 7.0 (TID 627). 5829 bytes result sent to driver
[2025-07-19T20:48:13.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 637) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 627) in 123 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:48:13.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 34.0 in stage 7.0 (TID 637)
[2025-07-19T20:48:13.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@581c1736
[2025-07-19T20:48:13.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33] for update
[2025-07-19T20:48:13.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.2.delta.0b490ac4-5dbf-4e3a-8348-73805b755e12.TID631.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/2.delta
[2025-07-19T20:48:13.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/28/2.delta
[2025-07-19T20:48:13.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.2.delta.3f495fbd-9fdd-4f92-b8a7-d0ef1639c0f1.TID630.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/2.delta
[2025-07-19T20:48:13.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/27/2.delta
[2025-07-19T20:48:13.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T20:48:13.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T20:48:13.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T20:48:13.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 27.0 in stage 7.0 (TID 630). 5829 bytes result sent to driver
[2025-07-19T20:48:13.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T20:48:13.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 28.0 in stage 7.0 (TID 631). 5829 bytes result sent to driver
[2025-07-19T20:48:13.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3893cd94
[2025-07-19T20:48:13.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 638) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.2.delta.b689c08d-e19e-4e7b-a487-6b58a6d47722.TID635.tmp
[2025-07-19T20:48:13.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 35.0 in stage 7.0 (TID 638)
[2025-07-19T20:48:13.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34] for update
[2025-07-19T20:48:13.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 639) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 630) in 95 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:48:13.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 631) in 87 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:48:13.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 36.0 in stage 7.0 (TID 639)
[2025-07-19T20:48:13.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SnapshotProducer: Committed snapshot 4262704169509717529 (FastAppend)
[2025-07-19T20:48:13.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.2.delta.16f60f14-defe-4b0d-9a5b-697539c18b02.TID634.tmp
[2025-07-19T20:48:13.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dba2229
[2025-07-19T20:48:13.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36] for update
[2025-07-19T20:48:13.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:13.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.2.delta.1adc532c-3986-424e-808d-a57d61aa0a5b.TID636.tmp
[2025-07-19T20:48:13.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2921a842
[2025-07-19T20:48:13.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.2.delta.39bfcb97-48f7-40e2-9a24-a7a3b35d8cb5.TID637.tmp
[2025-07-19T20:48:13.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35] for update
[2025-07-19T20:48:13.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.2.delta.22fa0735-802a-447d-8dc2-087e4f0d178c.TID639.tmp
[2025-07-19T20:48:13.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.2.delta.7314f096-85e6-48a0-87fe-a65d31ed36d0.TID632.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/2.delta
[2025-07-19T20:48:13.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/29/2.delta
[2025-07-19T20:48:13.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T20:48:13.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T20:48:13.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 29.0 in stage 7.0 (TID 632). 5829 bytes result sent to driver
[2025-07-19T20:48:13.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 640) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 632) in 96 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:48:13.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 37.0 in stage 7.0 (TID 640)
[2025-07-19T20:48:13.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6476ce11
[2025-07-19T20:48:13.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37] for update
[2025-07-19T20:48:13.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=4262704169509717529, sequenceNumber=119, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.371106459S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=134}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5710}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=222}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8010}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=436146}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=18487824}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958074309, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:48:13.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Committed in 371 ms
[2025-07-19T20:48:13.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T20:48:13.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752784740000 ms
[2025-07-19T20:48:13.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.2.delta.b689c08d-e19e-4e7b-a487-6b58a6d47722.TID635.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/2.delta
[2025-07-19T20:48:13.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/32/2.delta
[2025-07-19T20:48:13.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T20:48:13.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.2.delta.dcbe2cb7-efb0-4fe6-9ce2-d4a5c1b38767.TID633.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/2.delta
[2025-07-19T20:48:13.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/30/2.delta
[2025-07-19T20:48:13.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T20:48:13.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.2.delta.dcbc253b-e433-4a3b-b48a-8602e960c451.TID638.tmp
[2025-07-19T20:48:13.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T20:48:13.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 32.0 in stage 7.0 (TID 635). 5829 bytes result sent to driver
[2025-07-19T20:48:13.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T20:48:13.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 30.0 in stage 7.0 (TID 633). 5829 bytes result sent to driver
[2025-07-19T20:48:13.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/.0.f000b551-fc27-4e09-86b6-2fbc209aaa36.tmp
[2025-07-19T20:48:13.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.2.delta.3a542bf8-d2be-4602-8275-0d19466e0799.TID640.tmp
[2025-07-19T20:48:13.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 641) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 642) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 39.0 in stage 7.0 (TID 642)
[2025-07-19T20:48:13.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 38.0 in stage 7.0 (TID 641)
[2025-07-19T20:48:13.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.2.delta.16f60f14-defe-4b0d-9a5b-697539c18b02.TID634.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/2.delta
[2025-07-19T20:48:13.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/31/2.delta
[2025-07-19T20:48:13.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 635) in 106 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:48:13.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 633) in 114 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:48:13.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T20:48:13.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.2.delta.39bfcb97-48f7-40e2-9a24-a7a3b35d8cb5.TID637.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/2.delta
[2025-07-19T20:48:13.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/34/2.delta
[2025-07-19T20:48:13.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T20:48:13.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1109f3a4
[2025-07-19T20:48:13.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 31.0 in stage 7.0 (TID 634). 5829 bytes result sent to driver
[2025-07-19T20:48:13.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 643) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T20:48:13.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38] for update
[2025-07-19T20:48:13.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58b61605
[2025-07-19T20:48:13.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 634) in 115 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:48:13.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 40.0 in stage 7.0 (TID 643)
[2025-07-19T20:48:13.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39] for update
[2025-07-19T20:48:13.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4773d8d8
[2025-07-19T20:48:13.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40] for update
[2025-07-19T20:48:13.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T20:48:13.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 34.0 in stage 7.0 (TID 637). 5829 bytes result sent to driver
[2025-07-19T20:48:13.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 644) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 41.0 in stage 7.0 (TID 644)
[2025-07-19T20:48:13.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 637) in 100 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:48:13.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.2.delta.15d0b4bc-bf86-41d5-8377-b0b58a4ed621.TID641.tmp
[2025-07-19T20:48:13.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.2.delta.22fa0735-802a-447d-8dc2-087e4f0d178c.TID639.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/2.delta
[2025-07-19T20:48:13.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/36/2.delta
[2025-07-19T20:48:13.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.2.delta.1adc532c-3986-424e-808d-a57d61aa0a5b.TID636.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/2.delta
[2025-07-19T20:48:13.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/33/2.delta
[2025-07-19T20:48:13.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T20:48:13.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T20:48:13.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43db4f
[2025-07-19T20:48:13.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.2.delta.1a6dbb7f-c496-453a-8bb8-7ecedbe207aa.TID643.tmp
[2025-07-19T20:48:13.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41] for update
[2025-07-19T20:48:13.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.2.delta.78dc5f7d-efde-4627-ad0d-abbfc633d5e1.TID642.tmp
[2025-07-19T20:48:13.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T20:48:13.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 36.0 in stage 7.0 (TID 639). 5829 bytes result sent to driver
[2025-07-19T20:48:13.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T20:48:13.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 645) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 42.0 in stage 7.0 (TID 645)
[2025-07-19T20:48:13.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 639) in 107 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:48:13.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 33.0 in stage 7.0 (TID 636). 5829 bytes result sent to driver
[2025-07-19T20:48:13.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 646) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 43.0 in stage 7.0 (TID 646)
[2025-07-19T20:48:13.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2311060b
[2025-07-19T20:48:13.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 636) in 135 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:48:13.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42] for update
[2025-07-19T20:48:13.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.2.delta.83ac2ad5-a811-42b5-b963-8a92cf2c2924.TID644.tmp
[2025-07-19T20:48:13.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.2.delta.dcbc253b-e433-4a3b-b48a-8602e960c451.TID638.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/2.delta
[2025-07-19T20:48:13.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:48:13.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/35/2.delta
[2025-07-19T20:48:13.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T20:48:13.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42f075c9
[2025-07-19T20:48:13.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43] for update
[2025-07-19T20:48:13.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T20:48:13.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.2.delta.695b4c16-60d4-4f9c-80ac-5f4e677816ed.TID645.tmp
[2025-07-19T20:48:13.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 35.0 in stage 7.0 (TID 638). 5829 bytes result sent to driver
[2025-07-19T20:48:13.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 638) in 132 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:48:13.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/.0.f000b551-fc27-4e09-86b6-2fbc209aaa36.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/0
[2025-07-19T20:48:13.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 647) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 44.0 in stage 7.0 (TID 647)
[2025-07-19T20:48:13.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.2.delta.3a542bf8-d2be-4602-8275-0d19466e0799.TID640.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/2.delta
[2025-07-19T20:48:13.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/37/2.delta
[2025-07-19T20:48:13.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c68ddce
[2025-07-19T20:48:13.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:48:13.760+0000] {subprocess.py:93} INFO -   "id" : "302fc0f2-ecb3-4b30-9b45-e72bb5225779",
[2025-07-19T20:48:13.761+0000] {subprocess.py:93} INFO -   "runId" : "3851e258-c04f-469c-9e1b-1d5426ca45a3",
[2025-07-19T20:48:13.761+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:48:13.761+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:47:56.779Z",
[2025-07-19T20:48:13.761+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T20:48:13.763+0000] {subprocess.py:93} INFO -   "numInputRows" : 222,
[2025-07-19T20:48:13.763+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:13.764+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 13.085764809902741,
[2025-07-19T20:48:13.764+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:48:13.764+0000] {subprocess.py:93} INFO -     "addBatch" : 15967,
[2025-07-19T20:48:13.764+0000] {subprocess.py:93} INFO -     "commitOffsets" : 81,
[2025-07-19T20:48:13.765+0000] {subprocess.py:93} INFO -     "getBatch" : 9,
[2025-07-19T20:48:13.765+0000] {subprocess.py:93} INFO -     "latestOffset" : 415,
[2025-07-19T20:48:13.766+0000] {subprocess.py:93} INFO -     "queryPlanning" : 442,
[2025-07-19T20:48:13.767+0000] {subprocess.py:93} INFO -     "triggerExecution" : 16965,
[2025-07-19T20:48:13.769+0000] {subprocess.py:93} INFO -     "walCommit" : 42
[2025-07-19T20:48:13.772+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:13.773+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:48:13.773+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T18:08:28.108Z",
[2025-07-19T20:48:13.773+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T20:39:00.000Z",
[2025-07-19T20:48:13.774+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T16:04:00.000Z",
[2025-07-19T20:48:13.774+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T20:48:13.774+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:13.775+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:48:13.776+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:48:13.777+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 222,
[2025-07-19T20:48:13.778+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 222,
[2025-07-19T20:48:13.780+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 3382,
[2025-07-19T20:48:13.781+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:48:13.784+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 135,
[2025-07-19T20:48:13.787+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 14820,
[2025-07-19T20:48:13.789+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 99568,
[2025-07-19T20:48:13.791+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:48:13.791+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:48:13.791+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:48:13.791+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:48:13.792+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T20:48:13.792+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:48:13.793+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:48:13.794+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 70768
[2025-07-19T20:48:13.794+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:13.795+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:13.796+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:48:13.796+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T20:48:13.796+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T20:48:13.797+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:48:13.797+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:13.798+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:13.799+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:13.799+0000] {subprocess.py:93} INFO -     "numInputRows" : 222,
[2025-07-19T20:48:13.800+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:13.800+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 13.085764809902741,
[2025-07-19T20:48:13.801+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:48:13.802+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:48:13.802+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -     "numOutputRows" : 222
[2025-07-19T20:48:13.803+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44] for update
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T20:48:13.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.2.delta.facc772c-42ee-45f7-bb3b-10cbd8a38383.TID646.tmp
[2025-07-19T20:48:13.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 37.0 in stage 7.0 (TID 640). 5829 bytes result sent to driver
[2025-07-19T20:48:13.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 648) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 640) in 119 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:48:13.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 45.0 in stage 7.0 (TID 648)
[2025-07-19T20:48:13.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.2.delta.15d0b4bc-bf86-41d5-8377-b0b58a4ed621.TID641.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/2.delta
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/38/2.delta
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.2.delta.1a6dbb7f-c496-453a-8bb8-7ecedbe207aa.TID643.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/2.delta
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/40/2.delta
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.2.delta.78dc5f7d-efde-4627-ad0d-abbfc633d5e1.TID642.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/2.delta
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/39/2.delta
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T20:48:13.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.2.delta.c69d96a3-8806-4416-8da6-0d138444bad9.TID647.tmp
[2025-07-19T20:48:13.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T20:48:13.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T20:48:13.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/.1.065368ba-fc0c-4e2f-be2e-eb0783b5ccc5.tmp
[2025-07-19T20:48:13.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@788c9179
[2025-07-19T20:48:13.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 38.0 in stage 7.0 (TID 641). 5829 bytes result sent to driver
[2025-07-19T20:48:13.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45] for update
[2025-07-19T20:48:13.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 649) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 46.0 in stage 7.0 (TID 649)
[2025-07-19T20:48:13.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 641) in 101 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:48:13.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T20:48:13.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 39.0 in stage 7.0 (TID 642). 5829 bytes result sent to driver
[2025-07-19T20:48:13.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@233609ef
[2025-07-19T20:48:13.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 650) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T20:48:13.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 40.0 in stage 7.0 (TID 643). 5829 bytes result sent to driver
[2025-07-19T20:48:13.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 651) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 47.0 in stage 7.0 (TID 650)
[2025-07-19T20:48:13.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 48.0 in stage 7.0 (TID 651)
[2025-07-19T20:48:13.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46] for update
[2025-07-19T20:48:13.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 643) in 101 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:48:13.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 642) in 109 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:48:13.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:13.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15457bf3
[2025-07-19T20:48:13.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48] for update
[2025-07-19T20:48:13.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@226efe90
[2025-07-19T20:48:13.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47] for update
[2025-07-19T20:48:13.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.2.delta.805dcff1-73ec-4854-903b-6a86102ebc88.TID651.tmp
[2025-07-19T20:48:13.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.2.delta.782c1686-a9bc-4ada-8631-b313b8acbdd8.TID649.tmp
[2025-07-19T20:48:13.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.2.delta.9def3218-8966-4fdd-b991-2a46bd3ac7d5.TID648.tmp
[2025-07-19T20:48:13.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.2.delta.facc772c-42ee-45f7-bb3b-10cbd8a38383.TID646.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/2.delta
[2025-07-19T20:48:13.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/43/2.delta
[2025-07-19T20:48:13.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T20:48:13.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.2.delta.83ac2ad5-a811-42b5-b963-8a92cf2c2924.TID644.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/2.delta
[2025-07-19T20:48:13.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/41/2.delta
[2025-07-19T20:48:13.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T20:48:13.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.2.delta.f9ce9fdc-3cc5-4093-81f4-30d6ff9c7c5d.TID650.tmp
[2025-07-19T20:48:13.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T20:48:13.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 43.0 in stage 7.0 (TID 646). 5829 bytes result sent to driver
[2025-07-19T20:48:13.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.2.delta.695b4c16-60d4-4f9c-80ac-5f4e677816ed.TID645.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/2.delta
[2025-07-19T20:48:13.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/42/2.delta
[2025-07-19T20:48:13.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 652) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T20:48:13.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 646) in 94 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:48:13.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 49.0 in stage 7.0 (TID 652)
[2025-07-19T20:48:13.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T20:48:13.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 41.0 in stage 7.0 (TID 644). 5829 bytes result sent to driver
[2025-07-19T20:48:13.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 653) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T20:48:13.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 50.0 in stage 7.0 (TID 653)
[2025-07-19T20:48:13.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 42.0 in stage 7.0 (TID 645). 5829 bytes result sent to driver
[2025-07-19T20:48:13.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f064b2a
[2025-07-19T20:48:13.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 644) in 125 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:48:13.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49] for update
[2025-07-19T20:48:13.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 654) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 645) in 107 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:48:13.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.2.delta.c69d96a3-8806-4416-8da6-0d138444bad9.TID647.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/2.delta
[2025-07-19T20:48:13.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/44/2.delta
[2025-07-19T20:48:13.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 51.0 in stage 7.0 (TID 654)
[2025-07-19T20:48:13.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73117fd0
[2025-07-19T20:48:13.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50] for update
[2025-07-19T20:48:13.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T20:48:13.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@647174dd
[2025-07-19T20:48:13.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T20:48:13.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 44.0 in stage 7.0 (TID 647). 5829 bytes result sent to driver
[2025-07-19T20:48:13.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/.1.065368ba-fc0c-4e2f-be2e-eb0783b5ccc5.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/offsets/1
[2025-07-19T20:48:13.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752784740000,1752958093766,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:48:13.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51] for update
[2025-07-19T20:48:13.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 655) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 647) in 94 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:48:13.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 52.0 in stage 7.0 (TID 655)
[2025-07-19T20:48:13.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.2.delta.35ca819b-7207-4e25-b061-add9ae4a66d6.TID652.tmp
[2025-07-19T20:48:13.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.2.delta.8ad81630-de1b-4315-9af4-02d45514d770.TID653.tmp
[2025-07-19T20:48:13.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.2.delta.805dcff1-73ec-4854-903b-6a86102ebc88.TID651.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/2.delta
[2025-07-19T20:48:13.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/48/2.delta
[2025-07-19T20:48:13.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.2.delta.782c1686-a9bc-4ada-8631-b313b8acbdd8.TID649.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/2.delta
[2025-07-19T20:48:13.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/46/2.delta
[2025-07-19T20:48:13.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T20:48:13.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T20:48:13.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e57f5fa
[2025-07-19T20:48:13.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T20:48:13.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 48.0 in stage 7.0 (TID 651). 5829 bytes result sent to driver
[2025-07-19T20:48:13.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.2.delta.38b484dc-a8a4-4a94-a76e-adf1244b6ee0.TID654.tmp
[2025-07-19T20:48:13.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52] for update
[2025-07-19T20:48:13.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T20:48:13.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 46.0 in stage 7.0 (TID 649). 5829 bytes result sent to driver
[2025-07-19T20:48:13.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 656) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 657) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 54.0 in stage 7.0 (TID 657)
[2025-07-19T20:48:13.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 649) in 82 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:48:13.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 651) in 76 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:48:13.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 53.0 in stage 7.0 (TID 656)
[2025-07-19T20:48:13.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1415701f
[2025-07-19T20:48:13.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53] for update
[2025-07-19T20:48:13.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12e61271
[2025-07-19T20:48:13.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54] for update
[2025-07-19T20:48:13.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.2.delta.9def3218-8966-4fdd-b991-2a46bd3ac7d5.TID648.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/2.delta
[2025-07-19T20:48:13.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/45/2.delta
[2025-07-19T20:48:13.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T20:48:13.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.2.delta.747297d1-04b5-49ca-8944-c82ecd7fdc2c.TID657.tmp
[2025-07-19T20:48:13.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 45.0 in stage 7.0 (TID 648). 5829 bytes result sent to driver
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.2.delta.74391e9b-b15b-4577-af4b-6e2d512c2bc2.TID656.tmp
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 658) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.2.delta.f9ce9fdc-3cc5-4093-81f4-30d6ff9c7c5d.TID650.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/2.delta
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/47/2.delta
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 648) in 118 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 55.0 in stage 7.0 (TID 658)
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@158face
[2025-07-19T20:48:13.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55] for update
[2025-07-19T20:48:13.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.2.delta.35ca819b-7207-4e25-b061-add9ae4a66d6.TID652.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/2.delta
[2025-07-19T20:48:13.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/49/2.delta
[2025-07-19T20:48:13.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.2.delta.50c7d914-ad34-4b39-bd70-68cba97b33ea.TID655.tmp
[2025-07-19T20:48:13.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T20:48:13.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T20:48:13.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T20:48:13.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.2.delta.8ad81630-de1b-4315-9af4-02d45514d770.TID653.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/2.delta
[2025-07-19T20:48:13.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/50/2.delta
[2025-07-19T20:48:13.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T20:48:13.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.2.delta.b9a1e054-9866-4e1c-b711-18ef1f10639c.TID658.tmp
[2025-07-19T20:48:13.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T20:48:13.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 47.0 in stage 7.0 (TID 650). 5915 bytes result sent to driver
[2025-07-19T20:48:13.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 50.0 in stage 7.0 (TID 653). 5915 bytes result sent to driver
[2025-07-19T20:48:13.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 659) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 56.0 in stage 7.0 (TID 659)
[2025-07-19T20:48:13.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 660) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aa2faa4
[2025-07-19T20:48:13.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 57.0 in stage 7.0 (TID 660)
[2025-07-19T20:48:13.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 650) in 161 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:48:13.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 653) in 125 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:48:13.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56] for update
[2025-07-19T20:48:13.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:13.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 49.0 in stage 7.0 (TID 652). 5915 bytes result sent to driver
[2025-07-19T20:48:13.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.2.delta.38b484dc-a8a4-4a94-a76e-adf1244b6ee0.TID654.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/2.delta
[2025-07-19T20:48:13.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/51/2.delta
[2025-07-19T20:48:13.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 661) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 652) in 136 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:48:13.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T20:48:13.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:13.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T20:48:13.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 51.0 in stage 7.0 (TID 654). 5872 bytes result sent to driver
[2025-07-19T20:48:13.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 58.0 in stage 7.0 (TID 661)
[2025-07-19T20:48:13.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6521b43b
[2025-07-19T20:48:13.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 662) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 59.0 in stage 7.0 (TID 662)
[2025-07-19T20:48:13.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.2.delta.747297d1-04b5-49ca-8944-c82ecd7fdc2c.TID657.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/2.delta
[2025-07-19T20:48:13.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/54/2.delta
[2025-07-19T20:48:13.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 654) in 141 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:48:13.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T20:48:13.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:13.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57] for update
[2025-07-19T20:48:13.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30ae5a58
[2025-07-19T20:48:13.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO DataWritingSparkTask: Committed partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T20:48:13.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Finished task 54.0 in stage 7.0 (TID 657). 5872 bytes result sent to driver
[2025-07-19T20:48:13.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59] for update
[2025-07-19T20:48:13.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 663) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:13.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 657) in 114 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:48:13.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO Executor: Running task 60.0 in stage 7.0 (TID 663)
[2025-07-19T20:48:13.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5880af96
[2025-07-19T20:48:13.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58] for update
[2025-07-19T20:48:13.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:13.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:13.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:13.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.2.delta.20e3866b-ead9-43dc-8faa-02cbc37310e7.TID659.tmp
[2025-07-19T20:48:13.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67bf6003
[2025-07-19T20:48:13.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:13.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60] for update
[2025-07-19T20:48:14.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:14.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:14.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:14.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:13 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.2.delta.e1c90804-ecbd-44e1-930d-409214ee6bb9.TID660.tmp
[2025-07-19T20:48:14.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.2.delta.74391e9b-b15b-4577-af4b-6e2d512c2bc2.TID656.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/2.delta
[2025-07-19T20:48:14.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/53/2.delta
[2025-07-19T20:48:14.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T20:48:14.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.2.delta.50c7d914-ad34-4b39-bd70-68cba97b33ea.TID655.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/2.delta
[2025-07-19T20:48:14.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/52/2.delta
[2025-07-19T20:48:14.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.2.delta.58a59c87-341d-48c5-b609-62fbe07415c4.TID663.tmp
[2025-07-19T20:48:14.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T20:48:14.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T20:48:14.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 53.0 in stage 7.0 (TID 656). 5872 bytes result sent to driver
[2025-07-19T20:48:14.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 656) in 151 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:48:14.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 664) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 61.0 in stage 7.0 (TID 664)
[2025-07-19T20:48:14.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.2.delta.507e6d1b-94f8-4514-aa2a-00f83ecee821.TID662.tmp
[2025-07-19T20:48:14.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T20:48:14.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42019556
[2025-07-19T20:48:14.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 52.0 in stage 7.0 (TID 655). 5872 bytes result sent to driver
[2025-07-19T20:48:14.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61] for update
[2025-07-19T20:48:14.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 665) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 655) in 183 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:48:14.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 62.0 in stage 7.0 (TID 665)
[2025-07-19T20:48:14.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.2.delta.89be7044-25ec-48f2-9ab1-d93e23ce8180.TID661.tmp
[2025-07-19T20:48:14.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@675c6737
[2025-07-19T20:48:14.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62] for update
[2025-07-19T20:48:14.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.2.delta.db3a26cf-7dc8-4fdd-95a3-bdda477a3fc7.TID664.tmp
[2025-07-19T20:48:14.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.2.delta.a3ad53d6-5ed9-496e-83f6-b1a0dad2e35d.TID665.tmp
[2025-07-19T20:48:14.074+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.2.delta.b9a1e054-9866-4e1c-b711-18ef1f10639c.TID658.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/2.delta
[2025-07-19T20:48:14.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/55/2.delta
[2025-07-19T20:48:14.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 209.0 KiB, free 433.5 MiB)
[2025-07-19T20:48:14.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T20:48:14.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T20:48:14.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 8b44f3d35cfa:46433 in memory (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T20:48:14.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 55.0 in stage 7.0 (TID 658). 5872 bytes result sent to driver
[2025-07-19T20:48:14.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 666) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 658) in 223 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:48:14.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.5 MiB)
[2025-07-19T20:48:14.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 8b44f3d35cfa:46433 (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T20:48:14.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 63.0 in stage 7.0 (TID 666)
[2025-07-19T20:48:14.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO SparkContext: Created broadcast 15 from start at <unknown>:0
[2025-07-19T20:48:14.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.2.delta.20e3866b-ead9-43dc-8faa-02cbc37310e7.TID659.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/2.delta
[2025-07-19T20:48:14.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/56/2.delta
[2025-07-19T20:48:14.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 433.5 MiB)
[2025-07-19T20:48:14.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T20:48:14.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.5 MiB)
[2025-07-19T20:48:14.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.2.delta.e1c90804-ecbd-44e1-930d-409214ee6bb9.TID660.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/2.delta
[2025-07-19T20:48:14.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/57/2.delta
[2025-07-19T20:48:14.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 8b44f3d35cfa:46433 (size: 29.6 KiB, free: 434.2 MiB)
[2025-07-19T20:48:14.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T20:48:14.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO SparkContext: Created broadcast 16 from start at <unknown>:0
[2025-07-19T20:48:14.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:48:14.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:48:14.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T20:48:14.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bdc8532
[2025-07-19T20:48:14.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8b44f3d35cfa:46433 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T20:48:14.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T20:48:14.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.2.delta.58a59c87-341d-48c5-b609-62fbe07415c4.TID663.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/2.delta
[2025-07-19T20:48:14.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Registering RDD 33 (start at <unknown>:0) as input to shuffle 4
[2025-07-19T20:48:14.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/60/2.delta
[2025-07-19T20:48:14.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63] for update
[2025-07-19T20:48:14.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 56.0 in stage 7.0 (TID 659). 5829 bytes result sent to driver
[2025-07-19T20:48:14.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T20:48:14.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Got job 4 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:48:14.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Final stage: ResultStage 9 (start at <unknown>:0)
[2025-07-19T20:48:14.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-19T20:48:14.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 57.0 in stage 7.0 (TID 660). 5829 bytes result sent to driver
[2025-07-19T20:48:14.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.2.delta.89be7044-25ec-48f2-9ab1-d93e23ce8180.TID661.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/2.delta
[2025-07-19T20:48:14.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/58/2.delta
[2025-07-19T20:48:14.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T20:48:14.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 667) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 668) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 659) in 194 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:48:14.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 660) in 190 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:48:14.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 65.0 in stage 7.0 (TID 668)
[2025-07-19T20:48:14.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T20:48:14.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 60.0 in stage 7.0 (TID 663). 5829 bytes result sent to driver
[2025-07-19T20:48:14.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 669) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 66.0 in stage 7.0 (TID 669)
[2025-07-19T20:48:14.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 663) in 157 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:48:14.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 64.0 in stage 7.0 (TID 667)
[2025-07-19T20:48:14.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Missing parents: List()
[2025-07-19T20:48:14.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T20:48:14.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Submitting ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:48:14.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 58.0 in stage 7.0 (TID 661). 5829 bytes result sent to driver
[2025-07-19T20:48:14.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 670) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 661) in 184 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:48:14.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 67.0 in stage 7.0 (TID 670)
[2025-07-19T20:48:14.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e81b9f
[2025-07-19T20:48:14.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65] for update
[2025-07-19T20:48:14.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.158+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 8b44f3d35cfa:46433 in memory (size: 19.9 KiB, free: 434.3 MiB)
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65fe7790
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64] for update
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@496989cc
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66] for update
[2025-07-19T20:48:14.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d7b9f2
[2025-07-19T20:48:14.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67] for update
[2025-07-19T20:48:14.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.2.delta.9927c25d-28b3-480b-ae53-94cc371bb5ae.TID666.tmp
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.2.delta.db3a26cf-7dc8-4fdd-95a3-bdda477a3fc7.TID664.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/2.delta
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/61/2.delta
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.2.delta.507e6d1b-94f8-4514-aa2a-00f83ecee821.TID662.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/2.delta
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/59/2.delta
[2025-07-19T20:48:14.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T20:48:14.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.2.delta.5cf6924a-83b4-4ff6-9fb7-c0aa0d2b8041.TID667.tmp
[2025-07-19T20:48:14.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.2.delta.0a7314d9-6dde-40cc-8f6d-296e1a810775.TID668.tmp
[2025-07-19T20:48:14.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T20:48:14.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 61.0 in stage 7.0 (TID 664). 5829 bytes result sent to driver
[2025-07-19T20:48:14.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.2.delta.a3ad53d6-5ed9-496e-83f6-b1a0dad2e35d.TID665.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/2.delta
[2025-07-19T20:48:14.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/62/2.delta
[2025-07-19T20:48:14.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T20:48:14.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.2.delta.cfb19079-42e4-440e-97e9-a52dd03b54e3.TID669.tmp
[2025-07-19T20:48:14.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 59.0 in stage 7.0 (TID 662). 5829 bytes result sent to driver
[2025-07-19T20:48:14.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 671) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 672) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 664) in 154 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 68.0 in stage 7.0 (TID 671)
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 662) in 203 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 69.0 in stage 7.0 (TID 672)
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.2.delta.bdceeffe-a3fb-4d34-88f7-042150438b7b.TID670.tmp
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cad3775
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 62.0 in stage 7.0 (TID 665). 5829 bytes result sent to driver
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 673) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69] for update
[2025-07-19T20:48:14.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 70.0 in stage 7.0 (TID 673)
[2025-07-19T20:48:14.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 665) in 155 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:48:14.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79432764
[2025-07-19T20:48:14.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68] for update
[2025-07-19T20:48:14.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15f86e18
[2025-07-19T20:48:14.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 32.0 KiB, free 433.7 MiB)
[2025-07-19T20:48:14.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70] for update
[2025-07-19T20:48:14.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.7 MiB)
[2025-07-19T20:48:14.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 8b44f3d35cfa:46433 (size: 15.9 KiB, free: 434.2 MiB)
[2025-07-19T20:48:14.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:48:14.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:48:14.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSchedulerImpl: Adding task set 9.0 with 200 tasks resource profile 0
[2025-07-19T20:48:14.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.2.delta.fae5e3d9-ba09-4c7e-a70b-beb3e53b0d6e.TID671.tmp
[2025-07-19T20:48:14.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.2.delta.2a5faa3e-aea0-4578-bfd9-7637141a16f1.TID673.tmp
[2025-07-19T20:48:14.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.2.delta.5cf6924a-83b4-4ff6-9fb7-c0aa0d2b8041.TID667.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/2.delta
[2025-07-19T20:48:14.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/64/2.delta
[2025-07-19T20:48:14.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T20:48:14.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.2.delta.783c6333-97b4-437a-a81b-efef9d962344.TID672.tmp
[2025-07-19T20:48:14.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T20:48:14.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 64.0 in stage 7.0 (TID 667). 5829 bytes result sent to driver
[2025-07-19T20:48:14.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 674) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 71.0 in stage 7.0 (TID 674)
[2025-07-19T20:48:14.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 667) in 83 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:48:14.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@514d1684
[2025-07-19T20:48:14.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71] for update
[2025-07-19T20:48:14.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.2.delta.9927c25d-28b3-480b-ae53-94cc371bb5ae.TID666.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/2.delta
[2025-07-19T20:48:14.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/63/2.delta
[2025-07-19T20:48:14.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T20:48:14.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.2.delta.cfb19079-42e4-440e-97e9-a52dd03b54e3.TID669.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/2.delta
[2025-07-19T20:48:14.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/66/2.delta
[2025-07-19T20:48:14.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T20:48:14.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T20:48:14.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 63.0 in stage 7.0 (TID 666). 5829 bytes result sent to driver
[2025-07-19T20:48:14.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 675) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 666) in 123 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:48:14.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 72.0 in stage 7.0 (TID 675)
[2025-07-19T20:48:14.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T20:48:14.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 66.0 in stage 7.0 (TID 669). 5829 bytes result sent to driver
[2025-07-19T20:48:14.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.2.delta.bdceeffe-a3fb-4d34-88f7-042150438b7b.TID670.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/2.delta
[2025-07-19T20:48:14.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/67/2.delta
[2025-07-19T20:48:14.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.2.delta.0a7314d9-6dde-40cc-8f6d-296e1a810775.TID668.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/2.delta
[2025-07-19T20:48:14.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/65/2.delta
[2025-07-19T20:48:14.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T20:48:14.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T20:48:14.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 676) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 669) in 99 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:48:14.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 73.0 in stage 7.0 (TID 676)
[2025-07-19T20:48:14.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67833087
[2025-07-19T20:48:14.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72] for update
[2025-07-19T20:48:14.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T20:48:14.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 67.0 in stage 7.0 (TID 670). 5829 bytes result sent to driver
[2025-07-19T20:48:14.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 677) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 670) in 104 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:48:14.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T20:48:14.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 65.0 in stage 7.0 (TID 668). 5829 bytes result sent to driver
[2025-07-19T20:48:14.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 74.0 in stage 7.0 (TID 677)
[2025-07-19T20:48:14.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 678) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 668) in 113 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:48:14.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74f357db
[2025-07-19T20:48:14.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73] for update
[2025-07-19T20:48:14.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 75.0 in stage 7.0 (TID 678)
[2025-07-19T20:48:14.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a36ccaa
[2025-07-19T20:48:14.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74] for update
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.2.delta.1ab6461d-c358-4649-b9e1-82a2582aeb9c.TID674.tmp
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48cc9603
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75] for update
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.2.delta.fae5e3d9-ba09-4c7e-a70b-beb3e53b0d6e.TID671.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/2.delta
[2025-07-19T20:48:14.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/68/2.delta
[2025-07-19T20:48:14.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T20:48:14.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T20:48:14.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 68.0 in stage 7.0 (TID 671). 5829 bytes result sent to driver
[2025-07-19T20:48:14.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 679) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.2.delta.9a96436e-9ece-4962-8153-7a21e77512a6.TID675.tmp
[2025-07-19T20:48:14.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 76.0 in stage 7.0 (TID 679)
[2025-07-19T20:48:14.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 671) in 91 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:48:14.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.2.delta.3693580c-bf47-4c5a-85dd-ddf31ce88732.TID676.tmp
[2025-07-19T20:48:14.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dc47636
[2025-07-19T20:48:14.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76] for update
[2025-07-19T20:48:14.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.2.delta.2a5faa3e-aea0-4578-bfd9-7637141a16f1.TID673.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/2.delta
[2025-07-19T20:48:14.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/70/2.delta
[2025-07-19T20:48:14.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T20:48:14.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.2.delta.83a97865-6edf-46af-b084-1fd017f61fdf.TID677.tmp
[2025-07-19T20:48:14.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T20:48:14.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 70.0 in stage 7.0 (TID 673). 5829 bytes result sent to driver
[2025-07-19T20:48:14.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 680) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 673) in 97 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:48:14.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 77.0 in stage 7.0 (TID 680)
[2025-07-19T20:48:14.307+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.2.delta.9f5d7e26-9f00-4bf6-b4b4-d2432f10d285.TID678.tmp
[2025-07-19T20:48:14.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e514a5f
[2025-07-19T20:48:14.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.2.delta.4537d3a3-9c0d-438d-978c-e525fa40d929.TID679.tmp
[2025-07-19T20:48:14.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.2.delta.783c6333-97b4-437a-a81b-efef9d962344.TID672.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/2.delta
[2025-07-19T20:48:14.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/69/2.delta
[2025-07-19T20:48:14.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T20:48:14.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77] for update
[2025-07-19T20:48:14.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T20:48:14.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 69.0 in stage 7.0 (TID 672). 5829 bytes result sent to driver
[2025-07-19T20:48:14.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 681) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 672) in 120 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:48:14.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 78.0 in stage 7.0 (TID 681)
[2025-07-19T20:48:14.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56960bae
[2025-07-19T20:48:14.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78] for update
[2025-07-19T20:48:14.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.2.delta.1bad110e-db82-42cd-98ec-9d039e086823.TID680.tmp
[2025-07-19T20:48:14.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.2.delta.1ab6461d-c358-4649-b9e1-82a2582aeb9c.TID674.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/2.delta
[2025-07-19T20:48:14.334+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/71/2.delta
[2025-07-19T20:48:14.338+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T20:48:14.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.2.delta.857daaa6-547a-43df-ab0a-6060d3ab2ab7.TID681.tmp
[2025-07-19T20:48:14.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T20:48:14.341+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 71.0 in stage 7.0 (TID 674). 5829 bytes result sent to driver
[2025-07-19T20:48:14.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.2.delta.9a96436e-9ece-4962-8153-7a21e77512a6.TID675.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/2.delta
[2025-07-19T20:48:14.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/72/2.delta
[2025-07-19T20:48:14.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 682) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.346+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 674) in 104 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:48:14.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 79.0 in stage 7.0 (TID 682)
[2025-07-19T20:48:14.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T20:48:14.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.2.delta.3693580c-bf47-4c5a-85dd-ddf31ce88732.TID676.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/2.delta
[2025-07-19T20:48:14.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/73/2.delta
[2025-07-19T20:48:14.353+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T20:48:14.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ceea82f
[2025-07-19T20:48:14.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79] for update
[2025-07-19T20:48:14.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.2.delta.83a97865-6edf-46af-b084-1fd017f61fdf.TID677.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/2.delta
[2025-07-19T20:48:14.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/74/2.delta
[2025-07-19T20:48:14.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T20:48:14.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T20:48:14.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 72.0 in stage 7.0 (TID 675). 5829 bytes result sent to driver
[2025-07-19T20:48:14.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T20:48:14.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 683) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 73.0 in stage 7.0 (TID 676). 5829 bytes result sent to driver
[2025-07-19T20:48:14.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 80.0 in stage 7.0 (TID 683)
[2025-07-19T20:48:14.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T20:48:14.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:14.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 675) in 105 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:48:14.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34aa8e65
[2025-07-19T20:48:14.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80] for update
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 684) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 81.0 in stage 7.0 (TID 684)
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 676) in 106 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 74.0 in stage 7.0 (TID 677). 5829 bytes result sent to driver
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 677) in 104 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a41afac
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 685) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81] for update
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 82.0 in stage 7.0 (TID 685)
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.2.delta.9f5d7e26-9f00-4bf6-b4b4-d2432f10d285.TID678.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/2.delta
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/75/2.delta
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d82e151
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82] for update
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.2.delta.88f06b07-891d-45eb-92b3-7c6c5495a090.TID682.tmp
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.2.delta.4537d3a3-9c0d-438d-978c-e525fa40d929.TID679.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/2.delta
[2025-07-19T20:48:14.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/76/2.delta
[2025-07-19T20:48:14.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.2.delta.1bad110e-db82-42cd-98ec-9d039e086823.TID680.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/2.delta
[2025-07-19T20:48:14.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/77/2.delta
[2025-07-19T20:48:14.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T20:48:14.382+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T20:48:14.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T20:48:14.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 75.0 in stage 7.0 (TID 678). 5829 bytes result sent to driver
[2025-07-19T20:48:14.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 686) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 678) in 115 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:48:14.384+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 83.0 in stage 7.0 (TID 686)
[2025-07-19T20:48:14.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T20:48:14.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 76.0 in stage 7.0 (TID 679). 5829 bytes result sent to driver
[2025-07-19T20:48:14.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.2.delta.774b6fc4-7b1b-4677-a5bb-5649b03866de.TID684.tmp
[2025-07-19T20:48:14.387+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.2.delta.f586abaf-4260-4f5e-b622-ea8868a9b7ae.TID685.tmp
[2025-07-19T20:48:14.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 687) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 679) in 102 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:48:14.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 84.0 in stage 7.0 (TID 687)
[2025-07-19T20:48:14.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T20:48:14.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 77.0 in stage 7.0 (TID 680). 5829 bytes result sent to driver
[2025-07-19T20:48:14.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a1b280
[2025-07-19T20:48:14.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 688) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 85.0 in stage 7.0 (TID 688)
[2025-07-19T20:48:14.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83] for update
[2025-07-19T20:48:14.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.2.delta.a5934cb3-3470-4c3d-9ef4-d6cce2a0fd77.TID683.tmp
[2025-07-19T20:48:14.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3031203d
[2025-07-19T20:48:14.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84] for update
[2025-07-19T20:48:14.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e3baa53
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 680) in 97 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85] for update
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.2.delta.c072f960-0c7f-4a51-892e-6d869366da9d.TID686.tmp
[2025-07-19T20:48:14.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.2.delta.728ccf14-8b20-4164-aff9-223cad8d300d.TID688.tmp
[2025-07-19T20:48:14.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.2.delta.572a1fae-55a4-432e-8f03-efd0d2b4e14d.TID687.tmp
[2025-07-19T20:48:14.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.2.delta.857daaa6-547a-43df-ab0a-6060d3ab2ab7.TID681.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/2.delta
[2025-07-19T20:48:14.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/78/2.delta
[2025-07-19T20:48:14.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T20:48:14.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T20:48:14.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 78.0 in stage 7.0 (TID 681). 5829 bytes result sent to driver
[2025-07-19T20:48:14.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 689) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 681) in 121 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:48:14.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 86.0 in stage 7.0 (TID 689)
[2025-07-19T20:48:14.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e0e40dd
[2025-07-19T20:48:14.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86] for update
[2025-07-19T20:48:14.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.2.delta.88f06b07-891d-45eb-92b3-7c6c5495a090.TID682.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/2.delta
[2025-07-19T20:48:14.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/79/2.delta
[2025-07-19T20:48:14.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T20:48:14.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.2.delta.f586abaf-4260-4f5e-b622-ea8868a9b7ae.TID685.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/2.delta
[2025-07-19T20:48:14.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/82/2.delta
[2025-07-19T20:48:14.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T20:48:14.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T20:48:14.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 79.0 in stage 7.0 (TID 682). 5829 bytes result sent to driver
[2025-07-19T20:48:14.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 690) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 682) in 115 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:48:14.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 87.0 in stage 7.0 (TID 690)
[2025-07-19T20:48:14.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.2.delta.5de38c86-aefa-4a2e-b276-0941378767a4.TID689.tmp
[2025-07-19T20:48:14.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T20:48:14.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 82.0 in stage 7.0 (TID 685). 5829 bytes result sent to driver
[2025-07-19T20:48:14.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.2.delta.a5934cb3-3470-4c3d-9ef4-d6cce2a0fd77.TID683.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/2.delta
[2025-07-19T20:48:14.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/80/2.delta
[2025-07-19T20:48:14.438+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 685) in 91 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:48:14.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 691) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 88.0 in stage 7.0 (TID 691)
[2025-07-19T20:48:14.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.2.delta.774b6fc4-7b1b-4677-a5bb-5649b03866de.TID684.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/2.delta
[2025-07-19T20:48:14.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/81/2.delta
[2025-07-19T20:48:14.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T20:48:14.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T20:48:14.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@625dc946
[2025-07-19T20:48:14.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87] for update
[2025-07-19T20:48:14.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T20:48:14.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56260e0b
[2025-07-19T20:48:14.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88] for update
[2025-07-19T20:48:14.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T20:48:14.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 81.0 in stage 7.0 (TID 684). 5829 bytes result sent to driver
[2025-07-19T20:48:14.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 692) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 89.0 in stage 7.0 (TID 692)
[2025-07-19T20:48:14.450+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.2.delta.572a1fae-55a4-432e-8f03-efd0d2b4e14d.TID687.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/2.delta
[2025-07-19T20:48:14.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/84/2.delta
[2025-07-19T20:48:14.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 80.0 in stage 7.0 (TID 683). 5829 bytes result sent to driver
[2025-07-19T20:48:14.456+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T20:48:14.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 693) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 90.0 in stage 7.0 (TID 693)
[2025-07-19T20:48:14.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 683) in 122 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:48:14.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 684) in 117 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:48:14.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T20:48:14.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@666956c3
[2025-07-19T20:48:14.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89] for update
[2025-07-19T20:48:14.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@180e30c3
[2025-07-19T20:48:14.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90] for update
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.2.delta.c072f960-0c7f-4a51-892e-6d869366da9d.TID686.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/2.delta
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/83/2.delta
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 84.0 in stage 7.0 (TID 687). 5872 bytes result sent to driver
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 694) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 687) in 106 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 91.0 in stage 7.0 (TID 694)
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T20:48:14.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45fad06a
[2025-07-19T20:48:14.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91] for update
[2025-07-19T20:48:14.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.2.delta.edb7ce8c-4362-41e3-b209-2d125f974ac4.TID690.tmp
[2025-07-19T20:48:14.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.2.delta.728ccf14-8b20-4164-aff9-223cad8d300d.TID688.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/2.delta
[2025-07-19T20:48:14.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/85/2.delta
[2025-07-19T20:48:14.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 83.0 in stage 7.0 (TID 686). 5915 bytes result sent to driver
[2025-07-19T20:48:14.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 695) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 686) in 126 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:48:14.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T20:48:14.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 92.0 in stage 7.0 (TID 695)
[2025-07-19T20:48:14.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.2.delta.ff592ade-ccef-4704-8725-a48b69e50511.TID693.tmp
[2025-07-19T20:48:14.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.2.delta.d21e8e5d-fceb-4faf-ac49-457c7b91c1cd.TID691.tmp
[2025-07-19T20:48:14.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36801194
[2025-07-19T20:48:14.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92] for update
[2025-07-19T20:48:14.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T20:48:14.509+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 85.0 in stage 7.0 (TID 688). 5872 bytes result sent to driver
[2025-07-19T20:48:14.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.2.delta.4c4050be-71fb-4635-a9a0-90984bd0d34c.TID692.tmp
[2025-07-19T20:48:14.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 696) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 688) in 124 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:48:14.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 93.0 in stage 7.0 (TID 696)
[2025-07-19T20:48:14.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37a80ffb
[2025-07-19T20:48:14.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93] for update
[2025-07-19T20:48:14.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.2.delta.f9a44d97-dbe3-443c-a88c-2ca438d3ea9d.TID694.tmp
[2025-07-19T20:48:14.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.2.delta.d92174ef-8696-4ef9-88d2-eeb8ee9dfd54.TID695.tmp
[2025-07-19T20:48:14.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.2.delta.5de38c86-aefa-4a2e-b276-0941378767a4.TID689.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/2.delta
[2025-07-19T20:48:14.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/86/2.delta
[2025-07-19T20:48:14.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T20:48:14.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T20:48:14.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.2.delta.d1ce8a15-c2a0-4638-b40f-4d1e488dc2f4.TID696.tmp
[2025-07-19T20:48:14.526+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 86.0 in stage 7.0 (TID 689). 5872 bytes result sent to driver
[2025-07-19T20:48:14.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 697) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 689) in 121 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:48:14.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 94.0 in stage 7.0 (TID 697)
[2025-07-19T20:48:14.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.536+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@556a7dd2
[2025-07-19T20:48:14.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94] for update
[2025-07-19T20:48:14.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.2.delta.d21e8e5d-fceb-4faf-ac49-457c7b91c1cd.TID691.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/2.delta
[2025-07-19T20:48:14.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/88/2.delta
[2025-07-19T20:48:14.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T20:48:14.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.2.delta.edb7ce8c-4362-41e3-b209-2d125f974ac4.TID690.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/2.delta
[2025-07-19T20:48:14.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/87/2.delta
[2025-07-19T20:48:14.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T20:48:14.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.2.delta.ff592ade-ccef-4704-8725-a48b69e50511.TID693.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/2.delta
[2025-07-19T20:48:14.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/90/2.delta
[2025-07-19T20:48:14.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T20:48:14.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 88.0 in stage 7.0 (TID 691). 5872 bytes result sent to driver
[2025-07-19T20:48:14.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T20:48:14.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 698) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 95.0 in stage 7.0 (TID 698)
[2025-07-19T20:48:14.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 691) in 112 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:48:14.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c1bc238
[2025-07-19T20:48:14.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95] for update
[2025-07-19T20:48:14.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.2.delta.4c4050be-71fb-4635-a9a0-90984bd0d34c.TID692.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/2.delta
[2025-07-19T20:48:14.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T20:48:14.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/89/2.delta
[2025-07-19T20:48:14.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.2.delta.e6dc6e13-55d9-464b-b46d-1a032d6bd067.TID697.tmp
[2025-07-19T20:48:14.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 87.0 in stage 7.0 (TID 690). 5915 bytes result sent to driver
[2025-07-19T20:48:14.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T20:48:14.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T20:48:14.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 90.0 in stage 7.0 (TID 693). 5872 bytes result sent to driver
[2025-07-19T20:48:14.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 690) in 125 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:48:14.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 699) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 700) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 97.0 in stage 7.0 (TID 700)
[2025-07-19T20:48:14.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 693) in 104 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:48:14.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T20:48:14.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 89.0 in stage 7.0 (TID 692). 5872 bytes result sent to driver
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 96.0 in stage 7.0 (TID 699)
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 701) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 692) in 117 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 98.0 in stage 7.0 (TID 701)
[2025-07-19T20:48:14.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dac21b8
[2025-07-19T20:48:14.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97] for update
[2025-07-19T20:48:14.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.2.delta.f9a44d97-dbe3-443c-a88c-2ca438d3ea9d.TID694.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/2.delta
[2025-07-19T20:48:14.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/91/2.delta
[2025-07-19T20:48:14.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T20:48:14.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:14.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c40cb2b
[2025-07-19T20:48:14.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.2.delta.8cfc2295-c579-43f7-bf87-677b1a6f46cc.TID698.tmp
[2025-07-19T20:48:14.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T20:48:14.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 91.0 in stage 7.0 (TID 694). 5872 bytes result sent to driver
[2025-07-19T20:48:14.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98] for update
[2025-07-19T20:48:14.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 702) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 99.0 in stage 7.0 (TID 702)
[2025-07-19T20:48:14.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 694) in 112 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:48:14.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bbcccd3
[2025-07-19T20:48:14.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96] for update
[2025-07-19T20:48:14.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7948bfb7
[2025-07-19T20:48:14.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99] for update
[2025-07-19T20:48:14.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.2.delta.5664aab6-10d0-479e-9746-3f74a37c5d10.TID700.tmp
[2025-07-19T20:48:14.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.2.delta.d92174ef-8696-4ef9-88d2-eeb8ee9dfd54.TID695.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/2.delta
[2025-07-19T20:48:14.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/92/2.delta
[2025-07-19T20:48:14.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T20:48:14.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.2.delta.513f396b-b6d5-4606-8b6a-9fc0712fe6ec.TID701.tmp
[2025-07-19T20:48:14.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.2.delta.d1ce8a15-c2a0-4638-b40f-4d1e488dc2f4.TID696.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/2.delta
[2025-07-19T20:48:14.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/93/2.delta
[2025-07-19T20:48:14.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T20:48:14.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T20:48:14.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 92.0 in stage 7.0 (TID 695). 5872 bytes result sent to driver
[2025-07-19T20:48:14.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 703) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 100.0 in stage 7.0 (TID 703)
[2025-07-19T20:48:14.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.2.delta.d435eecd-69ba-4b50-a09d-35a894a9708c.TID699.tmp
[2025-07-19T20:48:14.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 695) in 115 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:48:14.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T20:48:14.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 93.0 in stage 7.0 (TID 696). 5872 bytes result sent to driver
[2025-07-19T20:48:14.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 704) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 696) in 109 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:48:14.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 101.0 in stage 7.0 (TID 704)
[2025-07-19T20:48:14.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.2.delta.1172698e-62b9-4e91-80c1-99f2a2cf8225.TID702.tmp
[2025-07-19T20:48:14.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@258b0f9d
[2025-07-19T20:48:14.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101] for update
[2025-07-19T20:48:14.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13956124
[2025-07-19T20:48:14.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100] for update
[2025-07-19T20:48:14.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.2.delta.e6dc6e13-55d9-464b-b46d-1a032d6bd067.TID697.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/2.delta
[2025-07-19T20:48:14.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/94/2.delta
[2025-07-19T20:48:14.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T20:48:14.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.2.delta.9996e2eb-4466-4400-8c25-d9313ad52919.TID704.tmp
[2025-07-19T20:48:14.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.2.delta.35419474-5bea-47b5-87e1-eb6e4988bf69.TID703.tmp
[2025-07-19T20:48:14.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.2.delta.8cfc2295-c579-43f7-bf87-677b1a6f46cc.TID698.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/2.delta
[2025-07-19T20:48:14.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/95/2.delta
[2025-07-19T20:48:14.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T20:48:14.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T20:48:14.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 94.0 in stage 7.0 (TID 697). 5872 bytes result sent to driver
[2025-07-19T20:48:14.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 705) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 697) in 98 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:48:14.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T20:48:14.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 102.0 in stage 7.0 (TID 705)
[2025-07-19T20:48:14.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 95.0 in stage 7.0 (TID 698). 5872 bytes result sent to driver
[2025-07-19T20:48:14.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 706) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 698) in 84 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:48:14.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 103.0 in stage 7.0 (TID 706)
[2025-07-19T20:48:14.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.2.delta.5664aab6-10d0-479e-9746-3f74a37c5d10.TID700.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/2.delta
[2025-07-19T20:48:14.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/97/2.delta
[2025-07-19T20:48:14.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T20:48:14.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@374fa5
[2025-07-19T20:48:14.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.635+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102] for update
[2025-07-19T20:48:14.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.2.delta.513f396b-b6d5-4606-8b6a-9fc0712fe6ec.TID701.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/2.delta
[2025-07-19T20:48:14.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/98/2.delta
[2025-07-19T20:48:14.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T20:48:14.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d59de0
[2025-07-19T20:48:14.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T20:48:14.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 97.0 in stage 7.0 (TID 700). 5872 bytes result sent to driver
[2025-07-19T20:48:14.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103] for update
[2025-07-19T20:48:14.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 707) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 104.0 in stage 7.0 (TID 707)
[2025-07-19T20:48:14.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T20:48:14.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 98.0 in stage 7.0 (TID 701). 5829 bytes result sent to driver
[2025-07-19T20:48:14.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 700) in 89 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:48:14.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64be240b
[2025-07-19T20:48:14.657+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 708) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 105.0 in stage 7.0 (TID 708)
[2025-07-19T20:48:14.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104] for update
[2025-07-19T20:48:14.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.2.delta.d435eecd-69ba-4b50-a09d-35a894a9708c.TID699.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/2.delta
[2025-07-19T20:48:14.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/96/2.delta
[2025-07-19T20:48:14.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 701) in 83 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:48:14.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T20:48:14.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d7c05c1
[2025-07-19T20:48:14.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.2.delta.23b3906c-a146-4b26-8bb0-6db6391e02fc.TID706.tmp
[2025-07-19T20:48:14.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105] for update
[2025-07-19T20:48:14.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T20:48:14.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 96.0 in stage 7.0 (TID 699). 5872 bytes result sent to driver
[2025-07-19T20:48:14.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 709) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 106.0 in stage 7.0 (TID 709)
[2025-07-19T20:48:14.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.2.delta.1172698e-62b9-4e91-80c1-99f2a2cf8225.TID702.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/2.delta
[2025-07-19T20:48:14.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/99/2.delta
[2025-07-19T20:48:14.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.2.delta.a907e92f-e3ee-4992-a577-274891eeac8b.TID705.tmp
[2025-07-19T20:48:14.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T20:48:14.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 699) in 100 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:48:14.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42421720
[2025-07-19T20:48:14.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106] for update
[2025-07-19T20:48:14.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.2.delta.9996e2eb-4466-4400-8c25-d9313ad52919.TID704.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/2.delta
[2025-07-19T20:48:14.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/101/2.delta
[2025-07-19T20:48:14.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T20:48:14.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T20:48:14.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 99.0 in stage 7.0 (TID 702). 5829 bytes result sent to driver
[2025-07-19T20:48:14.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 710) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 702) in 92 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:48:14.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.2.delta.414aa8b8-812f-4232-baf4-5ca90ceaa9db.TID708.tmp
[2025-07-19T20:48:14.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.2.delta.c5192bd7-52fc-47a0-886c-1c0b6b7bf124.TID707.tmp
[2025-07-19T20:48:14.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 107.0 in stage 7.0 (TID 710)
[2025-07-19T20:48:14.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T20:48:14.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 101.0 in stage 7.0 (TID 704). 5829 bytes result sent to driver
[2025-07-19T20:48:14.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 711) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 108.0 in stage 7.0 (TID 711)
[2025-07-19T20:48:14.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 704) in 73 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:48:14.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.2.delta.35419474-5bea-47b5-87e1-eb6e4988bf69.TID703.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/2.delta
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/100/2.delta
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4aa1672c
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.2.delta.d995b0d6-c21b-4d9e-aa05-e441a716ca73.TID709.tmp
[2025-07-19T20:48:14.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cc54fb2
[2025-07-19T20:48:14.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107] for update
[2025-07-19T20:48:14.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108] for update
[2025-07-19T20:48:14.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T20:48:14.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 100.0 in stage 7.0 (TID 703). 5829 bytes result sent to driver
[2025-07-19T20:48:14.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.2.delta.3779755d-2024-4ff1-97df-6f9645a917e1.TID710.tmp
[2025-07-19T20:48:14.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 712) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 109.0 in stage 7.0 (TID 712)
[2025-07-19T20:48:14.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 703) in 94 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:48:14.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@340abd76
[2025-07-19T20:48:14.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109] for update
[2025-07-19T20:48:14.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.2.delta.d327f790-bab3-41b3-a379-d4a418808c58.TID711.tmp
[2025-07-19T20:48:14.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.2.delta.23b3906c-a146-4b26-8bb0-6db6391e02fc.TID706.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/2.delta
[2025-07-19T20:48:14.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/103/2.delta
[2025-07-19T20:48:14.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T20:48:14.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T20:48:14.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 103.0 in stage 7.0 (TID 706). 5829 bytes result sent to driver
[2025-07-19T20:48:14.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 713) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 110.0 in stage 7.0 (TID 713)
[2025-07-19T20:48:14.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 706) in 70 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:48:14.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.2.delta.a907e92f-e3ee-4992-a577-274891eeac8b.TID705.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/2.delta
[2025-07-19T20:48:14.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/102/2.delta
[2025-07-19T20:48:14.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@204ec59b
[2025-07-19T20:48:14.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T20:48:14.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.2.delta.94cc11de-2cc0-47d8-9d1b-0a3bff4be333.TID712.tmp
[2025-07-19T20:48:14.713+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110] for update
[2025-07-19T20:48:14.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T20:48:14.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 102.0 in stage 7.0 (TID 705). 5829 bytes result sent to driver
[2025-07-19T20:48:14.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 714) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.719+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 705) in 85 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:48:14.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 111.0 in stage 7.0 (TID 714)
[2025-07-19T20:48:14.722+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.2.delta.414aa8b8-812f-4232-baf4-5ca90ceaa9db.TID708.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/2.delta
[2025-07-19T20:48:14.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43286385
[2025-07-19T20:48:14.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/105/2.delta
[2025-07-19T20:48:14.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111] for update
[2025-07-19T20:48:14.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T20:48:14.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.2.delta.c5192bd7-52fc-47a0-886c-1c0b6b7bf124.TID707.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/2.delta
[2025-07-19T20:48:14.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/104/2.delta
[2025-07-19T20:48:14.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.2.delta.d995b0d6-c21b-4d9e-aa05-e441a716ca73.TID709.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/2.delta
[2025-07-19T20:48:14.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/106/2.delta
[2025-07-19T20:48:14.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T20:48:14.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T20:48:14.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.2.delta.9263a295-5412-45cd-981b-a8e853f47714.TID713.tmp
[2025-07-19T20:48:14.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T20:48:14.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 105.0 in stage 7.0 (TID 708). 5829 bytes result sent to driver
[2025-07-19T20:48:14.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 715) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 112.0 in stage 7.0 (TID 715)
[2025-07-19T20:48:14.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 708) in 79 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:48:14.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T20:48:14.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 106.0 in stage 7.0 (TID 709). 5829 bytes result sent to driver
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 104.0 in stage 7.0 (TID 707). 5829 bytes result sent to driver
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@354d0129
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 716) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 717) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 113.0 in stage 7.0 (TID 716)
[2025-07-19T20:48:14.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 707) in 87 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:48:14.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 709) in 73 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:48:14.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112] for update
[2025-07-19T20:48:14.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 114.0 in stage 7.0 (TID 717)
[2025-07-19T20:48:14.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.2.delta.3779755d-2024-4ff1-97df-6f9645a917e1.TID710.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/2.delta
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/107/2.delta
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T20:48:14.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@742b03c3
[2025-07-19T20:48:14.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114] for update
[2025-07-19T20:48:14.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 107.0 in stage 7.0 (TID 710). 5829 bytes result sent to driver
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.2.delta.546d934c-5cfa-498c-a7b4-024ad41c1328.TID714.tmp
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.2.delta.08f70919-f534-4fab-aa2a-3d7a863651eb.TID715.tmp
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.2.delta.d327f790-bab3-41b3-a379-d4a418808c58.TID711.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/2.delta
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/108/2.delta
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 718) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 710) in 73 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 115.0 in stage 7.0 (TID 718)
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54821fce
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113] for update
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T20:48:14.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.746+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5299003d
[2025-07-19T20:48:14.746+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T20:48:14.746+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 108.0 in stage 7.0 (TID 711). 5829 bytes result sent to driver
[2025-07-19T20:48:14.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 719) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.747+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115] for update
[2025-07-19T20:48:14.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 711) in 77 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:48:14.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 116.0 in stage 7.0 (TID 719)
[2025-07-19T20:48:14.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@720bbc59
[2025-07-19T20:48:14.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.2.delta.94cc11de-2cc0-47d8-9d1b-0a3bff4be333.TID712.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/2.delta
[2025-07-19T20:48:14.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/109/2.delta
[2025-07-19T20:48:14.757+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T20:48:14.758+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.2.delta.e9f15b53-b16b-4115-9234-f6eb3238c7a1.TID716.tmp
[2025-07-19T20:48:14.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116] for update
[2025-07-19T20:48:14.763+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.2.delta.aaa5a8dd-103a-43a6-9a9b-583dfdacdc84.TID717.tmp
[2025-07-19T20:48:14.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T20:48:14.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 109.0 in stage 7.0 (TID 712). 5829 bytes result sent to driver
[2025-07-19T20:48:14.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 720) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 712) in 79 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:48:14.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 117.0 in stage 7.0 (TID 720)
[2025-07-19T20:48:14.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11aa9845
[2025-07-19T20:48:14.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117] for update
[2025-07-19T20:48:14.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.2.delta.9263a295-5412-45cd-981b-a8e853f47714.TID713.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/2.delta
[2025-07-19T20:48:14.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/110/2.delta
[2025-07-19T20:48:14.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T20:48:14.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.2.delta.10dd4745-e460-4754-9351-044e52b484c8.TID719.tmp
[2025-07-19T20:48:14.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.2.delta.2d784ab9-74e6-46c4-a06f-64cceaff7215.TID718.tmp
[2025-07-19T20:48:14.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T20:48:14.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 110.0 in stage 7.0 (TID 713). 5829 bytes result sent to driver
[2025-07-19T20:48:14.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 721) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 118.0 in stage 7.0 (TID 721)
[2025-07-19T20:48:14.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 713) in 87 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:48:14.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.2.delta.c98316c3-5738-4847-ae73-f3875293f311.TID720.tmp
[2025-07-19T20:48:14.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c26e9c2
[2025-07-19T20:48:14.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118] for update
[2025-07-19T20:48:14.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.2.delta.08f70919-f534-4fab-aa2a-3d7a863651eb.TID715.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/2.delta
[2025-07-19T20:48:14.797+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/112/2.delta
[2025-07-19T20:48:14.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T20:48:14.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T20:48:14.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 112.0 in stage 7.0 (TID 715). 5829 bytes result sent to driver
[2025-07-19T20:48:14.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 722) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 715) in 86 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:48:14.807+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 119.0 in stage 7.0 (TID 722)
[2025-07-19T20:48:14.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17d5bccb
[2025-07-19T20:48:14.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119] for update
[2025-07-19T20:48:14.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.2.delta.3bb4c157-f03c-4d39-a7f1-88315a3f1a89.TID721.tmp
[2025-07-19T20:48:14.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.2.delta.546d934c-5cfa-498c-a7b4-024ad41c1328.TID714.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/2.delta
[2025-07-19T20:48:14.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/111/2.delta
[2025-07-19T20:48:14.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T20:48:14.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.2.delta.aaa5a8dd-103a-43a6-9a9b-583dfdacdc84.TID717.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/2.delta
[2025-07-19T20:48:14.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/114/2.delta
[2025-07-19T20:48:14.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T20:48:14.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T20:48:14.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.2.delta.e9f15b53-b16b-4115-9234-f6eb3238c7a1.TID716.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/2.delta
[2025-07-19T20:48:14.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/113/2.delta
[2025-07-19T20:48:14.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T20:48:14.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 114.0 in stage 7.0 (TID 717). 5786 bytes result sent to driver
[2025-07-19T20:48:14.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 723) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 120.0 in stage 7.0 (TID 723)
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 717) in 98 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 111.0 in stage 7.0 (TID 714). 5829 bytes result sent to driver
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 714) in 117 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 724) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.2.delta.fbf72b27-b7d7-4676-a260-736bc7301a52.TID722.tmp
[2025-07-19T20:48:14.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e9f380e
[2025-07-19T20:48:14.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120] for update
[2025-07-19T20:48:14.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T20:48:14.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 113.0 in stage 7.0 (TID 716). 5829 bytes result sent to driver
[2025-07-19T20:48:14.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 121.0 in stage 7.0 (TID 724)
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 725) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.2.delta.10dd4745-e460-4754-9351-044e52b484c8.TID719.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/2.delta
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/116/2.delta
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 122.0 in stage 7.0 (TID 725)
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 716) in 109 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:48:14.835+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:14.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b487379
[2025-07-19T20:48:14.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122] for update
[2025-07-19T20:48:14.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T20:48:14.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 116.0 in stage 7.0 (TID 719). 5829 bytes result sent to driver
[2025-07-19T20:48:14.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 726) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 123.0 in stage 7.0 (TID 726)
[2025-07-19T20:48:14.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 719) in 93 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:48:14.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.2.delta.2d784ab9-74e6-46c4-a06f-64cceaff7215.TID718.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/2.delta
[2025-07-19T20:48:14.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/115/2.delta
[2025-07-19T20:48:14.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.2.delta.c98316c3-5738-4847-ae73-f3875293f311.TID720.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/2.delta
[2025-07-19T20:48:14.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/117/2.delta
[2025-07-19T20:48:14.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.2.delta.86cc2bcc-6fd2-4398-ba67-43af3a87f603.TID723.tmp
[2025-07-19T20:48:14.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5570a502
[2025-07-19T20:48:14.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T20:48:14.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T20:48:14.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121] for update
[2025-07-19T20:48:14.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e5d0172
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123] for update
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.2.delta.5d5bab42-bc5d-48ca-b0f7-f58247cb146d.TID725.tmp
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 115.0 in stage 7.0 (TID 718). 5829 bytes result sent to driver
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 727) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 124.0 in stage 7.0 (TID 727)
[2025-07-19T20:48:14.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 718) in 116 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:48:14.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T20:48:14.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 117.0 in stage 7.0 (TID 720). 5829 bytes result sent to driver
[2025-07-19T20:48:14.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 728) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 720) in 91 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:48:14.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 125.0 in stage 7.0 (TID 728)
[2025-07-19T20:48:14.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7289d07a
[2025-07-19T20:48:14.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124] for update
[2025-07-19T20:48:14.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73db6b61
[2025-07-19T20:48:14.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125] for update
[2025-07-19T20:48:14.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.2.delta.7719ac68-f9b6-474d-b0d4-df0affa837ec.TID724.tmp
[2025-07-19T20:48:14.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.2.delta.9010ed5a-bdf3-4ed7-b239-c88bab865cd6.TID726.tmp
[2025-07-19T20:48:14.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.2.delta.2bca69de-49b5-4fe2-b020-c55ca67b5a79.TID727.tmp
[2025-07-19T20:48:14.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.2.delta.fbf72b27-b7d7-4676-a260-736bc7301a52.TID722.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/2.delta
[2025-07-19T20:48:14.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/119/2.delta
[2025-07-19T20:48:14.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.2.delta.fe312495-5b34-406d-b27b-f6d4faabd06f.TID728.tmp
[2025-07-19T20:48:14.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T20:48:14.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.2.delta.3bb4c157-f03c-4d39-a7f1-88315a3f1a89.TID721.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/2.delta
[2025-07-19T20:48:14.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/118/2.delta
[2025-07-19T20:48:14.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T20:48:14.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T20:48:14.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 118.0 in stage 7.0 (TID 721). 5829 bytes result sent to driver
[2025-07-19T20:48:14.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T20:48:14.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 119.0 in stage 7.0 (TID 722). 5829 bytes result sent to driver
[2025-07-19T20:48:14.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 729) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 730) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 721) in 100 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:48:14.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 126.0 in stage 7.0 (TID 729)
[2025-07-19T20:48:14.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 722) in 78 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:48:14.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 127.0 in stage 7.0 (TID 730)
[2025-07-19T20:48:14.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3398d7bb
[2025-07-19T20:48:14.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126] for update
[2025-07-19T20:48:14.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a33a4ef
[2025-07-19T20:48:14.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127] for update
[2025-07-19T20:48:14.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.2.delta.86cc2bcc-6fd2-4398-ba67-43af3a87f603.TID723.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/2.delta
[2025-07-19T20:48:14.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/120/2.delta
[2025-07-19T20:48:14.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.894+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T20:48:14.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.2.delta.5d5bab42-bc5d-48ca-b0f7-f58247cb146d.TID725.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/2.delta
[2025-07-19T20:48:14.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/122/2.delta
[2025-07-19T20:48:14.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T20:48:14.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T20:48:14.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 120.0 in stage 7.0 (TID 723). 5829 bytes result sent to driver
[2025-07-19T20:48:14.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 731) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T20:48:14.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 122.0 in stage 7.0 (TID 725). 5829 bytes result sent to driver
[2025-07-19T20:48:14.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 723) in 73 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:48:14.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 128.0 in stage 7.0 (TID 731)
[2025-07-19T20:48:14.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 732) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 725) in 67 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:48:14.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 129.0 in stage 7.0 (TID 732)
[2025-07-19T20:48:14.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dd9c183
[2025-07-19T20:48:14.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.2.delta.bc0eba1e-1030-4905-b844-877811ef0cde.TID730.tmp
[2025-07-19T20:48:14.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.2.delta.a442cb96-308d-4f61-b35c-c297959928b4.TID729.tmp
[2025-07-19T20:48:14.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129] for update
[2025-07-19T20:48:14.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23cd00d4
[2025-07-19T20:48:14.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128] for update
[2025-07-19T20:48:14.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.2.delta.9010ed5a-bdf3-4ed7-b239-c88bab865cd6.TID726.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/2.delta
[2025-07-19T20:48:14.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/123/2.delta
[2025-07-19T20:48:14.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.2.delta.7719ac68-f9b6-474d-b0d4-df0affa837ec.TID724.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/2.delta
[2025-07-19T20:48:14.916+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/121/2.delta
[2025-07-19T20:48:14.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T20:48:14.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T20:48:14.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.2.delta.2bca69de-49b5-4fe2-b020-c55ca67b5a79.TID727.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/2.delta
[2025-07-19T20:48:14.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/124/2.delta
[2025-07-19T20:48:14.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T20:48:14.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.2.delta.ce21ee33-a182-4a39-b5c1-9743e77e2cb8.TID732.tmp
[2025-07-19T20:48:14.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.2.delta.fe312495-5b34-406d-b27b-f6d4faabd06f.TID728.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/2.delta
[2025-07-19T20:48:14.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/125/2.delta
[2025-07-19T20:48:14.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T20:48:14.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T20:48:14.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T20:48:14.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 124.0 in stage 7.0 (TID 727). 5829 bytes result sent to driver
[2025-07-19T20:48:14.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 123.0 in stage 7.0 (TID 726). 5829 bytes result sent to driver
[2025-07-19T20:48:14.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T20:48:14.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 121.0 in stage 7.0 (TID 724). 5829 bytes result sent to driver
[2025-07-19T20:48:14.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.2.delta.65bad917-846b-40e0-9878-ad8b50353d1b.TID731.tmp
[2025-07-19T20:48:14.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 733) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 734) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 735) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 130.0 in stage 7.0 (TID 733)
[2025-07-19T20:48:14.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 131.0 in stage 7.0 (TID 734)
[2025-07-19T20:48:14.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 132.0 in stage 7.0 (TID 735)
[2025-07-19T20:48:14.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T20:48:14.930+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 125.0 in stage 7.0 (TID 728). 5829 bytes result sent to driver
[2025-07-19T20:48:14.930+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 736) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 133.0 in stage 7.0 (TID 736)
[2025-07-19T20:48:14.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 727) in 78 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:48:14.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 728) in 76 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:48:14.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 724) in 105 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 726) in 95 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:48:14.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10a3b029
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130] for update
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@116d3217
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133] for update
[2025-07-19T20:48:14.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ac07d9d
[2025-07-19T20:48:14.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.2.delta.4bd9e4cf-93f8-4355-be70-2763f6008741.TID733.tmp
[2025-07-19T20:48:14.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131] for update
[2025-07-19T20:48:14.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.2.delta.bc0eba1e-1030-4905-b844-877811ef0cde.TID730.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/2.delta
[2025-07-19T20:48:14.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/127/2.delta
[2025-07-19T20:48:14.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70328347
[2025-07-19T20:48:14.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T20:48:14.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.2.delta.d986eebf-9eb8-40ae-97b8-ca2826066e2d.TID736.tmp
[2025-07-19T20:48:14.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132] for update
[2025-07-19T20:48:14.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T20:48:14.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 127.0 in stage 7.0 (TID 730). 5829 bytes result sent to driver
[2025-07-19T20:48:14.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 730) in 79 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:48:14.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 737) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 134.0 in stage 7.0 (TID 737)
[2025-07-19T20:48:14.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.2.delta.a442cb96-308d-4f61-b35c-c297959928b4.TID729.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/2.delta
[2025-07-19T20:48:14.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/126/2.delta
[2025-07-19T20:48:14.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T20:48:14.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.2.delta.ce21ee33-a182-4a39-b5c1-9743e77e2cb8.TID732.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/2.delta
[2025-07-19T20:48:14.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/129/2.delta
[2025-07-19T20:48:14.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T20:48:14.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T20:48:14.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 126.0 in stage 7.0 (TID 729). 5829 bytes result sent to driver
[2025-07-19T20:48:14.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e1934ca
[2025-07-19T20:48:14.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134] for update
[2025-07-19T20:48:14.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 738) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.2.delta.65bad917-846b-40e0-9878-ad8b50353d1b.TID731.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/2.delta
[2025-07-19T20:48:14.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 729) in 87 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:48:14.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/128/2.delta
[2025-07-19T20:48:14.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 135.0 in stage 7.0 (TID 738)
[2025-07-19T20:48:14.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T20:48:14.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T20:48:14.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 129.0 in stage 7.0 (TID 732). 5829 bytes result sent to driver
[2025-07-19T20:48:14.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO DataWritingSparkTask: Committed partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T20:48:14.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.2.delta.1d0dcb8a-5b8a-416c-b777-5eaf87588b20.TID734.tmp
[2025-07-19T20:48:14.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Finished task 128.0 in stage 7.0 (TID 731). 5915 bytes result sent to driver
[2025-07-19T20:48:14.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 739) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.2.delta.8709bb9b-546f-4779-ab0f-107f1f3bfa21.TID735.tmp
[2025-07-19T20:48:14.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 740) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:14.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 732) in 86 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:48:14.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 731) in 88 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:48:14.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd195ff
[2025-07-19T20:48:14.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 137.0 in stage 7.0 (TID 740)
[2025-07-19T20:48:14.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:14.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135] for update
[2025-07-19T20:48:14.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:14.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO Executor: Running task 136.0 in stage 7.0 (TID 739)
[2025-07-19T20:48:14.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:14.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:14.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:14.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25bd300b
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137] for update
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51b8160d
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136] for update
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:14 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.2.delta.9a060b61-63ad-4c90-85ed-851f1adc7bcb.TID737.tmp
[2025-07-19T20:48:15.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.2.delta.6c88357a-0919-42ff-b0ed-f6e9fd725a7e.TID740.tmp
[2025-07-19T20:48:15.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.2.delta.4bd9e4cf-93f8-4355-be70-2763f6008741.TID733.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/2.delta
[2025-07-19T20:48:15.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/130/2.delta
[2025-07-19T20:48:15.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T20:48:15.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.2.delta.425c504c-eccc-4fe4-a8db-a31847ade0d3.TID739.tmp
[2025-07-19T20:48:15.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.2.delta.d6090f97-0e36-447d-833a-e28c3beca5f0.TID738.tmp
[2025-07-19T20:48:15.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T20:48:15.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 130.0 in stage 7.0 (TID 733). 5872 bytes result sent to driver
[2025-07-19T20:48:15.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 741) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 138.0 in stage 7.0 (TID 741)
[2025-07-19T20:48:15.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 733) in 96 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:48:15.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ed825d3
[2025-07-19T20:48:15.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138] for update
[2025-07-19T20:48:15.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.2.delta.d986eebf-9eb8-40ae-97b8-ca2826066e2d.TID736.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/2.delta
[2025-07-19T20:48:15.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/133/2.delta
[2025-07-19T20:48:15.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T20:48:15.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T20:48:15.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 133.0 in stage 7.0 (TID 736). 5872 bytes result sent to driver
[2025-07-19T20:48:15.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 742) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 139.0 in stage 7.0 (TID 742)
[2025-07-19T20:48:15.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 736) in 115 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:48:15.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@211c104a
[2025-07-19T20:48:15.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139] for update
[2025-07-19T20:48:15.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.2.delta.1d0dcb8a-5b8a-416c-b777-5eaf87588b20.TID734.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/2.delta
[2025-07-19T20:48:15.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/131/2.delta
[2025-07-19T20:48:15.052+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T20:48:15.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.2.delta.8709bb9b-546f-4779-ab0f-107f1f3bfa21.TID735.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/2.delta
[2025-07-19T20:48:15.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/132/2.delta
[2025-07-19T20:48:15.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.2.delta.9a060b61-63ad-4c90-85ed-851f1adc7bcb.TID737.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/2.delta
[2025-07-19T20:48:15.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/134/2.delta
[2025-07-19T20:48:15.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.2.delta.e39dedba-bc46-48a2-9b90-33bcb70be08c.TID741.tmp
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 131.0 in stage 7.0 (TID 734). 5872 bytes result sent to driver
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 743) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 140.0 in stage 7.0 (TID 743)
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 734) in 134 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:48:15.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T20:48:15.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T20:48:15.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 132.0 in stage 7.0 (TID 735). 5872 bytes result sent to driver
[2025-07-19T20:48:15.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 744) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 735) in 140 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:48:15.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.2.delta.283883fd-aa99-4ed3-b088-6a32bfb23273.TID742.tmp
[2025-07-19T20:48:15.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:15.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T20:48:15.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 134.0 in stage 7.0 (TID 737). 5872 bytes result sent to driver
[2025-07-19T20:48:15.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 745) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1151b058
[2025-07-19T20:48:15.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 141.0 in stage 7.0 (TID 744)
[2025-07-19T20:48:15.069+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140] for update
[2025-07-19T20:48:15.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 737) in 112 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:48:15.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 142.0 in stage 7.0 (TID 745)
[2025-07-19T20:48:15.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37598b9
[2025-07-19T20:48:15.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.2.delta.425c504c-eccc-4fe4-a8db-a31847ade0d3.TID739.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/2.delta
[2025-07-19T20:48:15.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/136/2.delta
[2025-07-19T20:48:15.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T20:48:15.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.2.delta.d6090f97-0e36-447d-833a-e28c3beca5f0.TID738.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/2.delta
[2025-07-19T20:48:15.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/135/2.delta
[2025-07-19T20:48:15.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.2.delta.6c88357a-0919-42ff-b0ed-f6e9fd725a7e.TID740.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/2.delta
[2025-07-19T20:48:15.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/137/2.delta
[2025-07-19T20:48:15.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T20:48:15.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T20:48:15.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141] for update
[2025-07-19T20:48:15.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48f8de46
[2025-07-19T20:48:15.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T20:48:15.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T20:48:15.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 137.0 in stage 7.0 (TID 740). 5872 bytes result sent to driver
[2025-07-19T20:48:15.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 136.0 in stage 7.0 (TID 739). 5829 bytes result sent to driver
[2025-07-19T20:48:15.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142] for update
[2025-07-19T20:48:15.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 746) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 143.0 in stage 7.0 (TID 746)
[2025-07-19T20:48:15.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T20:48:15.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.2.delta.d1fc6b41-fa27-4706-9241-72e08a19c2d9.TID743.tmp
[2025-07-19T20:48:15.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 135.0 in stage 7.0 (TID 738). 5872 bytes result sent to driver
[2025-07-19T20:48:15.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 739) in 106 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:48:15.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 747) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 144.0 in stage 7.0 (TID 747)
[2025-07-19T20:48:15.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@674806f
[2025-07-19T20:48:15.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143] for update
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 748) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 740) in 104 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 738) in 119 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 145.0 in stage 7.0 (TID 748)
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.2.delta.269501f1-f611-4de4-9000-208c1a761c03.TID744.tmp
[2025-07-19T20:48:15.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7df8354b
[2025-07-19T20:48:15.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144] for update
[2025-07-19T20:48:15.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:15.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ebcbc95
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145] for update
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.2.delta.e15f7ee0-2426-48f2-9552-ef2d228b7db6.TID745.tmp
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.2.delta.283883fd-aa99-4ed3-b088-6a32bfb23273.TID742.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/2.delta
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/139/2.delta
[2025-07-19T20:48:15.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.2.delta.d5d9623e-a385-43cb-9a28-9bd810aef27f.TID746.tmp
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 139.0 in stage 7.0 (TID 742). 5829 bytes result sent to driver
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 749) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 742) in 70 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 146.0 in stage 7.0 (TID 749)
[2025-07-19T20:48:15.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.2.delta.75de3266-f022-4d97-a5e5-2c6527f0c9c2.TID747.tmp
[2025-07-19T20:48:15.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c2032b9
[2025-07-19T20:48:15.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146] for update
[2025-07-19T20:48:15.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.2.delta.e39dedba-bc46-48a2-9b90-33bcb70be08c.TID741.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/2.delta
[2025-07-19T20:48:15.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/138/2.delta
[2025-07-19T20:48:15.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.2.delta.9655beed-6f92-4e3b-af43-dc7b0356d1a9.TID748.tmp
[2025-07-19T20:48:15.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T20:48:15.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T20:48:15.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 138.0 in stage 7.0 (TID 741). 5829 bytes result sent to driver
[2025-07-19T20:48:15.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 750) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 741) in 98 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:48:15.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 147.0 in stage 7.0 (TID 750)
[2025-07-19T20:48:15.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7897af5a
[2025-07-19T20:48:15.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147] for update
[2025-07-19T20:48:15.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.2.delta.9c1af7aa-fdac-40ff-afb7-ee5966090bd9.TID749.tmp
[2025-07-19T20:48:15.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.2.delta.d1fc6b41-fa27-4706-9241-72e08a19c2d9.TID743.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/2.delta
[2025-07-19T20:48:15.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/140/2.delta
[2025-07-19T20:48:15.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T20:48:15.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.2.delta.ea3d2550-080b-4c87-b792-c5682f48e92c.TID750.tmp
[2025-07-19T20:48:15.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T20:48:15.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 140.0 in stage 7.0 (TID 743). 5829 bytes result sent to driver
[2025-07-19T20:48:15.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.2.delta.269501f1-f611-4de4-9000-208c1a761c03.TID744.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/2.delta
[2025-07-19T20:48:15.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/141/2.delta
[2025-07-19T20:48:15.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 751) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T20:48:15.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 743) in 89 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:48:15.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 148.0 in stage 7.0 (TID 751)
[2025-07-19T20:48:15.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.2.delta.e15f7ee0-2426-48f2-9552-ef2d228b7db6.TID745.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/2.delta
[2025-07-19T20:48:15.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/142/2.delta
[2025-07-19T20:48:15.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.2.delta.d5d9623e-a385-43cb-9a28-9bd810aef27f.TID746.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/2.delta
[2025-07-19T20:48:15.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/143/2.delta
[2025-07-19T20:48:15.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T20:48:15.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T20:48:15.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.2.delta.75de3266-f022-4d97-a5e5-2c6527f0c9c2.TID747.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/2.delta
[2025-07-19T20:48:15.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/144/2.delta
[2025-07-19T20:48:15.157+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.2.delta.9655beed-6f92-4e3b-af43-dc7b0356d1a9.TID748.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/2.delta
[2025-07-19T20:48:15.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/145/2.delta
[2025-07-19T20:48:15.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T20:48:15.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T20:48:15.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T20:48:15.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 141.0 in stage 7.0 (TID 744). 5829 bytes result sent to driver
[2025-07-19T20:48:15.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 752) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 744) in 93 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:48:15.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 149.0 in stage 7.0 (TID 752)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 144.0 in stage 7.0 (TID 747). 5786 bytes result sent to driver
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 145.0 in stage 7.0 (TID 748). 5829 bytes result sent to driver
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 143.0 in stage 7.0 (TID 746). 5829 bytes result sent to driver
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 753) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 754) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 755) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34efa655
[2025-07-19T20:48:15.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 152.0 in stage 7.0 (TID 755)
[2025-07-19T20:48:15.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 746) in 77 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:48:15.169+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 151.0 in stage 7.0 (TID 754)
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 747) in 75 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 150.0 in stage 7.0 (TID 753)
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148] for update
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 748) in 75 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.170+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T20:48:15.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cca0571
[2025-07-19T20:48:15.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 142.0 in stage 7.0 (TID 745). 5829 bytes result sent to driver
[2025-07-19T20:48:15.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 756) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150] for update
[2025-07-19T20:48:15.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 153.0 in stage 7.0 (TID 756)
[2025-07-19T20:48:15.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b006163
[2025-07-19T20:48:15.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.2.delta.9c1af7aa-fdac-40ff-afb7-ee5966090bd9.TID749.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/2.delta
[2025-07-19T20:48:15.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/146/2.delta
[2025-07-19T20:48:15.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 745) in 97 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:48:15.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T20:48:15.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149] for update
[2025-07-19T20:48:15.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8125ba6
[2025-07-19T20:48:15.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152] for update
[2025-07-19T20:48:15.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T20:48:15.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ef67195
[2025-07-19T20:48:15.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 146.0 in stage 7.0 (TID 749). 5829 bytes result sent to driver
[2025-07-19T20:48:15.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151] for update
[2025-07-19T20:48:15.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 757) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 154.0 in stage 7.0 (TID 757)
[2025-07-19T20:48:15.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 749) in 70 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:48:15.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.195+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cd5f152
[2025-07-19T20:48:15.195+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.2.delta.ea3d2550-080b-4c87-b792-c5682f48e92c.TID750.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/2.delta
[2025-07-19T20:48:15.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/147/2.delta
[2025-07-19T20:48:15.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153] for update
[2025-07-19T20:48:15.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T20:48:15.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.2.delta.75ff93cb-e435-4882-bd6e-6b7ffa3876ef.TID753.tmp
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.2.delta.cfee9d64-7fd4-4f17-9c1d-9335dafb0cd0.TID755.tmp
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.2.delta.f8d28c85-dbff-4350-8b48-d6a4a5198fa7.TID751.tmp
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b3f3dc8
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154] for update
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.198+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T20:48:15.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.2.delta.36676a53-b8b7-4a2f-b2ad-f18dc14e24e8.TID752.tmp
[2025-07-19T20:48:15.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 147.0 in stage 7.0 (TID 750). 5829 bytes result sent to driver
[2025-07-19T20:48:15.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 758) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 155.0 in stage 7.0 (TID 758)
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 750) in 72 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.2.delta.97098245-51cf-489c-bd89-5039c3a9b3c9.TID754.tmp
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.2.delta.12539eff-289f-4f01-8df3-a964b60ae7a4.TID756.tmp
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72df35db
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155] for update
[2025-07-19T20:48:15.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.2.delta.1a1e91b7-357a-4fd6-899a-2c9e41309d72.TID757.tmp
[2025-07-19T20:48:15.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.2.delta.fb720881-d31d-4527-86bd-91bccb7f10ad.TID758.tmp
[2025-07-19T20:48:15.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.2.delta.f8d28c85-dbff-4350-8b48-d6a4a5198fa7.TID751.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/2.delta
[2025-07-19T20:48:15.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/148/2.delta
[2025-07-19T20:48:15.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T20:48:15.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.2.delta.cfee9d64-7fd4-4f17-9c1d-9335dafb0cd0.TID755.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/2.delta
[2025-07-19T20:48:15.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/152/2.delta
[2025-07-19T20:48:15.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T20:48:15.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T20:48:15.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 148.0 in stage 7.0 (TID 751). 5829 bytes result sent to driver
[2025-07-19T20:48:15.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T20:48:15.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 152.0 in stage 7.0 (TID 755). 5829 bytes result sent to driver
[2025-07-19T20:48:15.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.2.delta.12539eff-289f-4f01-8df3-a964b60ae7a4.TID756.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/2.delta
[2025-07-19T20:48:15.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/153/2.delta
[2025-07-19T20:48:15.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 759) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 156.0 in stage 7.0 (TID 759)
[2025-07-19T20:48:15.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T20:48:15.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 760) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 751) in 142 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:48:15.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 157.0 in stage 7.0 (TID 760)
[2025-07-19T20:48:15.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 755) in 129 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:48:15.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d663dc3
[2025-07-19T20:48:15.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157] for update
[2025-07-19T20:48:15.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.2.delta.36676a53-b8b7-4a2f-b2ad-f18dc14e24e8.TID752.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/2.delta
[2025-07-19T20:48:15.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/149/2.delta
[2025-07-19T20:48:15.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T20:48:15.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 28 ms
[2025-07-19T20:48:15.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T20:48:15.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T20:48:15.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 153.0 in stage 7.0 (TID 756). 5829 bytes result sent to driver
[2025-07-19T20:48:15.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 149.0 in stage 7.0 (TID 752). 5829 bytes result sent to driver
[2025-07-19T20:48:15.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 761) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68a66633
[2025-07-19T20:48:15.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 762) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 159.0 in stage 7.0 (TID 762)
[2025-07-19T20:48:15.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 158.0 in stage 7.0 (TID 761)
[2025-07-19T20:48:15.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156] for update
[2025-07-19T20:48:15.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ca98a03
[2025-07-19T20:48:15.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159] for update
[2025-07-19T20:48:15.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:15.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 752) in 199 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:48:15.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.2.delta.75ff93cb-e435-4882-bd6e-6b7ffa3876ef.TID753.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/2.delta
[2025-07-19T20:48:15.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/150/2.delta
[2025-07-19T20:48:15.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 756) in 202 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ec949b1
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.2.delta.97098245-51cf-489c-bd89-5039c3a9b3c9.TID754.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/2.delta
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/151/2.delta
[2025-07-19T20:48:15.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158] for update
[2025-07-19T20:48:15.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T20:48:15.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.2.delta.273b5ab8-0303-495f-8080-5f86479fe9a0.TID760.tmp
[2025-07-19T20:48:15.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T20:48:15.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 151.0 in stage 7.0 (TID 754). 5829 bytes result sent to driver
[2025-07-19T20:48:15.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 763) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 754) in 240 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:48:15.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T20:48:15.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.2.delta.fb720881-d31d-4527-86bd-91bccb7f10ad.TID758.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/2.delta
[2025-07-19T20:48:15.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/155/2.delta
[2025-07-19T20:48:15.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 160.0 in stage 7.0 (TID 763)
[2025-07-19T20:48:15.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T20:48:15.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b435d21
[2025-07-19T20:48:15.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 150.0 in stage 7.0 (TID 753). 5786 bytes result sent to driver
[2025-07-19T20:48:15.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 764) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160] for update
[2025-07-19T20:48:15.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 753) in 252 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:48:15.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T20:48:15.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 155.0 in stage 7.0 (TID 758). 5829 bytes result sent to driver
[2025-07-19T20:48:15.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 765) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 758) in 228 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:48:15.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 162.0 in stage 7.0 (TID 765)
[2025-07-19T20:48:15.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.2.delta.ae3a3f8c-b2f8-452b-b075-b4e8c62d37cf.TID762.tmp
[2025-07-19T20:48:15.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 161.0 in stage 7.0 (TID 764)
[2025-07-19T20:48:15.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.2.delta.f1a3fdf3-5f31-43b4-9190-874459264154.TID759.tmp
[2025-07-19T20:48:15.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e82ee26
[2025-07-19T20:48:15.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162] for update
[2025-07-19T20:48:15.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.2.delta.11ca7dc9-058d-4a96-98ab-0a99f499ab0a.TID761.tmp
[2025-07-19T20:48:15.442+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3898d26a
[2025-07-19T20:48:15.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161] for update
[2025-07-19T20:48:15.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.445+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.2.delta.207d4ce5-c727-4424-b7b9-8ebbbfa5f160.TID763.tmp
[2025-07-19T20:48:15.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.2.delta.1a1e91b7-357a-4fd6-899a-2c9e41309d72.TID757.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/2.delta
[2025-07-19T20:48:15.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/154/2.delta
[2025-07-19T20:48:15.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T20:48:15.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.2.delta.49300f24-13a3-4767-a5a8-96fb71fd45aa.TID765.tmp
[2025-07-19T20:48:15.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T20:48:15.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 154.0 in stage 7.0 (TID 757). 5829 bytes result sent to driver
[2025-07-19T20:48:15.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 766) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 163.0 in stage 7.0 (TID 766)
[2025-07-19T20:48:15.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 757) in 294 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:48:15.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.2.delta.7110abb7-1698-4d1e-862f-5c9064dd68b9.TID764.tmp
[2025-07-19T20:48:15.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f37ea31
[2025-07-19T20:48:15.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163] for update
[2025-07-19T20:48:15.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.2.delta.273b5ab8-0303-495f-8080-5f86479fe9a0.TID760.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/2.delta
[2025-07-19T20:48:15.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/157/2.delta
[2025-07-19T20:48:15.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T20:48:15.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.2.delta.f1a3fdf3-5f31-43b4-9190-874459264154.TID759.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/2.delta
[2025-07-19T20:48:15.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/156/2.delta
[2025-07-19T20:48:15.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T20:48:15.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.2.delta.ae3a3f8c-b2f8-452b-b075-b4e8c62d37cf.TID762.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/2.delta
[2025-07-19T20:48:15.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/159/2.delta
[2025-07-19T20:48:15.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T20:48:15.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T20:48:15.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 157.0 in stage 7.0 (TID 760). 5829 bytes result sent to driver
[2025-07-19T20:48:15.515+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 767) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 164.0 in stage 7.0 (TID 767)
[2025-07-19T20:48:15.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T20:48:15.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 159.0 in stage 7.0 (TID 762). 5829 bytes result sent to driver
[2025-07-19T20:48:15.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 768) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 165.0 in stage 7.0 (TID 768)
[2025-07-19T20:48:15.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 760) in 230 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:48:15.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.518+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.2.delta.57381ed9-2952-4e0c-b2a6-75f50c21e624.TID766.tmp
[2025-07-19T20:48:15.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bec4f6
[2025-07-19T20:48:15.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.2.delta.11ca7dc9-058d-4a96-98ab-0a99f499ab0a.TID761.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/2.delta
[2025-07-19T20:48:15.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/158/2.delta
[2025-07-19T20:48:15.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T20:48:15.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T20:48:15.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 762) in 172 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:48:15.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164] for update
[2025-07-19T20:48:15.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 156.0 in stage 7.0 (TID 759). 5829 bytes result sent to driver
[2025-07-19T20:48:15.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T20:48:15.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.2.delta.207d4ce5-c727-4424-b7b9-8ebbbfa5f160.TID763.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/2.delta
[2025-07-19T20:48:15.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/160/2.delta
[2025-07-19T20:48:15.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 158.0 in stage 7.0 (TID 761). 5829 bytes result sent to driver
[2025-07-19T20:48:15.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 769) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T20:48:15.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 770) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@691483be
[2025-07-19T20:48:15.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 166.0 in stage 7.0 (TID 769)
[2025-07-19T20:48:15.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165] for update
[2025-07-19T20:48:15.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.2.delta.49300f24-13a3-4767-a5a8-96fb71fd45aa.TID765.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/2.delta
[2025-07-19T20:48:15.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/162/2.delta
[2025-07-19T20:48:15.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 167.0 in stage 7.0 (TID 770)
[2025-07-19T20:48:15.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 759) in 243 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:48:15.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T20:48:15.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 761) in 188 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:48:15.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4db7dc0c
[2025-07-19T20:48:15.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166] for update
[2025-07-19T20:48:15.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T20:48:15.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 160.0 in stage 7.0 (TID 763). 5829 bytes result sent to driver
[2025-07-19T20:48:15.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T20:48:15.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 162.0 in stage 7.0 (TID 765). 5829 bytes result sent to driver
[2025-07-19T20:48:15.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 771) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 168.0 in stage 7.0 (TID 771)
[2025-07-19T20:48:15.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 772) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.570+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.2.delta.7110abb7-1698-4d1e-862f-5c9064dd68b9.TID764.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/2.delta
[2025-07-19T20:48:15.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/161/2.delta
[2025-07-19T20:48:15.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 763) in 134 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:48:15.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T20:48:15.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 169.0 in stage 7.0 (TID 772)
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 765) in 117 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17139f6c
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167] for update
[2025-07-19T20:48:15.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@572d09b5
[2025-07-19T20:48:15.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169] for update
[2025-07-19T20:48:15.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.574+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.575+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:15.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T20:48:15.576+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 161.0 in stage 7.0 (TID 764). 5829 bytes result sent to driver
[2025-07-19T20:48:15.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 773) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.2.delta.0efc9dec-6335-488e-9835-fea30726f95a.TID768.tmp
[2025-07-19T20:48:15.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 170.0 in stage 7.0 (TID 773)
[2025-07-19T20:48:15.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 764) in 138 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:48:15.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.2.delta.783c3480-41bc-40c1-94d9-0e64147fe8a2.TID767.tmp
[2025-07-19T20:48:15.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@48517481
[2025-07-19T20:48:15.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168] for update
[2025-07-19T20:48:15.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6abe77fe
[2025-07-19T20:48:15.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170] for update
[2025-07-19T20:48:15.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.2.delta.d5d4580a-3ae8-4a03-bf4b-15a34c641253.TID770.tmp
[2025-07-19T20:48:15.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.2.delta.88793799-5a77-40d7-bb8f-5727f35e74b5.TID772.tmp
[2025-07-19T20:48:15.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.2.delta.50bc2e4d-cc98-4fdc-aa88-29d933ef2999.TID769.tmp
[2025-07-19T20:48:15.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.2.delta.98ba1b51-ccc5-4e88-b11c-a27373edfb0f.TID773.tmp
[2025-07-19T20:48:15.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.2.delta.b1afe229-e49b-4c70-a557-beb8dbdc2d94.TID771.tmp
[2025-07-19T20:48:15.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.2.delta.57381ed9-2952-4e0c-b2a6-75f50c21e624.TID766.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/2.delta
[2025-07-19T20:48:15.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/163/2.delta
[2025-07-19T20:48:15.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.2.delta.0efc9dec-6335-488e-9835-fea30726f95a.TID768.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/2.delta
[2025-07-19T20:48:15.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T20:48:15.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/165/2.delta
[2025-07-19T20:48:15.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T20:48:15.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T20:48:15.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T20:48:15.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.2.delta.783c3480-41bc-40c1-94d9-0e64147fe8a2.TID767.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/2.delta
[2025-07-19T20:48:15.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/164/2.delta
[2025-07-19T20:48:15.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 165.0 in stage 7.0 (TID 768). 5829 bytes result sent to driver
[2025-07-19T20:48:15.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 163.0 in stage 7.0 (TID 766). 5829 bytes result sent to driver
[2025-07-19T20:48:15.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.2.delta.d5d4580a-3ae8-4a03-bf4b-15a34c641253.TID770.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/2.delta
[2025-07-19T20:48:15.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/167/2.delta
[2025-07-19T20:48:15.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T20:48:15.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T20:48:15.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 774) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 775) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 768) in 104 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:48:15.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 172.0 in stage 7.0 (TID 775)
[2025-07-19T20:48:15.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 171.0 in stage 7.0 (TID 774)
[2025-07-19T20:48:15.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 766) in 146 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1993407f
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171] for update
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 167.0 in stage 7.0 (TID 770). 5829 bytes result sent to driver
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T20:48:15.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 164.0 in stage 7.0 (TID 767). 5829 bytes result sent to driver
[2025-07-19T20:48:15.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@542addf4
[2025-07-19T20:48:15.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 776) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 777) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 173.0 in stage 7.0 (TID 776)
[2025-07-19T20:48:15.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 770) in 96 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:48:15.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 767) in 114 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:48:15.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 174.0 in stage 7.0 (TID 777)
[2025-07-19T20:48:15.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172] for update
[2025-07-19T20:48:15.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.2.delta.50bc2e4d-cc98-4fdc-aa88-29d933ef2999.TID769.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/2.delta
[2025-07-19T20:48:15.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/166/2.delta
[2025-07-19T20:48:15.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T20:48:15.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.2.delta.88793799-5a77-40d7-bb8f-5727f35e74b5.TID772.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/2.delta
[2025-07-19T20:48:15.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/169/2.delta
[2025-07-19T20:48:15.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4243d806
[2025-07-19T20:48:15.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T20:48:15.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173] for update
[2025-07-19T20:48:15.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T20:48:15.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.2.delta.b1afe229-e49b-4c70-a557-beb8dbdc2d94.TID771.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/2.delta
[2025-07-19T20:48:15.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/168/2.delta
[2025-07-19T20:48:15.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.645+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bcfae50
[2025-07-19T20:48:15.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T20:48:15.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T20:48:15.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174] for update
[2025-07-19T20:48:15.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 166.0 in stage 7.0 (TID 769). 5872 bytes result sent to driver
[2025-07-19T20:48:15.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 169.0 in stage 7.0 (TID 772). 5872 bytes result sent to driver
[2025-07-19T20:48:15.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.2.delta.6b5558d2-d05a-47cc-a9b8-7156309c0f6b.TID774.tmp
[2025-07-19T20:48:15.658+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.2.delta.10e59cbf-652d-4798-9f14-c7608c552fd8.TID775.tmp
[2025-07-19T20:48:15.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.2.delta.98ba1b51-ccc5-4e88-b11c-a27373edfb0f.TID773.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/2.delta
[2025-07-19T20:48:15.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/170/2.delta
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 778) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 779) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 176.0 in stage 7.0 (TID 779)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 769) in 128 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 175.0 in stage 7.0 (TID 778)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T20:48:15.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 168.0 in stage 7.0 (TID 771). 5872 bytes result sent to driver
[2025-07-19T20:48:15.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 772) in 120 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:48:15.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 780) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.662+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e6ef917
[2025-07-19T20:48:15.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 771) in 122 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:48:15.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.2.delta.5937b864-28c3-44a2-a524-551d3cab73ac.TID776.tmp
[2025-07-19T20:48:15.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 177.0 in stage 7.0 (TID 780)
[2025-07-19T20:48:15.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176] for update
[2025-07-19T20:48:15.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:15.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2019e66f
[2025-07-19T20:48:15.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177] for update
[2025-07-19T20:48:15.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T20:48:15.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 170.0 in stage 7.0 (TID 773). 5872 bytes result sent to driver
[2025-07-19T20:48:15.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@474ddf97
[2025-07-19T20:48:15.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175] for update
[2025-07-19T20:48:15.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 781) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.2.delta.03eb33eb-362b-4bac-a28f-5828e33c576e.TID779.tmp
[2025-07-19T20:48:15.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.2.delta.8e3e77a5-4baa-427a-869e-97d80afc12cd.TID777.tmp
[2025-07-19T20:48:15.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 178.0 in stage 7.0 (TID 781)
[2025-07-19T20:48:15.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@70e2fded
[2025-07-19T20:48:15.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178] for update
[2025-07-19T20:48:15.718+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 773) in 147 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:48:15.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.2.delta.ea04d534-0aa9-4a6a-b622-91605611e61a.TID780.tmp
[2025-07-19T20:48:15.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.2.delta.2d3e9080-4030-42c9-8351-52abe0529555.TID778.tmp
[2025-07-19T20:48:15.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.2.delta.806172e9-0ac3-4531-aa06-7a57daee3c75.TID781.tmp
[2025-07-19T20:48:15.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.2.delta.10e59cbf-652d-4798-9f14-c7608c552fd8.TID775.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/2.delta
[2025-07-19T20:48:15.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/172/2.delta
[2025-07-19T20:48:15.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.2.delta.5937b864-28c3-44a2-a524-551d3cab73ac.TID776.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/2.delta
[2025-07-19T20:48:15.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/173/2.delta
[2025-07-19T20:48:15.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T20:48:15.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T20:48:15.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.2.delta.6b5558d2-d05a-47cc-a9b8-7156309c0f6b.TID774.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/2.delta
[2025-07-19T20:48:15.834+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/171/2.delta
[2025-07-19T20:48:15.837+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T20:48:15.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T20:48:15.840+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 173.0 in stage 7.0 (TID 776). 5872 bytes result sent to driver
[2025-07-19T20:48:15.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T20:48:15.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 172.0 in stage 7.0 (TID 775). 5872 bytes result sent to driver
[2025-07-19T20:48:15.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 782) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 783) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 180.0 in stage 7.0 (TID 783)
[2025-07-19T20:48:15.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T20:48:15.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 775) in 240 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:48:15.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 171.0 in stage 7.0 (TID 774). 5872 bytes result sent to driver
[2025-07-19T20:48:15.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.2.delta.03eb33eb-362b-4bac-a28f-5828e33c576e.TID779.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/2.delta
[2025-07-19T20:48:15.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/176/2.delta
[2025-07-19T20:48:15.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 784) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 179.0 in stage 7.0 (TID 782)
[2025-07-19T20:48:15.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 181.0 in stage 7.0 (TID 784)
[2025-07-19T20:48:15.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 776) in 328 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:48:15.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 774) in 339 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:48:15.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:15.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:15.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T20:48:15.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@202db614
[2025-07-19T20:48:15.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180] for update
[2025-07-19T20:48:15.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26b8c427
[2025-07-19T20:48:15.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179] for update
[2025-07-19T20:48:15.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30cb2ae4
[2025-07-19T20:48:15.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:15.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181] for update
[2025-07-19T20:48:15.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T20:48:15.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:15.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.2.delta.ea04d534-0aa9-4a6a-b622-91605611e61a.TID780.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/2.delta
[2025-07-19T20:48:15.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/177/2.delta
[2025-07-19T20:48:15.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.2.delta.8e3e77a5-4baa-427a-869e-97d80afc12cd.TID777.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/2.delta
[2025-07-19T20:48:15.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/174/2.delta
[2025-07-19T20:48:15.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T20:48:15.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T20:48:15.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 176.0 in stage 7.0 (TID 779). 5915 bytes result sent to driver
[2025-07-19T20:48:15.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 779) in 333 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:48:15.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 785) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 182.0 in stage 7.0 (TID 785)
[2025-07-19T20:48:15.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T20:48:15.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO DataWritingSparkTask: Committed partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T20:48:15.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 174.0 in stage 7.0 (TID 777). 5872 bytes result sent to driver
[2025-07-19T20:48:15.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Finished task 177.0 in stage 7.0 (TID 780). 5872 bytes result sent to driver
[2025-07-19T20:48:15.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 786) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:15.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 183.0 in stage 7.0 (TID 786)
[2025-07-19T20:48:15.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 787) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.2.delta.c1ca2b70-c3a5-46ff-aff9-6524877b5da9.TID782.tmp
[2025-07-19T20:48:16.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO Executor: Running task 184.0 in stage 7.0 (TID 787)
[2025-07-19T20:48:16.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 780) in 340 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:48:16.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 777) in 378 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:48:16.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:16.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b3d3c3a
[2025-07-19T20:48:16.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182] for update
[2025-07-19T20:48:16.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b074d6c
[2025-07-19T20:48:16.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183] for update
[2025-07-19T20:48:16.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fd7cc7c
[2025-07-19T20:48:16.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184] for update
[2025-07-19T20:48:16.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.2.delta.facd0062-0280-4400-a13e-41eb504658b6.TID783.tmp
[2025-07-19T20:48:16.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.2.delta.79699f7a-cd6c-45d4-b943-053aa6af0147.TID784.tmp
[2025-07-19T20:48:16.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.2.delta.165a44a5-d1c4-48e9-8257-a63e8e4f3bdb.TID787.tmp
[2025-07-19T20:48:16.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.2.delta.2d3e9080-4030-42c9-8351-52abe0529555.TID778.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/2.delta
[2025-07-19T20:48:16.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/175/2.delta
[2025-07-19T20:48:16.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T20:48:16.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.2.delta.8664cd63-2f63-4e1c-9b8d-942c602707b7.TID786.tmp
[2025-07-19T20:48:16.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.2.delta.806172e9-0ac3-4531-aa06-7a57daee3c75.TID781.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/2.delta
[2025-07-19T20:48:16.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/178/2.delta
[2025-07-19T20:48:16.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T20:48:16.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T20:48:16.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 175.0 in stage 7.0 (TID 778). 5872 bytes result sent to driver
[2025-07-19T20:48:16.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T20:48:16.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 178.0 in stage 7.0 (TID 781). 5872 bytes result sent to driver
[2025-07-19T20:48:16.063+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 788) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 789) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 185.0 in stage 7.0 (TID 788)
[2025-07-19T20:48:16.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 781) in 392 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:48:16.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 778) in 414 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:48:16.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.2.delta.1e59f4d3-fda7-49dc-9258-60e9d4a8bb13.TID785.tmp
[2025-07-19T20:48:16.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 186.0 in stage 7.0 (TID 789)
[2025-07-19T20:48:16.067+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1abbadc7
[2025-07-19T20:48:16.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185] for update
[2025-07-19T20:48:16.075+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4be8d2c9
[2025-07-19T20:48:16.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186] for update
[2025-07-19T20:48:16.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.2.delta.c1ca2b70-c3a5-46ff-aff9-6524877b5da9.TID782.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/2.delta
[2025-07-19T20:48:16.111+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/179/2.delta
[2025-07-19T20:48:16.112+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T20:48:16.113+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T20:48:16.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.2.delta.f46437e8-051e-49e2-9d9a-f7b5e43316b2.TID788.tmp
[2025-07-19T20:48:16.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 179.0 in stage 7.0 (TID 782). 5829 bytes result sent to driver
[2025-07-19T20:48:16.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.2.delta.165a44a5-d1c4-48e9-8257-a63e8e4f3bdb.TID787.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/2.delta
[2025-07-19T20:48:16.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/184/2.delta
[2025-07-19T20:48:16.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T20:48:16.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 790) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 187.0 in stage 7.0 (TID 790)
[2025-07-19T20:48:16.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 782) in 282 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:48:16.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.2.delta.79699f7a-cd6c-45d4-b943-053aa6af0147.TID784.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/2.delta
[2025-07-19T20:48:16.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/181/2.delta
[2025-07-19T20:48:16.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T20:48:16.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.2.delta.c9db0c5c-1335-4c5c-baa0-b2045f80a135.TID789.tmp
[2025-07-19T20:48:16.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 184.0 in stage 7.0 (TID 787). 5829 bytes result sent to driver
[2025-07-19T20:48:16.137+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.2.delta.facd0062-0280-4400-a13e-41eb504658b6.TID783.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/2.delta
[2025-07-19T20:48:16.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/180/2.delta
[2025-07-19T20:48:16.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T20:48:16.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3975e835
[2025-07-19T20:48:16.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 791) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 188.0 in stage 7.0 (TID 791)
[2025-07-19T20:48:16.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 787) in 142 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:48:16.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T20:48:16.140+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187] for update
[2025-07-19T20:48:16.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T20:48:16.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 181.0 in stage 7.0 (TID 784). 5829 bytes result sent to driver
[2025-07-19T20:48:16.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 792) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.143+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 189.0 in stage 7.0 (TID 792)
[2025-07-19T20:48:16.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T20:48:16.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 784) in 284 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:48:16.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 180.0 in stage 7.0 (TID 783). 5872 bytes result sent to driver
[2025-07-19T20:48:16.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49383e0a
[2025-07-19T20:48:16.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 783) in 296 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:48:16.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188] for update
[2025-07-19T20:48:16.150+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 793) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 190.0 in stage 7.0 (TID 793)
[2025-07-19T20:48:16.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.2.delta.8664cd63-2f63-4e1c-9b8d-942c602707b7.TID786.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/2.delta
[2025-07-19T20:48:16.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/183/2.delta
[2025-07-19T20:48:16.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f4905b6
[2025-07-19T20:48:16.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T20:48:16.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189] for update
[2025-07-19T20:48:16.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.155+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dee9d1b
[2025-07-19T20:48:16.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190] for update
[2025-07-19T20:48:16.160+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.161+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T20:48:16.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 183.0 in stage 7.0 (TID 786). 5829 bytes result sent to driver
[2025-07-19T20:48:16.162+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 794) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 191.0 in stage 7.0 (TID 794)
[2025-07-19T20:48:16.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 786) in 173 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:48:16.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.2.delta.322d365f-f890-455b-b35a-953587179a53.TID791.tmp
[2025-07-19T20:48:16.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.2.delta.31d9d899-dcee-4d43-9d71-595eb34efb23.TID790.tmp
[2025-07-19T20:48:16.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:16.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3952bfca
[2025-07-19T20:48:16.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191] for update
[2025-07-19T20:48:16.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.2.delta.8deb0f2d-1cfe-42b5-a0fb-95f18a9ebfc0.TID793.tmp
[2025-07-19T20:48:16.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.2.delta.3cd75577-9ba6-45c9-af38-5fb7901e55f2.TID792.tmp
[2025-07-19T20:48:16.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.2.delta.1e59f4d3-fda7-49dc-9258-60e9d4a8bb13.TID785.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/2.delta
[2025-07-19T20:48:16.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/182/2.delta
[2025-07-19T20:48:16.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T20:48:16.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T20:48:16.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 182.0 in stage 7.0 (TID 785). 5829 bytes result sent to driver
[2025-07-19T20:48:16.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.2.delta.f46437e8-051e-49e2-9d9a-f7b5e43316b2.TID788.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/2.delta
[2025-07-19T20:48:16.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/185/2.delta
[2025-07-19T20:48:16.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 795) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 785) in 203 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:48:16.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 192.0 in stage 7.0 (TID 795)
[2025-07-19T20:48:16.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T20:48:16.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c30d9b0
[2025-07-19T20:48:16.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192] for update
[2025-07-19T20:48:16.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.2.delta.1ce1e916-47e5-42ac-a627-896b9d3a5651.TID794.tmp
[2025-07-19T20:48:16.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.195+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T20:48:16.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 185.0 in stage 7.0 (TID 788). 5829 bytes result sent to driver
[2025-07-19T20:48:16.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 788) in 139 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:48:16.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 796) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 193.0 in stage 7.0 (TID 796)
[2025-07-19T20:48:16.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.203+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b0d813d
[2025-07-19T20:48:16.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193] for update
[2025-07-19T20:48:16.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.2.delta.704d7e47-1241-4c9a-94a4-d88d71d4826f.TID795.tmp
[2025-07-19T20:48:16.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.2.delta.c9db0c5c-1335-4c5c-baa0-b2045f80a135.TID789.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/2.delta
[2025-07-19T20:48:16.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/186/2.delta
[2025-07-19T20:48:16.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T20:48:16.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.2.delta.f307077f-e09c-4488-9fc4-448cae9ba282.TID796.tmp
[2025-07-19T20:48:16.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T20:48:16.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 186.0 in stage 7.0 (TID 789). 5829 bytes result sent to driver
[2025-07-19T20:48:16.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 797) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 789) in 160 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:48:16.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 194.0 in stage 7.0 (TID 797)
[2025-07-19T20:48:16.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6af3cd4f
[2025-07-19T20:48:16.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194] for update
[2025-07-19T20:48:16.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.2.delta.3cd75577-9ba6-45c9-af38-5fb7901e55f2.TID792.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/2.delta
[2025-07-19T20:48:16.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/189/2.delta
[2025-07-19T20:48:16.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T20:48:16.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.2.delta.322d365f-f890-455b-b35a-953587179a53.TID791.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/2.delta
[2025-07-19T20:48:16.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/188/2.delta
[2025-07-19T20:48:16.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T20:48:16.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.2.delta.31d9d899-dcee-4d43-9d71-595eb34efb23.TID790.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/2.delta
[2025-07-19T20:48:16.235+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/187/2.delta
[2025-07-19T20:48:16.236+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T20:48:16.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.2.delta.8deb0f2d-1cfe-42b5-a0fb-95f18a9ebfc0.TID793.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/2.delta
[2025-07-19T20:48:16.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/190/2.delta
[2025-07-19T20:48:16.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T20:48:16.239+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T20:48:16.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 189.0 in stage 7.0 (TID 792). 5829 bytes result sent to driver
[2025-07-19T20:48:16.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 798) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 195.0 in stage 7.0 (TID 798)
[2025-07-19T20:48:16.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 792) in 100 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:48:16.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T20:48:16.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T20:48:16.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 188.0 in stage 7.0 (TID 791). 5829 bytes result sent to driver
[2025-07-19T20:48:16.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T20:48:16.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 187.0 in stage 7.0 (TID 790). 5829 bytes result sent to driver
[2025-07-19T20:48:16.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 190.0 in stage 7.0 (TID 793). 5829 bytes result sent to driver
[2025-07-19T20:48:16.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 799) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 196.0 in stage 7.0 (TID 799)
[2025-07-19T20:48:16.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 800) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 793) in 104 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:48:16.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 790) in 121 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:48:16.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 197.0 in stage 7.0 (TID 800)
[2025-07-19T20:48:16.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d56967b
[2025-07-19T20:48:16.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195] for update
[2025-07-19T20:48:16.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 801) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 791) in 118 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:48:16.256+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 198.0 in stage 7.0 (TID 801)
[2025-07-19T20:48:16.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.2.delta.1ce1e916-47e5-42ac-a627-896b9d3a5651.TID794.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/2.delta
[2025-07-19T20:48:16.261+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/191/2.delta
[2025-07-19T20:48:16.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.2.delta.79ba3fc4-08b0-4703-8717-3c2e29c6215d.TID797.tmp
[2025-07-19T20:48:16.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T20:48:16.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22702442
[2025-07-19T20:48:16.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197] for update
[2025-07-19T20:48:16.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76f3e8cd
[2025-07-19T20:48:16.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196] for update
[2025-07-19T20:48:16.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T20:48:16.275+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 191.0 in stage 7.0 (TID 794). 5829 bytes result sent to driver
[2025-07-19T20:48:16.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b633e7d
[2025-07-19T20:48:16.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 802) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 199.0 in stage 7.0 (TID 802)
[2025-07-19T20:48:16.279+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198] for update
[2025-07-19T20:48:16.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 794) in 111 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:48:16.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2dc9db00
[2025-07-19T20:48:16.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],1de00c25-9d15-45b4-834f-e4fa238248c8) is active
[2025-07-19T20:48:16.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199] for update
[2025-07-19T20:48:16.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.2.delta.5e98fda8-20eb-4329-8297-2df2de85e921.TID799.tmp
[2025-07-19T20:48:16.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.2.delta.f307077f-e09c-4488-9fc4-448cae9ba282.TID796.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/2.delta
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/193/2.delta
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.2.delta.970b70b0-7611-4f8c-8ac6-6a6b0395b4e3.TID798.tmp
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.2.delta.3909de81-24bc-4fc5-873b-d80760482d60.TID801.tmp
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.2.delta.704d7e47-1241-4c9a-94a4-d88d71d4826f.TID795.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/2.delta
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/192/2.delta
[2025-07-19T20:48:16.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T20:48:16.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 193.0 in stage 7.0 (TID 796). 5829 bytes result sent to driver
[2025-07-19T20:48:16.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 803) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 796) in 87 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:48:16.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 0.0 in stage 9.0 (TID 803)
[2025-07-19T20:48:16.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.2.delta.9b3a4f0b-dbe8-447b-a330-b762358d02d4.TID800.tmp
[2025-07-19T20:48:16.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T20:48:16.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.2.delta.ad6a545b-e156-48c4-a327-16b9833a28b9.TID802.tmp
[2025-07-19T20:48:16.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T20:48:16.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 192.0 in stage 7.0 (TID 795). 5829 bytes result sent to driver
[2025-07-19T20:48:16.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 804) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32f3a46f
[2025-07-19T20:48:16.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 795) in 123 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:48:16.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 1.0 in stage 9.0 (TID 804)
[2025-07-19T20:48:16.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0] for update
[2025-07-19T20:48:16.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3687b71e
[2025-07-19T20:48:16.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1] for update
[2025-07-19T20:48:16.322+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.323+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.2.delta.79ba3fc4-08b0-4703-8717-3c2e29c6215d.TID797.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/2.delta
[2025-07-19T20:48:16.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/194/2.delta
[2025-07-19T20:48:16.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T20:48:16.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T20:48:16.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 194.0 in stage 7.0 (TID 797). 5829 bytes result sent to driver
[2025-07-19T20:48:16.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 805) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 797) in 104 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:48:16.330+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.2.delta.3909de81-24bc-4fc5-873b-d80760482d60.TID801.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/2.delta
[2025-07-19T20:48:16.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/198/2.delta
[2025-07-19T20:48:16.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T20:48:16.332+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 2.0 in stage 9.0 (TID 805)
[2025-07-19T20:48:16.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.2.delta.5e98fda8-20eb-4329-8297-2df2de85e921.TID799.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/2.delta
[2025-07-19T20:48:16.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/196/2.delta
[2025-07-19T20:48:16.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T20:48:16.344+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T20:48:16.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 198.0 in stage 7.0 (TID 801). 5829 bytes result sent to driver
[2025-07-19T20:48:16.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.2.delta.970b70b0-7611-4f8c-8ac6-6a6b0395b4e3.TID798.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/2.delta
[2025-07-19T20:48:16.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/195/2.delta
[2025-07-19T20:48:16.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodeGenerator: Code generated in 21.753708 ms
[2025-07-19T20:48:16.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 806) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 3.0 in stage 9.0 (TID 806)
[2025-07-19T20:48:16.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 801) in 87 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:48:16.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T20:48:16.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.2.delta.9b3a4f0b-dbe8-447b-a330-b762358d02d4.TID800.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/2.delta
[2025-07-19T20:48:16.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/197/2.delta
[2025-07-19T20:48:16.355+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T20:48:16.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 196.0 in stage 7.0 (TID 799). 5829 bytes result sent to driver
[2025-07-19T20:48:16.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 807) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.360+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:16.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 799) in 100 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:48:16.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 4.0 in stage 9.0 (TID 807)
[2025-07-19T20:48:16.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T20:48:16.363+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25a0ca18
[2025-07-19T20:48:16.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2] for update
[2025-07-19T20:48:16.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6121a061
[2025-07-19T20:48:16.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3] for update
[2025-07-19T20:48:16.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T20:48:16.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 195.0 in stage 7.0 (TID 798). 5829 bytes result sent to driver
[2025-07-19T20:48:16.369+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:16.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 808) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 5.0 in stage 9.0 (TID 808)
[2025-07-19T20:48:16.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 798) in 112 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:48:16.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T20:48:16.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 197.0 in stage 7.0 (TID 800). 5829 bytes result sent to driver
[2025-07-19T20:48:16.372+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fc16ea6
[2025-07-19T20:48:16.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4] for update
[2025-07-19T20:48:16.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.375+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 809) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 800) in 114 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:48:16.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ca0e66f
[2025-07-19T20:48:16.388+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5] for update
[2025-07-19T20:48:16.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 6.0 in stage 9.0 (TID 809)
[2025-07-19T20:48:16.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.2.delta.fce6a8fe-e34a-45d8-a961-533bfd7974a5.TID805.tmp
[2025-07-19T20:48:16.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:16.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20f5fd45
[2025-07-19T20:48:16.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6] for update
[2025-07-19T20:48:16.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.2.delta.0a1f7f22-38a9-420f-9cfc-9c12ae5fd78e.TID806.tmp
[2025-07-19T20:48:16.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.2.delta.7951f9b3-14ba-4123-932f-0c67934b31c0.TID804.tmp
[2025-07-19T20:48:16.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.2.delta.ad6a545b-e156-48c4-a327-16b9833a28b9.TID802.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/2.delta
[2025-07-19T20:48:16.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/state/0/199/2.delta
[2025-07-19T20:48:16.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T20:48:16.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.2.delta.b3b67f24-a1f9-4c77-91eb-056af062e002.TID803.tmp
[2025-07-19T20:48:16.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.2.delta.d734292d-e2cb-4cb8-98b5-e84c4bf9f548.TID807.tmp
[2025-07-19T20:48:16.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T20:48:16.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 199.0 in stage 7.0 (TID 802). 5872 bytes result sent to driver
[2025-07-19T20:48:16.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 810) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 7.0 in stage 9.0 (TID 810)
[2025-07-19T20:48:16.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 802) in 125 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:48:16.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-19T20:48:16.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DAGScheduler: ResultStage 7 (start at <unknown>:0) finished in 5.973 s
[2025-07-19T20:48:16.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ca26150
[2025-07-19T20:48:16.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7] for update
[2025-07-19T20:48:16.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:48:16.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-19T20:48:16.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DAGScheduler: Job 3 finished: start at <unknown>:0, took 6.064623 s
[2025-07-19T20:48:16.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T20:48:16.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO SparkWrite: Committing epoch 1 for query b0ea99b8-5ad6-454d-8c07-6fb91d8182de in append mode
[2025-07-19T20:48:16.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.2.delta.99da38ca-4c69-4060-a88f-dedefd49a873.TID809.tmp
[2025-07-19T20:48:16.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.2.delta.ed8fa3fb-7853-434b-a067-d6fff4ecc987.TID808.tmp
[2025-07-19T20:48:16.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.2.delta.9f189d75-c742-4cb8-8a4e-609566511209.TID810.tmp
[2025-07-19T20:48:16.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T20:48:16.446+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/.2.delta.7951f9b3-14ba-4123-932f-0c67934b31c0.TID804.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/2.delta
[2025-07-19T20:48:16.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/1/2.delta
[2025-07-19T20:48:16.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T20:48:16.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T20:48:16.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 1.0 in stage 9.0 (TID 804). 5829 bytes result sent to driver
[2025-07-19T20:48:16.456+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 811) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.456+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 8.0 in stage 9.0 (TID 811)
[2025-07-19T20:48:16.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 804) in 150 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:48:16.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/.2.delta.fce6a8fe-e34a-45d8-a961-533bfd7974a5.TID805.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/2.delta
[2025-07-19T20:48:16.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/2/2.delta
[2025-07-19T20:48:16.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T20:48:16.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41139daa
[2025-07-19T20:48:16.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8] for update
[2025-07-19T20:48:16.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.477+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T20:48:16.477+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 2.0 in stage 9.0 (TID 805). 5829 bytes result sent to driver
[2025-07-19T20:48:16.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/.2.delta.d734292d-e2cb-4cb8-98b5-e84c4bf9f548.TID807.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/2.delta
[2025-07-19T20:48:16.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/4/2.delta
[2025-07-19T20:48:16.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 812) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T20:48:16.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 9.0 in stage 9.0 (TID 812)
[2025-07-19T20:48:16.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 805) in 153 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:48:16.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.491+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33170e57
[2025-07-19T20:48:16.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.494+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9] for update
[2025-07-19T20:48:16.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T20:48:16.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 4.0 in stage 9.0 (TID 807). 5829 bytes result sent to driver
[2025-07-19T20:48:16.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/.2.delta.0a1f7f22-38a9-420f-9cfc-9c12ae5fd78e.TID806.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/2.delta
[2025-07-19T20:48:16.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/3/2.delta
[2025-07-19T20:48:16.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 813) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T20:48:16.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 10.0 in stage 9.0 (TID 813)
[2025-07-19T20:48:16.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 807) in 152 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:48:16.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:16.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T20:48:16.536+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25859143
[2025-07-19T20:48:16.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10] for update
[2025-07-19T20:48:16.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 3.0 in stage 9.0 (TID 806). 5829 bytes result sent to driver
[2025-07-19T20:48:16.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 814) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/.2.delta.99da38ca-4c69-4060-a88f-dedefd49a873.TID809.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/2.delta
[2025-07-19T20:48:16.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/6/2.delta
[2025-07-19T20:48:16.552+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 806) in 171 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:48:16.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 11.0 in stage 9.0 (TID 814)
[2025-07-19T20:48:16.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T20:48:16.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/.2.delta.b3b67f24-a1f9-4c77-91eb-056af062e002.TID803.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/2.delta
[2025-07-19T20:48:16.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/0/2.delta
[2025-07-19T20:48:16.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T20:48:16.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a346d2
[2025-07-19T20:48:16.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11] for update
[2025-07-19T20:48:16.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.2.delta.faed173a-641e-46c1-81e4-2bf05f195ccc.TID811.tmp
[2025-07-19T20:48:16.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T20:48:16.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T20:48:16.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 0.0 in stage 9.0 (TID 803). 5829 bytes result sent to driver
[2025-07-19T20:48:16.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 6.0 in stage 9.0 (TID 809). 5829 bytes result sent to driver
[2025-07-19T20:48:16.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 815) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 12.0 in stage 9.0 (TID 815)
[2025-07-19T20:48:16.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 803) in 234 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:48:16.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 816) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 13.0 in stage 9.0 (TID 816)
[2025-07-19T20:48:16.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 809) in 170 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:48:16.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/.2.delta.9f189d75-c742-4cb8-8a4e-609566511209.TID810.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/2.delta
[2025-07-19T20:48:16.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/7/2.delta
[2025-07-19T20:48:16.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T20:48:16.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T20:48:16.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 7.0 in stage 9.0 (TID 810). 5829 bytes result sent to driver
[2025-07-19T20:48:16.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71e5d20d
[2025-07-19T20:48:16.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.2.delta.492ed189-a03e-4be6-8ee8-d76a6c46da0a.TID813.tmp
[2025-07-19T20:48:16.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 817) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 14.0 in stage 9.0 (TID 817)
[2025-07-19T20:48:16.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12] for update
[2025-07-19T20:48:16.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 810) in 152 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:48:16.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c5ada0c
[2025-07-19T20:48:16.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13] for update
[2025-07-19T20:48:16.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.2.delta.3ead3680-94b4-42d1-ba9b-fee2156802a5.TID814.tmp
[2025-07-19T20:48:16.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:16.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@238a806f
[2025-07-19T20:48:16.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14] for update
[2025-07-19T20:48:16.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.2.delta.36d5501f-95a3-4648-8a64-b349f421311b.TID812.tmp
[2025-07-19T20:48:16.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/.2.delta.ed8fa3fb-7853-434b-a067-d6fff4ecc987.TID808.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/2.delta
[2025-07-19T20:48:16.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/5/2.delta
[2025-07-19T20:48:16.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T20:48:16.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T20:48:16.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 5.0 in stage 9.0 (TID 808). 5829 bytes result sent to driver
[2025-07-19T20:48:16.628+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 818) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 15.0 in stage 9.0 (TID 818)
[2025-07-19T20:48:16.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 808) in 222 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:48:16.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.2.delta.8537dbba-d928-495d-aa89-6341be54788c.TID816.tmp
[2025-07-19T20:48:16.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.2.delta.937787fc-8aba-4145-bd46-f0850d30a4f6.TID817.tmp
[2025-07-19T20:48:16.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.2.delta.cbb56fe6-b45c-4849-b96e-cd9497f7458d.TID815.tmp
[2025-07-19T20:48:16.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a59f37
[2025-07-19T20:48:16.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15] for update
[2025-07-19T20:48:16.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/.2.delta.492ed189-a03e-4be6-8ee8-d76a6c46da0a.TID813.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/2.delta
[2025-07-19T20:48:16.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/10/2.delta
[2025-07-19T20:48:16.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T20:48:16.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.2.delta.5dd6fcb8-44ec-4669-b7c6-e58d34a942d5.TID818.tmp
[2025-07-19T20:48:16.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T20:48:16.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 10.0 in stage 9.0 (TID 813). 5829 bytes result sent to driver
[2025-07-19T20:48:16.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 813) in 124 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:48:16.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 819) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 16.0 in stage 9.0 (TID 819)
[2025-07-19T20:48:16.634+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dabb21a
[2025-07-19T20:48:16.640+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16] for update
[2025-07-19T20:48:16.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:16.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v121.metadata.json
[2025-07-19T20:48:16.642+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/.2.delta.36d5501f-95a3-4648-8a64-b349f421311b.TID812.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/2.delta
[2025-07-19T20:48:16.644+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/9/2.delta
[2025-07-19T20:48:16.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T20:48:16.647+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/.2.delta.faed173a-641e-46c1-81e4-2bf05f195ccc.TID811.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/2.delta
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/8/2.delta
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/.2.delta.3ead3680-94b4-42d1-ba9b-fee2156802a5.TID814.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/2.delta
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/11/2.delta
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T20:48:16.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T20:48:16.649+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T20:48:16.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 9.0 in stage 9.0 (TID 812). 5915 bytes result sent to driver
[2025-07-19T20:48:16.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 8.0 in stage 9.0 (TID 811). 5915 bytes result sent to driver
[2025-07-19T20:48:16.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 11.0 in stage 9.0 (TID 814). 5915 bytes result sent to driver
[2025-07-19T20:48:16.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/.2.delta.8537dbba-d928-495d-aa89-6341be54788c.TID816.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/2.delta
[2025-07-19T20:48:16.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/13/2.delta
[2025-07-19T20:48:16.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 820) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 821) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 822) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 19.0 in stage 9.0 (TID 822)
[2025-07-19T20:48:16.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 18.0 in stage 9.0 (TID 821)
[2025-07-19T20:48:16.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T20:48:16.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 17.0 in stage 9.0 (TID 820)
[2025-07-19T20:48:16.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 812) in 215 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:48:16.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 811) in 251 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:48:16.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 814) in 201 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:48:16.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/.2.delta.cbb56fe6-b45c-4849-b96e-cd9497f7458d.TID815.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/2.delta
[2025-07-19T20:48:16.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/12/2.delta
[2025-07-19T20:48:16.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:48:16.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T20:48:16.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d3525f1
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19] for update
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.2.delta.93a79bb5-bc5c-49c0-8dc5-74f9a312de9a.TID819.tmp
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/.2.delta.937787fc-8aba-4145-bd46-f0850d30a4f6.TID817.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/2.delta
[2025-07-19T20:48:16.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/14/2.delta
[2025-07-19T20:48:16.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T20:48:16.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cb443a6
[2025-07-19T20:48:16.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Committed partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T20:48:16.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18] for update
[2025-07-19T20:48:16.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 13.0 in stage 9.0 (TID 816). 5915 bytes result sent to driver
[2025-07-19T20:48:16.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Finished task 12.0 in stage 9.0 (TID 815). 5915 bytes result sent to driver
[2025-07-19T20:48:16.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T20:48:16.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b87b4dc
[2025-07-19T20:48:16.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:16.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17] for update
[2025-07-19T20:48:16.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 823) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.832+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 20.0 in stage 9.0 (TID 823)
[2025-07-19T20:48:16.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:16.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 824) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:16.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 815) in 365 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:48:16.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 816) in 379 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:48:16.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO Executor: Running task 21.0 in stage 9.0 (TID 824)
[2025-07-19T20:48:16.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.2.delta.8ec63664-5e18-4ae6-a183-a9173e831fca.TID821.tmp
[2025-07-19T20:48:17.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:17.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 30 ms
[2025-07-19T20:48:17.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:16 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@333b9cc2
[2025-07-19T20:48:17.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20] for update
[2025-07-19T20:48:17.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/.2.delta.5dd6fcb8-44ec-4669-b7c6-e58d34a942d5.TID818.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/2.delta
[2025-07-19T20:48:17.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/15/2.delta
[2025-07-19T20:48:17.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T20:48:17.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T20:48:17.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 14.0 in stage 9.0 (TID 817). 5872 bytes result sent to driver
[2025-07-19T20:48:17.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.2.delta.41e54ca8-313f-430d-9244-798f57b9f26b.TID822.tmp
[2025-07-19T20:48:17.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 825) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO SnapshotProducer: Committed snapshot 500105052577255874 (FastAppend)
[2025-07-19T20:48:17.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d929c7c
[2025-07-19T20:48:17.122+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.2.delta.e93397ea-272a-403b-b92e-65530592866a.TID820.tmp
[2025-07-19T20:48:17.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 22.0 in stage 9.0 (TID 825)
[2025-07-19T20:48:17.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21] for update
[2025-07-19T20:48:17.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T20:48:17.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 15.0 in stage 9.0 (TID 818). 5872 bytes result sent to driver
[2025-07-19T20:48:17.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.135+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:17.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.144+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a2e7174
[2025-07-19T20:48:17.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.146+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22] for update
[2025-07-19T20:48:17.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.151+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 817) in 556 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:48:17.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 826) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 23.0 in stage 9.0 (TID 826)
[2025-07-19T20:48:17.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 818) in 596 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:48:17.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.2.delta.cf9b3a2e-1792-4f2d-b4d5-801c2394a848.TID823.tmp
[2025-07-19T20:48:17.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.2.delta.f189f5ac-32c7-48c9-860c-2f58c708e002.TID824.tmp
[2025-07-19T20:48:17.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd4650d
[2025-07-19T20:48:17.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.266+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23] for update
[2025-07-19T20:48:17.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.2.delta.fc0271a4-4af3-479e-8342-531df6a18afa.TID825.tmp
[2025-07-19T20:48:17.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=500105052577255874, sequenceNumber=120, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.880504251S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5828}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8010}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=16788812}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958074309, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:48:17.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO SparkWrite: Committed in 884 ms
[2025-07-19T20:48:17.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T20:48:17.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.2.delta.04d1ffef-f3bc-4151-8794-701250e1b01d.TID826.tmp
[2025-07-19T20:48:17.390+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 8b44f3d35cfa:46433 in memory (size: 15.8 KiB, free: 434.3 MiB)
[2025-07-19T20:48:17.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/.2.delta.93a79bb5-bc5c-49c0-8dc5-74f9a312de9a.TID819.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/2.delta
[2025-07-19T20:48:17.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/16/2.delta
[2025-07-19T20:48:17.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T20:48:17.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/.2.delta.8ec63664-5e18-4ae6-a183-a9173e831fca.TID821.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/2.delta
[2025-07-19T20:48:17.399+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/18/2.delta
[2025-07-19T20:48:17.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T20:48:17.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 16.0 in stage 9.0 (TID 819). 5872 bytes result sent to driver
[2025-07-19T20:48:17.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T20:48:17.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 827) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 24.0 in stage 9.0 (TID 827)
[2025-07-19T20:48:17.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 819) in 785 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:48:17.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.410+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dc5270a
[2025-07-19T20:48:17.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/.1.14798b37-7c5d-4e97-b09f-909dfe2aa504.tmp
[2025-07-19T20:48:17.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24] for update
[2025-07-19T20:48:17.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T20:48:17.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 18.0 in stage 9.0 (TID 821). 5915 bytes result sent to driver
[2025-07-19T20:48:17.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 828) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.412+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 821) in 731 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:48:17.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/.2.delta.41e54ca8-313f-430d-9244-798f57b9f26b.TID822.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/2.delta
[2025-07-19T20:48:17.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/19/2.delta
[2025-07-19T20:48:17.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T20:48:17.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/.2.delta.e93397ea-272a-403b-b92e-65530592866a.TID820.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/2.delta
[2025-07-19T20:48:17.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/17/2.delta
[2025-07-19T20:48:17.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T20:48:17.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 25.0 in stage 9.0 (TID 828)
[2025-07-19T20:48:17.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f0f43a2
[2025-07-19T20:48:17.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25] for update
[2025-07-19T20:48:17.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T20:48:17.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T20:48:17.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 19.0 in stage 9.0 (TID 822). 5872 bytes result sent to driver
[2025-07-19T20:48:17.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 17.0 in stage 9.0 (TID 820). 5872 bytes result sent to driver
[2025-07-19T20:48:17.436+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 829) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 26.0 in stage 9.0 (TID 829)
[2025-07-19T20:48:17.439+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 820) in 748 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:48:17.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 830) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.443+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 27.0 in stage 9.0 (TID 830)
[2025-07-19T20:48:17.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 822) in 745 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:48:17.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.465+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7acf953b
[2025-07-19T20:48:17.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26] for update
[2025-07-19T20:48:17.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3945a36e
[2025-07-19T20:48:17.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/.2.delta.cf9b3a2e-1792-4f2d-b4d5-801c2394a848.TID823.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/2.delta
[2025-07-19T20:48:17.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/20/2.delta
[2025-07-19T20:48:17.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T20:48:17.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27] for update
[2025-07-19T20:48:17.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.2.delta.d457570a-d832-4d9e-9d8d-c604f6fcd16d.TID827.tmp
[2025-07-19T20:48:17.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T20:48:17.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.2.delta.e67c8165-1cf7-4ba1-9340-eab3dd28ddf2.TID829.tmp
[2025-07-19T20:48:17.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 20.0 in stage 9.0 (TID 823). 5872 bytes result sent to driver
[2025-07-19T20:48:17.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 831) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 823) in 681 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:48:17.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 28.0 in stage 9.0 (TID 831)
[2025-07-19T20:48:17.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.2.delta.99107ad8-22a9-4647-a73b-706545fc7659.TID828.tmp
[2025-07-19T20:48:17.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.2.delta.e9772055-0249-4de4-82bc-55e46e589b95.TID830.tmp
[2025-07-19T20:48:17.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/.2.delta.04d1ffef-f3bc-4151-8794-701250e1b01d.TID826.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/2.delta
[2025-07-19T20:48:17.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/23/2.delta
[2025-07-19T20:48:17.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T20:48:17.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76f9cba
[2025-07-19T20:48:17.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28] for update
[2025-07-19T20:48:17.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/.2.delta.f189f5ac-32c7-48c9-860c-2f58c708e002.TID824.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/2.delta
[2025-07-19T20:48:17.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/21/2.delta
[2025-07-19T20:48:17.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T20:48:17.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T20:48:17.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 23.0 in stage 9.0 (TID 826). 5829 bytes result sent to driver
[2025-07-19T20:48:17.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T20:48:17.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 21.0 in stage 9.0 (TID 824). 5829 bytes result sent to driver
[2025-07-19T20:48:17.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 832) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 826) in 415 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:48:17.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 833) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 29.0 in stage 9.0 (TID 832)
[2025-07-19T20:48:17.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.2.delta.8001b750-e0f4-4529-9203-10ae6f120340.TID831.tmp
[2025-07-19T20:48:17.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 824) in 720 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:48:17.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 30.0 in stage 9.0 (TID 833)
[2025-07-19T20:48:17.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/.2.delta.fc0271a4-4af3-479e-8342-531df6a18afa.TID825.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/2.delta
[2025-07-19T20:48:17.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/22/2.delta
[2025-07-19T20:48:17.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T20:48:17.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aa28ce8
[2025-07-19T20:48:17.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:17.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T20:48:17.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 22.0 in stage 9.0 (TID 825). 5829 bytes result sent to driver
[2025-07-19T20:48:17.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30] for update
[2025-07-19T20:48:17.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 834) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/.1.14798b37-7c5d-4e97-b09f-909dfe2aa504.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:44:00+00:00/commits/1
[2025-07-19T20:48:17.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47b0d3d1
[2025-07-19T20:48:17.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:48:17.593+0000] {subprocess.py:93} INFO -   "id" : "b0ea99b8-5ad6-454d-8c07-6fb91d8182de",
[2025-07-19T20:48:17.593+0000] {subprocess.py:93} INFO -   "runId" : "1de00c25-9d15-45b4-834f-e4fa238248c8",
[2025-07-19T20:48:17.594+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:48:17.596+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:48:09.898Z",
[2025-07-19T20:48:17.596+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T20:48:17.597+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T20:48:17.599+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:17.600+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T20:48:17.600+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:48:17.601+0000] {subprocess.py:93} INFO -     "addBatch" : 7204,
[2025-07-19T20:48:17.601+0000] {subprocess.py:93} INFO -     "commitOffsets" : 226,
[2025-07-19T20:48:17.601+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T20:48:17.602+0000] {subprocess.py:93} INFO -     "latestOffset" : 19,
[2025-07-19T20:48:17.602+0000] {subprocess.py:93} INFO -     "queryPlanning" : 94,
[2025-07-19T20:48:17.602+0000] {subprocess.py:93} INFO -     "triggerExecution" : 7686,
[2025-07-19T20:48:17.603+0000] {subprocess.py:93} INFO -     "walCommit" : 121
[2025-07-19T20:48:17.603+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:17.604+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:48:17.604+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T20:47:48.000Z"
[2025-07-19T20:48:17.605+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:17.605+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:48:17.606+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:48:17.606+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 222,
[2025-07-19T20:48:17.611+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T20:48:17.612+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 261,
[2025-07-19T20:48:17.621+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:48:17.624+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 172,
[2025-07-19T20:48:17.625+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 18701,
[2025-07-19T20:48:17.626+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 146192,
[2025-07-19T20:48:17.628+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:48:17.629+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:48:17.630+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:48:17.631+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:48:17.633+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T20:48:17.637+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:48:17.641+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:48:17.643+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 66848
[2025-07-19T20:48:17.650+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:17.651+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:17.657+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:48:17.661+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T20:48:17.662+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T20:48:17.663+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:48:17.663+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:17.663+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:17.664+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:17.666+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:48:17.667+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:48:17.667+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:17.668+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:17.668+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:17.670+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:48:17.672+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:48:17.676+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:17.677+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:17.677+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:17.678+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T20:48:17.681+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:17.683+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T20:48:17.685+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:48:17.686+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:48:17.691+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:48:17.693+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:48:17.699+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:17.711+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:17.717+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:48:17.721+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T20:48:17.724+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T20:48:17.725+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:48:17.725+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:48:17.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 31.0 in stage 9.0 (TID 834)
[2025-07-19T20:48:17.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 825) in 499 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:48:17.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/.2.delta.d457570a-d832-4d9e-9d8d-c604f6fcd16d.TID827.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/2.delta
[2025-07-19T20:48:17.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/24/2.delta
[2025-07-19T20:48:17.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29] for update
[2025-07-19T20:48:17.735+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a257c39
[2025-07-19T20:48:17.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.737+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T20:48:17.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31] for update
[2025-07-19T20:48:17.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.2.delta.bd814dc1-4020-4927-9e19-11e3ff711415.TID833.tmp
[2025-07-19T20:48:17.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T20:48:17.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 24.0 in stage 9.0 (TID 827). 5829 bytes result sent to driver
[2025-07-19T20:48:17.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 835) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 827) in 227 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:48:17.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 32.0 in stage 9.0 (TID 835)
[2025-07-19T20:48:17.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/.2.delta.e67c8165-1cf7-4ba1-9340-eab3dd28ddf2.TID829.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/2.delta
[2025-07-19T20:48:17.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/26/2.delta
[2025-07-19T20:48:17.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T20:48:17.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.2.delta.e5015b41-51bd-48ee-849d-8c073089fcc3.TID832.tmp
[2025-07-19T20:48:17.776+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.2.delta.2f248959-1c6a-43c4-ab7a-9245806f1ef1.TID834.tmp
[2025-07-19T20:48:17.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65380e8a
[2025-07-19T20:48:17.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32] for update
[2025-07-19T20:48:17.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/.2.delta.e9772055-0249-4de4-82bc-55e46e589b95.TID830.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/2.delta
[2025-07-19T20:48:17.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/27/2.delta
[2025-07-19T20:48:17.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T20:48:17.788+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T20:48:17.790+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 26.0 in stage 9.0 (TID 829). 5829 bytes result sent to driver
[2025-07-19T20:48:17.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 836) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 829) in 237 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:48:17.799+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 33.0 in stage 9.0 (TID 836)
[2025-07-19T20:48:17.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T20:48:17.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 27.0 in stage 9.0 (TID 830). 5829 bytes result sent to driver
[2025-07-19T20:48:17.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 837) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 34.0 in stage 9.0 (TID 837)
[2025-07-19T20:48:17.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 830) in 237 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:48:17.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:17.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25ea686a
[2025-07-19T20:48:17.826+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34] for update
[2025-07-19T20:48:17.830+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7213371
[2025-07-19T20:48:17.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33] for update
[2025-07-19T20:48:17.843+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/.2.delta.99107ad8-22a9-4647-a73b-706545fc7659.TID828.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/2.delta
[2025-07-19T20:48:17.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/25/2.delta
[2025-07-19T20:48:17.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T20:48:17.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.2.delta.93ed9207-63c2-48a7-af28-c396e2ea53bf.TID835.tmp
[2025-07-19T20:48:17.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T20:48:17.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 25.0 in stage 9.0 (TID 828). 5829 bytes result sent to driver
[2025-07-19T20:48:17.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 838) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 828) in 284 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:48:17.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 35.0 in stage 9.0 (TID 838)
[2025-07-19T20:48:17.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.857+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@772cdee5
[2025-07-19T20:48:17.858+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35] for update
[2025-07-19T20:48:17.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.2.delta.0a40be5c-c6cc-44bc-80e5-280dae7676ee.TID836.tmp
[2025-07-19T20:48:17.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/.2.delta.8001b750-e0f4-4529-9203-10ae6f120340.TID831.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/2.delta
[2025-07-19T20:48:17.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/28/2.delta
[2025-07-19T20:48:17.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T20:48:17.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.2.delta.28066711-63fd-4a38-af97-709bbad60824.TID837.tmp
[2025-07-19T20:48:17.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T20:48:17.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 28.0 in stage 9.0 (TID 831). 5829 bytes result sent to driver
[2025-07-19T20:48:17.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 839) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 36.0 in stage 9.0 (TID 839)
[2025-07-19T20:48:17.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:17.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 831) in 239 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:48:17.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.2.delta.e209ab10-fd65-4531-9541-bcd6b122d488.TID838.tmp
[2025-07-19T20:48:17.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@413830f
[2025-07-19T20:48:17.872+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.873+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36] for update
[2025-07-19T20:48:17.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/.2.delta.bd814dc1-4020-4927-9e19-11e3ff711415.TID833.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/2.delta
[2025-07-19T20:48:17.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/30/2.delta
[2025-07-19T20:48:17.874+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T20:48:17.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/.2.delta.e5015b41-51bd-48ee-849d-8c073089fcc3.TID832.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/2.delta
[2025-07-19T20:48:17.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/29/2.delta
[2025-07-19T20:48:17.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T20:48:17.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 30.0 in stage 9.0 (TID 833). 5829 bytes result sent to driver
[2025-07-19T20:48:17.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T20:48:17.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 840) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 833) in 208 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:48:17.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 37.0 in stage 9.0 (TID 840)
[2025-07-19T20:48:17.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/.2.delta.2f248959-1c6a-43c4-ab7a-9245806f1ef1.TID834.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/2.delta
[2025-07-19T20:48:17.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/31/2.delta
[2025-07-19T20:48:17.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.2.delta.a64b8817-251f-487c-a3a1-948346a740f2.TID839.tmp
[2025-07-19T20:48:17.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T20:48:17.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T20:48:17.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/.2.delta.93ed9207-63c2-48a7-af28-c396e2ea53bf.TID835.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/2.delta
[2025-07-19T20:48:17.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/32/2.delta
[2025-07-19T20:48:17.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T20:48:17.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 29.0 in stage 9.0 (TID 832). 5829 bytes result sent to driver
[2025-07-19T20:48:17.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T20:48:17.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 841) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 38.0 in stage 9.0 (TID 841)
[2025-07-19T20:48:17.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 832) in 226 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:48:17.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d8e907
[2025-07-19T20:48:17.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37] for update
[2025-07-19T20:48:17.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T20:48:17.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 31.0 in stage 9.0 (TID 834). 5829 bytes result sent to driver
[2025-07-19T20:48:17.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:48:17.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 842) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/.2.delta.0a40be5c-c6cc-44bc-80e5-280dae7676ee.TID836.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/2.delta
[2025-07-19T20:48:17.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/33/2.delta
[2025-07-19T20:48:17.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 39.0 in stage 9.0 (TID 842)
[2025-07-19T20:48:17.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T20:48:17.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T20:48:17.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 834) in 220 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:48:17.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 32.0 in stage 9.0 (TID 835). 5829 bytes result sent to driver
[2025-07-19T20:48:17.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a42f125
[2025-07-19T20:48:17.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 835) in 183 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:48:17.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 843) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 40.0 in stage 9.0 (TID 843)
[2025-07-19T20:48:17.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38] for update
[2025-07-19T20:48:17.896+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/.2.delta.28066711-63fd-4a38-af97-709bbad60824.TID837.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/2.delta
[2025-07-19T20:48:17.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/34/2.delta
[2025-07-19T20:48:17.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T20:48:17.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40588dc4
[2025-07-19T20:48:17.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40] for update
[2025-07-19T20:48:17.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T20:48:17.906+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 33.0 in stage 9.0 (TID 836). 5829 bytes result sent to driver
[2025-07-19T20:48:17.907+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T20:48:17.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 34.0 in stage 9.0 (TID 837). 5829 bytes result sent to driver
[2025-07-19T20:48:17.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 844) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.910+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 845) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.911+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 836) in 156 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:48:17.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 837) in 152 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:48:17.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 42.0 in stage 9.0 (TID 845)
[2025-07-19T20:48:17.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 41.0 in stage 9.0 (TID 844)
[2025-07-19T20:48:17.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ffb4f74
[2025-07-19T20:48:17.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42] for update
[2025-07-19T20:48:17.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/.2.delta.e209ab10-fd65-4531-9541-bcd6b122d488.TID838.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/2.delta
[2025-07-19T20:48:17.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/35/2.delta
[2025-07-19T20:48:17.927+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T20:48:17.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T20:48:17.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d7294e9
[2025-07-19T20:48:17.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.2.delta.30795a21-edfa-46c6-837a-6a8f2dc6adda.TID840.tmp
[2025-07-19T20:48:17.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 35.0 in stage 9.0 (TID 838). 5829 bytes result sent to driver
[2025-07-19T20:48:17.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.2.delta.e97adb71-5022-4e24-8858-145ee467ad30.TID841.tmp
[2025-07-19T20:48:17.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 846) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.2.delta.4c0eb7bc-2b36-4e8b-9b49-cae46c4a8083.TID843.tmp
[2025-07-19T20:48:17.936+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 838) in 140 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:48:17.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41] for update
[2025-07-19T20:48:17.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 43.0 in stage 9.0 (TID 846)
[2025-07-19T20:48:17.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@160cde6b
[2025-07-19T20:48:17.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39] for update
[2025-07-19T20:48:17.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/.2.delta.a64b8817-251f-487c-a3a1-948346a740f2.TID839.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/2.delta
[2025-07-19T20:48:17.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/36/2.delta
[2025-07-19T20:48:17.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1547db26
[2025-07-19T20:48:17.946+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43] for update
[2025-07-19T20:48:17.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T20:48:17.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T20:48:17.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 36.0 in stage 9.0 (TID 839). 5829 bytes result sent to driver
[2025-07-19T20:48:17.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 847) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 839) in 129 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:48:17.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 44.0 in stage 9.0 (TID 847)
[2025-07-19T20:48:17.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.954+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.955+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@159dcf38
[2025-07-19T20:48:17.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44] for update
[2025-07-19T20:48:17.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.2.delta.8b9a7e3a-ce93-439d-89e6-62972f530641.TID844.tmp
[2025-07-19T20:48:17.962+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.2.delta.8fe6673d-4b6c-4330-a421-4f0a66d6675d.TID842.tmp
[2025-07-19T20:48:17.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.2.delta.254806d0-b1d4-472b-a580-1a650429f6f9.TID845.tmp
[2025-07-19T20:48:17.965+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.2.delta.2a4081c7-9171-4370-a8cc-65d347526a04.TID846.tmp
[2025-07-19T20:48:17.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.2.delta.eaf88d37-c04b-490a-8773-faa72fac7976.TID847.tmp
[2025-07-19T20:48:17.967+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/.2.delta.e97adb71-5022-4e24-8858-145ee467ad30.TID841.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/2.delta
[2025-07-19T20:48:17.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/38/2.delta
[2025-07-19T20:48:17.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T20:48:17.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/.2.delta.30795a21-edfa-46c6-837a-6a8f2dc6adda.TID840.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/2.delta
[2025-07-19T20:48:17.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/37/2.delta
[2025-07-19T20:48:17.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T20:48:17.970+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T20:48:17.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 38.0 in stage 9.0 (TID 841). 5829 bytes result sent to driver
[2025-07-19T20:48:17.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 848) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 45.0 in stage 9.0 (TID 848)
[2025-07-19T20:48:17.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 841) in 109 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:48:17.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:17.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/.2.delta.4c0eb7bc-2b36-4e8b-9b49-cae46c4a8083.TID843.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/2.delta
[2025-07-19T20:48:17.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/40/2.delta
[2025-07-19T20:48:17.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T20:48:17.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 37.0 in stage 9.0 (TID 840). 5829 bytes result sent to driver
[2025-07-19T20:48:17.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T20:48:17.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 849) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:17.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fd983fd
[2025-07-19T20:48:17.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 46.0 in stage 9.0 (TID 849)
[2025-07-19T20:48:17.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45] for update
[2025-07-19T20:48:17.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 840) in 131 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:48:17.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/.2.delta.8fe6673d-4b6c-4330-a421-4f0a66d6675d.TID842.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/2.delta
[2025-07-19T20:48:17.981+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/39/2.delta
[2025-07-19T20:48:17.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:17.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:17.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T20:48:17.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16ea351e
[2025-07-19T20:48:17.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:17.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46] for update
[2025-07-19T20:48:17.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T20:48:17.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/.2.delta.254806d0-b1d4-472b-a580-1a650429f6f9.TID845.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/2.delta
[2025-07-19T20:48:17.989+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/42/2.delta
[2025-07-19T20:48:17.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:17.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T20:48:17.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/.2.delta.2a4081c7-9171-4370-a8cc-65d347526a04.TID846.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/2.delta
[2025-07-19T20:48:17.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/43/2.delta
[2025-07-19T20:48:17.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T20:48:17.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T20:48:17.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 40.0 in stage 9.0 (TID 843). 5829 bytes result sent to driver
[2025-07-19T20:48:18.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 39.0 in stage 9.0 (TID 842). 5829 bytes result sent to driver
[2025-07-19T20:48:18.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 850) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 851) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 842) in 112 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:48:18.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 47.0 in stage 9.0 (TID 850)
[2025-07-19T20:48:18.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 843) in 105 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:48:18.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 48.0 in stage 9.0 (TID 851)
[2025-07-19T20:48:18.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T20:48:18.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fd3e933
[2025-07-19T20:48:18.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 42.0 in stage 9.0 (TID 845). 5829 bytes result sent to driver
[2025-07-19T20:48:18.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 852) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 49.0 in stage 9.0 (TID 852)
[2025-07-19T20:48:18.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.014+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47] for update
[2025-07-19T20:48:18.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 845) in 98 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:48:18.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.016+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b1e404a
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 43.0 in stage 9.0 (TID 846). 5829 bytes result sent to driver
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49] for update
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 853) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 50.0 in stage 9.0 (TID 853)
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 846) in 86 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:48:18.018+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4752727f
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/.2.delta.eaf88d37-c04b-490a-8773-faa72fac7976.TID847.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/2.delta
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/44/2.delta
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48] for update
[2025-07-19T20:48:18.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.2.delta.89c2b027-a597-4883-b94e-0a098766915e.TID848.tmp
[2025-07-19T20:48:18.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/.2.delta.8b9a7e3a-ce93-439d-89e6-62972f530641.TID844.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/2.delta
[2025-07-19T20:48:18.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/41/2.delta
[2025-07-19T20:48:18.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a3ec808
[2025-07-19T20:48:18.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T20:48:18.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.2.delta.047bbf9f-f2e9-4acb-9cb3-61826e5beea5.TID849.tmp
[2025-07-19T20:48:18.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50] for update
[2025-07-19T20:48:18.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T20:48:18.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T20:48:18.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 41.0 in stage 9.0 (TID 844). 5829 bytes result sent to driver
[2025-07-19T20:48:18.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 854) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 44.0 in stage 9.0 (TID 847). 5872 bytes result sent to driver
[2025-07-19T20:48:18.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 855) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 844) in 112 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:48:18.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 847) in 75 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:48:18.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 52.0 in stage 9.0 (TID 855)
[2025-07-19T20:48:18.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 51.0 in stage 9.0 (TID 854)
[2025-07-19T20:48:18.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.2.delta.a50f54e9-8482-4e7e-a3f1-63383ed7d0b5.TID850.tmp
[2025-07-19T20:48:18.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52f677f1
[2025-07-19T20:48:18.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.058+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52] for update
[2025-07-19T20:48:18.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ae95975
[2025-07-19T20:48:18.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.2.delta.65af2e67-c3af-4f90-a95c-403c90ddf8bb.TID852.tmp
[2025-07-19T20:48:18.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51] for update
[2025-07-19T20:48:18.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.2.delta.afafd589-ee35-4c88-b348-2aa0f997c119.TID853.tmp
[2025-07-19T20:48:18.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.2.delta.f22f82a4-79e1-412e-8b8a-9621a161ae36.TID851.tmp
[2025-07-19T20:48:18.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.2.delta.d3897b0a-5a63-4124-98e1-d4a10c206f16.TID855.tmp
[2025-07-19T20:48:18.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.2.delta.eefc8dab-3cd3-4d4e-822e-96f3eda8e52a.TID854.tmp
[2025-07-19T20:48:18.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/.2.delta.047bbf9f-f2e9-4acb-9cb3-61826e5beea5.TID849.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/2.delta
[2025-07-19T20:48:18.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/46/2.delta
[2025-07-19T20:48:18.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T20:48:18.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T20:48:18.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 46.0 in stage 9.0 (TID 849). 5829 bytes result sent to driver
[2025-07-19T20:48:18.096+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 856) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 849) in 87 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:48:18.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Running task 53.0 in stage 9.0 (TID 856)
[2025-07-19T20:48:18.099+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/.2.delta.89c2b027-a597-4883-b94e-0a098766915e.TID848.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/2.delta
[2025-07-19T20:48:18.115+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/45/2.delta
[2025-07-19T20:48:18.121+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T20:48:18.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63d981ee
[2025-07-19T20:48:18.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53] for update
[2025-07-19T20:48:18.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/.2.delta.65af2e67-c3af-4f90-a95c-403c90ddf8bb.TID852.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/2.delta
[2025-07-19T20:48:18.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/49/2.delta
[2025-07-19T20:48:18.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Committed partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T20:48:18.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T20:48:18.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/.2.delta.a50f54e9-8482-4e7e-a3f1-63383ed7d0b5.TID850.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/2.delta
[2025-07-19T20:48:18.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/47/2.delta
[2025-07-19T20:48:18.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO Executor: Finished task 45.0 in stage 9.0 (TID 848). 5829 bytes result sent to driver
[2025-07-19T20:48:18.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:17 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T20:48:18.136+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T20:48:18.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 857) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/.2.delta.afafd589-ee35-4c88-b348-2aa0f997c119.TID853.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/2.delta
[2025-07-19T20:48:18.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/50/2.delta
[2025-07-19T20:48:18.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T20:48:18.163+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 49.0 in stage 9.0 (TID 852). 5829 bytes result sent to driver
[2025-07-19T20:48:18.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 858) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.165+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 848) in 111 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:48:18.166+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 54.0 in stage 9.0 (TID 857)
[2025-07-19T20:48:18.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 852) in 92 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:48:18.171+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 55.0 in stage 9.0 (TID 858)
[2025-07-19T20:48:18.172+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/.2.delta.f22f82a4-79e1-412e-8b8a-9621a161ae36.TID851.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/2.delta
[2025-07-19T20:48:18.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/48/2.delta
[2025-07-19T20:48:18.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.174+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T20:48:18.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T20:48:18.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T20:48:18.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 50.0 in stage 9.0 (TID 853). 5829 bytes result sent to driver
[2025-07-19T20:48:18.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.2.delta.7f7726f3-49c0-4074-a3a1-40d9fefbd7e9.TID856.tmp
[2025-07-19T20:48:18.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 859) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.187+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/.2.delta.d3897b0a-5a63-4124-98e1-d4a10c206f16.TID855.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/2.delta
[2025-07-19T20:48:18.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/52/2.delta
[2025-07-19T20:48:18.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T20:48:18.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 56.0 in stage 9.0 (TID 859)
[2025-07-19T20:48:18.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 853) in 94 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:48:18.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T20:48:18.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57123877
[2025-07-19T20:48:18.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 48.0 in stage 9.0 (TID 851). 5915 bytes result sent to driver
[2025-07-19T20:48:18.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 860) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 851) in 113 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:48:18.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55] for update
[2025-07-19T20:48:18.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 57.0 in stage 9.0 (TID 860)
[2025-07-19T20:48:18.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.207+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eb13a36
[2025-07-19T20:48:18.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54] for update
[2025-07-19T20:48:18.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T20:48:18.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 52.0 in stage 9.0 (TID 855). 5872 bytes result sent to driver
[2025-07-19T20:48:18.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 861) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 47.0 in stage 9.0 (TID 850). 5829 bytes result sent to driver
[2025-07-19T20:48:18.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 58.0 in stage 9.0 (TID 861)
[2025-07-19T20:48:18.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 862) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 59.0 in stage 9.0 (TID 862)
[2025-07-19T20:48:18.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2acc9507
[2025-07-19T20:48:18.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.210+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56] for update
[2025-07-19T20:48:18.211+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 855) in 102 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:48:18.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 850) in 122 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:48:18.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f383da9
[2025-07-19T20:48:18.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.213+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59] for update
[2025-07-19T20:48:18.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@97c5377
[2025-07-19T20:48:18.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57] for update
[2025-07-19T20:48:18.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d89e042
[2025-07-19T20:48:18.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.2.delta.eefb8007-c312-4f7e-8585-c17fd28ec48d.TID858.tmp
[2025-07-19T20:48:18.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58] for update
[2025-07-19T20:48:18.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/.2.delta.eefc8dab-3cd3-4d4e-822e-96f3eda8e52a.TID854.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/2.delta
[2025-07-19T20:48:18.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/51/2.delta
[2025-07-19T20:48:18.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T20:48:18.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T20:48:18.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 51.0 in stage 9.0 (TID 854). 5872 bytes result sent to driver
[2025-07-19T20:48:18.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 863) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 854) in 131 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:48:18.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.2.delta.9269826c-e653-413f-957f-29bee20a9598.TID859.tmp
[2025-07-19T20:48:18.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 60.0 in stage 9.0 (TID 863)
[2025-07-19T20:48:18.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:18.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.2.delta.bb8f476e-197d-4f44-8201-3930829c3176.TID862.tmp
[2025-07-19T20:48:18.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6623f5a
[2025-07-19T20:48:18.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.2.delta.f22d9df9-fb16-434f-b525-7df6137bb164.TID857.tmp
[2025-07-19T20:48:18.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60] for update
[2025-07-19T20:48:18.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.2.delta.5d56f7a8-464d-4783-ba09-309857cfb953.TID861.tmp
[2025-07-19T20:48:18.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.223+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.2.delta.69b155e8-89a7-4200-9faa-320a60df8e6d.TID860.tmp
[2025-07-19T20:48:18.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.2.delta.100a18b0-5628-43a7-ab8e-9acc74cd0139.TID863.tmp
[2025-07-19T20:48:18.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/.2.delta.7f7726f3-49c0-4074-a3a1-40d9fefbd7e9.TID856.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/2.delta
[2025-07-19T20:48:18.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/53/2.delta
[2025-07-19T20:48:18.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T20:48:18.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T20:48:18.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 53.0 in stage 9.0 (TID 856). 5872 bytes result sent to driver
[2025-07-19T20:48:18.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 864) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 61.0 in stage 9.0 (TID 864)
[2025-07-19T20:48:18.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 856) in 174 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:48:18.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:48:18.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a749b80
[2025-07-19T20:48:18.232+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61] for update
[2025-07-19T20:48:18.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.2.delta.765c9470-4d88-4a44-a562-3bbfab52cd7d.TID864.tmp
[2025-07-19T20:48:18.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/.2.delta.bb8f476e-197d-4f44-8201-3930829c3176.TID862.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/2.delta
[2025-07-19T20:48:18.246+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/59/2.delta
[2025-07-19T20:48:18.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/.2.delta.5d56f7a8-464d-4783-ba09-309857cfb953.TID861.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/2.delta
[2025-07-19T20:48:18.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/58/2.delta
[2025-07-19T20:48:18.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/.2.delta.eefb8007-c312-4f7e-8585-c17fd28ec48d.TID858.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/2.delta
[2025-07-19T20:48:18.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T20:48:18.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/55/2.delta
[2025-07-19T20:48:18.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T20:48:18.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T20:48:18.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/.2.delta.9269826c-e653-413f-957f-29bee20a9598.TID859.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/2.delta
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/56/2.delta
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/.2.delta.f22d9df9-fb16-434f-b525-7df6137bb164.TID857.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/2.delta
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/54/2.delta
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T20:48:18.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/.2.delta.69b155e8-89a7-4200-9faa-320a60df8e6d.TID860.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/2.delta
[2025-07-19T20:48:18.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/57/2.delta
[2025-07-19T20:48:18.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T20:48:18.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 55.0 in stage 9.0 (TID 858). 5829 bytes result sent to driver
[2025-07-19T20:48:18.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T20:48:18.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T20:48:18.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 59.0 in stage 9.0 (TID 862). 5872 bytes result sent to driver
[2025-07-19T20:48:18.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 58.0 in stage 9.0 (TID 861). 5915 bytes result sent to driver
[2025-07-19T20:48:18.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 865) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 866) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 62.0 in stage 9.0 (TID 865)
[2025-07-19T20:48:18.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 867) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 858) in 244 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:48:18.264+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 862) in 220 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:48:18.265+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 861) in 221 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:48:18.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 64.0 in stage 9.0 (TID 867)
[2025-07-19T20:48:18.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T20:48:18.267+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 56.0 in stage 9.0 (TID 859). 5872 bytes result sent to driver
[2025-07-19T20:48:18.268+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 63.0 in stage 9.0 (TID 866)
[2025-07-19T20:48:18.271+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 868) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 859) in 240 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:48:18.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T20:48:18.278+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 57.0 in stage 9.0 (TID 860). 5872 bytes result sent to driver
[2025-07-19T20:48:18.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 65.0 in stage 9.0 (TID 868)
[2025-07-19T20:48:18.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:18.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 869) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.284+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T20:48:18.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.285+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47f0a035
[2025-07-19T20:48:18.286+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 54.0 in stage 9.0 (TID 857). 5872 bytes result sent to driver
[2025-07-19T20:48:18.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.287+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 66.0 in stage 9.0 (TID 869)
[2025-07-19T20:48:18.289+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64] for update
[2025-07-19T20:48:18.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 860) in 236 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:48:18.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@728b3652
[2025-07-19T20:48:18.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 870) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 67.0 in stage 9.0 (TID 870)
[2025-07-19T20:48:18.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 857) in 256 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:48:18.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.293+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65] for update
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b59214e
[2025-07-19T20:48:18.294+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.295+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63] for update
[2025-07-19T20:48:18.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/.2.delta.100a18b0-5628-43a7-ab8e-9acc74cd0139.TID863.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/2.delta
[2025-07-19T20:48:18.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/60/2.delta
[2025-07-19T20:48:18.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f52c9f1
[2025-07-19T20:48:18.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T20:48:18.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62] for update
[2025-07-19T20:48:18.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5acb5c82
[2025-07-19T20:48:18.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66] for update
[2025-07-19T20:48:18.302+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T20:48:18.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 60.0 in stage 9.0 (TID 863). 5872 bytes result sent to driver
[2025-07-19T20:48:18.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 871) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.304+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 68.0 in stage 9.0 (TID 871)
[2025-07-19T20:48:18.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 863) in 214 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:48:18.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cdbfc77
[2025-07-19T20:48:18.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67] for update
[2025-07-19T20:48:18.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:18.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fd73f3e
[2025-07-19T20:48:18.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68] for update
[2025-07-19T20:48:18.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.2.delta.f2f264e6-7796-4fbd-80c6-4c833df7a0dd.TID869.tmp
[2025-07-19T20:48:18.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.2.delta.69aac6b0-3f93-417f-88ad-4ae035074b09.TID868.tmp
[2025-07-19T20:48:18.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/.2.delta.765c9470-4d88-4a44-a562-3bbfab52cd7d.TID864.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/2.delta
[2025-07-19T20:48:18.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/61/2.delta
[2025-07-19T20:48:18.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T20:48:18.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.2.delta.b1369dfe-8932-42f8-84a1-50aa56cd85ba.TID870.tmp
[2025-07-19T20:48:18.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.2.delta.8cca15e2-bba0-4612-b5e4-aa2f1c9f121d.TID865.tmp
[2025-07-19T20:48:18.315+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.2.delta.7b55c3e3-9401-434b-9bb1-8aafaba07bf7.TID867.tmp
[2025-07-19T20:48:18.316+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.2.delta.cdaa1366-d686-44b9-88a9-7c7e6a45893c.TID871.tmp
[2025-07-19T20:48:18.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T20:48:18.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 61.0 in stage 9.0 (TID 864). 5872 bytes result sent to driver
[2025-07-19T20:48:18.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 872) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 864) in 143 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:48:18.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 69.0 in stage 9.0 (TID 872)
[2025-07-19T20:48:18.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a6933ef
[2025-07-19T20:48:18.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69] for update
[2025-07-19T20:48:18.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.2.delta.38caad44-55e8-416e-a5fe-1ade68a2c0eb.TID866.tmp
[2025-07-19T20:48:18.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.2.delta.0c7a95b2-9cad-47f1-b311-112fa64c14f6.TID872.tmp
[2025-07-19T20:48:18.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/.2.delta.f2f264e6-7796-4fbd-80c6-4c833df7a0dd.TID869.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/2.delta
[2025-07-19T20:48:18.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/66/2.delta
[2025-07-19T20:48:18.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T20:48:18.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/.2.delta.8cca15e2-bba0-4612-b5e4-aa2f1c9f121d.TID865.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/2.delta
[2025-07-19T20:48:18.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/62/2.delta
[2025-07-19T20:48:18.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T20:48:18.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/.2.delta.69aac6b0-3f93-417f-88ad-4ae035074b09.TID868.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/2.delta
[2025-07-19T20:48:18.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/65/2.delta
[2025-07-19T20:48:18.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T20:48:18.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 66.0 in stage 9.0 (TID 869). 5829 bytes result sent to driver
[2025-07-19T20:48:18.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 873) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 70.0 in stage 9.0 (TID 873)
[2025-07-19T20:48:18.356+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T20:48:18.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 869) in 95 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:48:18.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c8132a8
[2025-07-19T20:48:18.358+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.361+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70] for update
[2025-07-19T20:48:18.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T20:48:18.364+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T20:48:18.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 62.0 in stage 9.0 (TID 865). 5829 bytes result sent to driver
[2025-07-19T20:48:18.367+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 874) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.368+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 71.0 in stage 9.0 (TID 874)
[2025-07-19T20:48:18.370+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/.2.delta.38caad44-55e8-416e-a5fe-1ade68a2c0eb.TID866.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/2.delta
[2025-07-19T20:48:18.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/63/2.delta
[2025-07-19T20:48:18.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T20:48:18.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.376+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 865) in 118 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:48:18.378+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 65.0 in stage 9.0 (TID 868). 5829 bytes result sent to driver
[2025-07-19T20:48:18.380+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 875) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.381+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 868) in 114 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:48:18.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 72.0 in stage 9.0 (TID 875)
[2025-07-19T20:48:18.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66ebc42
[2025-07-19T20:48:18.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71] for update
[2025-07-19T20:48:18.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T20:48:18.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@376ab1b1
[2025-07-19T20:48:18.407+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72] for update
[2025-07-19T20:48:18.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 63.0 in stage 9.0 (TID 866). 5829 bytes result sent to driver
[2025-07-19T20:48:18.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 876) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.414+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 73.0 in stage 9.0 (TID 876)
[2025-07-19T20:48:18.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 866) in 126 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:48:18.419+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.422+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/.2.delta.b1369dfe-8932-42f8-84a1-50aa56cd85ba.TID870.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/2.delta
[2025-07-19T20:48:18.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@741fb811
[2025-07-19T20:48:18.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/67/2.delta
[2025-07-19T20:48:18.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.431+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73] for update
[2025-07-19T20:48:18.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T20:48:18.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/.2.delta.7b55c3e3-9401-434b-9bb1-8aafaba07bf7.TID867.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/2.delta
[2025-07-19T20:48:18.440+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/64/2.delta
[2025-07-19T20:48:18.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T20:48:18.444+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.2.delta.fc482600-7b3e-4de8-8909-89c2034e885e.TID874.tmp
[2025-07-19T20:48:18.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.2.delta.0eb30576-ffee-441b-9cca-72e266bac75e.TID873.tmp
[2025-07-19T20:48:18.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T20:48:18.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T20:48:18.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 67.0 in stage 9.0 (TID 870). 5829 bytes result sent to driver
[2025-07-19T20:48:18.458+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 877) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 74.0 in stage 9.0 (TID 877)
[2025-07-19T20:48:18.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 870) in 130 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:48:18.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 64.0 in stage 9.0 (TID 867). 5872 bytes result sent to driver
[2025-07-19T20:48:18.462+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 75.0 in stage 9.0 (TID 878) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.469+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.471+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 867) in 146 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:48:18.473+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 75.0 in stage 9.0 (TID 878)
[2025-07-19T20:48:18.474+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/.2.delta.cdaa1366-d686-44b9-88a9-7c7e6a45893c.TID871.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/2.delta
[2025-07-19T20:48:18.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/68/2.delta
[2025-07-19T20:48:18.476+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ba862b7
[2025-07-19T20:48:18.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T20:48:18.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74] for update
[2025-07-19T20:48:18.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/.2.delta.0c7a95b2-9cad-47f1-b311-112fa64c14f6.TID872.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/2.delta
[2025-07-19T20:48:18.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/69/2.delta
[2025-07-19T20:48:18.484+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T20:48:18.485+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.486+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.2.delta.3b2b7021-f605-44de-b285-53c43f181e4f.TID876.tmp
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.2.delta.d991d206-25c6-450c-bfaf-3b6e57c88760.TID875.tmp
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 69.0 in stage 9.0 (TID 872). 5829 bytes result sent to driver
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 76.0 in stage 9.0 (TID 879) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 76.0 in stage 9.0 (TID 879)
[2025-07-19T20:48:18.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T20:48:18.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 68.0 in stage 9.0 (TID 871). 5829 bytes result sent to driver
[2025-07-19T20:48:18.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59651127
[2025-07-19T20:48:18.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75] for update
[2025-07-19T20:48:18.495+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 872) in 113 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:48:18.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@abcdb68
[2025-07-19T20:48:18.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.502+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76] for update
[2025-07-19T20:48:18.504+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 77.0 in stage 9.0 (TID 880) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 77.0 in stage 9.0 (TID 880)
[2025-07-19T20:48:18.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.2.delta.c623b1fa-88fa-4fdf-a62f-2aff9d97e714.TID877.tmp
[2025-07-19T20:48:18.505+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 871) in 150 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:48:18.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:18.507+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e1d95dc
[2025-07-19T20:48:18.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.509+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77] for update
[2025-07-19T20:48:18.510+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.2.delta.4afda399-4383-4d02-9cba-c3bb073d1672.TID879.tmp
[2025-07-19T20:48:18.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.2.delta.f1422510-1f7f-431d-a0cd-e59c23c01bb6.TID878.tmp
[2025-07-19T20:48:18.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.2.delta.18141b78-4e06-4b43-810f-4d4a595273f0.TID880.tmp
[2025-07-19T20:48:18.516+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/.2.delta.fc482600-7b3e-4de8-8909-89c2034e885e.TID874.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/2.delta
[2025-07-19T20:48:18.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/71/2.delta
[2025-07-19T20:48:18.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T20:48:18.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T20:48:18.521+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 71.0 in stage 9.0 (TID 874). 5829 bytes result sent to driver
[2025-07-19T20:48:18.522+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 78.0 in stage 9.0 (TID 881) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 874) in 132 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:48:18.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 78.0 in stage 9.0 (TID 881)
[2025-07-19T20:48:18.525+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@268a6a18
[2025-07-19T20:48:18.530+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78] for update
[2025-07-19T20:48:18.531+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/.2.delta.0eb30576-ffee-441b-9cca-72e266bac75e.TID873.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/2.delta
[2025-07-19T20:48:18.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/70/2.delta
[2025-07-19T20:48:18.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/.2.delta.3b2b7021-f605-44de-b285-53c43f181e4f.TID876.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/2.delta
[2025-07-19T20:48:18.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/73/2.delta
[2025-07-19T20:48:18.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T20:48:18.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T20:48:18.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T20:48:18.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 70.0 in stage 9.0 (TID 873). 5829 bytes result sent to driver
[2025-07-19T20:48:18.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T20:48:18.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 73.0 in stage 9.0 (TID 876). 5829 bytes result sent to driver
[2025-07-19T20:48:18.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 79.0 in stage 9.0 (TID 882) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 80.0 in stage 9.0 (TID 883) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 876) in 146 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:48:18.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 873) in 170 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:48:18.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 79.0 in stage 9.0 (TID 882)
[2025-07-19T20:48:18.549+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 80.0 in stage 9.0 (TID 883)
[2025-07-19T20:48:18.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.2.delta.f23885f4-93f4-4a01-a08d-c55c76d1ed0b.TID881.tmp
[2025-07-19T20:48:18.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.553+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@330ca913
[2025-07-19T20:48:18.556+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/.2.delta.d991d206-25c6-450c-bfaf-3b6e57c88760.TID875.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/2.delta
[2025-07-19T20:48:18.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/72/2.delta
[2025-07-19T20:48:18.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T20:48:18.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79] for update
[2025-07-19T20:48:18.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62a417d0
[2025-07-19T20:48:18.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T20:48:18.573+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80] for update
[2025-07-19T20:48:18.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 72.0 in stage 9.0 (TID 875). 5872 bytes result sent to driver
[2025-07-19T20:48:18.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/.2.delta.4afda399-4383-4d02-9cba-c3bb073d1672.TID879.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/2.delta
[2025-07-19T20:48:18.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/76/2.delta
[2025-07-19T20:48:18.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 81.0 in stage 9.0 (TID 884) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 81.0 in stage 9.0 (TID 884)
[2025-07-19T20:48:18.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 875) in 174 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:48:18.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/.2.delta.c623b1fa-88fa-4fdf-a62f-2aff9d97e714.TID877.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/2.delta
[2025-07-19T20:48:18.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/74/2.delta
[2025-07-19T20:48:18.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T20:48:18.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T20:48:18.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/.2.delta.f1422510-1f7f-431d-a0cd-e59c23c01bb6.TID878.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/2.delta
[2025-07-19T20:48:18.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/75/2.delta
[2025-07-19T20:48:18.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T20:48:18.589+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T20:48:18.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:18.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T20:48:18.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 74.0 in stage 9.0 (TID 877). 5829 bytes result sent to driver
[2025-07-19T20:48:18.595+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T20:48:18.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 82.0 in stage 9.0 (TID 885) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 75.0 in stage 9.0 (TID 878). 5829 bytes result sent to driver
[2025-07-19T20:48:18.598+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 82.0 in stage 9.0 (TID 885)
[2025-07-19T20:48:18.600+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 83.0 in stage 9.0 (TID 886) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 83.0 in stage 9.0 (TID 886)
[2025-07-19T20:48:18.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62348a1f
[2025-07-19T20:48:18.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.2.delta.958653c3-9f66-4694-89b2-eaee1a5743fc.TID883.tmp
[2025-07-19T20:48:18.602+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 76.0 in stage 9.0 (TID 879). 5872 bytes result sent to driver
[2025-07-19T20:48:18.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.2.delta.0397becf-8b9c-4baa-ae50-7369e4b82cb6.TID882.tmp
[2025-07-19T20:48:18.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.604+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/.2.delta.18141b78-4e06-4b43-810f-4d4a595273f0.TID880.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/2.delta
[2025-07-19T20:48:18.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/77/2.delta
[2025-07-19T20:48:18.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81] for update
[2025-07-19T20:48:18.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 877) in 167 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:48:18.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 75.0 in stage 9.0 (TID 878) in 171 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:48:18.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 84.0 in stage 9.0 (TID 887) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d7c56a4
[2025-07-19T20:48:18.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 76.0 in stage 9.0 (TID 879) in 155 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:48:18.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 84.0 in stage 9.0 (TID 887)
[2025-07-19T20:48:18.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T20:48:18.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:18.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83] for update
[2025-07-19T20:48:18.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@104cbed0
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 77.0 in stage 9.0 (TID 880). 5829 bytes result sent to driver
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 77.0 in stage 9.0 (TID 880) in 154 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 85.0 in stage 9.0 (TID 888) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 85.0 in stage 9.0 (TID 888)
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84] for update
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77564bc9
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82] for update
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46fc7bf0
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85] for update
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.2.delta.df91ff0f-acfd-477e-bc2b-5398cb13b7de.TID886.tmp
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.2.delta.e797f220-8251-4bc2-993a-5791b8bfdf09.TID887.tmp
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/.2.delta.f23885f4-93f4-4a01-a08d-c55c76d1ed0b.TID881.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/2.delta
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/78/2.delta
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.2.delta.c21b506b-9496-49f7-b562-a40c0b8ce2a5.TID884.tmp
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.2.delta.8caa5f5e-80f5-4858-89c3-62fa5d10c600.TID888.tmp
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 78.0 in stage 9.0 (TID 881). 5829 bytes result sent to driver
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 86.0 in stage 9.0 (TID 889) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.621+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 78.0 in stage 9.0 (TID 881) in 111 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 86.0 in stage 9.0 (TID 889)
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24f94e25
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86] for update
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/.2.delta.0397becf-8b9c-4baa-ae50-7369e4b82cb6.TID882.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/2.delta
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/79/2.delta
[2025-07-19T20:48:18.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T20:48:18.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/.2.delta.958653c3-9f66-4694-89b2-eaee1a5743fc.TID883.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/2.delta
[2025-07-19T20:48:18.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/80/2.delta
[2025-07-19T20:48:18.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T20:48:18.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.2.delta.a30848fc-48e9-44b9-af60-f6200520c262.TID885.tmp
[2025-07-19T20:48:18.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T20:48:18.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 80.0 in stage 9.0 (TID 883). 5829 bytes result sent to driver
[2025-07-19T20:48:18.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 87.0 in stage 9.0 (TID 890) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 80.0 in stage 9.0 (TID 883) in 101 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:48:18.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T20:48:18.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 87.0 in stage 9.0 (TID 890)
[2025-07-19T20:48:18.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68d34401
[2025-07-19T20:48:18.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 79.0 in stage 9.0 (TID 882). 5829 bytes result sent to driver
[2025-07-19T20:48:18.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.633+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87] for update
[2025-07-19T20:48:18.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 88.0 in stage 9.0 (TID 891) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 88.0 in stage 9.0 (TID 891)
[2025-07-19T20:48:18.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 79.0 in stage 9.0 (TID 882) in 110 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:48:18.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.638+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7397573e
[2025-07-19T20:48:18.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.2.delta.128381f9-1211-4240-8b97-c6e1d10c0b52.TID889.tmp
[2025-07-19T20:48:18.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88] for update
[2025-07-19T20:48:18.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/.2.delta.df91ff0f-acfd-477e-bc2b-5398cb13b7de.TID886.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/2.delta
[2025-07-19T20:48:18.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/83/2.delta
[2025-07-19T20:48:18.651+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T20:48:18.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.2.delta.c6fbbfc3-adb1-44b6-a48d-445afff31f1b.TID890.tmp
[2025-07-19T20:48:18.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/.2.delta.c21b506b-9496-49f7-b562-a40c0b8ce2a5.TID884.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/2.delta
[2025-07-19T20:48:18.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/81/2.delta
[2025-07-19T20:48:18.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T20:48:18.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 83.0 in stage 9.0 (TID 886). 5829 bytes result sent to driver
[2025-07-19T20:48:18.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T20:48:18.661+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 89.0 in stage 9.0 (TID 892) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.663+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 89.0 in stage 9.0 (TID 892)
[2025-07-19T20:48:18.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 83.0 in stage 9.0 (TID 886) in 106 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:48:18.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/.2.delta.8caa5f5e-80f5-4858-89c3-62fa5d10c600.TID888.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/2.delta
[2025-07-19T20:48:18.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/85/2.delta
[2025-07-19T20:48:18.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.2.delta.c6fc129c-562f-42c0-b907-ff56eefdb85a.TID891.tmp
[2025-07-19T20:48:18.666+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T20:48:18.667+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T20:48:18.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cba12b3
[2025-07-19T20:48:18.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 81.0 in stage 9.0 (TID 884). 5829 bytes result sent to driver
[2025-07-19T20:48:18.673+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T20:48:18.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 90.0 in stage 9.0 (TID 893) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 81.0 in stage 9.0 (TID 884) in 131 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:48:18.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 85.0 in stage 9.0 (TID 888). 5829 bytes result sent to driver
[2025-07-19T20:48:18.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 90.0 in stage 9.0 (TID 893)
[2025-07-19T20:48:18.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89] for update
[2025-07-19T20:48:18.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 91.0 in stage 9.0 (TID 894) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 85.0 in stage 9.0 (TID 888) in 99 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:48:18.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/.2.delta.e797f220-8251-4bc2-993a-5791b8bfdf09.TID887.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/2.delta
[2025-07-19T20:48:18.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/84/2.delta
[2025-07-19T20:48:18.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 91.0 in stage 9.0 (TID 894)
[2025-07-19T20:48:18.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T20:48:18.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T20:48:18.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 84.0 in stage 9.0 (TID 887). 5829 bytes result sent to driver
[2025-07-19T20:48:18.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:18.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@711e7110
[2025-07-19T20:48:18.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/.2.delta.a30848fc-48e9-44b9-af60-f6200520c262.TID885.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/2.delta
[2025-07-19T20:48:18.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/82/2.delta
[2025-07-19T20:48:18.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T20:48:18.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91] for update
[2025-07-19T20:48:18.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.2.delta.d63ba60f-22d9-4a26-8c50-a681a70c3720.TID892.tmp
[2025-07-19T20:48:18.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 92.0 in stage 9.0 (TID 895) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.691+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 92.0 in stage 9.0 (TID 895)
[2025-07-19T20:48:18.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T20:48:18.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.695+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 84.0 in stage 9.0 (TID 887) in 132 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:48:18.696+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@838b40d
[2025-07-19T20:48:18.697+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/.2.delta.128381f9-1211-4240-8b97-c6e1d10c0b52.TID889.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/2.delta
[2025-07-19T20:48:18.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/86/2.delta
[2025-07-19T20:48:18.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90] for update
[2025-07-19T20:48:18.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T20:48:18.701+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 82.0 in stage 9.0 (TID 885). 5829 bytes result sent to driver
[2025-07-19T20:48:18.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57727674
[2025-07-19T20:48:18.702+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 93.0 in stage 9.0 (TID 896) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 93.0 in stage 9.0 (TID 896)
[2025-07-19T20:48:18.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92] for update
[2025-07-19T20:48:18.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T20:48:18.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 86.0 in stage 9.0 (TID 889). 5829 bytes result sent to driver
[2025-07-19T20:48:18.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.2.delta.2d1bf10c-4f4a-4717-8863-e571358c3a1b.TID894.tmp
[2025-07-19T20:48:18.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 94.0 in stage 9.0 (TID 897) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 82.0 in stage 9.0 (TID 885) in 152 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:48:18.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 86.0 in stage 9.0 (TID 889) in 100 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:48:18.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/.2.delta.c6fbbfc3-adb1-44b6-a48d-445afff31f1b.TID890.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/2.delta
[2025-07-19T20:48:18.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/87/2.delta
[2025-07-19T20:48:18.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T20:48:18.712+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.2.delta.bdcfe23b-0ceb-4101-88a5-027a9aee99f5.TID893.tmp
[2025-07-19T20:48:18.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T20:48:18.714+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 87.0 in stage 9.0 (TID 890). 5829 bytes result sent to driver
[2025-07-19T20:48:18.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.2.delta.69e5609b-8260-4ddb-9dce-017a5c980ea0.TID895.tmp
[2025-07-19T20:48:18.723+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 94.0 in stage 9.0 (TID 897)
[2025-07-19T20:48:18.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 95.0 in stage 9.0 (TID 898) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.727+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 95.0 in stage 9.0 (TID 898)
[2025-07-19T20:48:18.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 87.0 in stage 9.0 (TID 890) in 105 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:48:18.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/.2.delta.c6fc129c-562f-42c0-b907-ff56eefdb85a.TID891.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/2.delta
[2025-07-19T20:48:18.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/88/2.delta
[2025-07-19T20:48:18.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T20:48:18.729+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:18.734+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.736+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@271e6303
[2025-07-19T20:48:18.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:18.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T20:48:18.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 88.0 in stage 9.0 (TID 891). 5829 bytes result sent to driver
[2025-07-19T20:48:18.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95] for update
[2025-07-19T20:48:18.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 88.0 in stage 9.0 (TID 891) in 107 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:48:18.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@376aa374
[2025-07-19T20:48:18.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 96.0 in stage 9.0 (TID 899) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93] for update
[2025-07-19T20:48:18.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/.2.delta.d63ba60f-22d9-4a26-8c50-a681a70c3720.TID892.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/2.delta
[2025-07-19T20:48:18.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/89/2.delta
[2025-07-19T20:48:18.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 96.0 in stage 9.0 (TID 899)
[2025-07-19T20:48:18.746+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T20:48:18.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.750+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79466555
[2025-07-19T20:48:18.751+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94] for update
[2025-07-19T20:48:18.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T20:48:18.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5111cb20
[2025-07-19T20:48:18.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 89.0 in stage 9.0 (TID 892). 5829 bytes result sent to driver
[2025-07-19T20:48:18.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96] for update
[2025-07-19T20:48:18.765+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 97.0 in stage 9.0 (TID 900) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 89.0 in stage 9.0 (TID 892) in 85 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:48:18.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 97.0 in stage 9.0 (TID 900)
[2025-07-19T20:48:18.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/.2.delta.2d1bf10c-4f4a-4717-8863-e571358c3a1b.TID894.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/2.delta
[2025-07-19T20:48:18.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/91/2.delta
[2025-07-19T20:48:18.775+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.2.delta.6c0c5629-fcc6-4878-91d1-261f3657bba0.TID898.tmp
[2025-07-19T20:48:18.777+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T20:48:18.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.2.delta.c0e57d88-2f2a-4145-97d5-7819b54dbbee.TID896.tmp
[2025-07-19T20:48:18.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T20:48:18.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 91.0 in stage 9.0 (TID 894). 5829 bytes result sent to driver
[2025-07-19T20:48:18.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:48:18.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 98.0 in stage 9.0 (TID 901) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 91.0 in stage 9.0 (TID 894) in 90 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:48:18.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 98.0 in stage 9.0 (TID 901)
[2025-07-19T20:48:18.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.2.delta.8bc6377e-273c-4450-a6e8-34703aad4264.TID899.tmp
[2025-07-19T20:48:18.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.2.delta.1dd28b75-4a4c-43f2-aaeb-b94eaf079955.TID897.tmp
[2025-07-19T20:48:18.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/.2.delta.bdcfe23b-0ceb-4101-88a5-027a9aee99f5.TID893.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/2.delta
[2025-07-19T20:48:18.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/90/2.delta
[2025-07-19T20:48:18.789+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T20:48:18.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7be0568b
[2025-07-19T20:48:18.791+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97] for update
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@217044ae
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T20:48:18.792+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 90.0 in stage 9.0 (TID 893). 5829 bytes result sent to driver
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 99.0 in stage 9.0 (TID 902) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98] for update
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/.2.delta.69e5609b-8260-4ddb-9dce-017a5c980ea0.TID895.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/2.delta
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/92/2.delta
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 90.0 in stage 9.0 (TID 893) in 105 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:48:18.793+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 99.0 in stage 9.0 (TID 902)
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 92.0 in stage 9.0 (TID 895). 5829 bytes result sent to driver
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 100.0 in stage 9.0 (TID 903) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 92.0 in stage 9.0 (TID 895) in 89 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 100.0 in stage 9.0 (TID 903)
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@996899f
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99] for update
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ee2d247
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.795+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100] for update
[2025-07-19T20:48:18.796+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.803+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.2.delta.e1f8f47d-5f1b-4e13-8fff-a6e732f4fc05.TID900.tmp
[2025-07-19T20:48:18.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.2.delta.27b89ceb-6972-4ea0-b8a7-561ec6b8acd6.TID901.tmp
[2025-07-19T20:48:18.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.2.delta.372ff9e0-b16a-4b2d-bd34-c0de139a0be1.TID902.tmp
[2025-07-19T20:48:18.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.2.delta.a798da22-c6f2-4ade-aa4a-c71f00630bed.TID903.tmp
[2025-07-19T20:48:18.820+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/.2.delta.c0e57d88-2f2a-4145-97d5-7819b54dbbee.TID896.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/2.delta
[2025-07-19T20:48:18.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/93/2.delta
[2025-07-19T20:48:18.823+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T20:48:18.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/.2.delta.6c0c5629-fcc6-4878-91d1-261f3657bba0.TID898.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/2.delta
[2025-07-19T20:48:18.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/95/2.delta
[2025-07-19T20:48:18.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T20:48:18.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T20:48:18.831+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/.2.delta.1dd28b75-4a4c-43f2-aaeb-b94eaf079955.TID897.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/2.delta
[2025-07-19T20:48:18.836+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/94/2.delta
[2025-07-19T20:48:18.841+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T20:48:18.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T20:48:18.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 93.0 in stage 9.0 (TID 896). 5915 bytes result sent to driver
[2025-07-19T20:48:18.847+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 95.0 in stage 9.0 (TID 898). 5872 bytes result sent to driver
[2025-07-19T20:48:18.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 101.0 in stage 9.0 (TID 904) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.849+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 93.0 in stage 9.0 (TID 896) in 141 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:48:18.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 101.0 in stage 9.0 (TID 904)
[2025-07-19T20:48:18.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 102.0 in stage 9.0 (TID 905) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 95.0 in stage 9.0 (TID 898) in 117 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:48:18.861+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/.2.delta.8bc6377e-273c-4450-a6e8-34703aad4264.TID899.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/2.delta
[2025-07-19T20:48:18.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/96/2.delta
[2025-07-19T20:48:18.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 102.0 in stage 9.0 (TID 905)
[2025-07-19T20:48:18.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T20:48:18.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a15eb15
[2025-07-19T20:48:18.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T20:48:18.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 94.0 in stage 9.0 (TID 897). 5872 bytes result sent to driver
[2025-07-19T20:48:18.867+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102] for update
[2025-07-19T20:48:18.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 103.0 in stage 9.0 (TID 906) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 103.0 in stage 9.0 (TID 906)
[2025-07-19T20:48:18.871+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 94.0 in stage 9.0 (TID 897) in 145 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:48:18.875+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T20:48:18.876+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 96.0 in stage 9.0 (TID 899). 5872 bytes result sent to driver
[2025-07-19T20:48:18.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 104.0 in stage 9.0 (TID 907) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.877+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 96.0 in stage 9.0 (TID 899) in 119 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:48:18.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.878+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a4c20d5
[2025-07-19T20:48:18.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 104.0 in stage 9.0 (TID 907)
[2025-07-19T20:48:18.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.879+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101] for update
[2025-07-19T20:48:18.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@418d2ca0
[2025-07-19T20:48:18.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103] for update
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.2.delta.e11c41cb-3e39-45f9-87d6-8d4dc2ed531d.TID905.tmp
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/.2.delta.372ff9e0-b16a-4b2d-bd34-c0de139a0be1.TID902.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/2.delta
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/99/2.delta
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/.2.delta.27b89ceb-6972-4ea0-b8a7-561ec6b8acd6.TID901.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/2.delta
[2025-07-19T20:48:18.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/98/2.delta
[2025-07-19T20:48:18.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14160f6f
[2025-07-19T20:48:18.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T20:48:18.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104] for update
[2025-07-19T20:48:18.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T20:48:18.882+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.885+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/.2.delta.e1f8f47d-5f1b-4e13-8fff-a6e732f4fc05.TID900.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/2.delta
[2025-07-19T20:48:18.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/97/2.delta
[2025-07-19T20:48:18.887+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T20:48:18.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T20:48:18.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.2.delta.d5025e0e-6205-43f4-9fd7-934e88725cba.TID906.tmp
[2025-07-19T20:48:18.889+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T20:48:18.890+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 98.0 in stage 9.0 (TID 901). 5872 bytes result sent to driver
[2025-07-19T20:48:18.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 99.0 in stage 9.0 (TID 902). 5872 bytes result sent to driver
[2025-07-19T20:48:18.892+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 105.0 in stage 9.0 (TID 908) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.893+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 105.0 in stage 9.0 (TID 908)
[2025-07-19T20:48:18.895+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 106.0 in stage 9.0 (TID 909) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 99.0 in stage 9.0 (TID 902) in 118 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:48:18.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T20:48:18.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 106.0 in stage 9.0 (TID 909)
[2025-07-19T20:48:18.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 97.0 in stage 9.0 (TID 900). 5872 bytes result sent to driver
[2025-07-19T20:48:18.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 107.0 in stage 9.0 (TID 910) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.900+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 98.0 in stage 9.0 (TID 901) in 134 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:48:18.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 97.0 in stage 9.0 (TID 900) in 152 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:48:18.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/.2.delta.a798da22-c6f2-4ade-aa4a-c71f00630bed.TID903.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/2.delta
[2025-07-19T20:48:18.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/100/2.delta
[2025-07-19T20:48:18.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:18.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 107.0 in stage 9.0 (TID 910)
[2025-07-19T20:48:18.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fbcbf9c
[2025-07-19T20:48:18.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105] for update
[2025-07-19T20:48:18.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T20:48:18.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.2.delta.d9ab54fc-ef07-4a7e-9893-379da3bfdb22.TID907.tmp
[2025-07-19T20:48:18.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.2.delta.4d1d3933-a74a-418b-bce7-af931fb735c1.TID904.tmp
[2025-07-19T20:48:18.912+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@257fc2fc
[2025-07-19T20:48:18.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107] for update
[2025-07-19T20:48:18.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T20:48:18.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.918+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 100.0 in stage 9.0 (TID 903). 5872 bytes result sent to driver
[2025-07-19T20:48:18.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 108.0 in stage 9.0 (TID 911) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 100.0 in stage 9.0 (TID 903) in 140 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:48:18.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@129824ad
[2025-07-19T20:48:18.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 108.0 in stage 9.0 (TID 911)
[2025-07-19T20:48:18.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106] for update
[2025-07-19T20:48:18.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:48:18.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44d03ebb
[2025-07-19T20:48:18.931+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108] for update
[2025-07-19T20:48:18.932+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 8b44f3d35cfa:46433 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:48:18.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.2.delta.63e49184-e3e0-4da6-9509-e86bb6492d06.TID908.tmp
[2025-07-19T20:48:18.947+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.2.delta.afe31313-719c-44d4-970a-d61da0c56bef.TID910.tmp
[2025-07-19T20:48:18.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.2.delta.ee5216c0-e949-421b-90bd-a60c6cab4cd2.TID909.tmp
[2025-07-19T20:48:18.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.2.delta.23ee1ecc-9b75-46eb-932f-538411eb9fd6.TID911.tmp
[2025-07-19T20:48:18.960+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 8b44f3d35cfa:46433 in memory (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T20:48:18.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/.2.delta.e11c41cb-3e39-45f9-87d6-8d4dc2ed531d.TID905.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/2.delta
[2025-07-19T20:48:18.966+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/102/2.delta
[2025-07-19T20:48:18.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T20:48:18.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T20:48:18.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 102.0 in stage 9.0 (TID 905). 5829 bytes result sent to driver
[2025-07-19T20:48:18.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 109.0 in stage 9.0 (TID 912) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.973+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 102.0 in stage 9.0 (TID 905) in 133 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:48:18.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 109.0 in stage 9.0 (TID 912)
[2025-07-19T20:48:18.975+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/.2.delta.4d1d3933-a74a-418b-bce7-af931fb735c1.TID904.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/2.delta
[2025-07-19T20:48:18.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/101/2.delta
[2025-07-19T20:48:18.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T20:48:18.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75a2902a
[2025-07-19T20:48:18.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.979+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109] for update
[2025-07-19T20:48:18.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/.2.delta.d9ab54fc-ef07-4a7e-9893-379da3bfdb22.TID907.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/2.delta
[2025-07-19T20:48:18.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/104/2.delta
[2025-07-19T20:48:18.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T20:48:18.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:18.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/.2.delta.d5025e0e-6205-43f4-9fd7-934e88725cba.TID906.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/2.delta
[2025-07-19T20:48:18.985+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/103/2.delta
[2025-07-19T20:48:18.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T20:48:18.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T20:48:18.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 104.0 in stage 9.0 (TID 907). 5829 bytes result sent to driver
[2025-07-19T20:48:18.988+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T20:48:18.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 110.0 in stage 9.0 (TID 913) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.991+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 104.0 in stage 9.0 (TID 907) in 131 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:48:18.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 110.0 in stage 9.0 (TID 913)
[2025-07-19T20:48:18.993+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:18.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:18.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 101.0 in stage 9.0 (TID 904). 5829 bytes result sent to driver
[2025-07-19T20:48:18.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f6b34e0
[2025-07-19T20:48:18.996+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 111.0 in stage 9.0 (TID 914) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:18.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:18.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110] for update
[2025-07-19T20:48:19.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 101.0 in stage 9.0 (TID 904) in 150 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:48:19.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO DataWritingSparkTask: Committed partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T20:48:19.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Finished task 103.0 in stage 9.0 (TID 906). 5829 bytes result sent to driver
[2025-07-19T20:48:19.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Starting task 112.0 in stage 9.0 (TID 915) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 112.0 in stage 9.0 (TID 915)
[2025-07-19T20:48:19.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO TaskSetManager: Finished task 103.0 in stage 9.0 (TID 906) in 143 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:48:19.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO Executor: Running task 111.0 in stage 9.0 (TID 914)
[2025-07-19T20:48:19.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.2.delta.5ca1764f-b12e-4bd5-82ee-2668852e2a6d.TID912.tmp
[2025-07-19T20:48:19.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74403788
[2025-07-19T20:48:19.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.007+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111] for update
[2025-07-19T20:48:19.008+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47699746
[2025-07-19T20:48:19.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:18 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112] for update
[2025-07-19T20:48:19.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.017+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/.2.delta.ee5216c0-e949-421b-90bd-a60c6cab4cd2.TID909.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/2.delta
[2025-07-19T20:48:19.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/106/2.delta
[2025-07-19T20:48:19.019+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T20:48:19.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/.2.delta.afe31313-719c-44d4-970a-d61da0c56bef.TID910.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/2.delta
[2025-07-19T20:48:19.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/107/2.delta
[2025-07-19T20:48:19.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/.2.delta.63e49184-e3e0-4da6-9509-e86bb6492d06.TID908.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/2.delta
[2025-07-19T20:48:19.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/105/2.delta
[2025-07-19T20:48:19.022+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T20:48:19.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T20:48:19.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T20:48:19.025+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 106.0 in stage 9.0 (TID 909). 5829 bytes result sent to driver
[2025-07-19T20:48:19.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 106.0 in stage 9.0 (TID 909) in 120 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:48:19.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 113.0 in stage 9.0 (TID 916) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 113.0 in stage 9.0 (TID 916)
[2025-07-19T20:48:19.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.2.delta.d25a5a48-9a61-4bcc-96c7-92e4ada8860d.TID914.tmp
[2025-07-19T20:48:19.028+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.2.delta.223621cb-9855-4e0c-8365-8c95dd2cbb89.TID913.tmp
[2025-07-19T20:48:19.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a0776d3
[2025-07-19T20:48:19.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113] for update
[2025-07-19T20:48:19.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T20:48:19.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.2.delta.ac56f57a-bc15-47f8-a019-56d134fc020f.TID915.tmp
[2025-07-19T20:48:19.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T20:48:19.035+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 107.0 in stage 9.0 (TID 910). 5829 bytes result sent to driver
[2025-07-19T20:48:19.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 114.0 in stage 9.0 (TID 917) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 107.0 in stage 9.0 (TID 910) in 131 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:48:19.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 114.0 in stage 9.0 (TID 917)
[2025-07-19T20:48:19.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.038+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/.2.delta.23ee1ecc-9b75-46eb-932f-538411eb9fd6.TID911.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/2.delta
[2025-07-19T20:48:19.040+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/108/2.delta
[2025-07-19T20:48:19.041+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 105.0 in stage 9.0 (TID 908). 5829 bytes result sent to driver
[2025-07-19T20:48:19.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.2.delta.ae9b1bf0-947e-4646-b87c-719d569c60a7.TID916.tmp
[2025-07-19T20:48:19.042+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 115.0 in stage 9.0 (TID 918) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.043+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T20:48:19.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 105.0 in stage 9.0 (TID 908) in 140 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:48:19.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 115.0 in stage 9.0 (TID 918)
[2025-07-19T20:48:19.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cd81cff
[2025-07-19T20:48:19.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.048+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.049+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114] for update
[2025-07-19T20:48:19.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@679a121c
[2025-07-19T20:48:19.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115] for update
[2025-07-19T20:48:19.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T20:48:19.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 108.0 in stage 9.0 (TID 911). 5829 bytes result sent to driver
[2025-07-19T20:48:19.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 116.0 in stage 9.0 (TID 919) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.056+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 108.0 in stage 9.0 (TID 911) in 120 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:48:19.060+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 116.0 in stage 9.0 (TID 919)
[2025-07-19T20:48:19.061+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.062+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5be97ce5
[2025-07-19T20:48:19.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.064+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116] for update
[2025-07-19T20:48:19.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.065+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/.2.delta.5ca1764f-b12e-4bd5-82ee-2668852e2a6d.TID912.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/2.delta
[2025-07-19T20:48:19.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/109/2.delta
[2025-07-19T20:48:19.066+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.2.delta.3b1f04bb-e990-462f-aef9-756ddaae2f4f.TID917.tmp
[2025-07-19T20:48:19.068+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T20:48:19.070+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.2.delta.55bf788d-0195-4f17-ab00-b9989c66b32b.TID918.tmp
[2025-07-19T20:48:19.071+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T20:48:19.072+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 109.0 in stage 9.0 (TID 912). 5829 bytes result sent to driver
[2025-07-19T20:48:19.074+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 109.0 in stage 9.0 (TID 912) in 88 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:48:19.076+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 117.0 in stage 9.0 (TID 920) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.077+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 117.0 in stage 9.0 (TID 920)
[2025-07-19T20:48:19.078+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/.2.delta.d25a5a48-9a61-4bcc-96c7-92e4ada8860d.TID914.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/2.delta
[2025-07-19T20:48:19.079+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/111/2.delta
[2025-07-19T20:48:19.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T20:48:19.080+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.081+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.082+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T20:48:19.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ad6f571
[2025-07-19T20:48:19.083+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 111.0 in stage 9.0 (TID 914). 5829 bytes result sent to driver
[2025-07-19T20:48:19.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.2.delta.e512751b-3edd-498d-952f-59ce87f9fee5.TID919.tmp
[2025-07-19T20:48:19.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117] for update
[2025-07-19T20:48:19.084+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 118.0 in stage 9.0 (TID 921) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 118.0 in stage 9.0 (TID 921)
[2025-07-19T20:48:19.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 111.0 in stage 9.0 (TID 914) in 82 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:48:19.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.085+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e73eda0
[2025-07-19T20:48:19.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.086+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118] for update
[2025-07-19T20:48:19.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.2.delta.c24ff403-2593-4cf8-a5c7-3f7e703fcb33.TID920.tmp
[2025-07-19T20:48:19.087+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/.2.delta.223621cb-9855-4e0c-8365-8c95dd2cbb89.TID913.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/2.delta
[2025-07-19T20:48:19.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/110/2.delta
[2025-07-19T20:48:19.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T20:48:19.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/.2.delta.ac56f57a-bc15-47f8-a019-56d134fc020f.TID915.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/2.delta
[2025-07-19T20:48:19.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/112/2.delta
[2025-07-19T20:48:19.088+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T20:48:19.089+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T20:48:19.090+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/.2.delta.ae9b1bf0-947e-4646-b87c-719d569c60a7.TID916.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/2.delta
[2025-07-19T20:48:19.091+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/113/2.delta
[2025-07-19T20:48:19.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T20:48:19.092+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T20:48:19.093+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 112.0 in stage 9.0 (TID 915). 5829 bytes result sent to driver
[2025-07-19T20:48:19.094+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 110.0 in stage 9.0 (TID 913). 5829 bytes result sent to driver
[2025-07-19T20:48:19.095+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 119.0 in stage 9.0 (TID 922) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.097+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 120.0 in stage 9.0 (TID 923) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.098+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 112.0 in stage 9.0 (TID 915) in 101 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:48:19.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 110.0 in stage 9.0 (TID 913) in 108 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:48:19.100+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 119.0 in stage 9.0 (TID 922)
[2025-07-19T20:48:19.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 120.0 in stage 9.0 (TID 923)
[2025-07-19T20:48:19.101+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.102+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.103+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33bde3e2
[2025-07-19T20:48:19.104+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120] for update
[2025-07-19T20:48:19.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T20:48:19.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.2.delta.f0f6a14d-72db-426d-a105-fd9f66c6dd4b.TID921.tmp
[2025-07-19T20:48:19.105+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 113.0 in stage 9.0 (TID 916). 5829 bytes result sent to driver
[2025-07-19T20:48:19.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.106+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 121.0 in stage 9.0 (TID 924) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 121.0 in stage 9.0 (TID 924)
[2025-07-19T20:48:19.107+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 113.0 in stage 9.0 (TID 916) in 88 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d734edc
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119] for update
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e961522
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.108+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121] for update
[2025-07-19T20:48:19.109+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/.2.delta.3b1f04bb-e990-462f-aef9-756ddaae2f4f.TID917.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/2.delta
[2025-07-19T20:48:19.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/114/2.delta
[2025-07-19T20:48:19.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T20:48:19.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T20:48:19.114+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.2.delta.73eb6258-323b-4820-a1f6-442947c4e370.TID923.tmp
[2025-07-19T20:48:19.116+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 114.0 in stage 9.0 (TID 917). 5829 bytes result sent to driver
[2025-07-19T20:48:19.117+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/.2.delta.55bf788d-0195-4f17-ab00-b9989c66b32b.TID918.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/2.delta
[2025-07-19T20:48:19.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/115/2.delta
[2025-07-19T20:48:19.118+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 122.0 in stage 9.0 (TID 925) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 114.0 in stage 9.0 (TID 917) in 93 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:48:19.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T20:48:19.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 122.0 in stage 9.0 (TID 925)
[2025-07-19T20:48:19.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.2.delta.5742e918-9903-459e-a8e5-c036a9f5a352.TID924.tmp
[2025-07-19T20:48:19.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.2.delta.8c38c93a-af01-4cd6-a73d-4bd242dc6f12.TID922.tmp
[2025-07-19T20:48:19.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T20:48:19.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 115.0 in stage 9.0 (TID 918). 5829 bytes result sent to driver
[2025-07-19T20:48:19.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/.2.delta.e512751b-3edd-498d-952f-59ce87f9fee5.TID919.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/2.delta
[2025-07-19T20:48:19.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/116/2.delta
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 123.0 in stage 9.0 (TID 926) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3bc7e000
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 115.0 in stage 9.0 (TID 918) in 96 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122] for update
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 123.0 in stage 9.0 (TID 926)
[2025-07-19T20:48:19.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T20:48:19.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 116.0 in stage 9.0 (TID 919). 5829 bytes result sent to driver
[2025-07-19T20:48:19.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 124.0 in stage 9.0 (TID 927) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 124.0 in stage 9.0 (TID 927)
[2025-07-19T20:48:19.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 116.0 in stage 9.0 (TID 919) in 90 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:48:19.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.131+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1210bb67
[2025-07-19T20:48:19.132+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123] for update
[2025-07-19T20:48:19.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.133+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/.2.delta.c24ff403-2593-4cf8-a5c7-3f7e703fcb33.TID920.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/2.delta
[2025-07-19T20:48:19.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/117/2.delta
[2025-07-19T20:48:19.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f2e472d
[2025-07-19T20:48:19.134+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124] for update
[2025-07-19T20:48:19.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T20:48:19.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.138+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 117.0 in stage 9.0 (TID 920). 5829 bytes result sent to driver
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 125.0 in stage 9.0 (TID 928) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 125.0 in stage 9.0 (TID 928)
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 117.0 in stage 9.0 (TID 920) in 77 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9d9a5bf
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125] for update
[2025-07-19T20:48:19.139+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.141+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/.2.delta.f0f6a14d-72db-426d-a105-fd9f66c6dd4b.TID921.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/2.delta
[2025-07-19T20:48:19.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/118/2.delta
[2025-07-19T20:48:19.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.2.delta.7d195eea-fabc-46e9-a3c1-276a8c7f8db5.TID927.tmp
[2025-07-19T20:48:19.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T20:48:19.142+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.2.delta.e49e7076-ed09-4747-a291-3c8b230d5b62.TID925.tmp
[2025-07-19T20:48:19.145+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.2.delta.ce52b870-4921-4a93-b2da-78e313d73210.TID926.tmp
[2025-07-19T20:48:19.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T20:48:19.148+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 118.0 in stage 9.0 (TID 921). 5829 bytes result sent to driver
[2025-07-19T20:48:19.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 126.0 in stage 9.0 (TID 929) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 118.0 in stage 9.0 (TID 921) in 80 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:48:19.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 126.0 in stage 9.0 (TID 929)
[2025-07-19T20:48:19.152+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.153+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f13d5e
[2025-07-19T20:48:19.154+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.156+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126] for update
[2025-07-19T20:48:19.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.2.delta.1ac3e647-d048-4973-8edf-b15f83ca1617.TID928.tmp
[2025-07-19T20:48:19.159+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/.2.delta.8c38c93a-af01-4cd6-a73d-4bd242dc6f12.TID922.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/2.delta
[2025-07-19T20:48:19.167+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/119/2.delta
[2025-07-19T20:48:19.168+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T20:48:19.173+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T20:48:19.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 119.0 in stage 9.0 (TID 922). 5829 bytes result sent to driver
[2025-07-19T20:48:19.175+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 119.0 in stage 9.0 (TID 922) in 82 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:48:19.176+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 127.0 in stage 9.0 (TID 930) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 127.0 in stage 9.0 (TID 930)
[2025-07-19T20:48:19.177+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/.2.delta.73eb6258-323b-4820-a1f6-442947c4e370.TID923.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/2.delta
[2025-07-19T20:48:19.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/120/2.delta
[2025-07-19T20:48:19.178+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T20:48:19.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.179+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.180+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bfc6bcf
[2025-07-19T20:48:19.181+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127] for update
[2025-07-19T20:48:19.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.2.delta.ef81bb3d-5476-4236-9a11-fd6d6fc89f44.TID929.tmp
[2025-07-19T20:48:19.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T20:48:19.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 120.0 in stage 9.0 (TID 923). 5829 bytes result sent to driver
[2025-07-19T20:48:19.184+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 128.0 in stage 9.0 (TID 931) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 120.0 in stage 9.0 (TID 923) in 90 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:48:19.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 128.0 in stage 9.0 (TID 931)
[2025-07-19T20:48:19.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/.2.delta.5742e918-9903-459e-a8e5-c036a9f5a352.TID924.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/2.delta
[2025-07-19T20:48:19.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/121/2.delta
[2025-07-19T20:48:19.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T20:48:19.185+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1be54cf9
[2025-07-19T20:48:19.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128] for update
[2025-07-19T20:48:19.186+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.188+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T20:48:19.189+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 121.0 in stage 9.0 (TID 924). 5829 bytes result sent to driver
[2025-07-19T20:48:19.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 129.0 in stage 9.0 (TID 932) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.2.delta.5191bf7f-079f-47e2-b02a-bacc05984b13.TID930.tmp
[2025-07-19T20:48:19.191+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 129.0 in stage 9.0 (TID 932)
[2025-07-19T20:48:19.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 121.0 in stage 9.0 (TID 924) in 92 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:48:19.192+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/.2.delta.7d195eea-fabc-46e9-a3c1-276a8c7f8db5.TID927.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/2.delta
[2025-07-19T20:48:19.193+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/124/2.delta
[2025-07-19T20:48:19.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T20:48:19.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.194+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.197+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@195d03c2
[2025-07-19T20:48:19.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.199+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129] for update
[2025-07-19T20:48:19.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.200+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.2.delta.2e1248e3-3bef-4a28-8d67-a9ef8456f4ee.TID931.tmp
[2025-07-19T20:48:19.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T20:48:19.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 124.0 in stage 9.0 (TID 927). 5829 bytes result sent to driver
[2025-07-19T20:48:19.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 130.0 in stage 9.0 (TID 933) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.201+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 124.0 in stage 9.0 (TID 927) in 75 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:48:19.202+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 130.0 in stage 9.0 (TID 933)
[2025-07-19T20:48:19.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/.2.delta.ce52b870-4921-4a93-b2da-78e313d73210.TID926.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/2.delta
[2025-07-19T20:48:19.204+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/123/2.delta
[2025-07-19T20:48:19.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T20:48:19.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/.2.delta.e49e7076-ed09-4747-a291-3c8b230d5b62.TID925.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/2.delta
[2025-07-19T20:48:19.205+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/122/2.delta
[2025-07-19T20:48:19.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.206+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.208+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T20:48:19.209+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 123.0 in stage 9.0 (TID 926). 5829 bytes result sent to driver
[2025-07-19T20:48:19.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c618a2c
[2025-07-19T20:48:19.212+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T20:48:19.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 131.0 in stage 9.0 (TID 934) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.214+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 131.0 in stage 9.0 (TID 934)
[2025-07-19T20:48:19.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.2.delta.e3743591-f272-42d4-8f72-3bf80eb9cd95.TID932.tmp
[2025-07-19T20:48:19.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130] for update
[2025-07-19T20:48:19.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/.2.delta.1ac3e647-d048-4973-8edf-b15f83ca1617.TID928.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/2.delta
[2025-07-19T20:48:19.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/125/2.delta
[2025-07-19T20:48:19.216+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T20:48:19.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 123.0 in stage 9.0 (TID 926) in 90 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:48:19.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.218+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45691aae
[2025-07-19T20:48:19.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131] for update
[2025-07-19T20:48:19.219+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T20:48:19.220+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 122.0 in stage 9.0 (TID 925). 5829 bytes result sent to driver
[2025-07-19T20:48:19.221+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 132.0 in stage 9.0 (TID 935) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T20:48:19.222+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 125.0 in stage 9.0 (TID 928). 5829 bytes result sent to driver
[2025-07-19T20:48:19.224+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 133.0 in stage 9.0 (TID 936) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 122.0 in stage 9.0 (TID 925) in 107 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:48:19.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 125.0 in stage 9.0 (TID 928) in 87 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:48:19.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/.2.delta.ef81bb3d-5476-4236-9a11-fd6d6fc89f44.TID929.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/2.delta
[2025-07-19T20:48:19.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/126/2.delta
[2025-07-19T20:48:19.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T20:48:19.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 132.0 in stage 9.0 (TID 935)
[2025-07-19T20:48:19.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 133.0 in stage 9.0 (TID 936)
[2025-07-19T20:48:19.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.228+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bfaf5ba
[2025-07-19T20:48:19.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.2.delta.27c837bf-3d92-46dc-8c17-37a906ab1945.TID933.tmp
[2025-07-19T20:48:19.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T20:48:19.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.229+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132] for update
[2025-07-19T20:48:19.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 126.0 in stage 9.0 (TID 929). 5829 bytes result sent to driver
[2025-07-19T20:48:19.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.230+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.2.delta.a6772659-9b26-4585-b16a-12c32c40c3aa.TID934.tmp
[2025-07-19T20:48:19.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 134.0 in stage 9.0 (TID 937) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 126.0 in stage 9.0 (TID 929) in 83 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:48:19.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c5353a5
[2025-07-19T20:48:19.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.231+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133] for update
[2025-07-19T20:48:19.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.233+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 134.0 in stage 9.0 (TID 937)
[2025-07-19T20:48:19.237+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@dcfa626
[2025-07-19T20:48:19.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134] for update
[2025-07-19T20:48:19.238+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.241+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.2.delta.3bd7ac15-4f6d-49fb-88cc-f72758d32457.TID935.tmp
[2025-07-19T20:48:19.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/.2.delta.5191bf7f-079f-47e2-b02a-bacc05984b13.TID930.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/2.delta
[2025-07-19T20:48:19.242+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/127/2.delta
[2025-07-19T20:48:19.243+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T20:48:19.244+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.2.delta.92dc35ce-26e8-412f-919f-456bceeecec2.TID936.tmp
[2025-07-19T20:48:19.245+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/.2.delta.2e1248e3-3bef-4a28-8d67-a9ef8456f4ee.TID931.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/2.delta
[2025-07-19T20:48:19.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/128/2.delta
[2025-07-19T20:48:19.248+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T20:48:19.249+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T20:48:19.250+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 127.0 in stage 9.0 (TID 930). 5829 bytes result sent to driver
[2025-07-19T20:48:19.251+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 127.0 in stage 9.0 (TID 930) in 75 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:48:19.252+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 135.0 in stage 9.0 (TID 938) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.253+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.2.delta.07c57587-4b35-4a08-959a-1c9113bd22c2.TID937.tmp
[2025-07-19T20:48:19.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 135.0 in stage 9.0 (TID 938)
[2025-07-19T20:48:19.254+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T20:48:19.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 128.0 in stage 9.0 (TID 931). 5829 bytes result sent to driver
[2025-07-19T20:48:19.255+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 136.0 in stage 9.0 (TID 939) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 128.0 in stage 9.0 (TID 931) in 71 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:48:19.257+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 136.0 in stage 9.0 (TID 939)
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14e38610
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136] for update
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59b77a11
[2025-07-19T20:48:19.258+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.259+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135] for update
[2025-07-19T20:48:19.260+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.262+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/.2.delta.e3743591-f272-42d4-8f72-3bf80eb9cd95.TID932.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/2.delta
[2025-07-19T20:48:19.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/129/2.delta
[2025-07-19T20:48:19.263+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T20:48:19.269+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T20:48:19.270+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.2.delta.f1fe32d2-99a8-44f7-a7ad-b36cf6a977d8.TID939.tmp
[2025-07-19T20:48:19.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 129.0 in stage 9.0 (TID 932). 5829 bytes result sent to driver
[2025-07-19T20:48:19.272+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 137.0 in stage 9.0 (TID 940) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.273+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 129.0 in stage 9.0 (TID 932) in 80 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:48:19.274+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 137.0 in stage 9.0 (TID 940)
[2025-07-19T20:48:19.276+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/.2.delta.27c837bf-3d92-46dc-8c17-37a906ab1945.TID933.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/2.delta
[2025-07-19T20:48:19.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/130/2.delta
[2025-07-19T20:48:19.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T20:48:19.277+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.2.delta.4f155d63-519a-4d83-9595-16bfdfb306b0.TID938.tmp
[2025-07-19T20:48:19.280+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.281+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@166db7fa
[2025-07-19T20:48:19.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137] for update
[2025-07-19T20:48:19.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T20:48:19.282+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 130.0 in stage 9.0 (TID 933). 5829 bytes result sent to driver
[2025-07-19T20:48:19.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 138.0 in stage 9.0 (TID 941) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.283+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.288+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 138.0 in stage 9.0 (TID 941)
[2025-07-19T20:48:19.290+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 130.0 in stage 9.0 (TID 933) in 88 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:48:19.291+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.292+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.296+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@736358a3
[2025-07-19T20:48:19.297+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/.2.delta.a6772659-9b26-4585-b16a-12c32c40c3aa.TID934.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/2.delta
[2025-07-19T20:48:19.298+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/131/2.delta
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/.2.delta.3bd7ac15-4f6d-49fb-88cc-f72758d32457.TID935.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/2.delta
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/132/2.delta
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138] for update
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/.2.delta.92dc35ce-26e8-412f-919f-456bceeecec2.TID936.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/2.delta
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/133/2.delta
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T20:48:19.299+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T20:48:19.300+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T20:48:19.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 131.0 in stage 9.0 (TID 934). 5872 bytes result sent to driver
[2025-07-19T20:48:19.301+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 139.0 in stage 9.0 (TID 942) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.303+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 139.0 in stage 9.0 (TID 942)
[2025-07-19T20:48:19.305+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 131.0 in stage 9.0 (TID 934) in 89 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:48:19.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.306+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.308+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T20:48:19.309+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54bc352f
[2025-07-19T20:48:19.310+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.311+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139] for update
[2025-07-19T20:48:19.312+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 133.0 in stage 9.0 (TID 936). 5872 bytes result sent to driver
[2025-07-19T20:48:19.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T20:48:19.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 132.0 in stage 9.0 (TID 935). 5872 bytes result sent to driver
[2025-07-19T20:48:19.317+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 140.0 in stage 9.0 (TID 943) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.318+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 133.0 in stage 9.0 (TID 936) in 85 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:48:19.319+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 140.0 in stage 9.0 (TID 943)
[2025-07-19T20:48:19.320+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 132.0 in stage 9.0 (TID 935) in 91 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:48:19.321+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 141.0 in stage 9.0 (TID 944) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 141.0 in stage 9.0 (TID 944)
[2025-07-19T20:48:19.324+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.2.delta.9bb414d0-9a2f-4d72-86a0-c62ad14ed40d.TID940.tmp
[2025-07-19T20:48:19.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.326+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@509441f7
[2025-07-19T20:48:19.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.328+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141] for update
[2025-07-19T20:48:19.329+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.2.delta.4298520a-5d1c-4191-8350-b221d4a992c1.TID941.tmp
[2025-07-19T20:48:19.331+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@660b1c3
[2025-07-19T20:48:19.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.333+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140] for update
[2025-07-19T20:48:19.335+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.337+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/.2.delta.07c57587-4b35-4a08-959a-1c9113bd22c2.TID937.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/2.delta
[2025-07-19T20:48:19.339+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/134/2.delta
[2025-07-19T20:48:19.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T20:48:19.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.2.delta.71981fa5-8a77-4cbe-aaab-45b5d8a2ce01.TID942.tmp
[2025-07-19T20:48:19.340+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T20:48:19.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 134.0 in stage 9.0 (TID 937). 5872 bytes result sent to driver
[2025-07-19T20:48:19.342+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 142.0 in stage 9.0 (TID 945) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 134.0 in stage 9.0 (TID 937) in 100 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:48:19.343+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 142.0 in stage 9.0 (TID 945)
[2025-07-19T20:48:19.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.345+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.347+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ea50e6d
[2025-07-19T20:48:19.348+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.349+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142] for update
[2025-07-19T20:48:19.350+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.351+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.2.delta.63eaa53e-57f6-45ca-9c75-2ba7a084f566.TID943.tmp
[2025-07-19T20:48:19.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/.2.delta.f1fe32d2-99a8-44f7-a7ad-b36cf6a977d8.TID939.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/2.delta
[2025-07-19T20:48:19.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/136/2.delta
[2025-07-19T20:48:19.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.2.delta.db3b7930-8037-407d-b29b-d6633fa75da3.TID944.tmp
[2025-07-19T20:48:19.352+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T20:48:19.359+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.2.delta.f85f00c4-5d7c-4dc6-8536-08e2e7b772ef.TID945.tmp
[2025-07-19T20:48:19.362+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T20:48:19.365+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 136.0 in stage 9.0 (TID 939). 5872 bytes result sent to driver
[2025-07-19T20:48:19.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/.2.delta.4f155d63-519a-4d83-9595-16bfdfb306b0.TID938.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/2.delta
[2025-07-19T20:48:19.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/135/2.delta
[2025-07-19T20:48:19.371+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 143.0 in stage 9.0 (TID 946) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 143.0 in stage 9.0 (TID 946)
[2025-07-19T20:48:19.373+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 136.0 in stage 9.0 (TID 939) in 109 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:48:19.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T20:48:19.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fb354cf
[2025-07-19T20:48:19.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.374+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143] for update
[2025-07-19T20:48:19.377+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.379+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T20:48:19.383+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 135.0 in stage 9.0 (TID 938). 5872 bytes result sent to driver
[2025-07-19T20:48:19.385+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 144.0 in stage 9.0 (TID 947) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.386+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 135.0 in stage 9.0 (TID 938) in 135 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:48:19.389+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 144.0 in stage 9.0 (TID 947)
[2025-07-19T20:48:19.391+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.392+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.393+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d538f7e
[2025-07-19T20:48:19.394+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.395+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144] for update
[2025-07-19T20:48:19.396+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.2.delta.58d7470d-8428-4889-8dac-2a87d8983d41.TID946.tmp
[2025-07-19T20:48:19.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/.2.delta.71981fa5-8a77-4cbe-aaab-45b5d8a2ce01.TID942.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/2.delta
[2025-07-19T20:48:19.397+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/139/2.delta
[2025-07-19T20:48:19.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T20:48:19.398+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/.2.delta.9bb414d0-9a2f-4d72-86a0-c62ad14ed40d.TID940.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/2.delta
[2025-07-19T20:48:19.400+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/137/2.delta
[2025-07-19T20:48:19.401+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T20:48:19.402+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T20:48:19.403+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 139.0 in stage 9.0 (TID 942). 5872 bytes result sent to driver
[2025-07-19T20:48:19.404+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/.2.delta.4298520a-5d1c-4191-8350-b221d4a992c1.TID941.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/2.delta
[2025-07-19T20:48:19.405+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/138/2.delta
[2025-07-19T20:48:19.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 145.0 in stage 9.0 (TID 948) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.406+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 139.0 in stage 9.0 (TID 942) in 99 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:48:19.408+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T20:48:19.409+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 145.0 in stage 9.0 (TID 948)
[2025-07-19T20:48:19.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T20:48:19.411+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T20:48:19.413+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 137.0 in stage 9.0 (TID 940). 5872 bytes result sent to driver
[2025-07-19T20:48:19.415+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 138.0 in stage 9.0 (TID 941). 5872 bytes result sent to driver
[2025-07-19T20:48:19.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.417+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 146.0 in stage 9.0 (TID 949) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.418+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47f7d444
[2025-07-19T20:48:19.420+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 147.0 in stage 9.0 (TID 950) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 147.0 in stage 9.0 (TID 950)
[2025-07-19T20:48:19.421+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145] for update
[2025-07-19T20:48:19.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 146.0 in stage 9.0 (TID 949)
[2025-07-19T20:48:19.425+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 138.0 in stage 9.0 (TID 941) in 128 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:48:19.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 137.0 in stage 9.0 (TID 940) in 138 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:48:19.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.2.delta.c84433d2-f692-4996-a7f6-86a649a89720.TID947.tmp
[2025-07-19T20:48:19.426+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.427+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.428+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cf0ca47
[2025-07-19T20:48:19.429+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.430+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.432+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147] for update
[2025-07-19T20:48:19.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.433+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79e2f5fd
[2025-07-19T20:48:19.434+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146] for update
[2025-07-19T20:48:19.435+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/.2.delta.63eaa53e-57f6-45ca-9c75-2ba7a084f566.TID943.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/2.delta
[2025-07-19T20:48:19.437+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/140/2.delta
[2025-07-19T20:48:19.441+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T20:48:19.447+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.448+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T20:48:19.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 140.0 in stage 9.0 (TID 943). 5872 bytes result sent to driver
[2025-07-19T20:48:19.449+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 148.0 in stage 9.0 (TID 951) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.451+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 140.0 in stage 9.0 (TID 943) in 119 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:48:19.452+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 148.0 in stage 9.0 (TID 951)
[2025-07-19T20:48:19.453+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.454+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b2b893d
[2025-07-19T20:48:19.455+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.457+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148] for update
[2025-07-19T20:48:19.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.459+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/.2.delta.f85f00c4-5d7c-4dc6-8536-08e2e7b772ef.TID945.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/2.delta
[2025-07-19T20:48:19.460+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/142/2.delta
[2025-07-19T20:48:19.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T20:48:19.461+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.2.delta.75d2398b-ea46-4a7a-b84c-a9455a8eb7c0.TID948.tmp
[2025-07-19T20:48:19.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.2.delta.df26a064-5bbf-4226-a4ef-8b07a51404ff.TID949.tmp
[2025-07-19T20:48:19.463+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.2.delta.ee01a3cd-de89-4855-bd0f-eb66972486bf.TID950.tmp
[2025-07-19T20:48:19.464+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/.2.delta.db3b7930-8037-407d-b29b-d6633fa75da3.TID944.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/2.delta
[2025-07-19T20:48:19.466+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/141/2.delta
[2025-07-19T20:48:19.467+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T20:48:19.468+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T20:48:19.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 142.0 in stage 9.0 (TID 945). 5872 bytes result sent to driver
[2025-07-19T20:48:19.470+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 149.0 in stage 9.0 (TID 952) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.472+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 142.0 in stage 9.0 (TID 945) in 108 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:48:19.475+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 149.0 in stage 9.0 (TID 952)
[2025-07-19T20:48:19.476+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T20:48:19.478+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 141.0 in stage 9.0 (TID 944). 5872 bytes result sent to driver
[2025-07-19T20:48:19.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 150.0 in stage 9.0 (TID 953) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 141.0 in stage 9.0 (TID 944) in 131 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:48:19.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 150.0 in stage 9.0 (TID 953)
[2025-07-19T20:48:19.479+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46d13dde
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149] for update
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fc960f
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150] for update
[2025-07-19T20:48:19.480+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.2.delta.64444d97-0a91-4e59-8ac8-1ac99651e90a.TID951.tmp
[2025-07-19T20:48:19.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.2.delta.879119be-96f4-4c1b-97d9-d869fff50007.TID952.tmp
[2025-07-19T20:48:19.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/.2.delta.58d7470d-8428-4889-8dac-2a87d8983d41.TID946.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/2.delta
[2025-07-19T20:48:19.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/143/2.delta
[2025-07-19T20:48:19.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T20:48:19.481+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.2.delta.c48030a6-ca2e-461c-bf15-9b95148d558c.TID953.tmp
[2025-07-19T20:48:19.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T20:48:19.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 143.0 in stage 9.0 (TID 946). 5872 bytes result sent to driver
[2025-07-19T20:48:19.482+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 151.0 in stage 9.0 (TID 954) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 143.0 in stage 9.0 (TID 946) in 103 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:48:19.483+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/.2.delta.c84433d2-f692-4996-a7f6-86a649a89720.TID947.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/2.delta
[2025-07-19T20:48:19.487+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/144/2.delta
[2025-07-19T20:48:19.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T20:48:19.488+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 151.0 in stage 9.0 (TID 954)
[2025-07-19T20:48:19.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65754d83
[2025-07-19T20:48:19.489+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T20:48:19.490+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 144.0 in stage 9.0 (TID 947). 5829 bytes result sent to driver
[2025-07-19T20:48:19.492+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 152.0 in stage 9.0 (TID 955) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.493+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 152.0 in stage 9.0 (TID 955)
[2025-07-19T20:48:19.496+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 144.0 in stage 9.0 (TID 947) in 89 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:48:19.497+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.498+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151] for update
[2025-07-19T20:48:19.499+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.500+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.501+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fa8fbe9
[2025-07-19T20:48:19.503+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.506+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152] for update
[2025-07-19T20:48:19.508+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.509+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.511+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/.2.delta.ee01a3cd-de89-4855-bd0f-eb66972486bf.TID950.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/2.delta
[2025-07-19T20:48:19.512+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/147/2.delta
[2025-07-19T20:48:19.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T20:48:19.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.2.delta.1d3427a6-44e5-439a-9144-489f55b8db53.TID954.tmp
[2025-07-19T20:48:19.513+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.2.delta.8bb2910e-65e2-4234-a751-436b60323f3e.TID955.tmp
[2025-07-19T20:48:19.514+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/.2.delta.75d2398b-ea46-4a7a-b84c-a9455a8eb7c0.TID948.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/2.delta
[2025-07-19T20:48:19.517+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/145/2.delta
[2025-07-19T20:48:19.519+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T20:48:19.520+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T20:48:19.523+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 147.0 in stage 9.0 (TID 950). 5829 bytes result sent to driver
[2025-07-19T20:48:19.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 153.0 in stage 9.0 (TID 956) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 153.0 in stage 9.0 (TID 956)
[2025-07-19T20:48:19.524+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 147.0 in stage 9.0 (TID 950) in 94 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:48:19.527+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.528+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f94ba52
[2025-07-19T20:48:19.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/.2.delta.df26a064-5bbf-4226-a4ef-8b07a51404ff.TID949.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/2.delta
[2025-07-19T20:48:19.529+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/146/2.delta
[2025-07-19T20:48:19.532+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T20:48:19.533+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153] for update
[2025-07-19T20:48:19.534+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T20:48:19.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 145.0 in stage 9.0 (TID 948). 5829 bytes result sent to driver
[2025-07-19T20:48:19.535+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.537+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T20:48:19.538+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 154.0 in stage 9.0 (TID 957) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.539+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 145.0 in stage 9.0 (TID 948) in 109 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:48:19.540+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 146.0 in stage 9.0 (TID 949). 5829 bytes result sent to driver
[2025-07-19T20:48:19.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 155.0 in stage 9.0 (TID 958) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.541+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 155.0 in stage 9.0 (TID 958)
[2025-07-19T20:48:19.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 154.0 in stage 9.0 (TID 957)
[2025-07-19T20:48:19.542+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.544+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 146.0 in stage 9.0 (TID 949) in 104 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:48:19.545+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55571d71
[2025-07-19T20:48:19.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155] for update
[2025-07-19T20:48:19.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.546+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b34c541
[2025-07-19T20:48:19.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154] for update
[2025-07-19T20:48:19.547+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/.2.delta.64444d97-0a91-4e59-8ac8-1ac99651e90a.TID951.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/2.delta
[2025-07-19T20:48:19.548+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/148/2.delta
[2025-07-19T20:48:19.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T20:48:19.550+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T20:48:19.551+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 148.0 in stage 9.0 (TID 951). 5829 bytes result sent to driver
[2025-07-19T20:48:19.554+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/.2.delta.879119be-96f4-4c1b-97d9-d869fff50007.TID952.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/2.delta
[2025-07-19T20:48:19.555+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/149/2.delta
[2025-07-19T20:48:19.557+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 156.0 in stage 9.0 (TID 959) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 156.0 in stage 9.0 (TID 959)
[2025-07-19T20:48:19.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 148.0 in stage 9.0 (TID 951) in 97 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:48:19.558+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.2.delta.4c6a1bd5-7e8f-4921-9616-a7170f90a3bc.TID956.tmp
[2025-07-19T20:48:19.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.559+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.560+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T20:48:19.561+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/.2.delta.c48030a6-ca2e-461c-bf15-9b95148d558c.TID953.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/2.delta
[2025-07-19T20:48:19.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/150/2.delta
[2025-07-19T20:48:19.562+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55a0805d
[2025-07-19T20:48:19.563+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T20:48:19.564+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.2.delta.970216eb-ee57-4f20-98db-00cc8ef38441.TID958.tmp
[2025-07-19T20:48:19.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T20:48:19.565+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 149.0 in stage 9.0 (TID 952). 5829 bytes result sent to driver
[2025-07-19T20:48:19.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.566+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156] for update
[2025-07-19T20:48:19.567+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.568+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 157.0 in stage 9.0 (TID 960) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.569+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 149.0 in stage 9.0 (TID 952) in 92 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:48:19.571+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 157.0 in stage 9.0 (TID 960)
[2025-07-19T20:48:19.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T20:48:19.572+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 150.0 in stage 9.0 (TID 953). 5829 bytes result sent to driver
[2025-07-19T20:48:19.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 158.0 in stage 9.0 (TID 961) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.577+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 150.0 in stage 9.0 (TID 953) in 94 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:48:19.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.578+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 158.0 in stage 9.0 (TID 961)
[2025-07-19T20:48:19.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@358fdced
[2025-07-19T20:48:19.579+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157] for update
[2025-07-19T20:48:19.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.2.delta.47a15caa-0ed0-4179-b7a2-c239c06ddc95.TID957.tmp
[2025-07-19T20:48:19.580+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.581+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.582+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c32791
[2025-07-19T20:48:19.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.583+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158] for update
[2025-07-19T20:48:19.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.584+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.2.delta.0011d025-7473-49e1-b10d-b5a535da52b7.TID959.tmp
[2025-07-19T20:48:19.585+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.2.delta.d90bd1d2-3209-46cf-815a-439a02055f9a.TID961.tmp
[2025-07-19T20:48:19.586+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.2.delta.3b54535c-04ab-4d81-b96f-99a8621d04e8.TID960.tmp
[2025-07-19T20:48:19.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/.2.delta.8bb2910e-65e2-4234-a751-436b60323f3e.TID955.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/2.delta
[2025-07-19T20:48:19.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/152/2.delta
[2025-07-19T20:48:19.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T20:48:19.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/.2.delta.1d3427a6-44e5-439a-9144-489f55b8db53.TID954.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/2.delta
[2025-07-19T20:48:19.587+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/151/2.delta
[2025-07-19T20:48:19.588+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T20:48:19.590+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T20:48:19.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T20:48:19.591+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 152.0 in stage 9.0 (TID 955). 5829 bytes result sent to driver
[2025-07-19T20:48:19.592+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 151.0 in stage 9.0 (TID 954). 5829 bytes result sent to driver
[2025-07-19T20:48:19.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 152.0 in stage 9.0 (TID 955) in 97 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:48:19.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 159.0 in stage 9.0 (TID 962) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 159.0 in stage 9.0 (TID 962)
[2025-07-19T20:48:19.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 160.0 in stage 9.0 (TID 963) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.596+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 151.0 in stage 9.0 (TID 954) in 106 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:48:19.597+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43e6887a
[2025-07-19T20:48:19.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.599+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159] for update
[2025-07-19T20:48:19.601+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 160.0 in stage 9.0 (TID 963)
[2025-07-19T20:48:19.603+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@628f3ecc
[2025-07-19T20:48:19.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.605+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160] for update
[2025-07-19T20:48:19.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.607+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/.2.delta.4c6a1bd5-7e8f-4921-9616-a7170f90a3bc.TID956.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/2.delta
[2025-07-19T20:48:19.608+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/153/2.delta
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/.2.delta.970216eb-ee57-4f20-98db-00cc8ef38441.TID958.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/2.delta
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/155/2.delta
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.2.delta.c873aa7c-4e2b-4442-93a5-9620de48489e.TID962.tmp
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 153.0 in stage 9.0 (TID 956). 5829 bytes result sent to driver
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 155.0 in stage 9.0 (TID 958). 5829 bytes result sent to driver
[2025-07-19T20:48:19.609+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/.2.delta.47a15caa-0ed0-4179-b7a2-c239c06ddc95.TID957.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/2.delta
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/154/2.delta
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 161.0 in stage 9.0 (TID 964) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 162.0 in stage 9.0 (TID 965) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 161.0 in stage 9.0 (TID 964)
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 162.0 in stage 9.0 (TID 965)
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 155.0 in stage 9.0 (TID 958) in 84 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:48:19.610+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 153.0 in stage 9.0 (TID 956) in 93 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.2.delta.fc032e46-314f-4eca-ae0d-56dfaa625814.TID963.tmp
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 154.0 in stage 9.0 (TID 957). 5829 bytes result sent to driver
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 163.0 in stage 9.0 (TID 966) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 154.0 in stage 9.0 (TID 957) in 91 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 163.0 in stage 9.0 (TID 966)
[2025-07-19T20:48:19.611+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fb2e2a
[2025-07-19T20:48:19.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162] for update
[2025-07-19T20:48:19.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/.2.delta.0011d025-7473-49e1-b10d-b5a535da52b7.TID959.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/2.delta
[2025-07-19T20:48:19.612+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/156/2.delta
[2025-07-19T20:48:19.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/.2.delta.d90bd1d2-3209-46cf-815a-439a02055f9a.TID961.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/2.delta
[2025-07-19T20:48:19.613+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/158/2.delta
[2025-07-19T20:48:19.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a281d3d
[2025-07-19T20:48:19.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T20:48:19.614+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.615+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161] for update
[2025-07-19T20:48:19.616+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T20:48:19.617+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/.2.delta.3b54535c-04ab-4d81-b96f-99a8621d04e8.TID960.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/2.delta
[2025-07-19T20:48:19.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/157/2.delta
[2025-07-19T20:48:19.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59c9d359
[2025-07-19T20:48:19.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.618+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163] for update
[2025-07-19T20:48:19.619+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T20:48:19.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T20:48:19.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 156.0 in stage 9.0 (TID 959). 5829 bytes result sent to driver
[2025-07-19T20:48:19.622+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 164.0 in stage 9.0 (TID 967) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 164.0 in stage 9.0 (TID 967)
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 156.0 in stage 9.0 (TID 959) in 88 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 158.0 in stage 9.0 (TID 961). 5829 bytes result sent to driver
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 157.0 in stage 9.0 (TID 960). 5829 bytes result sent to driver
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 165.0 in stage 9.0 (TID 968) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.623+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44240a3f
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 158.0 in stage 9.0 (TID 961) in 79 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 165.0 in stage 9.0 (TID 968)
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 166.0 in stage 9.0 (TID 969) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 157.0 in stage 9.0 (TID 960) in 84 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 166.0 in stage 9.0 (TID 969)
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164] for update
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.624+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d949757
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166] for update
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32d965d5
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165] for update
[2025-07-19T20:48:19.625+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.2.delta.0462f8d8-62de-4603-8768-ecd95a953980.TID965.tmp
[2025-07-19T20:48:19.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.2.delta.b3844f3e-237f-4ed3-be1f-87696e16ce52.TID964.tmp
[2025-07-19T20:48:19.626+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.2.delta.ae12ce51-96c4-4a03-9327-2c373d8f4184.TID966.tmp
[2025-07-19T20:48:19.627+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.2.delta.d2ebee0b-adb1-43bc-bbf7-d0b246411c20.TID969.tmp
[2025-07-19T20:48:19.629+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.2.delta.7c74e423-60b8-4e9a-af16-f66f5dc8a736.TID967.tmp
[2025-07-19T20:48:19.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/.2.delta.c873aa7c-4e2b-4442-93a5-9620de48489e.TID962.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/2.delta
[2025-07-19T20:48:19.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/159/2.delta
[2025-07-19T20:48:19.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T20:48:19.632+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.2.delta.f24c36bc-5e9c-4341-a5e4-084b1f00de09.TID968.tmp
[2025-07-19T20:48:19.636+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T20:48:19.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 159.0 in stage 9.0 (TID 962). 5829 bytes result sent to driver
[2025-07-19T20:48:19.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 167.0 in stage 9.0 (TID 970) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 159.0 in stage 9.0 (TID 962) in 69 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:48:19.637+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 167.0 in stage 9.0 (TID 970)
[2025-07-19T20:48:19.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.639+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d867f0b
[2025-07-19T20:48:19.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.641+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167] for update
[2025-07-19T20:48:19.643+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/.2.delta.fc032e46-314f-4eca-ae0d-56dfaa625814.TID963.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/2.delta
[2025-07-19T20:48:19.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/160/2.delta
[2025-07-19T20:48:19.646+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T20:48:19.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T20:48:19.650+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 160.0 in stage 9.0 (TID 963). 5829 bytes result sent to driver
[2025-07-19T20:48:19.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 168.0 in stage 9.0 (TID 971) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.652+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 160.0 in stage 9.0 (TID 963) in 82 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:48:19.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 168.0 in stage 9.0 (TID 971)
[2025-07-19T20:48:19.653+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.654+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@453d8980
[2025-07-19T20:48:19.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.655+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168] for update
[2025-07-19T20:48:19.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.656+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.2.delta.7c1eabbe-38aa-4879-8f2f-52d6c78a278c.TID970.tmp
[2025-07-19T20:48:19.659+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/.2.delta.b3844f3e-237f-4ed3-be1f-87696e16ce52.TID964.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/2.delta
[2025-07-19T20:48:19.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/161/2.delta
[2025-07-19T20:48:19.660+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T20:48:19.664+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T20:48:19.665+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 161.0 in stage 9.0 (TID 964). 5829 bytes result sent to driver
[2025-07-19T20:48:19.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 169.0 in stage 9.0 (TID 972) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 169.0 in stage 9.0 (TID 972)
[2025-07-19T20:48:19.668+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/.2.delta.ae12ce51-96c4-4a03-9327-2c373d8f4184.TID966.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/2.delta
[2025-07-19T20:48:19.669+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/163/2.delta
[2025-07-19T20:48:19.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 161.0 in stage 9.0 (TID 964) in 75 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:48:19.670+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.2.delta.61feb76b-8d38-4b88-928c-9ec3d1249569.TID971.tmp
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/.2.delta.0462f8d8-62de-4603-8768-ecd95a953980.TID965.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/2.delta
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/162/2.delta
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af7f2a2
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169] for update
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T20:48:19.671+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 163.0 in stage 9.0 (TID 966). 5829 bytes result sent to driver
[2025-07-19T20:48:19.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 170.0 in stage 9.0 (TID 973) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 163.0 in stage 9.0 (TID 966) in 75 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:48:19.672+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 170.0 in stage 9.0 (TID 973)
[2025-07-19T20:48:19.674+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T20:48:19.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 162.0 in stage 9.0 (TID 965). 5829 bytes result sent to driver
[2025-07-19T20:48:19.675+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.676+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 171.0 in stage 9.0 (TID 974) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.677+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dcdf28d
[2025-07-19T20:48:19.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.678+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 162.0 in stage 9.0 (TID 965) in 87 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:48:19.679+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170] for update
[2025-07-19T20:48:19.680+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/.2.delta.f24c36bc-5e9c-4341-a5e4-084b1f00de09.TID968.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/2.delta
[2025-07-19T20:48:19.681+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/165/2.delta
[2025-07-19T20:48:19.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T20:48:19.682+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.683+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/.2.delta.7c74e423-60b8-4e9a-af16-f66f5dc8a736.TID967.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/2.delta
[2025-07-19T20:48:19.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/164/2.delta
[2025-07-19T20:48:19.684+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 171.0 in stage 9.0 (TID 974)
[2025-07-19T20:48:19.685+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/.2.delta.d2ebee0b-adb1-43bc-bbf7-d0b246411c20.TID969.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/2.delta
[2025-07-19T20:48:19.686+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/166/2.delta
[2025-07-19T20:48:19.687+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T20:48:19.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T20:48:19.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T20:48:19.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.688+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 165.0 in stage 9.0 (TID 968). 5829 bytes result sent to driver
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551cc392
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 166.0 in stage 9.0 (TID 969). 5786 bytes result sent to driver
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 164.0 in stage 9.0 (TID 967). 5829 bytes result sent to driver
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 172.0 in stage 9.0 (TID 975) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.689+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 173.0 in stage 9.0 (TID 976) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.690+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 174.0 in stage 9.0 (TID 977) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 165.0 in stage 9.0 (TID 968) in 76 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:48:19.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 166.0 in stage 9.0 (TID 969) in 73 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:48:19.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 164.0 in stage 9.0 (TID 967) in 79 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:48:19.692+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171] for update
[2025-07-19T20:48:19.693+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 174.0 in stage 9.0 (TID 977)
[2025-07-19T20:48:19.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 173.0 in stage 9.0 (TID 976)
[2025-07-19T20:48:19.694+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 172.0 in stage 9.0 (TID 975)
[2025-07-19T20:48:19.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.2.delta.d4d78785-fea3-4542-be34-82670f2d008a.TID973.tmp
[2025-07-19T20:48:19.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ab50d64
[2025-07-19T20:48:19.698+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173] for update
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.2.delta.7e11c940-fc24-4706-8851-02ddde831627.TID972.tmp
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@598e35c2
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.699+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174] for update
[2025-07-19T20:48:19.700+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.703+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f98a7ed
[2025-07-19T20:48:19.704+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172] for update
[2025-07-19T20:48:19.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/.2.delta.7c1eabbe-38aa-4879-8f2f-52d6c78a278c.TID970.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/2.delta
[2025-07-19T20:48:19.705+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/167/2.delta
[2025-07-19T20:48:19.706+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T20:48:19.707+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T20:48:19.708+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 167.0 in stage 9.0 (TID 970). 5829 bytes result sent to driver
[2025-07-19T20:48:19.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 175.0 in stage 9.0 (TID 978) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 175.0 in stage 9.0 (TID 978)
[2025-07-19T20:48:19.709+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 167.0 in stage 9.0 (TID 970) in 71 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:48:19.710+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.2.delta.6c530e8f-06a3-458e-888a-20e0cc823c71.TID977.tmp
[2025-07-19T20:48:19.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.2.delta.fee3a837-deca-4315-8ab9-6168e43ee6d4.TID976.tmp
[2025-07-19T20:48:19.711+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.2.delta.2b8a2dc6-39ab-4cd3-95c4-bdea20aa11a0.TID974.tmp
[2025-07-19T20:48:19.715+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.2.delta.47bcd2eb-c2a1-4b8d-9e2f-dbb86d234f5d.TID975.tmp
[2025-07-19T20:48:19.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:19.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78dfad5
[2025-07-19T20:48:19.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.716+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175] for update
[2025-07-19T20:48:19.717+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.720+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/.2.delta.61feb76b-8d38-4b88-928c-9ec3d1249569.TID971.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/2.delta
[2025-07-19T20:48:19.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/168/2.delta
[2025-07-19T20:48:19.721+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T20:48:19.724+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T20:48:19.725+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 168.0 in stage 9.0 (TID 971). 5829 bytes result sent to driver
[2025-07-19T20:48:19.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 176.0 in stage 9.0 (TID 979) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.726+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 176.0 in stage 9.0 (TID 979)
[2025-07-19T20:48:19.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.728+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.730+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c0d3498
[2025-07-19T20:48:19.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 168.0 in stage 9.0 (TID 971) in 78 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:48:19.731+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176] for update
[2025-07-19T20:48:19.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.2.delta.1b878ce8-616c-4745-919c-be0bc2ceca43.TID978.tmp
[2025-07-19T20:48:19.732+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/.2.delta.d4d78785-fea3-4542-be34-82670f2d008a.TID973.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/2.delta
[2025-07-19T20:48:19.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/170/2.delta
[2025-07-19T20:48:19.733+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T20:48:19.738+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T20:48:19.739+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 170.0 in stage 9.0 (TID 973). 5829 bytes result sent to driver
[2025-07-19T20:48:19.740+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 177.0 in stage 9.0 (TID 980) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 177.0 in stage 9.0 (TID 980)
[2025-07-19T20:48:19.741+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.2.delta.69583542-807c-45d5-b3a4-e9ebd2f5c1a9.TID979.tmp
[2025-07-19T20:48:19.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 170.0 in stage 9.0 (TID 973) in 68 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:48:19.742+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.743+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24caa923
[2025-07-19T20:48:19.744+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177] for update
[2025-07-19T20:48:19.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/.2.delta.7e11c940-fc24-4706-8851-02ddde831627.TID972.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/2.delta
[2025-07-19T20:48:19.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/169/2.delta
[2025-07-19T20:48:19.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T20:48:19.745+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T20:48:19.748+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 169.0 in stage 9.0 (TID 972). 5829 bytes result sent to driver
[2025-07-19T20:48:19.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 178.0 in stage 9.0 (TID 981) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 169.0 in stage 9.0 (TID 972) in 83 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:48:19.749+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 178.0 in stage 9.0 (TID 981)
[2025-07-19T20:48:19.752+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.753+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bf62026
[2025-07-19T20:48:19.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.754+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178] for update
[2025-07-19T20:48:19.755+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.756+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.2.delta.1fd14eeb-c35d-4ba7-9478-dfb5879ee921.TID980.tmp
[2025-07-19T20:48:19.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/.2.delta.fee3a837-deca-4315-8ab9-6168e43ee6d4.TID976.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/2.delta
[2025-07-19T20:48:19.759+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/173/2.delta
[2025-07-19T20:48:19.760+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/.2.delta.6c530e8f-06a3-458e-888a-20e0cc823c71.TID977.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/2.delta
[2025-07-19T20:48:19.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/174/2.delta
[2025-07-19T20:48:19.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T20:48:19.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T20:48:19.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T20:48:19.761+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T20:48:19.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 174.0 in stage 9.0 (TID 977). 5829 bytes result sent to driver
[2025-07-19T20:48:19.762+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 173.0 in stage 9.0 (TID 976). 5829 bytes result sent to driver
[2025-07-19T20:48:19.764+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/.2.delta.47bcd2eb-c2a1-4b8d-9e2f-dbb86d234f5d.TID975.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/2.delta
[2025-07-19T20:48:19.766+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/172/2.delta
[2025-07-19T20:48:19.767+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T20:48:19.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 179.0 in stage 9.0 (TID 982) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 180.0 in stage 9.0 (TID 983) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.769+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 180.0 in stage 9.0 (TID 983)
[2025-07-19T20:48:19.770+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 174.0 in stage 9.0 (TID 977) in 81 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 179.0 in stage 9.0 (TID 982)
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 173.0 in stage 9.0 (TID 976) in 82 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 172.0 in stage 9.0 (TID 975). 5829 bytes result sent to driver
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.2.delta.606c3953-0365-4f9a-8044-1cea53ffe989.TID981.tmp
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.771+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 181.0 in stage 9.0 (TID 984) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 172.0 in stage 9.0 (TID 975) in 85 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12406736
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.772+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180] for update
[2025-07-19T20:48:19.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d06893b
[2025-07-19T20:48:19.773+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 181.0 in stage 9.0 (TID 984)
[2025-07-19T20:48:19.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.774+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179] for update
[2025-07-19T20:48:19.778+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.779+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/.2.delta.2b8a2dc6-39ab-4cd3-95c4-bdea20aa11a0.TID974.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/2.delta
[2025-07-19T20:48:19.780+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/171/2.delta
[2025-07-19T20:48:19.781+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T20:48:19.782+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69bf1b42
[2025-07-19T20:48:19.783+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.784+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181] for update
[2025-07-19T20:48:19.785+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T20:48:19.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.2.delta.1f82f2cd-9b85-4c79-926f-6f36241970d9.TID983.tmp
[2025-07-19T20:48:19.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 171.0 in stage 9.0 (TID 974). 5872 bytes result sent to driver
[2025-07-19T20:48:19.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 182.0 in stage 9.0 (TID 985) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 171.0 in stage 9.0 (TID 974) in 109 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:48:19.786+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 182.0 in stage 9.0 (TID 985)
[2025-07-19T20:48:19.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/.2.delta.1b878ce8-616c-4745-919c-be0bc2ceca43.TID978.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/2.delta
[2025-07-19T20:48:19.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/175/2.delta
[2025-07-19T20:48:19.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T20:48:19.787+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b5c3cb6
[2025-07-19T20:48:19.794+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T20:48:19.802+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.803+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182] for update
[2025-07-19T20:48:19.804+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 175.0 in stage 9.0 (TID 978). 5915 bytes result sent to driver
[2025-07-19T20:48:19.805+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 183.0 in stage 9.0 (TID 986) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.806+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 175.0 in stage 9.0 (TID 978) in 95 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:48:19.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 183.0 in stage 9.0 (TID 986)
[2025-07-19T20:48:19.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.2.delta.077dc137-364d-4df8-8171-20bb79bdbdf3.TID982.tmp
[2025-07-19T20:48:19.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.808+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.809+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.2.delta.afcf9997-22ca-4a10-9b32-85a5355671c9.TID984.tmp
[2025-07-19T20:48:19.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.810+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/.2.delta.69583542-807c-45d5-b3a4-e9ebd2f5c1a9.TID979.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/2.delta
[2025-07-19T20:48:19.811+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/176/2.delta
[2025-07-19T20:48:19.812+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T20:48:19.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cd495a2
[2025-07-19T20:48:19.813+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.814+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183] for update
[2025-07-19T20:48:19.815+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T20:48:19.816+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.817+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 176.0 in stage 9.0 (TID 979). 5872 bytes result sent to driver
[2025-07-19T20:48:19.818+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 184.0 in stage 9.0 (TID 987) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 176.0 in stage 9.0 (TID 979) in 91 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:48:19.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 184.0 in stage 9.0 (TID 987)
[2025-07-19T20:48:19.819+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.821+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.2.delta.cadce676-1a92-4036-a7d4-a934c5e5ac1d.TID985.tmp
[2025-07-19T20:48:19.822+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47dc9d53
[2025-07-19T20:48:19.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.824+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184] for update
[2025-07-19T20:48:19.825+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.827+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/.2.delta.1fd14eeb-c35d-4ba7-9478-dfb5879ee921.TID980.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/2.delta
[2025-07-19T20:48:19.828+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/177/2.delta
[2025-07-19T20:48:19.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T20:48:19.829+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.2.delta.dfc6f5e4-d866-45ad-9b1c-e5fab52b3385.TID986.tmp
[2025-07-19T20:48:19.833+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/.2.delta.606c3953-0365-4f9a-8044-1cea53ffe989.TID981.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/2.delta
[2025-07-19T20:48:19.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/178/2.delta
[2025-07-19T20:48:19.838+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T20:48:19.839+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T20:48:19.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 177.0 in stage 9.0 (TID 980). 5872 bytes result sent to driver
[2025-07-19T20:48:19.842+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 185.0 in stage 9.0 (TID 988) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.844+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 185.0 in stage 9.0 (TID 988)
[2025-07-19T20:48:19.845+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 177.0 in stage 9.0 (TID 980) in 100 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:48:19.846+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T20:48:19.848+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 178.0 in stage 9.0 (TID 981). 5872 bytes result sent to driver
[2025-07-19T20:48:19.850+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@501aeb86
[2025-07-19T20:48:19.851+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 186.0 in stage 9.0 (TID 989) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.852+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 178.0 in stage 9.0 (TID 981) in 93 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:48:19.853+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 186.0 in stage 9.0 (TID 989)
[2025-07-19T20:48:19.854+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185] for update
[2025-07-19T20:48:19.855+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.2.delta.0ddd2a81-3f6c-4d95-9e75-783a9538a03c.TID987.tmp
[2025-07-19T20:48:19.856+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/.2.delta.1f82f2cd-9b85-4c79-926f-6f36241970d9.TID983.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/2.delta
[2025-07-19T20:48:19.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/180/2.delta
[2025-07-19T20:48:19.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28750b97
[2025-07-19T20:48:19.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T20:48:19.859+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186] for update
[2025-07-19T20:48:19.860+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T20:48:19.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 180.0 in stage 9.0 (TID 983). 5872 bytes result sent to driver
[2025-07-19T20:48:19.862+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 187.0 in stage 9.0 (TID 990) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 180.0 in stage 9.0 (TID 983) in 87 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:48:19.863+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 187.0 in stage 9.0 (TID 990)
[2025-07-19T20:48:19.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.864+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.2.delta.442cc8ac-af30-4926-9333-2f5594f06e77.TID988.tmp
[2025-07-19T20:48:19.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32ecf99d
[2025-07-19T20:48:19.865+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187] for update
[2025-07-19T20:48:19.866+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/.2.delta.afcf9997-22ca-4a10-9b32-85a5355671c9.TID984.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/2.delta
[2025-07-19T20:48:19.868+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/181/2.delta
[2025-07-19T20:48:19.869+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T20:48:19.870+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T20:48:19.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.2.delta.df2081df-91e8-4983-b1a9-646e24614fa1.TID989.tmp
[2025-07-19T20:48:19.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/.2.delta.077dc137-364d-4df8-8171-20bb79bdbdf3.TID982.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/2.delta
[2025-07-19T20:48:19.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 181.0 in stage 9.0 (TID 984). 5915 bytes result sent to driver
[2025-07-19T20:48:19.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/179/2.delta
[2025-07-19T20:48:19.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 188.0 in stage 9.0 (TID 991) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.880+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T20:48:19.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 181.0 in stage 9.0 (TID 984) in 109 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:48:19.881+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 188.0 in stage 9.0 (TID 991)
[2025-07-19T20:48:19.883+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.2.delta.847aae69-0821-440f-be87-cf0dfeb3be53.TID990.tmp
[2025-07-19T20:48:19.884+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aa3e286
[2025-07-19T20:48:19.886+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T20:48:19.888+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.891+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188] for update
[2025-07-19T20:48:19.897+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 179.0 in stage 9.0 (TID 982). 5872 bytes result sent to driver
[2025-07-19T20:48:19.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 189.0 in stage 9.0 (TID 992) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.898+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 179.0 in stage 9.0 (TID 982) in 123 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 189.0 in stage 9.0 (TID 992)
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@351ccd46
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.899+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189] for update
[2025-07-19T20:48:19.901+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.902+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/.2.delta.dfc6f5e4-d866-45ad-9b1c-e5fab52b3385.TID986.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/2.delta
[2025-07-19T20:48:19.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/183/2.delta
[2025-07-19T20:48:19.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/.2.delta.cadce676-1a92-4036-a7d4-a934c5e5ac1d.TID985.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/2.delta
[2025-07-19T20:48:19.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/182/2.delta
[2025-07-19T20:48:19.903+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T20:48:19.904+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T20:48:19.905+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.2.delta.0834874b-8fbb-45d6-bb3a-fce49ca1b30c.TID991.tmp
[2025-07-19T20:48:19.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T20:48:19.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T20:48:19.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 183.0 in stage 9.0 (TID 986). 5829 bytes result sent to driver
[2025-07-19T20:48:19.908+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 190.0 in stage 9.0 (TID 993) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 182.0 in stage 9.0 (TID 985). 5915 bytes result sent to driver
[2025-07-19T20:48:19.909+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 190.0 in stage 9.0 (TID 993)
[2025-07-19T20:48:19.913+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 191.0 in stage 9.0 (TID 994) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.914+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 191.0 in stage 9.0 (TID 994)
[2025-07-19T20:48:19.915+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 182.0 in stage 9.0 (TID 985) in 129 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:48:19.917+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 183.0 in stage 9.0 (TID 986) in 111 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:48:19.919+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:48:19.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.2.delta.6bb2ff1d-30c0-4bec-a4bb-fddc3f84e1c6.TID992.tmp
[2025-07-19T20:48:19.920+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14c32703
[2025-07-19T20:48:19.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.921+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190] for update
[2025-07-19T20:48:19.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.922+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@342369ad
[2025-07-19T20:48:19.923+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191] for update
[2025-07-19T20:48:19.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.924+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/.2.delta.442cc8ac-af30-4926-9333-2f5594f06e77.TID988.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/2.delta
[2025-07-19T20:48:19.925+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/185/2.delta
[2025-07-19T20:48:19.926+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T20:48:19.928+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T20:48:19.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 185.0 in stage 9.0 (TID 988). 5829 bytes result sent to driver
[2025-07-19T20:48:19.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 192.0 in stage 9.0 (TID 995) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 185.0 in stage 9.0 (TID 988) in 95 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:48:19.929+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 192.0 in stage 9.0 (TID 995)
[2025-07-19T20:48:19.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.933+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/.2.delta.0ddd2a81-3f6c-4d95-9e75-783a9538a03c.TID987.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/2.delta
[2025-07-19T20:48:19.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/184/2.delta
[2025-07-19T20:48:19.934+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.935+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T20:48:19.937+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.2.delta.75e065ea-b3cf-4c5b-be82-7c36ce8eccf5.TID994.tmp
[2025-07-19T20:48:19.939+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bef909d
[2025-07-19T20:48:19.940+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.2.delta.1a433cce-8ea6-4409-98a6-0a635c266fe4.TID993.tmp
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192] for update
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/.2.delta.df2081df-91e8-4983-b1a9-646e24614fa1.TID989.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/2.delta
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/186/2.delta
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T20:48:19.941+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 184.0 in stage 9.0 (TID 987). 5829 bytes result sent to driver
[2025-07-19T20:48:19.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T20:48:19.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 193.0 in stage 9.0 (TID 996) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.942+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 193.0 in stage 9.0 (TID 996)
[2025-07-19T20:48:19.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 184.0 in stage 9.0 (TID 987) in 124 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:48:19.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 186.0 in stage 9.0 (TID 989). 5829 bytes result sent to driver
[2025-07-19T20:48:19.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 186.0 in stage 9.0 (TID 989) in 100 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:48:19.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 194.0 in stage 9.0 (TID 997) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.943+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@549efc9e
[2025-07-19T20:48:19.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193] for update
[2025-07-19T20:48:19.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 194.0 in stage 9.0 (TID 997)
[2025-07-19T20:48:19.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.944+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.945+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.948+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/.2.delta.847aae69-0821-440f-be87-cf0dfeb3be53.TID990.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/2.delta
[2025-07-19T20:48:19.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/187/2.delta
[2025-07-19T20:48:19.949+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T20:48:19.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c6e773d
[2025-07-19T20:48:19.950+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.951+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194] for update
[2025-07-19T20:48:19.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/.2.delta.0834874b-8fbb-45d6-bb3a-fce49ca1b30c.TID991.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/2.delta
[2025-07-19T20:48:19.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/188/2.delta
[2025-07-19T20:48:19.952+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T20:48:19.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T20:48:19.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 187.0 in stage 9.0 (TID 990). 5829 bytes result sent to driver
[2025-07-19T20:48:19.953+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 195.0 in stage 9.0 (TID 998) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.957+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 187.0 in stage 9.0 (TID 990) in 97 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:48:19.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 195.0 in stage 9.0 (TID 998)
[2025-07-19T20:48:19.958+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cb5d7a2
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195] for update
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.2.delta.4d7fdb1f-f3d4-43f0-9cb7-e9167c50434f.TID996.tmp
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 188.0 in stage 9.0 (TID 991). 5829 bytes result sent to driver
[2025-07-19T20:48:19.959+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.2.delta.71384a73-a0ef-422d-9f19-bdb9d89c7323.TID995.tmp
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 196.0 in stage 9.0 (TID 999) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 196.0 in stage 9.0 (TID 999)
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 188.0 in stage 9.0 (TID 991) in 81 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3175c1a2
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.961+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196] for update
[2025-07-19T20:48:19.963+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.964+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.2.delta.219e36da-d651-4438-8f11-d9bca7aac3b3.TID997.tmp
[2025-07-19T20:48:19.968+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/.2.delta.6bb2ff1d-30c0-4bec-a4bb-fddc3f84e1c6.TID992.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/2.delta
[2025-07-19T20:48:19.969+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/189/2.delta
[2025-07-19T20:48:19.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T20:48:19.971+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T20:48:19.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 189.0 in stage 9.0 (TID 992). 5829 bytes result sent to driver
[2025-07-19T20:48:19.972+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 197.0 in stage 9.0 (TID 1000) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.974+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 189.0 in stage 9.0 (TID 992) in 86 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:48:19.976+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 197.0 in stage 9.0 (TID 1000)
[2025-07-19T20:48:19.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.2.delta.064c90be-a2a0-42a7-8b4d-3e5421a6ef30.TID998.tmp
[2025-07-19T20:48:19.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.977+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2903132a
[2025-07-19T20:48:19.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:19.978+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197] for update
[2025-07-19T20:48:19.980+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:19.982+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/.2.delta.1a433cce-8ea6-4409-98a6-0a635c266fe4.TID993.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/2.delta
[2025-07-19T20:48:19.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/190/2.delta
[2025-07-19T20:48:19.983+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T20:48:19.984+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.2.delta.9400be6f-2a0e-4fc9-8894-b2c4f9e1978c.TID999.tmp
[2025-07-19T20:48:19.986+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T20:48:19.987+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 190.0 in stage 9.0 (TID 993). 5829 bytes result sent to driver
[2025-07-19T20:48:19.990+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Starting task 198.0 in stage 9.0 (TID 1001) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:19.992+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO TaskSetManager: Finished task 190.0 in stage 9.0 (TID 993) in 76 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:48:19.994+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Running task 198.0 in stage 9.0 (TID 1001)
[2025-07-19T20:48:19.995+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:19.997+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:19.998+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15c9e001
[2025-07-19T20:48:19.999+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/.2.delta.75e065ea-b3cf-4c5b-be82-7c36ce8eccf5.TID994.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/2.delta
[2025-07-19T20:48:20.000+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/191/2.delta
[2025-07-19T20:48:20.001+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T20:48:20.002+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:20.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.2.delta.9e942d62-6c86-4047-b788-889ce2340b63.TID1000.tmp
[2025-07-19T20:48:20.003+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198] for update
[2025-07-19T20:48:20.004+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:20.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO DataWritingSparkTask: Committed partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T20:48:20.005+0000] {subprocess.py:93} INFO - 25/07/19 20:48:19 INFO Executor: Finished task 191.0 in stage 9.0 (TID 994). 5829 bytes result sent to driver
[2025-07-19T20:48:20.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Starting task 199.0 in stage 9.0 (TID 1002) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:48:20.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Running task 199.0 in stage 9.0 (TID 1002)
[2025-07-19T20:48:20.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/.2.delta.71384a73-a0ef-422d-9f19-bdb9d89c7323.TID995.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/2.delta
[2025-07-19T20:48:20.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/192/2.delta
[2025-07-19T20:48:20.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 191.0 in stage 9.0 (TID 994) in 93 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:48:20.006+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T20:48:20.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T20:48:20.009+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 192.0 in stage 9.0 (TID 995). 5829 bytes result sent to driver
[2025-07-19T20:48:20.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:48:20.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:48:20.010+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 192.0 in stage 9.0 (TID 995) in 81 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:48:20.011+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aaf002e
[2025-07-19T20:48:20.012+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],3851e258-c04f-469c-9e1b-1d5426ca45a3) is active
[2025-07-19T20:48:20.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199] for update
[2025-07-19T20:48:20.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.2.delta.320a5404-b73b-4bcb-a270-2eac1c645a5b.TID1001.tmp
[2025-07-19T20:48:20.013+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:48:20.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/.2.delta.4d7fdb1f-f3d4-43f0-9cb7-e9167c50434f.TID996.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/2.delta
[2025-07-19T20:48:20.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/193/2.delta
[2025-07-19T20:48:20.015+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T20:48:20.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T20:48:20.020+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 193.0 in stage 9.0 (TID 996). 5829 bytes result sent to driver
[2025-07-19T20:48:20.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 193.0 in stage 9.0 (TID 996) in 82 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:48:20.021+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.2.delta.edc2fe1e-834b-4d18-9c6c-f2b91e9b8d52.TID1002.tmp
[2025-07-19T20:48:20.023+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/.2.delta.219e36da-d651-4438-8f11-d9bca7aac3b3.TID997.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/2.delta
[2025-07-19T20:48:20.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/194/2.delta
[2025-07-19T20:48:20.024+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T20:48:20.026+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/.2.delta.9400be6f-2a0e-4fc9-8894-b2c4f9e1978c.TID999.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/2.delta
[2025-07-19T20:48:20.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/196/2.delta
[2025-07-19T20:48:20.027+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T20:48:20.029+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/.2.delta.064c90be-a2a0-42a7-8b4d-3e5421a6ef30.TID998.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/2.delta
[2025-07-19T20:48:20.030+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/195/2.delta
[2025-07-19T20:48:20.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T20:48:20.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T20:48:20.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T20:48:20.031+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 194.0 in stage 9.0 (TID 997). 5829 bytes result sent to driver
[2025-07-19T20:48:20.032+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 196.0 in stage 9.0 (TID 999). 5829 bytes result sent to driver
[2025-07-19T20:48:20.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 194.0 in stage 9.0 (TID 997) in 91 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:48:20.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 196.0 in stage 9.0 (TID 999) in 76 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:48:20.033+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T20:48:20.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 195.0 in stage 9.0 (TID 998). 5829 bytes result sent to driver
[2025-07-19T20:48:20.034+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/.2.delta.9e942d62-6c86-4047-b788-889ce2340b63.TID1000.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/2.delta
[2025-07-19T20:48:20.036+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/197/2.delta
[2025-07-19T20:48:20.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T20:48:20.037+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 195.0 in stage 9.0 (TID 998) in 85 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:48:20.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T20:48:20.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 197.0 in stage 9.0 (TID 1000). 5829 bytes result sent to driver
[2025-07-19T20:48:20.039+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 197.0 in stage 9.0 (TID 1000) in 66 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:48:20.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/.2.delta.320a5404-b73b-4bcb-a270-2eac1c645a5b.TID1001.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/2.delta
[2025-07-19T20:48:20.044+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/198/2.delta
[2025-07-19T20:48:20.045+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T20:48:20.046+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T20:48:20.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/.2.delta.edc2fe1e-834b-4d18-9c6c-f2b91e9b8d52.TID1002.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/2.delta
[2025-07-19T20:48:20.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/state/0/199/2.delta
[2025-07-19T20:48:20.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 198.0 in stage 9.0 (TID 1001). 5829 bytes result sent to driver
[2025-07-19T20:48:20.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T20:48:20.047+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 198.0 in stage 9.0 (TID 1001) in 63 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:48:20.050+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DataWritingSparkTask: Committed partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T20:48:20.051+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO Executor: Finished task 199.0 in stage 9.0 (TID 1002). 5829 bytes result sent to driver
[2025-07-19T20:48:20.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSetManager: Finished task 199.0 in stage 9.0 (TID 1002) in 50 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:48:20.053+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-19T20:48:20.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DAGScheduler: ResultStage 9 (start at <unknown>:0) finished in 5.874 s
[2025-07-19T20:48:20.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:48:20.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-19T20:48:20.054+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO DAGScheduler: Job 4 finished: start at <unknown>:0, took 5.928715 s
[2025-07-19T20:48:20.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T20:48:20.055+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO SparkWrite: Committing epoch 1 for query 302fc0f2-ecb3-4b30-9b45-e72bb5225779 in append mode
[2025-07-19T20:48:20.059+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T20:48:20.123+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v121.metadata.json
[2025-07-19T20:48:20.149+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO SnapshotProducer: Committed snapshot 1262439620896038629 (FastAppend)
[2025-07-19T20:48:20.182+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=1262439620896038629, sequenceNumber=120, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.114639917S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5710}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=8010}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=18487824}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752958074309, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:48:20.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO SparkWrite: Committed in 115 ms
[2025-07-19T20:48:20.183+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T20:48:20.190+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/.1.386f7cde-a949-4d82-9e13-b013861d3033.tmp
[2025-07-19T20:48:20.215+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/.1.386f7cde-a949-4d82-9e13-b013861d3033.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:44:00+00:00/commits/1
[2025-07-19T20:48:20.217+0000] {subprocess.py:93} INFO - 25/07/19 20:48:20 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:48:20.218+0000] {subprocess.py:93} INFO -   "id" : "302fc0f2-ecb3-4b30-9b45-e72bb5225779",
[2025-07-19T20:48:20.218+0000] {subprocess.py:93} INFO -   "runId" : "3851e258-c04f-469c-9e1b-1d5426ca45a3",
[2025-07-19T20:48:20.218+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:48:20.219+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:48:13.754Z",
[2025-07-19T20:48:20.219+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T20:48:20.219+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T20:48:20.219+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:20.219+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T20:48:20.219+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "addBatch" : 6251,
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "commitOffsets" : 39,
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "latestOffset" : 12,
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "queryPlanning" : 84,
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "triggerExecution" : 6459,
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "walCommit" : 71
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T20:39:00.000Z"
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:48:20.220+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 222,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 288,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 167,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 22349,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 145704,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:48:20.221+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 67080
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:48:20.222+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -         "0" : 222
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:48:20.223+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:48:20.224+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:48:26.620+0000] {subprocess.py:93} INFO - 25/07/19 20:48:26 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:27.593+0000] {subprocess.py:93} INFO - 25/07/19 20:48:27 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:30.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:36.630+0000] {subprocess.py:93} INFO - 25/07/19 20:48:36 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:37.594+0000] {subprocess.py:93} INFO - 25/07/19 20:48:37 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:40.226+0000] {subprocess.py:93} INFO - 25/07/19 20:48:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:46.631+0000] {subprocess.py:93} INFO - 25/07/19 20:48:46 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:47.606+0000] {subprocess.py:93} INFO - 25/07/19 20:48:47 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:50.240+0000] {subprocess.py:93} INFO - 25/07/19 20:48:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:56.648+0000] {subprocess.py:93} INFO - 25/07/19 20:48:56 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:48:57.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T20:48:57.110+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1, groupId=spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T20:48:57.119+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Metrics scheduler closed
[2025-07-19T20:48:57.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T20:48:57.120+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Metrics reporters closed
[2025-07-19T20:48:57.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-b1bc7e92-d8ef-4600-963b-367ebd1d26e4--2105915623-executor-1 unregistered
[2025-07-19T20:48:57.124+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T20:48:57.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2, groupId=spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T20:48:57.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Metrics scheduler closed
[2025-07-19T20:48:57.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T20:48:57.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Metrics reporters closed
[2025-07-19T20:48:57.125+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-8226b01e-1909-48cb-9595-2f0d28f11368--580447592-executor-2 unregistered
[2025-07-19T20:48:57.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T20:48:57.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3, groupId=spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T20:48:57.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Metrics scheduler closed
[2025-07-19T20:48:57.126+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T20:48:57.127+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO Metrics: Metrics reporters closed
[2025-07-19T20:48:57.128+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-25b77587-c837-494e-90a9-072196f2dfef--1127945545-executor-3 unregistered
[2025-07-19T20:48:57.129+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO SparkContext: Invoking stop() from shutdown hook
[2025-07-19T20:48:57.130+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-19T20:48:57.147+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO SparkUI: Stopped Spark web UI at http://8b44f3d35cfa:4041
[2025-07-19T20:48:57.164+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-19T20:48:57.225+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO MemoryStore: MemoryStore cleared
[2025-07-19T20:48:57.227+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO BlockManager: BlockManager stopped
[2025-07-19T20:48:57.234+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-19T20:48:57.247+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-19T20:48:57.313+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO SparkContext: Successfully stopped SparkContext
[2025-07-19T20:48:57.314+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ShutdownHookManager: Shutdown hook called
[2025-07-19T20:48:57.325+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-e5f2498a-2a48-43af-85ca-eea8e65d4c7a
[2025-07-19T20:48:57.354+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-e2fd4fa4-49d8-4336-9c0f-6975630b5c48
[2025-07-19T20:48:57.366+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-e2fd4fa4-49d8-4336-9c0f-6975630b5c48/pyspark-ec18e968-7ac7-4f76-9ac4-025008e04738
[2025-07-19T20:48:57.423+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-07-19T20:48:57.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-07-19T20:48:57.424+0000] {subprocess.py:93} INFO - 25/07/19 20:48:57 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-07-19T20:48:57.902+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-19T20:48:57.954+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=restaurant_pipeline, task_id=stream_to_bronze, execution_date=20250719T204400, start_date=20250719T204752, end_date=20250719T204857
[2025-07-19T20:48:57.969+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-19T20:48:58.005+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
