[2025-07-19T20:30:44.199+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T20:28:00+00:00 [queued]>
[2025-07-19T20:30:44.203+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T20:28:00+00:00 [queued]>
[2025-07-19T20:30:44.203+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-19T20:30:44.212+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): stream_to_bronze> on 2025-07-19 20:28:00+00:00
[2025-07-19T20:30:44.214+0000] {standard_task_runner.py:57} INFO - Started process 3491 to run task
[2025-07-19T20:30:44.216+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restaurant_pipeline', 'stream_to_bronze', 'scheduled__2025-07-19T20:28:00+00:00', '--job-id', '1191', '--raw', '--subdir', 'DAGS_FOLDER/restaurant_pipeline.py', '--cfg-path', '/tmp/tmpla10ltdi']
[2025-07-19T20:30:44.218+0000] {standard_task_runner.py:85} INFO - Job 1191: Subtask stream_to_bronze
[2025-07-19T20:30:44.245+0000] {task_command.py:416} INFO - Running <TaskInstance: restaurant_pipeline.stream_to_bronze scheduled__2025-07-19T20:28:00+00:00 [running]> on host e3f5d8fc4eef
[2025-07-19T20:30:44.283+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='moran' AIRFLOW_CTX_DAG_ID='restaurant_pipeline' AIRFLOW_CTX_TASK_ID='stream_to_bronze' AIRFLOW_CTX_EXECUTION_DATE='2025-07-19T20:28:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T20:28:00+00:00'
[2025-07-19T20:30:44.284+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-07-19T20:30:44.284+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', "docker exec -e AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-19T20:28:00+00:00' spark-iceberg spark-submit /home/iceberg/spark/stream_to_bronze.py"]
[2025-07-19T20:30:44.290+0000] {subprocess.py:86} INFO - Output:
[2025-07-19T20:30:46.011+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkContext: Running Spark version 3.5.6
[2025-07-19T20:30:46.012+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T20:30:46.013+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkContext: Java version 17.0.15
[2025-07-19T20:30:46.028+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO ResourceUtils: ==============================================================
[2025-07-19T20:30:46.029+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-07-19T20:30:46.029+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO ResourceUtils: ==============================================================
[2025-07-19T20:30:46.029+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkContext: Submitted application: StreamToBronze
[2025-07-19T20:30:46.039+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-07-19T20:30:46.044+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO ResourceProfile: Limiting resource is cpu
[2025-07-19T20:30:46.045+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-07-19T20:30:46.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SecurityManager: Changing view acls to: root,spark
[2025-07-19T20:30:46.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SecurityManager: Changing modify acls to: root,spark
[2025-07-19T20:30:46.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SecurityManager: Changing view acls groups to:
[2025-07-19T20:30:46.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SecurityManager: Changing modify acls groups to:
[2025-07-19T20:30:46.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
[2025-07-19T20:30:46.111+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-07-19T20:30:46.294+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Utils: Successfully started service 'sparkDriver' on port 40467.
[2025-07-19T20:30:46.322+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkEnv: Registering MapOutputTracker
[2025-07-19T20:30:46.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkEnv: Registering BlockManagerMaster
[2025-07-19T20:30:46.357+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-07-19T20:30:46.357+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-07-19T20:30:46.359+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-07-19T20:30:46.372+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8f30b1bd-ba9a-4b98-b7ca-0caf3db72705
[2025-07-19T20:30:46.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-07-19T20:30:46.389+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-07-19T20:30:46.462+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-07-19T20:30:46.505+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2025-07-19T20:30:46.511+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2025-07-19T20:30:46.574+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Executor: Starting executor ID driver on host 8b44f3d35cfa
[2025-07-19T20:30:46.574+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Executor: OS info Linux, 6.10.14-linuxkit, aarch64
[2025-07-19T20:30:46.574+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Executor: Java version 17.0.15
[2025-07-19T20:30:46.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-07-19T20:30:46.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@364420c1 for default.
[2025-07-19T20:30:46.590+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36593.
[2025-07-19T20:30:46.590+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO NettyBlockTransferService: Server created on 8b44f3d35cfa:36593
[2025-07-19T20:30:46.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-07-19T20:30:46.603+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8b44f3d35cfa, 36593, None)
[2025-07-19T20:30:46.606+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManagerMasterEndpoint: Registering block manager 8b44f3d35cfa:36593 with 434.4 MiB RAM, BlockManagerId(driver, 8b44f3d35cfa, 36593, None)
[2025-07-19T20:30:46.608+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8b44f3d35cfa, 36593, None)
[2025-07-19T20:30:46.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8b44f3d35cfa, 36593, None)
[2025-07-19T20:30:46.923+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-07-19T20:30:46.928+0000] {subprocess.py:93} INFO - 25/07/19 20:30:46 INFO SharedState: Warehouse path is 'file:/app/spark-warehouse'.
[2025-07-19T20:30:48.129+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-07-19T20:30:48.137+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-07-19T20:30:48.137+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-07-19T20:30:48.846+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:48.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-07-19T20:30:48.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00 resolved to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00.
[2025-07-19T20:30:48.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T20:30:48.934+0000] {subprocess.py:93} INFO - 25/07/19 20:30:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/metadata using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/.metadata.437cc62c-8986-41ca-811f-37331cfc3c75.tmp
[2025-07-19T20:30:49.016+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/.metadata.437cc62c-8986-41ca-811f-37331cfc3c75.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/metadata
[2025-07-19T20:30:49.047+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Starting [id = 3de98e67-50a3-4b36-b6f0-c27ff416e371, runId = 1022e83e-36d1-4afb-8314-3ff56fa50ef9]. Use file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00 to store the query checkpoint.
[2025-07-19T20:30:49.059+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5d548289] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@5c4059f3]
[2025-07-19T20:30:49.085+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:30:49.086+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:30:49.086+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T20:30:49.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T20:30:49.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:49.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00 resolved to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00.
[2025-07-19T20:30:49.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T20:30:49.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/metadata using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/.metadata.ef30eb97-3089-439e-903e-80a15b27b927.tmp
[2025-07-19T20:30:49.236+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/.metadata.ef30eb97-3089-439e-903e-80a15b27b927.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/metadata
[2025-07-19T20:30:49.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Starting [id = 1436cd49-bf2f-4720-8c9f-d251355ec5cf, runId = 0211514f-45c6-4006-a76e-be2d80eeafa5]. Use file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00 to store the query checkpoint.
[2025-07-19T20:30:49.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@6946f964] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@67811be4]
[2025-07-19T20:30:49.254+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:30:49.256+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:30:49.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T20:30:49.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T20:30:49.333+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T20:30:49.334+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:30:49.334+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:30:49.334+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:30:49.334+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T20:30:49.334+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T20:30:49.335+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:30:49.335+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:30:49.335+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:30:49.336+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:30:49.336+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:30:49.337+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:30:49.337+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:30:49.338+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:30:49.339+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:30:49.340+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:30:49.340+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T20:30:49.341+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:30:49.341+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:30:49.342+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:30:49.342+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:30:49.342+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:30:49.343+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:30:49.343+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:30:49.343+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:30:49.347+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:30:49.347+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:30:49.347+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:30:49.348+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:30:49.348+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:30:49.348+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:30:49.348+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:30:49.348+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:30:49.349+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:30:49.349+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:30:49.349+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:30:49.349+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:30:49.349+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:30:49.349+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:30:49.350+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:30:49.350+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:30:49.350+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:30:49.351+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:30:49.351+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:30:49.351+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:30:49.352+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:30:49.352+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:30:49.352+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:30:49.352+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:30:49.352+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:30:49.353+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:30:49.355+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:30:49.359+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:30:49.363+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:30:49.364+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:30:49.364+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:30:49.364+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:30:49.364+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:30:49.365+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:30:49.365+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:30:49.365+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:30:49.365+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:30:49.365+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:30:49.366+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:30:49.366+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:30:49.366+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:30:49.366+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:30:49.366+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:30:49.367+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:30:49.367+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:30:49.368+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:30:49.369+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T20:30:49.369+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:30:49.369+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:30:49.369+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:30:49.369+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T20:30:49.370+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T20:30:49.370+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:30:49.370+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:30:49.370+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:30:49.370+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:30:49.370+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:30:49.371+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:30:49.372+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:30:49.373+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:30:49.374+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:30:49.374+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:30:49.374+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:30:49.374+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:30:49.374+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:30:49.374+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:30:49.375+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:30:49.376+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:30:49.376+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:30:49.376+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:30:49.376+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:30:49.377+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:30:49.378+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:30:49.379+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:30:49.379+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:30:49.379+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:30:49.379+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:30:49.379+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:30:49.379+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:30:49.380+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:30:49.381+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:30:49.384+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:30:49.384+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:30:49.384+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:30:49.385+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO BaseMetastoreCatalog: Table loaded by catalog: my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:49.385+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00 resolved to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00.
[2025-07-19T20:30:49.386+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-07-19T20:30:49.402+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/metadata using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/.metadata.b5c32e08-0024-4559-a0e3-466de7ac1c3c.tmp
[2025-07-19T20:30:49.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T20:30:49.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T20:30:49.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:30:49.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:30:49.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka startTimeMs: 1752957049427
[2025-07-19T20:30:49.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:30:49.431+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:30:49.431+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka startTimeMs: 1752957049427
[2025-07-19T20:30:49.452+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/.metadata.b5c32e08-0024-4559-a0e3-466de7ac1c3c.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/metadata
[2025-07-19T20:30:49.464+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Starting [id = 60d03bb1-c474-4483-93df-474e93ff0d37, runId = 949692c4-67e9-4193-b7c5-0e7f8bd5bdfd]. Use file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00 to store the query checkpoint.
[2025-07-19T20:30:49.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@11d88156] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@1f1f6cc5]
[2025-07-19T20:30:49.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:30:49.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO OffsetSeqLog: BatchIds found from listing:
[2025-07-19T20:30:49.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Starting new streaming query.
[2025-07-19T20:30:49.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Stream started from {}
[2025-07-19T20:30:49.477+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AdminClientConfig: AdminClientConfig values:
[2025-07-19T20:30:49.478+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:30:49.478+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:30:49.479+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:30:49.479+0000] {subprocess.py:93} INFO - 	client.id =
[2025-07-19T20:30:49.479+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:30:49.480+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:30:49.481+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:30:49.482+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:30:49.483+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:30:49.484+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:30:49.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO AppInfoParser: Kafka startTimeMs: 1752957049478
[2025-07-19T20:30:49.626+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/sources/0/.0.5e3d36e7-a230-40d4-993f-34d4f5bf0c91.tmp
[2025-07-19T20:30:49.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/sources/0/.0.57206526-cd6a-4017-a0f5-0d81ecb8856e.tmp
[2025-07-19T20:30:49.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/sources/0/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/sources/0/.0.1873baaa-f5b3-4ad7-b096-ca85761b5d99.tmp
[2025-07-19T20:30:49.682+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/sources/0/.0.5e3d36e7-a230-40d4-993f-34d4f5bf0c91.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/sources/0/0
[2025-07-19T20:30:49.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO KafkaMicroBatchStream: Initial offsets: {"feedback":{"0":0}}
[2025-07-19T20:30:49.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/sources/0/.0.1873baaa-f5b3-4ad7-b096-ca85761b5d99.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/sources/0/0
[2025-07-19T20:30:49.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO KafkaMicroBatchStream: Initial offsets: {"checkins":{"0":0}}
[2025-07-19T20:30:49.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/sources/0/.0.57206526-cd6a-4017-a0f5-0d81ecb8856e.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/sources/0/0
[2025-07-19T20:30:49.684+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO KafkaMicroBatchStream: Initial offsets: {"reservations":{"0":0}}
[2025-07-19T20:30:49.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/offsets/.0.95934191-a31d-43eb-afb4-87180b5db326.tmp
[2025-07-19T20:30:49.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/.0.53b2e46d-f6f5-42ce-8974-8c4a6d2b454e.tmp
[2025-07-19T20:30:49.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/.0.0ba11a9a-5257-4afe-8ad6-4c2b939660ad.tmp
[2025-07-19T20:30:49.747+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/.0.53b2e46d-f6f5-42ce-8974-8c4a6d2b454e.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/0
[2025-07-19T20:30:49.747+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/.0.0ba11a9a-5257-4afe-8ad6-4c2b939660ad.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/0
[2025-07-19T20:30:49.747+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/offsets/.0.95934191-a31d-43eb-afb4-87180b5db326.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/offsets/0
[2025-07-19T20:30:49.748+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752957049689,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:30:49.748+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752957049689,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:30:49.749+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1752957049689,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:30:49.939+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:49.939+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:49.939+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:49.939+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:49.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:49.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:49.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:49.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:49.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:49 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.226+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO CodeGenerator: Code generated in 170.392833 ms
[2025-07-19T20:30:50.246+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.247+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.247+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.294+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.358+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.358+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.359+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.359+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:50.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:50.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:50.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:50.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:50.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:50.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.363+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.366+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.368+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.409+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:50.410+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:50.410+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Reservations_raw
[2025-07-19T20:30:50.413+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.416+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.416+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:30:50.418+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:50.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:50.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:50.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-07-19T20:30:50.579+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO CodeGenerator: Code generated in 63.468875 ms
[2025-07-19T20:30:50.579+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO CodeGenerator: Code generated in 66.572666 ms
[2025-07-19T20:30:50.626+0000] {subprocess.py:93} INFO - 25/07/19 20:30:50 INFO CodeGenerator: Code generated in 43.139209 ms
[2025-07-19T20:30:51.029+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 209.0 KiB, free 434.0 MiB)
[2025-07-19T20:30:51.031+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T20:30:51.031+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 209.0 KiB, free 433.8 MiB)
[2025-07-19T20:30:51.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T20:30:51.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T20:30:51.111+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.7 MiB)
[2025-07-19T20:30:51.112+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8b44f3d35cfa:36593 (size: 35.4 KiB, free: 434.4 MiB)
[2025-07-19T20:30:51.115+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8b44f3d35cfa:36593 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:30:51.115+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 0 from start at <unknown>:0
[2025-07-19T20:30:51.115+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 2 from start at <unknown>:0
[2025-07-19T20:30:51.129+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8b44f3d35cfa:36593 (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:30:51.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 1 from start at <unknown>:0
[2025-07-19T20:30:51.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 433.7 MiB)
[2025-07-19T20:30:51.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T20:30:51.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-07-19T20:30:51.188+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.6 MiB)
[2025-07-19T20:30:51.189+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8b44f3d35cfa:36593 (size: 29.5 KiB, free: 434.3 MiB)
[2025-07-19T20:30:51.190+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T20:30:51.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.5 MiB)
[2025-07-19T20:30:51.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 3 from start at <unknown>:0
[2025-07-19T20:30:51.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8b44f3d35cfa:36593 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T20:30:51.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 8b44f3d35cfa:36593 (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T20:30:51.195+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 4 from start at <unknown>:0
[2025-07-19T20:30:51.196+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 5 from start at <unknown>:0
[2025-07-19T20:30:51.197+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:30:51.197+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:30:51.200+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:30:51.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:30:51.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:30:51.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:30:51.220+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Registering RDD 16 (start at <unknown>:0) as input to shuffle 0
[2025-07-19T20:30:51.222+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:30:51.225+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-07-19T20:30:51.227+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
[2025-07-19T20:30:51.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
[2025-07-19T20:30:51.234+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[16] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:30:51.260+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 32.3 KiB, free 433.5 MiB)
[2025-07-19T20:30:51.309+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 433.5 MiB)
[2025-07-19T20:30:51.320+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 8b44f3d35cfa:36593 (size: 14.1 KiB, free: 434.2 MiB)
[2025-07-19T20:30:51.331+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:30:51.372+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[16] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T20:30:51.403+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-07-19T20:30:51.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Registering RDD 17 (start at <unknown>:0) as input to shuffle 2
[2025-07-19T20:30:51.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:30:51.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Final stage: ResultStage 3 (start at <unknown>:0)
[2025-07-19T20:30:51.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-07-19T20:30:51.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
[2025-07-19T20:30:51.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:30:51.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 35.8 KiB, free 433.4 MiB)
[2025-07-19T20:30:51.436+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.4 MiB)
[2025-07-19T20:30:51.437+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 8b44f3d35cfa:36593 (size: 15.8 KiB, free: 434.2 MiB)
[2025-07-19T20:30:51.439+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:30:51.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T20:30:51.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-07-19T20:30:51.461+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9923 bytes)
[2025-07-19T20:30:51.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Registering RDD 15 (start at <unknown>:0) as input to shuffle 1
[2025-07-19T20:30:51.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Got job 2 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:30:51.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Final stage: ResultStage 5 (start at <unknown>:0)
[2025-07-19T20:30:51.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-07-19T20:30:51.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
[2025-07-19T20:30:51.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 1) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9924 bytes)
[2025-07-19T20:30:51.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:30:51.483+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 33.8 KiB, free 433.4 MiB)
[2025-07-19T20:30:51.486+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 433.4 MiB)
[2025-07-19T20:30:51.486+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 8b44f3d35cfa:36593 (size: 14.7 KiB, free: 434.2 MiB)
[2025-07-19T20:30:51.488+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:30:51.489+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[15] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-07-19T20:30:51.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-07-19T20:30:51.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 2) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 9928 bytes)
[2025-07-19T20:30:51.492+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 1)
[2025-07-19T20:30:51.494+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO Executor: Running task 0.0 in stage 4.0 (TID 2)
[2025-07-19T20:30:51.494+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-07-19T20:30:51.676+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 19.513375 ms
[2025-07-19T20:30:51.676+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 21.705292 ms
[2025-07-19T20:30:51.677+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 25.164042 ms
[2025-07-19T20:30:51.693+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 20.676167 ms
[2025-07-19T20:30:51.693+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 17.195458 ms
[2025-07-19T20:30:51.694+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 23.639083 ms
[2025-07-19T20:30:51.713+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 11.471041 ms
[2025-07-19T20:30:51.715+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 11.244375 ms
[2025-07-19T20:30:51.742+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 21.525333 ms
[2025-07-19T20:30:51.742+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 25.714208 ms
[2025-07-19T20:30:51.749+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=checkins-0 fromOffset=0 untilOffset=207, for query queryId=1436cd49-bf2f-4720-8c9f-d251355ec5cf batchId=0 taskId=1 partitionId=0
[2025-07-19T20:30:51.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=feedback-0 fromOffset=0 untilOffset=207, for query queryId=60d03bb1-c474-4483-93df-474e93ff0d37 batchId=0 taskId=0 partitionId=0
[2025-07-19T20:30:51.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=reservations-0 fromOffset=0 untilOffset=207, for query queryId=3de98e67-50a3-4b36-b6f0-c27ff416e371 batchId=0 taskId=2 partitionId=0
[2025-07-19T20:30:51.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 13.989209 ms
[2025-07-19T20:30:51.817+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO CodeGenerator: Code generated in 18.572583 ms
[2025-07-19T20:30:51.847+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T20:30:51.848+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T20:30:51.848+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T20:30:51.849+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:30:51.849+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T20:30:51.850+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:30:51.850+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T20:30:51.850+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:30:51.850+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3
[2025-07-19T20:30:51.850+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T20:30:51.851+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T20:30:51.851+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:30:51.851+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T20:30:51.852+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T20:30:51.852+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T20:30:51.853+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T20:30:51.854+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T20:30:51.854+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor
[2025-07-19T20:30:51.854+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T20:30:51.855+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T20:30:51.855+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T20:30:51.856+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T20:30:51.856+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T20:30:51.857+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T20:30:51.857+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:30:51.858+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T20:30:51.858+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T20:30:51.859+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T20:30:51.859+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:30:51.859+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:30:51.860+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:30:51.860+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:30:51.861+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:30:51.861+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T20:30:51.861+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:30:51.862+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:30:51.863+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:30:51.863+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:30:51.864+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:30:51.864+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:30:51.864+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:30:51.865+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:30:51.865+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:30:51.866+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:30:51.866+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:30:51.866+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:30:51.867+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:30:51.867+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:30:51.868+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:30:51.868+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:30:51.869+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:30:51.870+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:30:51.872+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:30:51.873+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:30:51.873+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:30:51.873+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:30:51.874+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:30:51.874+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:30:51.874+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:30:51.874+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:30:51.875+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:30:51.875+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:30:51.876+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:30:51.876+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:30:51.876+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:30:51.877+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:30:51.877+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:30:51.877+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:30:51.878+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:30:51.878+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:30:51.878+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T20:30:51.879+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:30:51.879+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:30:51.879+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:30:51.879+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:30:51.880+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:30:51.880+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:30:51.880+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:30:51.880+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:30:51.881+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:30:51.881+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:30:51.882+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:30:51.883+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:30:51.883+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:30:51.883+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:30:51.884+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:30:51.884+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:30:51.884+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:30:51.884+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:30:51.885+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:30:51.885+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:30:51.885+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:30:51.886+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:30:51.886+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:30:51.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T20:30:51.887+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T20:30:51.888+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T20:30:51.888+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:30:51.888+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T20:30:51.888+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:30:51.888+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T20:30:51.888+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T20:30:51.889+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T20:30:51.890+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:30:51.891+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:30:51.892+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T20:30:51.892+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:30:51.892+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:30:51.892+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:30:51.893+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:30:51.894+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:30:51.894+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:30:51.894+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:30:51.894+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:30:51.895+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:30:51.895+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:30:51.896+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:30:51.896+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:30:51.896+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:30:51.897+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:30:51.897+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:30:51.897+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:30:51.897+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:30:51.898+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:30:51.898+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:30:51.898+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:30:51.898+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:30:51.898+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:30:51.898+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:30:51.899+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:30:51.899+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:30:51.899+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:30:51.899+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:30:51.900+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:30:51.901+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:30:51.902+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:30:51.902+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:30:51.902+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:30:51.903+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:30:51.903+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:30:51.903+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-07-19T20:30:51.903+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-07-19T20:30:51.903+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-07-19T20:30:51.904+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-07-19T20:30:51.904+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-07-19T20:30:51.904+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-07-19T20:30:51.904+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-07-19T20:30:51.905+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-07-19T20:30:51.906+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2
[2025-07-19T20:30:51.906+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-07-19T20:30:51.906+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-07-19T20:30:51.907+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-07-19T20:30:51.907+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-07-19T20:30:51.908+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-07-19T20:30:51.908+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-07-19T20:30:51.909+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-07-19T20:30:51.909+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-07-19T20:30:51.910+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor
[2025-07-19T20:30:51.910+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-07-19T20:30:51.910+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-07-19T20:30:51.911+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-07-19T20:30:51.911+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-07-19T20:30:51.911+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-07-19T20:30:51.911+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-07-19T20:30:51.911+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:30:51.912+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-07-19T20:30:51.912+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-07-19T20:30:51.912+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-07-19T20:30:51.913+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-07-19T20:30:51.913+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-07-19T20:30:51.914+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-07-19T20:30:51.915+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-07-19T20:30:51.915+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-07-19T20:30:51.916+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-07-19T20:30:51.916+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-07-19T20:30:51.917+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-07-19T20:30:51.917+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-07-19T20:30:51.917+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-07-19T20:30:51.917+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-07-19T20:30:51.917+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-07-19T20:30:51.918+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-07-19T20:30:51.918+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-07-19T20:30:51.918+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-07-19T20:30:51.918+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-07-19T20:30:51.918+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-07-19T20:30:51.919+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-07-19T20:30:51.919+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-07-19T20:30:51.919+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-07-19T20:30:51.920+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-07-19T20:30:51.920+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-07-19T20:30:51.920+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-07-19T20:30:51.920+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-07-19T20:30:51.921+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-07-19T20:30:51.921+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-07-19T20:30:51.921+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-07-19T20:30:51.921+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-07-19T20:30:51.921+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-07-19T20:30:51.922+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-07-19T20:30:51.922+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-07-19T20:30:51.922+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-07-19T20:30:51.923+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-07-19T20:30:51.923+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-07-19T20:30:51.925+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-07-19T20:30:51.927+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-07-19T20:30:51.928+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-07-19T20:30:51.928+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-07-19T20:30:51.929+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-07-19T20:30:51.930+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-07-19T20:30:51.931+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-07-19T20:30:51.932+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-07-19T20:30:51.933+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-07-19T20:30:51.934+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-07-19T20:30:51.934+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-07-19T20:30:51.935+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-07-19T20:30:51.935+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-07-19T20:30:51.935+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-07-19T20:30:51.936+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-07-19T20:30:51.936+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-07-19T20:30:51.937+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-07-19T20:30:51.937+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-07-19T20:30:51.937+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-07-19T20:30:51.937+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-07-19T20:30:51.938+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-07-19T20:30:51.938+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-07-19T20:30:51.938+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-07-19T20:30:51.938+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-07-19T20:30:51.939+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-07-19T20:30:51.939+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-07-19T20:30:51.940+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-07-19T20:30:51.940+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-07-19T20:30:51.940+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-07-19T20:30:51.941+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-07-19T20:30:51.941+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-07-19T20:30:51.941+0000] {subprocess.py:93} INFO - 
[2025-07-19T20:30:51.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:30:51.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka startTimeMs: 1752957051894
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka startTimeMs: 1752957051895
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka version: 3.5.1
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka commitId: 2c6fb6c54472e90a
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO AppInfoParser: Kafka startTimeMs: 1752957051895
[2025-07-19T20:30:51.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Assigned to partition(s): reservations-0
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Assigned to partition(s): feedback-0
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Assigned to partition(s): checkins-0
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Seeking to offset 0 for partition checkins-0
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Seeking to offset 0 for partition reservations-0
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Seeking to offset 0 for partition feedback-0
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T20:30:51.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T20:30:51.944+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Cluster ID: iIlr_WxeQ6OmNSr-bYGtHA
[2025-07-19T20:30:51.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Seeking to earliest offset of partition feedback-0
[2025-07-19T20:30:51.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Seeking to earliest offset of partition reservations-0
[2025-07-19T20:30:51.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Seeking to earliest offset of partition checkins-0
[2025-07-19T20:30:52.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:30:52.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:30:52.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:30:52.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Seeking to latest offset of partition checkins-0
[2025-07-19T20:30:52.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Seeking to latest offset of partition reservations-0
[2025-07-19T20:30:52.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Seeking to latest offset of partition feedback-0
[2025-07-19T20:30:52.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Resetting offset for partition checkins-0 to position FetchPosition{offset=207, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:30:52.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Resetting offset for partition feedback-0 to position FetchPosition{offset=207, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:30:52.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Resetting offset for partition reservations-0 to position FetchPosition{offset=207, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-07-19T20:30:52.758+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO KafkaDataConsumer: From Kafka topicPartition=checkins-0 groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor read 207 records through 1 polls (polled  out 207 records), taking 577229459 nanos, during time span of 854064917 nanos.
[2025-07-19T20:30:52.759+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO KafkaDataConsumer: From Kafka topicPartition=reservations-0 groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor read 207 records through 1 polls (polled  out 207 records), taking 577400709 nanos, during time span of 854092083 nanos.
[2025-07-19T20:30:52.760+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO KafkaDataConsumer: From Kafka topicPartition=feedback-0 groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor read 207 records through 1 polls (polled  out 207 records), taking 577256917 nanos, during time span of 854070167 nanos.
[2025-07-19T20:30:52.787+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Finished task 0.0 in stage 4.0 (TID 2). 2642 bytes result sent to driver
[2025-07-19T20:30:52.789+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Finished task 0.0 in stage 2.0 (TID 1). 2642 bytes result sent to driver
[2025-07-19T20:30:52.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2642 bytes result sent to driver
[2025-07-19T20:30:52.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 1) in 1322 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T20:30:52.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-07-19T20:30:52.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 2) in 1319 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T20:30:52.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-07-19T20:30:52.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1364 ms on 8b44f3d35cfa (executor driver) (1/1)
[2025-07-19T20:30:52.809+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-07-19T20:30:52.820+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: ShuffleMapStage 2 (start at <unknown>:0) finished in 1.393 s
[2025-07-19T20:30:52.820+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T20:30:52.820+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 4)
[2025-07-19T20:30:52.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5, ResultStage 3)
[2025-07-19T20:30:52.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: failed: Set()
[2025-07-19T20:30:52.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: Submitting ResultStage 3 (StateStoreRDD[21] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:30:52.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 40.1 KiB, free 433.3 MiB)
[2025-07-19T20:30:52.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 433.3 MiB)
[2025-07-19T20:30:52.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 8b44f3d35cfa:36593 (size: 19.9 KiB, free: 434.1 MiB)
[2025-07-19T20:30:52.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:30:52.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 3 (StateStoreRDD[21] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:30:52.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 200 tasks resource profile 0
[2025-07-19T20:30:52.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: ShuffleMapStage 4 (start at <unknown>:0) finished in 1.417 s
[2025-07-19T20:30:52.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T20:30:52.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ResultStage 3)
[2025-07-19T20:30:52.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: waiting: Set(ResultStage 1, ResultStage 5)
[2025-07-19T20:30:52.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: failed: Set()
[2025-07-19T20:30:52.901+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: Submitting ResultStage 5 (StateStoreRDD[22] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:30:52.901+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 3) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.901+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 4) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 5) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 6) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.905+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 7) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.905+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 8) (8b44f3d35cfa, executor driver, partition 8, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.905+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 9) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.905+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 10) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:52.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 1.0 in stage 3.0 (TID 3)
[2025-07-19T20:30:52.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 2.0 in stage 3.0 (TID 4)
[2025-07-19T20:30:52.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 5.0 in stage 3.0 (TID 5)
[2025-07-19T20:30:52.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 7.0 in stage 3.0 (TID 7)
[2025-07-19T20:30:52.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 10.0 in stage 3.0 (TID 9)
[2025-07-19T20:30:52.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 11.0 in stage 3.0 (TID 10)
[2025-07-19T20:30:52.916+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 8.0 in stage 3.0 (TID 8)
[2025-07-19T20:30:52.927+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO Executor: Running task 6.0 in stage 3.0 (TID 6)
[2025-07-19T20:30:52.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.961+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.962+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T20:30:52.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.964+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T20:30:52.964+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T20:30:52.964+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:52.965+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
[2025-07-19T20:30:52.965+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T20:30:52.965+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T20:30:52.965+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T20:30:52.965+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 16 ms
[2025-07-19T20:30:52.970+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 39.6 KiB, free 433.3 MiB)
[2025-07-19T20:30:52.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 19.7 KiB, free 433.2 MiB)
[2025-07-19T20:30:52.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO StateStore: State Store maintenance task started
[2025-07-19T20:30:52.974+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 8b44f3d35cfa:36593 (size: 19.7 KiB, free: 434.1 MiB)
[2025-07-19T20:30:52.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:30:52.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 5 (StateStoreRDD[22] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:30:52.983+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO TaskSchedulerImpl: Adding task set 5.0 with 200 tasks resource profile 0
[2025-07-19T20:30:52.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: ShuffleMapStage 0 (start at <unknown>:0) finished in 1.739 s
[2025-07-19T20:30:52.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-07-19T20:30:52.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: running: Set(ResultStage 5, ResultStage 3)
[2025-07-19T20:30:52.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: waiting: Set(ResultStage 1)
[2025-07-19T20:30:52.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: failed: Set()
[2025-07-19T20:30:52.985+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO DAGScheduler: Submitting ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:30:52.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8f03c83
[2025-07-19T20:30:53.007+0000] {subprocess.py:93} INFO - 25/07/19 20:30:52 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.009+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5] for update
[2025-07-19T20:30:53.020+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodeGenerator: Code generated in 9.552375 ms
[2025-07-19T20:30:53.026+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@448c9ea3
[2025-07-19T20:30:53.026+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.027+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11] for update
[2025-07-19T20:30:53.035+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@737b2e9
[2025-07-19T20:30:53.036+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodeGenerator: Code generated in 5.464791 ms
[2025-07-19T20:30:53.041+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.051+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1] for update
[2025-07-19T20:30:53.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68f2d56d
[2025-07-19T20:30:53.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2] for update
[2025-07-19T20:30:53.056+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 38.8 KiB, free 433.2 MiB)
[2025-07-19T20:30:53.056+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 433.2 MiB)
[2025-07-19T20:30:53.057+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 8b44f3d35cfa:36593 (size: 19.3 KiB, free: 434.1 MiB)
[2025-07-19T20:30:53.060+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:30:53.061+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 1 (StateStoreRDD[23] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:30:53.062+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 200 tasks resource profile 0
[2025-07-19T20:30:53.066+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@473406cf
[2025-07-19T20:30:53.068+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.068+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8] for update
[2025-07-19T20:30:53.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ae9b705
[2025-07-19T20:30:53.077+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.078+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7] for update
[2025-07-19T20:30:53.084+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20ea12ae
[2025-07-19T20:30:53.084+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.085+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6] for update
[2025-07-19T20:30:53.094+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f455646
[2025-07-19T20:30:53.094+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.095+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10] for update
[2025-07-19T20:30:53.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.126+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.126+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.1.delta.fa2efc6a-e516-46e7-8978-5877b62fd9ed.TID8.tmp
[2025-07-19T20:30:53.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.1.delta.4d199b9a-b315-4107-9489-57d5784857b1.TID6.tmp
[2025-07-19T20:30:53.365+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.1.delta.24dd1ee5-8cce-40a7-87bd-24b997f1d5c0.TID7.tmp
[2025-07-19T20:30:53.365+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.1.delta.0f20d7f4-b2b2-4a68-aa3f-34f2b4d614a5.TID3.tmp
[2025-07-19T20:30:53.367+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.1.delta.096d4864-ad74-45f3-8020-c72cdc1f059d.TID4.tmp
[2025-07-19T20:30:53.368+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.1.delta.467f99ad-3be6-4681-ab50-a801bd96993f.TID10.tmp
[2025-07-19T20:30:53.369+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.1.delta.6f5ce032-d544-4ac0-9f9a-f3b45228e041.TID5.tmp
[2025-07-19T20:30:53.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.1.delta.6247a652-413a-4860-9ba1-42ca3491a3a6.TID9.tmp
[2025-07-19T20:30:53.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodeGenerator: Code generated in 9.521667 ms
[2025-07-19T20:30:53.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.1.delta.096d4864-ad74-45f3-8020-c72cdc1f059d.TID4.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta
[2025-07-19T20:30:53.511+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta
[2025-07-19T20:30:53.512+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.1.delta.24dd1ee5-8cce-40a7-87bd-24b997f1d5c0.TID7.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta
[2025-07-19T20:30:53.514+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta
[2025-07-19T20:30:53.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.1.delta.4d199b9a-b315-4107-9489-57d5784857b1.TID6.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta
[2025-07-19T20:30:53.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta
[2025-07-19T20:30:53.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.1.delta.467f99ad-3be6-4681-ab50-a801bd96993f.TID10.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta
[2025-07-19T20:30:53.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta
[2025-07-19T20:30:53.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 4, attempt 0, stage 3.0)
[2025-07-19T20:30:53.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 10, attempt 0, stage 3.0)
[2025-07-19T20:30:53.533+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 6, attempt 0, stage 3.0)
[2025-07-19T20:30:53.533+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 7, attempt 0, stage 3.0)
[2025-07-19T20:30:53.537+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.1.delta.0f20d7f4-b2b2-4a68-aa3f-34f2b4d614a5.TID3.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta
[2025-07-19T20:30:53.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta
[2025-07-19T20:30:53.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.1.delta.6247a652-413a-4860-9ba1-42ca3491a3a6.TID9.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta
[2025-07-19T20:30:53.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta
[2025-07-19T20:30:53.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 3, attempt 0, stage 3.0)
[2025-07-19T20:30:53.540+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 9, attempt 0, stage 3.0)
[2025-07-19T20:30:53.546+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.1.delta.fa2efc6a-e516-46e7-8978-5877b62fd9ed.TID8.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta
[2025-07-19T20:30:53.552+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta
[2025-07-19T20:30:53.554+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 8, attempt 0, stage 3.0)
[2025-07-19T20:30:53.557+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.1.delta.6f5ce032-d544-4ac0-9f9a-f3b45228e041.TID5.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta
[2025-07-19T20:30:53.559+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta
[2025-07-19T20:30:53.566+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 5, attempt 0, stage 3.0)
[2025-07-19T20:30:53.777+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 8b44f3d35cfa:36593 in memory (size: 14.1 KiB, free: 434.1 MiB)
[2025-07-19T20:30:53.781+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 8b44f3d35cfa:36593 in memory (size: 15.8 KiB, free: 434.1 MiB)
[2025-07-19T20:30:53.783+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 8b44f3d35cfa:36593 in memory (size: 14.7 KiB, free: 434.2 MiB)
[2025-07-19T20:30:53.944+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 6 (task 6, attempt 0, stage 3.0)
[2025-07-19T20:30:53.944+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 11 (task 10, attempt 0, stage 3.0)
[2025-07-19T20:30:53.944+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 7 (task 7, attempt 0, stage 3.0)
[2025-07-19T20:30:53.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 5 (task 5, attempt 0, stage 3.0)
[2025-07-19T20:30:53.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 1 (task 3, attempt 0, stage 3.0)
[2025-07-19T20:30:53.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 2 (task 4, attempt 0, stage 3.0)
[2025-07-19T20:30:53.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 10 (task 9, attempt 0, stage 3.0)
[2025-07-19T20:30:53.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO DataWritingSparkTask: Committed partition 8 (task 8, attempt 0, stage 3.0)
[2025-07-19T20:30:53.948+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 11.0 in stage 3.0 (TID 10). 9335 bytes result sent to driver
[2025-07-19T20:30:53.948+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 7.0 in stage 3.0 (TID 7). 9337 bytes result sent to driver
[2025-07-19T20:30:53.950+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 8.0 in stage 3.0 (TID 8). 9334 bytes result sent to driver
[2025-07-19T20:30:53.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 5.0 in stage 3.0 (TID 5). 9319 bytes result sent to driver
[2025-07-19T20:30:53.956+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 10.0 in stage 3.0 (TID 9). 9330 bytes result sent to driver
[2025-07-19T20:30:53.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 1.0 in stage 3.0 (TID 3). 9328 bytes result sent to driver
[2025-07-19T20:30:53.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 2.0 in stage 3.0 (TID 4). 9301 bytes result sent to driver
[2025-07-19T20:30:53.958+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 11) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.959+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 12) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.962+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Finished task 6.0 in stage 3.0 (TID 6). 9330 bytes result sent to driver
[2025-07-19T20:30:53.964+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 13) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.966+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 14.0 in stage 3.0 (TID 12)
[2025-07-19T20:30:53.966+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 16.0 in stage 3.0 (TID 14) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.968+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 16.0 in stage 3.0 (TID 14)
[2025-07-19T20:30:53.970+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 12.0 in stage 3.0 (TID 11)
[2025-07-19T20:30:53.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 15.0 in stage 3.0 (TID 13)
[2025-07-19T20:30:53.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 17.0 in stage 3.0 (TID 15) (8b44f3d35cfa, executor driver, partition 17, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.974+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 18.0 in stage 3.0 (TID 16) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.975+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 17.0 in stage 3.0 (TID 15)
[2025-07-19T20:30:53.976+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:53.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 18.0 in stage 3.0 (TID 16)
[2025-07-19T20:30:53.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 8) in 1062 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:30:53.980+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 7) in 1064 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:30:53.982+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 5) in 1066 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:30:53.983+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 19.0 in stage 3.0 (TID 17) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.983+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:53.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Starting task 20.0 in stage 3.0 (TID 18) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:53.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 19.0 in stage 3.0 (TID 17)
[2025-07-19T20:30:53.985+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO Executor: Running task 20.0 in stage 3.0 (TID 18)
[2025-07-19T20:30:53.985+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.986+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 9) in 1068 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:30:53.986+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:53.987+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 4) in 1072 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:30:53.987+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 3) in 1075 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:30:53.987+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 10) in 1072 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:30:53.987+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.987+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:53.987+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 6) in 1079 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:30:53.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@af79314
[2025-07-19T20:30:53.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14] for update
[2025-07-19T20:30:53.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.989+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:53.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T20:30:53.991+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.991+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-07-19T20:30:53.991+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:53.994+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:53.994+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:53.995+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d3eb7aa
[2025-07-19T20:30:53.995+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:53.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20] for update
[2025-07-19T20:30:53.999+0000] {subprocess.py:93} INFO - 25/07/19 20:30:53 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.004+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37c08a7d
[2025-07-19T20:30:54.006+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.009+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16] for update
[2025-07-19T20:30:54.010+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.1.delta.95955ef1-63aa-4ade-842b-64f5f5af5f68.TID12.tmp
[2025-07-19T20:30:54.012+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.1.delta.6e29a2d0-04c5-412e-a0c8-83f69ed33b9e.TID18.tmp
[2025-07-19T20:30:54.012+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.023+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44795825
[2025-07-19T20:30:54.026+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.029+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12] for update
[2025-07-19T20:30:54.038+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.1.delta.777c0572-6968-4fe9-9725-5bbb5cd774af.TID14.tmp
[2025-07-19T20:30:54.043+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.049+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25efee2a
[2025-07-19T20:30:54.050+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.050+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15] for update
[2025-07-19T20:30:54.050+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.061+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@722efe64
[2025-07-19T20:30:54.070+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.1.delta.1acfd0b3-7fc5-4117-b403-7485003e92b9.TID13.tmp
[2025-07-19T20:30:54.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.074+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19] for update
[2025-07-19T20:30:54.075+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.1.delta.56a1f97a-7089-43aa-9e95-5c1a81f94830.TID11.tmp
[2025-07-19T20:30:54.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@596d223b
[2025-07-19T20:30:54.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.095+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18] for update
[2025-07-19T20:30:54.099+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.1.delta.6e29a2d0-04c5-412e-a0c8-83f69ed33b9e.TID18.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta
[2025-07-19T20:30:54.100+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta
[2025-07-19T20:30:54.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 18, attempt 0, stage 3.0)
[2025-07-19T20:30:54.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.113+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@712969a4
[2025-07-19T20:30:54.114+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.115+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.1.delta.95955ef1-63aa-4ade-842b-64f5f5af5f68.TID12.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta
[2025-07-19T20:30:54.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta
[2025-07-19T20:30:54.122+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17] for update
[2025-07-19T20:30:54.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 12, attempt 0, stage 3.0)
[2025-07-19T20:30:54.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.1.delta.51933c15-0f92-42f8-93d3-9caf5b86a630.TID17.tmp
[2025-07-19T20:30:54.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.133+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.1.delta.57908ee3-1772-4485-ad03-0ba63f8fe0d1.TID16.tmp
[2025-07-19T20:30:54.150+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.1.delta.777c0572-6968-4fe9-9725-5bbb5cd774af.TID14.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta
[2025-07-19T20:30:54.152+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta
[2025-07-19T20:30:54.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.1.delta.dd5ab972-9d3b-4c66-bde3-3c9d4ee16bde.TID15.tmp
[2025-07-19T20:30:54.181+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 14, attempt 0, stage 3.0)
[2025-07-19T20:30:54.189+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 14 (task 12, attempt 0, stage 3.0)
[2025-07-19T20:30:54.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 14.0 in stage 3.0 (TID 12). 9292 bytes result sent to driver
[2025-07-19T20:30:54.195+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 20 (task 18, attempt 0, stage 3.0)
[2025-07-19T20:30:54.198+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 20.0 in stage 3.0 (TID 18). 9271 bytes result sent to driver
[2025-07-19T20:30:54.199+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 24.0 in stage 3.0 (TID 19) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.199+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 24.0 in stage 3.0 (TID 19)
[2025-07-19T20:30:54.200+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.1.delta.1acfd0b3-7fc5-4117-b403-7485003e92b9.TID13.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta
[2025-07-19T20:30:54.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta
[2025-07-19T20:30:54.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 13, attempt 0, stage 3.0)
[2025-07-19T20:30:54.207+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 26.0 in stage 3.0 (TID 20) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.207+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 26.0 in stage 3.0 (TID 20)
[2025-07-19T20:30:54.208+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 20.0 in stage 3.0 (TID 18) in 236 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:30:54.208+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 12) in 252 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:30:54.213+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.213+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:54.220+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.220+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-07-19T20:30:54.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@700ccc2f
[2025-07-19T20:30:54.232+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.232+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24] for update
[2025-07-19T20:30:54.234+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.240+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.1.delta.56a1f97a-7089-43aa-9e95-5c1a81f94830.TID11.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta
[2025-07-19T20:30:54.242+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta
[2025-07-19T20:30:54.244+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58794830
[2025-07-19T20:30:54.245+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.245+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26] for update
[2025-07-19T20:30:54.245+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 16 (task 14, attempt 0, stage 3.0)
[2025-07-19T20:30:54.246+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.1.delta.51933c15-0f92-42f8-93d3-9caf5b86a630.TID17.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta
[2025-07-19T20:30:54.251+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta
[2025-07-19T20:30:54.251+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 16.0 in stage 3.0 (TID 14). 9303 bytes result sent to driver
[2025-07-19T20:30:54.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 11, attempt 0, stage 3.0)
[2025-07-19T20:30:54.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 27.0 in stage 3.0 (TID 21) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 16.0 in stage 3.0 (TID 14) in 294 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:30:54.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 27.0 in stage 3.0 (TID 21)
[2025-07-19T20:30:54.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 17, attempt 0, stage 3.0)
[2025-07-19T20:30:54.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.1.delta.522cf10d-76fc-402f-bfef-b48a1369d58a.TID19.tmp
[2025-07-19T20:30:54.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.1.delta.57908ee3-1772-4485-ad03-0ba63f8fe0d1.TID16.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta
[2025-07-19T20:30:54.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta
[2025-07-19T20:30:54.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 16, attempt 0, stage 3.0)
[2025-07-19T20:30:54.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 15 (task 13, attempt 0, stage 3.0)
[2025-07-19T20:30:54.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 15.0 in stage 3.0 (TID 13). 9305 bytes result sent to driver
[2025-07-19T20:30:54.268+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 28.0 in stage 3.0 (TID 22) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.269+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 28.0 in stage 3.0 (TID 22)
[2025-07-19T20:30:54.269+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 13) in 314 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:30:54.271+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@214eb17b
[2025-07-19T20:30:54.273+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.273+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27] for update
[2025-07-19T20:30:54.274+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.1.delta.165cbabf-8554-49dd-816d-532c7d41812a.TID20.tmp
[2025-07-19T20:30:54.275+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.1.delta.dd5ab972-9d3b-4c66-bde3-3c9d4ee16bde.TID15.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta
[2025-07-19T20:30:54.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta
[2025-07-19T20:30:54.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 15, attempt 0, stage 3.0)
[2025-07-19T20:30:54.280+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 18 (task 16, attempt 0, stage 3.0)
[2025-07-19T20:30:54.281+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 19 (task 17, attempt 0, stage 3.0)
[2025-07-19T20:30:54.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 18.0 in stage 3.0 (TID 16). 9287 bytes result sent to driver
[2025-07-19T20:30:54.287+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 19.0 in stage 3.0 (TID 17). 9303 bytes result sent to driver
[2025-07-19T20:30:54.288+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.288+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-07-19T20:30:54.289+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 29.0 in stage 3.0 (TID 23) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 30.0 in stage 3.0 (TID 24) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.291+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 30.0 in stage 3.0 (TID 24)
[2025-07-19T20:30:54.291+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 18.0 in stage 3.0 (TID 16) in 326 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:30:54.291+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 19.0 in stage 3.0 (TID 17) in 317 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:30:54.292+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 29.0 in stage 3.0 (TID 23)
[2025-07-19T20:30:54.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.1.delta.5195c056-fb87-4308-9879-604c51eb09f9.TID21.tmp
[2025-07-19T20:30:54.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@170bf460
[2025-07-19T20:30:54.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28] for update
[2025-07-19T20:30:54.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.317+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@277905a5
[2025-07-19T20:30:54.317+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.319+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30] for update
[2025-07-19T20:30:54.321+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.321+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.321+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 12 (task 11, attempt 0, stage 3.0)
[2025-07-19T20:30:54.326+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 17 (task 15, attempt 0, stage 3.0)
[2025-07-19T20:30:54.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 12.0 in stage 3.0 (TID 11). 9300 bytes result sent to driver
[2025-07-19T20:30:54.339+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 31.0 in stage 3.0 (TID 25) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 17.0 in stage 3.0 (TID 15). 9294 bytes result sent to driver
[2025-07-19T20:30:54.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 11) in 385 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:30:54.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.1.delta.522cf10d-76fc-402f-bfef-b48a1369d58a.TID19.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta
[2025-07-19T20:30:54.353+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 31.0 in stage 3.0 (TID 25)
[2025-07-19T20:30:54.353+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta
[2025-07-19T20:30:54.354+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 19, attempt 0, stage 3.0)
[2025-07-19T20:30:54.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 32.0 in stage 3.0 (TID 26) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:30:54.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 17.0 in stage 3.0 (TID 15) in 389 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:30:54.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.1.delta.1c1e90a9-f3b7-449b-bf91-17afaa242088.TID24.tmp
[2025-07-19T20:30:54.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 32.0 in stage 3.0 (TID 26)
[2025-07-19T20:30:54.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.1.delta.6e1a079b-0522-413e-b0c4-0f96f3504e34.TID22.tmp
[2025-07-19T20:30:54.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.357+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.357+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.357+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75469b20
[2025-07-19T20:30:54.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.363+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29] for update
[2025-07-19T20:30:54.369+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.375+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@467a3efc
[2025-07-19T20:30:54.375+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.376+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 24 (task 19, attempt 0, stage 3.0)
[2025-07-19T20:30:54.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31] for update
[2025-07-19T20:30:54.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.1.delta.165cbabf-8554-49dd-816d-532c7d41812a.TID20.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta
[2025-07-19T20:30:54.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta
[2025-07-19T20:30:54.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 24.0 in stage 3.0 (TID 19). 9249 bytes result sent to driver
[2025-07-19T20:30:54.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.1.delta.5195c056-fb87-4308-9879-604c51eb09f9.TID21.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta
[2025-07-19T20:30:54.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 33.0 in stage 3.0 (TID 27) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 20, attempt 0, stage 3.0)
[2025-07-19T20:30:54.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 33.0 in stage 3.0 (TID 27)
[2025-07-19T20:30:54.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta
[2025-07-19T20:30:54.381+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 21, attempt 0, stage 3.0)
[2025-07-19T20:30:54.389+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54ec47c
[2025-07-19T20:30:54.390+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 24.0 in stage 3.0 (TID 19) in 189 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:30:54.390+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.391+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.391+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.392+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32] for update
[2025-07-19T20:30:54.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.394+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.396+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d6a948b
[2025-07-19T20:30:54.399+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.400+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.1.delta.63139cad-82b5-4452-9b99-96dc0f2c2e7b.TID23.tmp
[2025-07-19T20:30:54.400+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33] for update
[2025-07-19T20:30:54.401+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.407+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.1.delta.fd6ef73f-4869-4868-91a6-47d51214e45a.TID25.tmp
[2025-07-19T20:30:54.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.1.delta.ae79ff8a-71ff-47e2-88d5-cc7c6ff83370.TID26.tmp
[2025-07-19T20:30:54.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 26 (task 20, attempt 0, stage 3.0)
[2025-07-19T20:30:54.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.1.delta.d46a2d9c-b596-440b-8fda-2c22cae1a885.TID27.tmp
[2025-07-19T20:30:54.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 26.0 in stage 3.0 (TID 20). 9293 bytes result sent to driver
[2025-07-19T20:30:54.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.1.delta.6e1a079b-0522-413e-b0c4-0f96f3504e34.TID22.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta
[2025-07-19T20:30:54.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta
[2025-07-19T20:30:54.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 22, attempt 0, stage 3.0)
[2025-07-19T20:30:54.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 34.0 in stage 3.0 (TID 28) (8b44f3d35cfa, executor driver, partition 34, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.432+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 26.0 in stage 3.0 (TID 20) in 228 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:30:54.438+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 27 (task 21, attempt 0, stage 3.0)
[2025-07-19T20:30:54.438+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 34.0 in stage 3.0 (TID 28)
[2025-07-19T20:30:54.439+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 27.0 in stage 3.0 (TID 21). 9301 bytes result sent to driver
[2025-07-19T20:30:54.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 35.0 in stage 3.0 (TID 29) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.443+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 35.0 in stage 3.0 (TID 29)
[2025-07-19T20:30:54.443+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 27.0 in stage 3.0 (TID 21) in 195 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:30:54.444+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.1.delta.1c1e90a9-f3b7-449b-bf91-17afaa242088.TID24.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta
[2025-07-19T20:30:54.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.449+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta
[2025-07-19T20:30:54.450+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:54.452+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 24, attempt 0, stage 3.0)
[2025-07-19T20:30:54.453+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.454+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:54.462+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1daa78bd
[2025-07-19T20:30:54.465+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 28 (task 22, attempt 0, stage 3.0)
[2025-07-19T20:30:54.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.469+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34] for update
[2025-07-19T20:30:54.469+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 28.0 in stage 3.0 (TID 22). 9312 bytes result sent to driver
[2025-07-19T20:30:54.470+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 36.0 in stage 3.0 (TID 30) (8b44f3d35cfa, executor driver, partition 36, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.470+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 28.0 in stage 3.0 (TID 22) in 199 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:30:54.470+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 36.0 in stage 3.0 (TID 30)
[2025-07-19T20:30:54.470+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.474+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a83f368
[2025-07-19T20:30:54.476+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.478+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.478+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35] for update
[2025-07-19T20:30:54.479+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.1.delta.63139cad-82b5-4452-9b99-96dc0f2c2e7b.TID23.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta
[2025-07-19T20:30:54.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta
[2025-07-19T20:30:54.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 23, attempt 0, stage 3.0)
[2025-07-19T20:30:54.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.487+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.1.delta.fd6ef73f-4869-4868-91a6-47d51214e45a.TID25.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta
[2025-07-19T20:30:54.488+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta
[2025-07-19T20:30:54.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46b956d9
[2025-07-19T20:30:54.491+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 25, attempt 0, stage 3.0)
[2025-07-19T20:30:54.491+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.492+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36] for update
[2025-07-19T20:30:54.496+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.1.delta.7785a4f3-447b-412f-b0a6-6c98eca72aa7.TID28.tmp
[2025-07-19T20:30:54.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.502+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 30 (task 24, attempt 0, stage 3.0)
[2025-07-19T20:30:54.503+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.1.delta.c7c31d66-27fa-4df5-9159-d7618bd6da36.TID29.tmp
[2025-07-19T20:30:54.512+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.1.delta.d46a2d9c-b596-440b-8fda-2c22cae1a885.TID27.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta
[2025-07-19T20:30:54.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.1.delta.ae79ff8a-71ff-47e2-88d5-cc7c6ff83370.TID26.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta
[2025-07-19T20:30:54.514+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta
[2025-07-19T20:30:54.515+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta
[2025-07-19T20:30:54.515+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 26, attempt 0, stage 3.0)
[2025-07-19T20:30:54.519+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 27, attempt 0, stage 3.0)
[2025-07-19T20:30:54.520+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 30.0 in stage 3.0 (TID 24). 9329 bytes result sent to driver
[2025-07-19T20:30:54.523+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 39.0 in stage 3.0 (TID 31) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 39.0 in stage 3.0 (TID 31)
[2025-07-19T20:30:54.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 30.0 in stage 3.0 (TID 24) in 239 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:30:54.535+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 29 (task 23, attempt 0, stage 3.0)
[2025-07-19T20:30:54.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.543+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:30:54.544+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.1.delta.3e97cbc5-ca3a-4260-af4f-f9428876d3df.TID30.tmp
[2025-07-19T20:30:54.546+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 29.0 in stage 3.0 (TID 23). 9288 bytes result sent to driver
[2025-07-19T20:30:54.550+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 40.0 in stage 3.0 (TID 32) (8b44f3d35cfa, executor driver, partition 40, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.550+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 40.0 in stage 3.0 (TID 32)
[2025-07-19T20:30:54.551+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 29.0 in stage 3.0 (TID 23) in 268 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:30:54.561+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d1d1dd4
[2025-07-19T20:30:54.563+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 31 (task 25, attempt 0, stage 3.0)
[2025-07-19T20:30:54.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 31.0 in stage 3.0 (TID 25). 9278 bytes result sent to driver
[2025-07-19T20:30:54.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 41.0 in stage 3.0 (TID 33) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 31.0 in stage 3.0 (TID 25) in 225 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:30:54.565+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.566+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39] for update
[2025-07-19T20:30:54.568+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 41.0 in stage 3.0 (TID 33)
[2025-07-19T20:30:54.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d84bb27
[2025-07-19T20:30:54.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40] for update
[2025-07-19T20:30:54.579+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 32 (task 26, attempt 0, stage 3.0)
[2025-07-19T20:30:54.579+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 32.0 in stage 3.0 (TID 26). 9292 bytes result sent to driver
[2025-07-19T20:30:54.580+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 33 (task 27, attempt 0, stage 3.0)
[2025-07-19T20:30:54.581+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 42.0 in stage 3.0 (TID 34) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.583+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.587+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 32.0 in stage 3.0 (TID 26) in 241 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:30:54.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 42.0 in stage 3.0 (TID 34)
[2025-07-19T20:30:54.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 33.0 in stage 3.0 (TID 27). 9288 bytes result sent to driver
[2025-07-19T20:30:54.589+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.1.delta.19f58172-ec0b-4df0-99b1-8d27837116e3.TID31.tmp
[2025-07-19T20:30:54.595+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 44.0 in stage 3.0 (TID 35) (8b44f3d35cfa, executor driver, partition 44, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.596+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 44.0 in stage 3.0 (TID 35)
[2025-07-19T20:30:54.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 33.0 in stage 3.0 (TID 27) in 218 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:30:54.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.598+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.599+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.1.delta.7785a4f3-447b-412f-b0a6-6c98eca72aa7.TID28.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta
[2025-07-19T20:30:54.600+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta
[2025-07-19T20:30:54.601+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 28, attempt 0, stage 3.0)
[2025-07-19T20:30:54.601+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.602+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:54.603+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@500c2fa4
[2025-07-19T20:30:54.604+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.604+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41] for update
[2025-07-19T20:30:54.607+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.1.delta.b08cd0af-b345-4f04-8953-4ab9bde87317.TID32.tmp
[2025-07-19T20:30:54.608+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.1.delta.c7c31d66-27fa-4df5-9159-d7618bd6da36.TID29.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta
[2025-07-19T20:30:54.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta
[2025-07-19T20:30:54.610+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 29, attempt 0, stage 3.0)
[2025-07-19T20:30:54.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@468ade71
[2025-07-19T20:30:54.614+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42] for update
[2025-07-19T20:30:54.617+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.619+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.621+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7039a38e
[2025-07-19T20:30:54.624+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.1.delta.3e97cbc5-ca3a-4260-af4f-f9428876d3df.TID30.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta
[2025-07-19T20:30:54.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta
[2025-07-19T20:30:54.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44] for update
[2025-07-19T20:30:54.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.630+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 30, attempt 0, stage 3.0)
[2025-07-19T20:30:54.632+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.1.delta.f35d0735-ca0e-4838-8476-4bf96c6bb86b.TID33.tmp
[2025-07-19T20:30:54.636+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 34 (task 28, attempt 0, stage 3.0)
[2025-07-19T20:30:54.637+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.1.delta.44d72dd6-173f-4086-8871-aab519b42f93.TID34.tmp
[2025-07-19T20:30:54.637+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 34.0 in stage 3.0 (TID 28). 9292 bytes result sent to driver
[2025-07-19T20:30:54.639+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 46.0 in stage 3.0 (TID 36) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.643+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 46.0 in stage 3.0 (TID 36)
[2025-07-19T20:30:54.644+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 34.0 in stage 3.0 (TID 28) in 213 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:30:54.648+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.649+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.1.delta.19f58172-ec0b-4df0-99b1-8d27837116e3.TID31.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta
[2025-07-19T20:30:54.653+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta
[2025-07-19T20:30:54.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.1.delta.acadc802-ed93-4efc-8a1d-1400171241f5.TID35.tmp
[2025-07-19T20:30:54.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 31, attempt 0, stage 3.0)
[2025-07-19T20:30:54.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 35 (task 29, attempt 0, stage 3.0)
[2025-07-19T20:30:54.662+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@439b5655
[2025-07-19T20:30:54.662+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.663+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.1.delta.b08cd0af-b345-4f04-8953-4ab9bde87317.TID32.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta
[2025-07-19T20:30:54.665+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46] for update
[2025-07-19T20:30:54.666+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta
[2025-07-19T20:30:54.667+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 32, attempt 0, stage 3.0)
[2025-07-19T20:30:54.671+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 35.0 in stage 3.0 (TID 29). 9289 bytes result sent to driver
[2025-07-19T20:30:54.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 47.0 in stage 3.0 (TID 37) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 35.0 in stage 3.0 (TID 29) in 223 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:30:54.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 47.0 in stage 3.0 (TID 37)
[2025-07-19T20:30:54.674+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.677+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 36 (task 30, attempt 0, stage 3.0)
[2025-07-19T20:30:54.682+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 36.0 in stage 3.0 (TID 30). 9272 bytes result sent to driver
[2025-07-19T20:30:54.691+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 36.0 in stage 3.0 (TID 30) in 219 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:30:54.691+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 48.0 in stage 3.0 (TID 38) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.694+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 48.0 in stage 3.0 (TID 38)
[2025-07-19T20:30:54.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.697+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:54.697+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 39 (task 31, attempt 0, stage 3.0)
[2025-07-19T20:30:54.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 39.0 in stage 3.0 (TID 31). 9226 bytes result sent to driver
[2025-07-19T20:30:54.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 49.0 in stage 3.0 (TID 39) (8b44f3d35cfa, executor driver, partition 49, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 49.0 in stage 3.0 (TID 39)
[2025-07-19T20:30:54.699+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 39.0 in stage 3.0 (TID 31) in 179 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:30:54.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.1.delta.1d89d1ec-ea41-451f-882f-2b53ccc584fe.TID36.tmp
[2025-07-19T20:30:54.710+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.711+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:54.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@489c972d
[2025-07-19T20:30:54.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.716+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48] for update
[2025-07-19T20:30:54.716+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.722+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.1.delta.f35d0735-ca0e-4838-8476-4bf96c6bb86b.TID33.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta
[2025-07-19T20:30:54.725+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta
[2025-07-19T20:30:54.725+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 40 (task 32, attempt 0, stage 3.0)
[2025-07-19T20:30:54.726+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 40.0 in stage 3.0 (TID 32). 9260 bytes result sent to driver
[2025-07-19T20:30:54.726+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27a5b60f
[2025-07-19T20:30:54.729+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49] for update
[2025-07-19T20:30:54.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 33, attempt 0, stage 3.0)
[2025-07-19T20:30:54.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 51.0 in stage 3.0 (TID 40) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 51.0 in stage 3.0 (TID 40)
[2025-07-19T20:30:54.734+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 40.0 in stage 3.0 (TID 32) in 185 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:30:54.737+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.738+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:54.738+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.743+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.1.delta.44d72dd6-173f-4086-8871-aab519b42f93.TID34.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta
[2025-07-19T20:30:54.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta
[2025-07-19T20:30:54.745+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ec0dca4
[2025-07-19T20:30:54.748+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.749+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 34, attempt 0, stage 3.0)
[2025-07-19T20:30:54.751+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47] for update
[2025-07-19T20:30:54.752+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.755+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.1.delta.03e0d28a-fd26-456d-aaa8-7c471184689b.TID39.tmp
[2025-07-19T20:30:54.758+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.1.delta.acadc802-ed93-4efc-8a1d-1400171241f5.TID35.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta
[2025-07-19T20:30:54.758+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta
[2025-07-19T20:30:54.761+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 35, attempt 0, stage 3.0)
[2025-07-19T20:30:54.768+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7155fa14
[2025-07-19T20:30:54.769+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.1.delta.51b8560f-b92c-4b08-851b-1bd7b0ff1b6e.TID38.tmp
[2025-07-19T20:30:54.769+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.770+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51] for update
[2025-07-19T20:30:54.779+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.781+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.1.delta.e6f00563-356d-4328-af29-dcf0baaaac89.TID37.tmp
[2025-07-19T20:30:54.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 41 (task 33, attempt 0, stage 3.0)
[2025-07-19T20:30:54.788+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 41.0 in stage 3.0 (TID 33). 9245 bytes result sent to driver
[2025-07-19T20:30:54.788+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 42 (task 34, attempt 0, stage 3.0)
[2025-07-19T20:30:54.791+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.1.delta.1d89d1ec-ea41-451f-882f-2b53ccc584fe.TID36.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta
[2025-07-19T20:30:54.792+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta
[2025-07-19T20:30:54.803+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 42.0 in stage 3.0 (TID 34). 9251 bytes result sent to driver
[2025-07-19T20:30:54.804+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 54.0 in stage 3.0 (TID 41) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 55.0 in stage 3.0 (TID 42) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 54.0 in stage 3.0 (TID 41)
[2025-07-19T20:30:54.810+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 44 (task 35, attempt 0, stage 3.0)
[2025-07-19T20:30:54.810+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 41.0 in stage 3.0 (TID 33) in 237 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:30:54.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 36, attempt 0, stage 3.0)
[2025-07-19T20:30:54.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:54.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 44.0 in stage 3.0 (TID 35). 9301 bytes result sent to driver
[2025-07-19T20:30:54.812+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 42.0 in stage 3.0 (TID 34) in 221 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:30:54.812+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 55.0 in stage 3.0 (TID 42)
[2025-07-19T20:30:54.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 57.0 in stage 3.0 (TID 43) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 57.0 in stage 3.0 (TID 43)
[2025-07-19T20:30:54.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 44.0 in stage 3.0 (TID 35) in 221 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:30:54.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.1.delta.f3c6039d-e310-44f8-9f33-ec53ac854c9d.TID40.tmp
[2025-07-19T20:30:54.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.823+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38db1cd8
[2025-07-19T20:30:54.823+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.826+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54] for update
[2025-07-19T20:30:54.833+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.1.delta.03e0d28a-fd26-456d-aaa8-7c471184689b.TID39.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta
[2025-07-19T20:30:54.838+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta
[2025-07-19T20:30:54.839+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 39, attempt 0, stage 3.0)
[2025-07-19T20:30:54.840+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.841+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 46 (task 36, attempt 0, stage 3.0)
[2025-07-19T20:30:54.842+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 46.0 in stage 3.0 (TID 36). 9286 bytes result sent to driver
[2025-07-19T20:30:54.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 46.0 in stage 3.0 (TID 36) in 199 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:30:54.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 58.0 in stage 3.0 (TID 44) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 58.0 in stage 3.0 (TID 44)
[2025-07-19T20:30:54.844+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17d88e54
[2025-07-19T20:30:54.845+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.846+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57] for update
[2025-07-19T20:30:54.850+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:54.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.1.delta.51b8560f-b92c-4b08-851b-1bd7b0ff1b6e.TID38.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta
[2025-07-19T20:30:54.860+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta
[2025-07-19T20:30:54.861+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 38, attempt 0, stage 3.0)
[2025-07-19T20:30:54.864+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@132041a1
[2025-07-19T20:30:54.867+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.867+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55] for update
[2025-07-19T20:30:54.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.880+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.1.delta.9f6b3717-893c-4697-b633-a2fe7a951555.TID41.tmp
[2025-07-19T20:30:54.883+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.884+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.1.delta.e6f00563-356d-4328-af29-dcf0baaaac89.TID37.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta
[2025-07-19T20:30:54.885+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta
[2025-07-19T20:30:54.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 37, attempt 0, stage 3.0)
[2025-07-19T20:30:54.890+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26702577
[2025-07-19T20:30:54.891+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58] for update
[2025-07-19T20:30:54.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:54.903+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 49 (task 39, attempt 0, stage 3.0)
[2025-07-19T20:30:54.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.1.delta.9869f26e-1454-464c-bf37-87eea18e6e84.TID42.tmp
[2025-07-19T20:30:54.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.1.delta.42b40977-0fa1-4168-b592-be54fcf651e6.TID43.tmp
[2025-07-19T20:30:54.912+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 48 (task 38, attempt 0, stage 3.0)
[2025-07-19T20:30:54.917+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 48.0 in stage 3.0 (TID 38). 9308 bytes result sent to driver
[2025-07-19T20:30:54.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.1.delta.f3c6039d-e310-44f8-9f33-ec53ac854c9d.TID40.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta
[2025-07-19T20:30:54.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta
[2025-07-19T20:30:54.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 49.0 in stage 3.0 (TID 39). 9311 bytes result sent to driver
[2025-07-19T20:30:54.920+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 60.0 in stage 3.0 (TID 45) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.923+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 40, attempt 0, stage 3.0)
[2025-07-19T20:30:54.926+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Committed partition 47 (task 37, attempt 0, stage 3.0)
[2025-07-19T20:30:54.927+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.1.delta.e2641b01-c04a-40ef-b82b-d946ce62f59b.TID44.tmp
[2025-07-19T20:30:54.929+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 62.0 in stage 3.0 (TID 46) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.930+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 49.0 in stage 3.0 (TID 39) in 224 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:30:54.930+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Finished task 47.0 in stage 3.0 (TID 37). 9361 bytes result sent to driver
[2025-07-19T20:30:54.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 48.0 in stage 3.0 (TID 38) in 239 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:30:54.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Starting task 63.0 in stage 3.0 (TID 47) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:54.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 60.0 in stage 3.0 (TID 45)
[2025-07-19T20:30:54.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO TaskSetManager: Finished task 47.0 in stage 3.0 (TID 37) in 263 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:30:54.950+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 63.0 in stage 3.0 (TID 47)
[2025-07-19T20:30:54.955+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO Executor: Running task 62.0 in stage 3.0 (TID 46)
[2025-07-19T20:30:54.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:54.964+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.967+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:54.967+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:54.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T20:30:54.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64f45b84
[2025-07-19T20:30:54.993+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.1.delta.9f6b3717-893c-4697-b633-a2fe7a951555.TID41.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta
[2025-07-19T20:30:54.993+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta
[2025-07-19T20:30:54.994+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:54.994+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60] for update
[2025-07-19T20:30:54.994+0000] {subprocess.py:93} INFO - 25/07/19 20:30:54 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 41, attempt 0, stage 3.0)
[2025-07-19T20:30:55.009+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.037+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18b0fd89
[2025-07-19T20:30:55.037+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.039+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63] for update
[2025-07-19T20:30:55.040+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.041+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 51 (task 40, attempt 0, stage 3.0)
[2025-07-19T20:30:55.041+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 51.0 in stage 3.0 (TID 40). 9311 bytes result sent to driver
[2025-07-19T20:30:55.042+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 64.0 in stage 3.0 (TID 48) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.043+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 64.0 in stage 3.0 (TID 48)
[2025-07-19T20:30:55.044+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 51.0 in stage 3.0 (TID 40) in 293 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:30:55.044+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.045+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:55.071+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 54 (task 41, attempt 0, stage 3.0)
[2025-07-19T20:30:55.073+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.1.delta.3cc738e8-188a-4f53-b92a-3e676513bf46.TID47.tmp
[2025-07-19T20:30:55.074+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 54.0 in stage 3.0 (TID 41). 9301 bytes result sent to driver
[2025-07-19T20:30:55.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 66.0 in stage 3.0 (TID 49) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.1.delta.42b40977-0fa1-4168-b592-be54fcf651e6.TID43.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta
[2025-07-19T20:30:55.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta
[2025-07-19T20:30:55.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 54.0 in stage 3.0 (TID 41) in 290 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:30:55.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.1.delta.e2641b01-c04a-40ef-b82b-d946ce62f59b.TID44.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta
[2025-07-19T20:30:55.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta
[2025-07-19T20:30:55.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 66.0 in stage 3.0 (TID 49)
[2025-07-19T20:30:55.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 44, attempt 0, stage 3.0)
[2025-07-19T20:30:55.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 43, attempt 0, stage 3.0)
[2025-07-19T20:30:55.084+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@562094c7
[2025-07-19T20:30:55.087+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62] for update
[2025-07-19T20:30:55.093+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.094+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.1.delta.9869f26e-1454-464c-bf37-87eea18e6e84.TID42.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta
[2025-07-19T20:30:55.099+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta
[2025-07-19T20:30:55.099+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 42, attempt 0, stage 3.0)
[2025-07-19T20:30:55.100+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e68205f
[2025-07-19T20:30:55.100+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64] for update
[2025-07-19T20:30:55.106+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.1.delta.0967e1fe-d199-4146-bd88-1debe6df3bb7.TID45.tmp
[2025-07-19T20:30:55.110+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.113+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.116+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f7340df
[2025-07-19T20:30:55.117+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.118+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66] for update
[2025-07-19T20:30:55.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.1.delta.ca55b5c4-45cd-42c0-823e-9bb18d740c7d.TID48.tmp
[2025-07-19T20:30:55.143+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 57 (task 43, attempt 0, stage 3.0)
[2025-07-19T20:30:55.143+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 55 (task 42, attempt 0, stage 3.0)
[2025-07-19T20:30:55.146+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 55.0 in stage 3.0 (TID 42). 9283 bytes result sent to driver
[2025-07-19T20:30:55.147+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 68.0 in stage 3.0 (TID 50) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.1.delta.3cc738e8-188a-4f53-b92a-3e676513bf46.TID47.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta
[2025-07-19T20:30:55.149+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta
[2025-07-19T20:30:55.150+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 55.0 in stage 3.0 (TID 42) in 356 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:30:55.151+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 68.0 in stage 3.0 (TID 50)
[2025-07-19T20:30:55.154+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 58 (task 44, attempt 0, stage 3.0)
[2025-07-19T20:30:55.155+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.1.delta.b36a3218-fa3e-4e67-80ea-c754020a75cd.TID46.tmp
[2025-07-19T20:30:55.155+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 47, attempt 0, stage 3.0)
[2025-07-19T20:30:55.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 57.0 in stage 3.0 (TID 43). 9286 bytes result sent to driver
[2025-07-19T20:30:55.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 58.0 in stage 3.0 (TID 44). 9288 bytes result sent to driver
[2025-07-19T20:30:55.158+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.1.delta.a0473a3c-98cc-4ad1-b2b5-3ecb0831aa09.TID49.tmp
[2025-07-19T20:30:55.165+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 71.0 in stage 3.0 (TID 51) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.165+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 73.0 in stage 3.0 (TID 52) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.166+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.166+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:55.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 73.0 in stage 3.0 (TID 52)
[2025-07-19T20:30:55.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 71.0 in stage 3.0 (TID 51)
[2025-07-19T20:30:55.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 57.0 in stage 3.0 (TID 43) in 361 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:30:55.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 58.0 in stage 3.0 (TID 44) in 329 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:30:55.170+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.170+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.185+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.1.delta.0967e1fe-d199-4146-bd88-1debe6df3bb7.TID45.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta
[2025-07-19T20:30:55.186+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta
[2025-07-19T20:30:55.187+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 45, attempt 0, stage 3.0)
[2025-07-19T20:30:55.189+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ed789d
[2025-07-19T20:30:55.190+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68] for update
[2025-07-19T20:30:55.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 63 (task 47, attempt 0, stage 3.0)
[2025-07-19T20:30:55.195+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 63.0 in stage 3.0 (TID 47). 9247 bytes result sent to driver
[2025-07-19T20:30:55.196+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 74.0 in stage 3.0 (TID 53) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.196+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 63.0 in stage 3.0 (TID 47) in 265 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:30:55.197+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 74.0 in stage 3.0 (TID 53)
[2025-07-19T20:30:55.198+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.198+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.199+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.208+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d8da890
[2025-07-19T20:30:55.210+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.216+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73] for update
[2025-07-19T20:30:55.222+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.1.delta.ca55b5c4-45cd-42c0-823e-9bb18d740c7d.TID48.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta
[2025-07-19T20:30:55.223+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta
[2025-07-19T20:30:55.224+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 48, attempt 0, stage 3.0)
[2025-07-19T20:30:55.225+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.1.delta.e5d1d2ab-cfd7-45f4-8d35-93965809a38e.TID50.tmp
[2025-07-19T20:30:55.225+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.226+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 60 (task 45, attempt 0, stage 3.0)
[2025-07-19T20:30:55.228+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c8c6796
[2025-07-19T20:30:55.230+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71] for update
[2025-07-19T20:30:55.236+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.239+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 60.0 in stage 3.0 (TID 45). 9337 bytes result sent to driver
[2025-07-19T20:30:55.249+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 76.0 in stage 3.0 (TID 54) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.251+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.1.delta.a0473a3c-98cc-4ad1-b2b5-3ecb0831aa09.TID49.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta
[2025-07-19T20:30:55.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta
[2025-07-19T20:30:55.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 76.0 in stage 3.0 (TID 54)
[2025-07-19T20:30:55.254+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 60.0 in stage 3.0 (TID 45) in 333 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:30:55.255+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8abc831
[2025-07-19T20:30:55.255+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.256+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74] for update
[2025-07-19T20:30:55.256+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 49, attempt 0, stage 3.0)
[2025-07-19T20:30:55.256+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.1.delta.4249c63f-2778-48dd-acce-2dabcb3ad2f4.TID52.tmp
[2025-07-19T20:30:55.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.274+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T20:30:55.280+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.1.delta.b36a3218-fa3e-4e67-80ea-c754020a75cd.TID46.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta
[2025-07-19T20:30:55.282+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta
[2025-07-19T20:30:55.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 46, attempt 0, stage 3.0)
[2025-07-19T20:30:55.284+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 64 (task 48, attempt 0, stage 3.0)
[2025-07-19T20:30:55.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 64.0 in stage 3.0 (TID 48). 9312 bytes result sent to driver
[2025-07-19T20:30:55.292+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 77.0 in stage 3.0 (TID 55) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.293+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 64.0 in stage 3.0 (TID 48) in 272 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:30:55.296+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 77.0 in stage 3.0 (TID 55)
[2025-07-19T20:30:55.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.1.delta.9022d963-4edc-4b46-8e4d-d5d71badb145.TID51.tmp
[2025-07-19T20:30:55.301+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ccd35e5
[2025-07-19T20:30:55.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76] for update
[2025-07-19T20:30:55.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:55.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.317+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c30a83c
[2025-07-19T20:30:55.318+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.1.delta.e2247aec-5028-491b-aead-0cd810908900.TID53.tmp
[2025-07-19T20:30:55.319+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.319+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77] for update
[2025-07-19T20:30:55.321+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.322+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 66 (task 49, attempt 0, stage 3.0)
[2025-07-19T20:30:55.326+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 66.0 in stage 3.0 (TID 49). 9312 bytes result sent to driver
[2025-07-19T20:30:55.329+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 79.0 in stage 3.0 (TID 56) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.330+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 62 (task 46, attempt 0, stage 3.0)
[2025-07-19T20:30:55.330+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 66.0 in stage 3.0 (TID 49) in 257 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:30:55.332+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 62.0 in stage 3.0 (TID 46). 9294 bytes result sent to driver
[2025-07-19T20:30:55.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 80.0 in stage 3.0 (TID 57) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 62.0 in stage 3.0 (TID 46) in 415 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:30:55.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 79.0 in stage 3.0 (TID 56)
[2025-07-19T20:30:55.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 80.0 in stage 3.0 (TID 57)
[2025-07-19T20:30:55.340+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.342+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:55.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.1.delta.47fd2f8d-1a5a-4f12-99a9-64ee4a9ef03b.TID54.tmp
[2025-07-19T20:30:55.344+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.1.delta.6433965b-d4ec-4da5-ba32-bd9fb4e1bcfc.TID55.tmp
[2025-07-19T20:30:55.353+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@210d62ba
[2025-07-19T20:30:55.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79] for update
[2025-07-19T20:30:55.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.1.delta.e5d1d2ab-cfd7-45f4-8d35-93965809a38e.TID50.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta
[2025-07-19T20:30:55.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta
[2025-07-19T20:30:55.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 50, attempt 0, stage 3.0)
[2025-07-19T20:30:55.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a149b07
[2025-07-19T20:30:55.382+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.384+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80] for update
[2025-07-19T20:30:55.384+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.395+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.1.delta.4249c63f-2778-48dd-acce-2dabcb3ad2f4.TID52.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta
[2025-07-19T20:30:55.398+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta
[2025-07-19T20:30:55.398+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 52, attempt 0, stage 3.0)
[2025-07-19T20:30:55.405+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.1.delta.e1c88dbf-53e8-4a1d-827b-3e5c21bdd9ac.TID56.tmp
[2025-07-19T20:30:55.411+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.1.delta.9022d963-4edc-4b46-8e4d-d5d71badb145.TID51.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta
[2025-07-19T20:30:55.413+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta
[2025-07-19T20:30:55.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 51, attempt 0, stage 3.0)
[2025-07-19T20:30:55.416+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.1.delta.e2247aec-5028-491b-aead-0cd810908900.TID53.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta
[2025-07-19T20:30:55.416+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta
[2025-07-19T20:30:55.417+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 53, attempt 0, stage 3.0)
[2025-07-19T20:30:55.418+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.1.delta.fc7802fd-852b-4cd0-ba10-d36bb7fdee55.TID57.tmp
[2025-07-19T20:30:55.426+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 68 (task 50, attempt 0, stage 3.0)
[2025-07-19T20:30:55.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 68.0 in stage 3.0 (TID 50). 9306 bytes result sent to driver
[2025-07-19T20:30:55.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 82.0 in stage 3.0 (TID 58) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 82.0 in stage 3.0 (TID 58)
[2025-07-19T20:30:55.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 68.0 in stage 3.0 (TID 50) in 283 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:30:55.435+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.435+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.442+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.1.delta.6433965b-d4ec-4da5-ba32-bd9fb4e1bcfc.TID55.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta
[2025-07-19T20:30:55.444+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta
[2025-07-19T20:30:55.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 55, attempt 0, stage 3.0)
[2025-07-19T20:30:55.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6217a096
[2025-07-19T20:30:55.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.446+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82] for update
[2025-07-19T20:30:55.449+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 71 (task 51, attempt 0, stage 3.0)
[2025-07-19T20:30:55.450+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.1.delta.47fd2f8d-1a5a-4f12-99a9-64ee4a9ef03b.TID54.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta
[2025-07-19T20:30:55.451+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta
[2025-07-19T20:30:55.452+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 54, attempt 0, stage 3.0)
[2025-07-19T20:30:55.453+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 71.0 in stage 3.0 (TID 51). 9300 bytes result sent to driver
[2025-07-19T20:30:55.454+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 83.0 in stage 3.0 (TID 59) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.455+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 83.0 in stage 3.0 (TID 59)
[2025-07-19T20:30:55.456+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (593.0 B) non-empty blocks including 1 (593.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.459+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.460+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 71.0 in stage 3.0 (TID 51) in 299 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:30:55.461+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 73 (task 52, attempt 0, stage 3.0)
[2025-07-19T20:30:55.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 73.0 in stage 3.0 (TID 52). 9277 bytes result sent to driver
[2025-07-19T20:30:55.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 86.0 in stage 3.0 (TID 60) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.464+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 86.0 in stage 3.0 (TID 60)
[2025-07-19T20:30:55.465+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 73.0 in stage 3.0 (TID 52) in 300 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:30:55.469+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.470+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:55.470+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 74 (task 53, attempt 0, stage 3.0)
[2025-07-19T20:30:55.471+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@359d7b0
[2025-07-19T20:30:55.471+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 74.0 in stage 3.0 (TID 53). 9304 bytes result sent to driver
[2025-07-19T20:30:55.472+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 87.0 in stage 3.0 (TID 61) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.473+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.473+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83] for update
[2025-07-19T20:30:55.475+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 87.0 in stage 3.0 (TID 61)
[2025-07-19T20:30:55.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 74.0 in stage 3.0 (TID 53) in 289 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:30:55.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 77 (task 55, attempt 0, stage 3.0)
[2025-07-19T20:30:55.483+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 76 (task 54, attempt 0, stage 3.0)
[2025-07-19T20:30:55.483+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 77.0 in stage 3.0 (TID 55). 9249 bytes result sent to driver
[2025-07-19T20:30:55.483+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 76.0 in stage 3.0 (TID 54). 9309 bytes result sent to driver
[2025-07-19T20:30:55.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 88.0 in stage 3.0 (TID 62) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.487+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 90.0 in stage 3.0 (TID 63) (8b44f3d35cfa, executor driver, partition 90, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.489+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.1.delta.e1c88dbf-53e8-4a1d-827b-3e5c21bdd9ac.TID56.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta
[2025-07-19T20:30:55.489+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta
[2025-07-19T20:30:55.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 56, attempt 0, stage 3.0)
[2025-07-19T20:30:55.491+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 77.0 in stage 3.0 (TID 55) in 198 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:30:55.492+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 76.0 in stage 3.0 (TID 54) in 242 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:30:55.492+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 88.0 in stage 3.0 (TID 62)
[2025-07-19T20:30:55.493+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.1.delta.21197a20-466b-409b-a9c0-a299857cb144.TID58.tmp
[2025-07-19T20:30:55.493+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@225a18eb
[2025-07-19T20:30:55.494+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 90.0 in stage 3.0 (TID 63)
[2025-07-19T20:30:55.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.1.delta.fc7802fd-852b-4cd0-ba10-d36bb7fdee55.TID57.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta
[2025-07-19T20:30:55.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta
[2025-07-19T20:30:55.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.496+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.497+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.497+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86] for update
[2025-07-19T20:30:55.498+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.1.delta.1ac218ec-7573-4b7d-beae-67efe1e92246.TID59.tmp
[2025-07-19T20:30:55.500+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 57, attempt 0, stage 3.0)
[2025-07-19T20:30:55.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:55.507+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.512+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d628cc4
[2025-07-19T20:30:55.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87] for update
[2025-07-19T20:30:55.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.1.delta.3c3e5de9-e306-42f8-9064-a27736028f61.TID60.tmp
[2025-07-19T20:30:55.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.518+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59e44159
[2025-07-19T20:30:55.520+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.521+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88] for update
[2025-07-19T20:30:55.523+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 79 (task 56, attempt 0, stage 3.0)
[2025-07-19T20:30:55.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 79.0 in stage 3.0 (TID 56). 9252 bytes result sent to driver
[2025-07-19T20:30:55.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 92.0 in stage 3.0 (TID 64) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 92.0 in stage 3.0 (TID 64)
[2025-07-19T20:30:55.526+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 79.0 in stage 3.0 (TID 56) in 195 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:30:55.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 80 (task 57, attempt 0, stage 3.0)
[2025-07-19T20:30:55.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 80.0 in stage 3.0 (TID 57). 9251 bytes result sent to driver
[2025-07-19T20:30:55.533+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 93.0 in stage 3.0 (TID 65) (8b44f3d35cfa, executor driver, partition 93, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 80.0 in stage 3.0 (TID 57) in 200 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:30:55.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 93.0 in stage 3.0 (TID 65)
[2025-07-19T20:30:55.537+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.540+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.1.delta.e508bc99-f9e3-496e-9837-51e0daf7b12c.TID61.tmp
[2025-07-19T20:30:55.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.545+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:30:55.545+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3237cdda
[2025-07-19T20:30:55.547+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.1.delta.4512bf70-ed4f-40c0-8e31-ce0aca69ce2b.TID62.tmp
[2025-07-19T20:30:55.547+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.549+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90] for update
[2025-07-19T20:30:55.551+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.555+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.1.delta.21197a20-466b-409b-a9c0-a299857cb144.TID58.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta
[2025-07-19T20:30:55.558+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta
[2025-07-19T20:30:55.560+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 58, attempt 0, stage 3.0)
[2025-07-19T20:30:55.561+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cc6470c
[2025-07-19T20:30:55.562+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.563+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92] for update
[2025-07-19T20:30:55.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.1.delta.1ac218ec-7573-4b7d-beae-67efe1e92246.TID59.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta
[2025-07-19T20:30:55.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta
[2025-07-19T20:30:55.565+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 59, attempt 0, stage 3.0)
[2025-07-19T20:30:55.565+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.569+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.1.delta.0abfec5e-88f3-4c0b-bb77-79d2468ffb74.TID63.tmp
[2025-07-19T20:30:55.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@396531ef
[2025-07-19T20:30:55.578+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.580+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93] for update
[2025-07-19T20:30:55.581+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.1.delta.e2a24997-fbbe-498d-b099-d84c1573a932.TID64.tmp
[2025-07-19T20:30:55.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 82 (task 58, attempt 0, stage 3.0)
[2025-07-19T20:30:55.590+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 82.0 in stage 3.0 (TID 58). 9265 bytes result sent to driver
[2025-07-19T20:30:55.592+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 96.0 in stage 3.0 (TID 66) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.593+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 82.0 in stage 3.0 (TID 58) in 162 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:30:55.593+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 96.0 in stage 3.0 (TID 66)
[2025-07-19T20:30:55.596+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.1.delta.de734b6d-d3b5-4583-ba85-501b4c62679b.TID65.tmp
[2025-07-19T20:30:55.602+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.602+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.604+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.1.delta.3c3e5de9-e306-42f8-9064-a27736028f61.TID60.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta
[2025-07-19T20:30:55.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta
[2025-07-19T20:30:55.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 60, attempt 0, stage 3.0)
[2025-07-19T20:30:55.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.1.delta.e508bc99-f9e3-496e-9837-51e0daf7b12c.TID61.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta
[2025-07-19T20:30:55.610+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta
[2025-07-19T20:30:55.614+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 61, attempt 0, stage 3.0)
[2025-07-19T20:30:55.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 83 (task 59, attempt 0, stage 3.0)
[2025-07-19T20:30:55.620+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 83.0 in stage 3.0 (TID 59). 9304 bytes result sent to driver
[2025-07-19T20:30:55.621+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 97.0 in stage 3.0 (TID 67) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.622+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 83.0 in stage 3.0 (TID 59) in 171 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:30:55.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d0da7df
[2025-07-19T20:30:55.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96] for update
[2025-07-19T20:30:55.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 97.0 in stage 3.0 (TID 67)
[2025-07-19T20:30:55.636+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.637+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.639+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:55.647+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.1.delta.4512bf70-ed4f-40c0-8e31-ce0aca69ce2b.TID62.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta
[2025-07-19T20:30:55.648+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta
[2025-07-19T20:30:55.651+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 62, attempt 0, stage 3.0)
[2025-07-19T20:30:55.659+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.1.delta.e2a24997-fbbe-498d-b099-d84c1573a932.TID64.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta
[2025-07-19T20:30:55.660+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta
[2025-07-19T20:30:55.660+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@158c1db
[2025-07-19T20:30:55.661+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 64, attempt 0, stage 3.0)
[2025-07-19T20:30:55.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.674+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97] for update
[2025-07-19T20:30:55.676+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.677+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.1.delta.18375eb5-7635-42ff-880e-8c5972381015.TID66.tmp
[2025-07-19T20:30:55.678+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 87 (task 61, attempt 0, stage 3.0)
[2025-07-19T20:30:55.678+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 86 (task 60, attempt 0, stage 3.0)
[2025-07-19T20:30:55.678+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 86.0 in stage 3.0 (TID 60). 9272 bytes result sent to driver
[2025-07-19T20:30:55.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 99.0 in stage 3.0 (TID 68) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 87.0 in stage 3.0 (TID 61). 9310 bytes result sent to driver
[2025-07-19T20:30:55.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 86.0 in stage 3.0 (TID 60) in 210 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:30:55.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 99.0 in stage 3.0 (TID 68)
[2025-07-19T20:30:55.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.1.delta.de734b6d-d3b5-4583-ba85-501b4c62679b.TID65.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta
[2025-07-19T20:30:55.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta
[2025-07-19T20:30:55.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 65, attempt 0, stage 3.0)
[2025-07-19T20:30:55.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 100.0 in stage 3.0 (TID 69) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 87.0 in stage 3.0 (TID 61) in 203 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:30:55.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 100.0 in stage 3.0 (TID 69)
[2025-07-19T20:30:55.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:55.682+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.1.delta.0abfec5e-88f3-4c0b-bb77-79d2468ffb74.TID63.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta
[2025-07-19T20:30:55.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta
[2025-07-19T20:30:55.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.1.delta.b90852c6-a5a1-4a19-8c5a-3fd788668ddc.TID67.tmp
[2025-07-19T20:30:55.688+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:55.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 63, attempt 0, stage 3.0)
[2025-07-19T20:30:55.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@232db35d
[2025-07-19T20:30:55.690+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.690+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99] for update
[2025-07-19T20:30:55.690+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 88 (task 62, attempt 0, stage 3.0)
[2025-07-19T20:30:55.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 88.0 in stage 3.0 (TID 62). 9261 bytes result sent to driver
[2025-07-19T20:30:55.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 102.0 in stage 3.0 (TID 70) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 102.0 in stage 3.0 (TID 70)
[2025-07-19T20:30:55.696+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.699+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e7f2e1d
[2025-07-19T20:30:55.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 88.0 in stage 3.0 (TID 62) in 219 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:30:55.706+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.706+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.709+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:55.709+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100] for update
[2025-07-19T20:30:55.711+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 92 (task 64, attempt 0, stage 3.0)
[2025-07-19T20:30:55.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 93 (task 65, attempt 0, stage 3.0)
[2025-07-19T20:30:55.717+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 92.0 in stage 3.0 (TID 64). 9238 bytes result sent to driver
[2025-07-19T20:30:55.718+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 103.0 in stage 3.0 (TID 71) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.720+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 93.0 in stage 3.0 (TID 65). 9226 bytes result sent to driver
[2025-07-19T20:30:55.720+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 105.0 in stage 3.0 (TID 72) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.722+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55cf7236
[2025-07-19T20:30:55.725+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 105.0 in stage 3.0 (TID 72)
[2025-07-19T20:30:55.726+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.729+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102] for update
[2025-07-19T20:30:55.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 103.0 in stage 3.0 (TID 71)
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 93.0 in stage 3.0 (TID 65) in 187 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 92.0 in stage 3.0 (TID 64) in 201 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 90 (task 63, attempt 0, stage 3.0)
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.1.delta.c50bf07a-612f-4f57-8d70-4536631a2fc7.TID68.tmp
[2025-07-19T20:30:55.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.732+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:55.738+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 90.0 in stage 3.0 (TID 63). 9344 bytes result sent to driver
[2025-07-19T20:30:55.738+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 106.0 in stage 3.0 (TID 73) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.739+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.1.delta.18375eb5-7635-42ff-880e-8c5972381015.TID66.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta
[2025-07-19T20:30:55.739+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta
[2025-07-19T20:30:55.739+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 90.0 in stage 3.0 (TID 63) in 253 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:30:55.741+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 106.0 in stage 3.0 (TID 73)
[2025-07-19T20:30:55.742+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 66, attempt 0, stage 3.0)
[2025-07-19T20:30:55.742+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@598d32a5
[2025-07-19T20:30:55.743+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.1.delta.8fa994af-0dbc-4fd3-8c18-af4bc8758112.TID70.tmp
[2025-07-19T20:30:55.756+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.759+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.1.delta.d7196ec7-ea76-476f-9bcc-d8b191cc495b.TID69.tmp
[2025-07-19T20:30:55.772+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.772+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.773+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105] for update
[2025-07-19T20:30:55.773+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6178afb
[2025-07-19T20:30:55.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.778+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103] for update
[2025-07-19T20:30:55.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.1.delta.be39e9a5-f1c6-4e4e-bdad-3f49c7b1631e.TID72.tmp
[2025-07-19T20:30:55.787+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.794+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f4f4871
[2025-07-19T20:30:55.795+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.796+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106] for update
[2025-07-19T20:30:55.800+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 96 (task 66, attempt 0, stage 3.0)
[2025-07-19T20:30:55.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 96.0 in stage 3.0 (TID 66). 9323 bytes result sent to driver
[2025-07-19T20:30:55.816+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.1.delta.38d927c7-99f3-40b0-b814-8a4964034a89.TID71.tmp
[2025-07-19T20:30:55.817+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 109.0 in stage 3.0 (TID 74) (8b44f3d35cfa, executor driver, partition 109, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.817+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 96.0 in stage 3.0 (TID 66) in 225 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:30:55.817+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 109.0 in stage 3.0 (TID 74)
[2025-07-19T20:30:55.818+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.1.delta.b90852c6-a5a1-4a19-8c5a-3fd788668ddc.TID67.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta
[2025-07-19T20:30:55.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta
[2025-07-19T20:30:55.820+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 67, attempt 0, stage 3.0)
[2025-07-19T20:30:55.820+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.1.delta.1923c84b-4220-4fab-ad10-d5f94808dcfd.TID73.tmp
[2025-07-19T20:30:55.828+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.829+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.839+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ea3d13d
[2025-07-19T20:30:55.840+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.840+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109] for update
[2025-07-19T20:30:55.842+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.1.delta.8fa994af-0dbc-4fd3-8c18-af4bc8758112.TID70.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta
[2025-07-19T20:30:55.844+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta
[2025-07-19T20:30:55.845+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 70, attempt 0, stage 3.0)
[2025-07-19T20:30:55.847+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.1.delta.d7196ec7-ea76-476f-9bcc-d8b191cc495b.TID69.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta
[2025-07-19T20:30:55.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta
[2025-07-19T20:30:55.851+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 69, attempt 0, stage 3.0)
[2025-07-19T20:30:55.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.1.delta.6ffdef1b-d482-4ae7-accb-3f007e057f73.TID74.tmp
[2025-07-19T20:30:55.862+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.1.delta.c50bf07a-612f-4f57-8d70-4536631a2fc7.TID68.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta
[2025-07-19T20:30:55.862+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta
[2025-07-19T20:30:55.863+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 68, attempt 0, stage 3.0)
[2025-07-19T20:30:55.864+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 97 (task 67, attempt 0, stage 3.0)
[2025-07-19T20:30:55.867+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 97.0 in stage 3.0 (TID 67). 9306 bytes result sent to driver
[2025-07-19T20:30:55.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 110.0 in stage 3.0 (TID 75) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 110.0 in stage 3.0 (TID 75)
[2025-07-19T20:30:55.872+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.1.delta.38d927c7-99f3-40b0-b814-8a4964034a89.TID71.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta
[2025-07-19T20:30:55.872+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta
[2025-07-19T20:30:55.872+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 71, attempt 0, stage 3.0)
[2025-07-19T20:30:55.873+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 97.0 in stage 3.0 (TID 67) in 254 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:30:55.876+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 102 (task 70, attempt 0, stage 3.0)
[2025-07-19T20:30:55.877+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 102.0 in stage 3.0 (TID 70). 9286 bytes result sent to driver
[2025-07-19T20:30:55.878+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 102.0 in stage 3.0 (TID 70) in 182 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:30:55.878+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 111.0 in stage 3.0 (TID 76) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.879+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.1.delta.be39e9a5-f1c6-4e4e-bdad-3f49c7b1631e.TID72.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta
[2025-07-19T20:30:55.880+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta
[2025-07-19T20:30:55.881+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 72, attempt 0, stage 3.0)
[2025-07-19T20:30:55.882+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 111.0 in stage 3.0 (TID 76)
[2025-07-19T20:30:55.883+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.884+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.884+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.884+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.885+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.1.delta.1923c84b-4220-4fab-ad10-d5f94808dcfd.TID73.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta
[2025-07-19T20:30:55.885+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta
[2025-07-19T20:30:55.886+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 100 (task 69, attempt 0, stage 3.0)
[2025-07-19T20:30:55.886+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 73, attempt 0, stage 3.0)
[2025-07-19T20:30:55.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 100.0 in stage 3.0 (TID 69). 9293 bytes result sent to driver
[2025-07-19T20:30:55.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 112.0 in stage 3.0 (TID 77) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 112.0 in stage 3.0 (TID 77)
[2025-07-19T20:30:55.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10b9f677
[2025-07-19T20:30:55.894+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 100.0 in stage 3.0 (TID 69) in 215 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:30:55.894+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.894+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110] for update
[2025-07-19T20:30:55.896+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.898+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@138b0db9
[2025-07-19T20:30:55.898+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112] for update
[2025-07-19T20:30:55.903+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 99 (task 68, attempt 0, stage 3.0)
[2025-07-19T20:30:55.903+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 99.0 in stage 3.0 (TID 68). 9320 bytes result sent to driver
[2025-07-19T20:30:55.903+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.904+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 113.0 in stage 3.0 (TID 78) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.905+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 99.0 in stage 3.0 (TID 68) in 235 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:30:55.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 113.0 in stage 3.0 (TID 78)
[2025-07-19T20:30:55.910+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 103 (task 71, attempt 0, stage 3.0)
[2025-07-19T20:30:55.913+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 106 (task 73, attempt 0, stage 3.0)
[2025-07-19T20:30:55.914+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 105 (task 72, attempt 0, stage 3.0)
[2025-07-19T20:30:55.914+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 103.0 in stage 3.0 (TID 71). 9303 bytes result sent to driver
[2025-07-19T20:30:55.914+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 106.0 in stage 3.0 (TID 73). 9290 bytes result sent to driver
[2025-07-19T20:30:55.916+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 105.0 in stage 3.0 (TID 72). 9294 bytes result sent to driver
[2025-07-19T20:30:55.917+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.1.delta.6ffdef1b-d482-4ae7-accb-3f007e057f73.TID74.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta
[2025-07-19T20:30:55.917+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta
[2025-07-19T20:30:55.917+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 114.0 in stage 3.0 (TID 79) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 116.0 in stage 3.0 (TID 80) (8b44f3d35cfa, executor driver, partition 116, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 117.0 in stage 3.0 (TID 81) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 105.0 in stage 3.0 (TID 72) in 194 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:30:55.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 106.0 in stage 3.0 (TID 73) in 172 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:30:55.920+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 114.0 in stage 3.0 (TID 79)
[2025-07-19T20:30:55.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 74, attempt 0, stage 3.0)
[2025-07-19T20:30:55.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 116.0 in stage 3.0 (TID 80)
[2025-07-19T20:30:55.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 117.0 in stage 3.0 (TID 81)
[2025-07-19T20:30:55.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4916bfc7
[2025-07-19T20:30:55.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111] for update
[2025-07-19T20:30:55.923+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.925+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.927+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.928+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.929+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.930+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.1.delta.b34f5c01-1a46-4ba1-be10-b87c7a4f2aa4.TID75.tmp
[2025-07-19T20:30:55.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 103.0 in stage 3.0 (TID 71) in 205 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:30:55.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9c65ab8
[2025-07-19T20:30:55.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113] for update
[2025-07-19T20:30:55.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.1.delta.e186859e-bcd9-4d20-b069-4358d90a386b.TID77.tmp
[2025-07-19T20:30:55.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47c9e201
[2025-07-19T20:30:55.933+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.933+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.1.delta.992c4d69-c268-4ece-ad25-b58c39fcdf7a.TID76.tmp
[2025-07-19T20:30:55.934+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.934+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116] for update
[2025-07-19T20:30:55.934+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@175010d2
[2025-07-19T20:30:55.947+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.947+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117] for update
[2025-07-19T20:30:55.947+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.1.delta.e9bb174a-9343-4eb0-bc70-40791be99635.TID78.tmp
[2025-07-19T20:30:55.948+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.948+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Committed partition 109 (task 74, attempt 0, stage 3.0)
[2025-07-19T20:30:55.949+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Finished task 109.0 in stage 3.0 (TID 74). 9313 bytes result sent to driver
[2025-07-19T20:30:55.949+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Starting task 118.0 in stage 3.0 (TID 82) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:55.952+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO Executor: Running task 118.0 in stage 3.0 (TID 82)
[2025-07-19T20:30:55.952+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO TaskSetManager: Finished task 109.0 in stage 3.0 (TID 74) in 140 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:30:55.952+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.1.delta.f4053a29-78fc-4c79-8d46-f3bc4f032dff.TID80.tmp
[2025-07-19T20:30:55.956+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:55.956+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:55.958+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7033e31a
[2025-07-19T20:30:55.959+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114] for update
[2025-07-19T20:30:55.967+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.1.delta.008fd41e-9d4e-442a-82c7-12979771785b.TID81.tmp
[2025-07-19T20:30:55.968+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ec328d3
[2025-07-19T20:30:55.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:55.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118] for update
[2025-07-19T20:30:55.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:55.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.1.delta.e186859e-bcd9-4d20-b069-4358d90a386b.TID77.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta
[2025-07-19T20:30:55.985+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta
[2025-07-19T20:30:55.986+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.1.delta.43ff69fb-537e-4265-aa84-c4835f5977ef.TID79.tmp
[2025-07-19T20:30:55.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 77, attempt 0, stage 3.0)
[2025-07-19T20:30:55.996+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.1.delta.992c4d69-c268-4ece-ad25-b58c39fcdf7a.TID76.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta
[2025-07-19T20:30:55.996+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta
[2025-07-19T20:30:55.996+0000] {subprocess.py:93} INFO - 25/07/19 20:30:55 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 76, attempt 0, stage 3.0)
[2025-07-19T20:30:56.002+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.1.delta.8087f48b-e1c3-481d-93b0-33e3421a6c61.TID82.tmp
[2025-07-19T20:30:56.003+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.1.delta.b34f5c01-1a46-4ba1-be10-b87c7a4f2aa4.TID75.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta
[2025-07-19T20:30:56.004+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta
[2025-07-19T20:30:56.005+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 75, attempt 0, stage 3.0)
[2025-07-19T20:30:56.012+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 112 (task 77, attempt 0, stage 3.0)
[2025-07-19T20:30:56.013+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.1.delta.e9bb174a-9343-4eb0-bc70-40791be99635.TID78.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta
[2025-07-19T20:30:56.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta
[2025-07-19T20:30:56.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 112.0 in stage 3.0 (TID 77). 9253 bytes result sent to driver
[2025-07-19T20:30:56.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 112.0 in stage 3.0 (TID 77) in 127 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:30:56.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 119.0 in stage 3.0 (TID 83) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 119.0 in stage 3.0 (TID 83)
[2025-07-19T20:30:56.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 78, attempt 0, stage 3.0)
[2025-07-19T20:30:56.017+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.017+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.036+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36150641
[2025-07-19T20:30:56.037+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.039+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119] for update
[2025-07-19T20:30:56.047+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 111 (task 76, attempt 0, stage 3.0)
[2025-07-19T20:30:56.048+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.1.delta.f4053a29-78fc-4c79-8d46-f3bc4f032dff.TID80.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta
[2025-07-19T20:30:56.050+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta
[2025-07-19T20:30:56.050+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 80, attempt 0, stage 3.0)
[2025-07-19T20:30:56.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 111.0 in stage 3.0 (TID 76). 9310 bytes result sent to driver
[2025-07-19T20:30:56.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.1.delta.008fd41e-9d4e-442a-82c7-12979771785b.TID81.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta
[2025-07-19T20:30:56.054+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta
[2025-07-19T20:30:56.058+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 81, attempt 0, stage 3.0)
[2025-07-19T20:30:56.059+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 120.0 in stage 3.0 (TID 84) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.060+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 111.0 in stage 3.0 (TID 76) in 173 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:30:56.061+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.1.delta.43ff69fb-537e-4265-aa84-c4835f5977ef.TID79.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta
[2025-07-19T20:30:56.062+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta
[2025-07-19T20:30:56.062+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 110 (task 75, attempt 0, stage 3.0)
[2025-07-19T20:30:56.063+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 113 (task 78, attempt 0, stage 3.0)
[2025-07-19T20:30:56.063+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 110.0 in stage 3.0 (TID 75). 9262 bytes result sent to driver
[2025-07-19T20:30:56.063+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 113.0 in stage 3.0 (TID 78). 9241 bytes result sent to driver
[2025-07-19T20:30:56.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 120.0 in stage 3.0 (TID 84)
[2025-07-19T20:30:56.065+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 79, attempt 0, stage 3.0)
[2025-07-19T20:30:56.065+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 124.0 in stage 3.0 (TID 85) (8b44f3d35cfa, executor driver, partition 124, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.066+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 125.0 in stage 3.0 (TID 86) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.067+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 125.0 in stage 3.0 (TID 86)
[2025-07-19T20:30:56.068+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 110.0 in stage 3.0 (TID 75) in 200 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:30:56.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 113.0 in stage 3.0 (TID 78) in 166 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:30:56.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 124.0 in stage 3.0 (TID 85)
[2025-07-19T20:30:56.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:56.077+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.1.delta.dbcd2d93-2dc9-43c3-8e05-70aecbbf5e00.TID83.tmp
[2025-07-19T20:30:56.078+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6532f4de
[2025-07-19T20:30:56.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125] for update
[2025-07-19T20:30:56.085+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.1.delta.8087f48b-e1c3-481d-93b0-33e3421a6c61.TID82.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta
[2025-07-19T20:30:56.086+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta
[2025-07-19T20:30:56.087+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 82, attempt 0, stage 3.0)
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 117 (task 81, attempt 0, stage 3.0)
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 116 (task 80, attempt 0, stage 3.0)
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 117.0 in stage 3.0 (TID 81). 9271 bytes result sent to driver
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 126.0 in stage 3.0 (TID 87) (8b44f3d35cfa, executor driver, partition 126, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 126.0 in stage 3.0 (TID 87)
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 117.0 in stage 3.0 (TID 81) in 176 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 116.0 in stage 3.0 (TID 80). 9264 bytes result sent to driver
[2025-07-19T20:30:56.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:56.091+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 127.0 in stage 3.0 (TID 88) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.092+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 127.0 in stage 3.0 (TID 88)
[2025-07-19T20:30:56.093+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 114 (task 79, attempt 0, stage 3.0)
[2025-07-19T20:30:56.095+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 116.0 in stage 3.0 (TID 80) in 184 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:30:56.095+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 114.0 in stage 3.0 (TID 79). 9253 bytes result sent to driver
[2025-07-19T20:30:56.096+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18581439
[2025-07-19T20:30:56.096+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.097+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 128.0 in stage 3.0 (TID 89) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.097+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120] for update
[2025-07-19T20:30:56.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 128.0 in stage 3.0 (TID 89)
[2025-07-19T20:30:56.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 114.0 in stage 3.0 (TID 79) in 188 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:30:56.101+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.101+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:56.103+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:56.103+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 118 (task 82, attempt 0, stage 3.0)
[2025-07-19T20:30:56.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 118.0 in stage 3.0 (TID 82). 9218 bytes result sent to driver
[2025-07-19T20:30:56.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 130.0 in stage 3.0 (TID 90) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 130.0 in stage 3.0 (TID 90)
[2025-07-19T20:30:56.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 118.0 in stage 3.0 (TID 82) in 155 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:30:56.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.110+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.110+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.1.delta.5ea7f1f5-63d7-41ca-b71b-9d25c01c38a1.TID86.tmp
[2025-07-19T20:30:56.111+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c8bbf18
[2025-07-19T20:30:56.111+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.111+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124] for update
[2025-07-19T20:30:56.112+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.1.delta.920139ad-768d-4d68-951b-16d410d921e1.TID84.tmp
[2025-07-19T20:30:56.113+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.123+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10ec9c0f
[2025-07-19T20:30:56.123+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126] for update
[2025-07-19T20:30:56.125+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.1.delta.8f810bd2-5fdb-4b92-bf0f-8f359dbebe19.TID85.tmp
[2025-07-19T20:30:56.126+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7da95506
[2025-07-19T20:30:56.135+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.1.delta.dbcd2d93-2dc9-43c3-8e05-70aecbbf5e00.TID83.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta
[2025-07-19T20:30:56.136+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta
[2025-07-19T20:30:56.136+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.136+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.1.delta.190ffbba-79b1-4a73-8293-183de19c3074.TID87.tmp
[2025-07-19T20:30:56.136+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 83, attempt 0, stage 3.0)
[2025-07-19T20:30:56.137+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130] for update
[2025-07-19T20:30:56.143+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b8a313e
[2025-07-19T20:30:56.145+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.145+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128] for update
[2025-07-19T20:30:56.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.150+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34d90621
[2025-07-19T20:30:56.150+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.1.delta.920139ad-768d-4d68-951b-16d410d921e1.TID84.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta
[2025-07-19T20:30:56.150+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta
[2025-07-19T20:30:56.152+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.1.delta.5ea7f1f5-63d7-41ca-b71b-9d25c01c38a1.TID86.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta
[2025-07-19T20:30:56.153+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta
[2025-07-19T20:30:56.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 86, attempt 0, stage 3.0)
[2025-07-19T20:30:56.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 84, attempt 0, stage 3.0)
[2025-07-19T20:30:56.157+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.157+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.157+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127] for update
[2025-07-19T20:30:56.158+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.162+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.1.delta.027698e0-9646-4b8b-8b1d-42aeeef18459.TID89.tmp
[2025-07-19T20:30:56.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.1.delta.190ffbba-79b1-4a73-8293-183de19c3074.TID87.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta
[2025-07-19T20:30:56.169+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta
[2025-07-19T20:30:56.169+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 87, attempt 0, stage 3.0)
[2025-07-19T20:30:56.170+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.1.delta.8f810bd2-5fdb-4b92-bf0f-8f359dbebe19.TID85.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta
[2025-07-19T20:30:56.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta
[2025-07-19T20:30:56.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 85, attempt 0, stage 3.0)
[2025-07-19T20:30:56.177+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.1.delta.11bd0d20-dfa0-4780-bc56-7e40a79e1259.TID90.tmp
[2025-07-19T20:30:56.177+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 119 (task 83, attempt 0, stage 3.0)
[2025-07-19T20:30:56.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 120 (task 84, attempt 0, stage 3.0)
[2025-07-19T20:30:56.182+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 120.0 in stage 3.0 (TID 84). 9263 bytes result sent to driver
[2025-07-19T20:30:56.183+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 131.0 in stage 3.0 (TID 91) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.183+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 120.0 in stage 3.0 (TID 84) in 132 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:30:56.184+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 131.0 in stage 3.0 (TID 91)
[2025-07-19T20:30:56.186+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 119.0 in stage 3.0 (TID 83). 9286 bytes result sent to driver
[2025-07-19T20:30:56.187+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 134.0 in stage 3.0 (TID 92) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.189+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.190+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:56.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 134.0 in stage 3.0 (TID 92)
[2025-07-19T20:30:56.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 119.0 in stage 3.0 (TID 83) in 178 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:30:56.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 125 (task 86, attempt 0, stage 3.0)
[2025-07-19T20:30:56.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.1.delta.3678b195-04c4-409e-b0b1-3bbe2067b351.TID88.tmp
[2025-07-19T20:30:56.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 126 (task 87, attempt 0, stage 3.0)
[2025-07-19T20:30:56.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 125.0 in stage 3.0 (TID 86). 9335 bytes result sent to driver
[2025-07-19T20:30:56.204+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 126.0 in stage 3.0 (TID 87). 9324 bytes result sent to driver
[2025-07-19T20:30:56.204+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 135.0 in stage 3.0 (TID 93) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.205+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a27601f
[2025-07-19T20:30:56.205+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.205+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.205+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131] for update
[2025-07-19T20:30:56.216+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.217+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 135.0 in stage 3.0 (TID 93)
[2025-07-19T20:30:56.218+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 136.0 in stage 3.0 (TID 94) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.219+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.219+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 126.0 in stage 3.0 (TID 87) in 122 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:30:56.220+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 136.0 in stage 3.0 (TID 94)
[2025-07-19T20:30:56.220+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14713b00
[2025-07-19T20:30:56.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 125.0 in stage 3.0 (TID 86) in 154 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:30:56.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134] for update
[2025-07-19T20:30:56.223+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.1.delta.51ec7fcb-2fcd-4dd6-94ab-072819a3622f.TID91.tmp
[2025-07-19T20:30:56.225+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
[2025-07-19T20:30:56.227+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64d0041f
[2025-07-19T20:30:56.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135] for update
[2025-07-19T20:30:56.232+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.1.delta.11bd0d20-dfa0-4780-bc56-7e40a79e1259.TID90.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta
[2025-07-19T20:30:56.233+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta
[2025-07-19T20:30:56.233+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 90, attempt 0, stage 3.0)
[2025-07-19T20:30:56.234+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.1.delta.027698e0-9646-4b8b-8b1d-42aeeef18459.TID89.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta
[2025-07-19T20:30:56.235+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta
[2025-07-19T20:30:56.235+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.243+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.245+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 124 (task 85, attempt 0, stage 3.0)
[2025-07-19T20:30:56.246+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5bc06388
[2025-07-19T20:30:56.246+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 89, attempt 0, stage 3.0)
[2025-07-19T20:30:56.248+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.250+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136] for update
[2025-07-19T20:30:56.250+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 124.0 in stage 3.0 (TID 85). 9296 bytes result sent to driver
[2025-07-19T20:30:56.260+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 137.0 in stage 3.0 (TID 95) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.261+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.1.delta.ee427245-f73a-41fa-96b5-48c228e74798.TID93.tmp
[2025-07-19T20:30:56.261+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 137.0 in stage 3.0 (TID 95)
[2025-07-19T20:30:56.262+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 124.0 in stage 3.0 (TID 85) in 197 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:30:56.268+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.1.delta.23b35567-d2e2-4f88-ae3b-c6408720b617.TID92.tmp
[2025-07-19T20:30:56.273+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.275+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.275+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.1.delta.76aa3af1-5c53-493e-ad46-8ceaa2149af1.TID94.tmp
[2025-07-19T20:30:56.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 130 (task 90, attempt 0, stage 3.0)
[2025-07-19T20:30:56.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 130.0 in stage 3.0 (TID 90). 9290 bytes result sent to driver
[2025-07-19T20:30:56.279+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.1.delta.3678b195-04c4-409e-b0b1-3bbe2067b351.TID88.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta
[2025-07-19T20:30:56.281+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta
[2025-07-19T20:30:56.281+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 140.0 in stage 3.0 (TID 96) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.282+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 140.0 in stage 3.0 (TID 96)
[2025-07-19T20:30:56.282+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 128 (task 89, attempt 0, stage 3.0)
[2025-07-19T20:30:56.284+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 128.0 in stage 3.0 (TID 89). 9275 bytes result sent to driver
[2025-07-19T20:30:56.286+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@776d02ee
[2025-07-19T20:30:56.291+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 141.0 in stage 3.0 (TID 97) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.301+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137] for update
[2025-07-19T20:30:56.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 130.0 in stage 3.0 (TID 90) in 185 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:30:56.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 128.0 in stage 3.0 (TID 89) in 193 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:30:56.306+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 141.0 in stage 3.0 (TID 97)
[2025-07-19T20:30:56.306+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.307+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 88, attempt 0, stage 3.0)
[2025-07-19T20:30:56.307+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.307+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:56.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.1.delta.bd314625-dd4c-458f-9ff3-78638433e4bd.TID95.tmp
[2025-07-19T20:30:56.310+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:56.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62734e83
[2025-07-19T20:30:56.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.319+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141] for update
[2025-07-19T20:30:56.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c21affd
[2025-07-19T20:30:56.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.1.delta.ee427245-f73a-41fa-96b5-48c228e74798.TID93.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta
[2025-07-19T20:30:56.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140] for update
[2025-07-19T20:30:56.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta
[2025-07-19T20:30:56.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 93, attempt 0, stage 3.0)
[2025-07-19T20:30:56.337+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.1.delta.51ec7fcb-2fcd-4dd6-94ab-072819a3622f.TID91.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta
[2025-07-19T20:30:56.337+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta
[2025-07-19T20:30:56.337+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 91, attempt 0, stage 3.0)
[2025-07-19T20:30:56.338+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.338+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.342+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 127 (task 88, attempt 0, stage 3.0)
[2025-07-19T20:30:56.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 127.0 in stage 3.0 (TID 88). 9285 bytes result sent to driver
[2025-07-19T20:30:56.346+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 142.0 in stage 3.0 (TID 98) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.347+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 142.0 in stage 3.0 (TID 98)
[2025-07-19T20:30:56.347+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 127.0 in stage 3.0 (TID 88) in 252 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:30:56.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.351+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.354+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.1.delta.ebf8f587-d503-4ecd-be06-06933362dd6c.TID97.tmp
[2025-07-19T20:30:56.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@284f5745
[2025-07-19T20:30:56.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 131 (task 91, attempt 0, stage 3.0)
[2025-07-19T20:30:56.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.1.delta.e5f09e32-7239-48fb-a760-079c41ccf513.TID96.tmp
[2025-07-19T20:30:56.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 135 (task 93, attempt 0, stage 3.0)
[2025-07-19T20:30:56.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142] for update
[2025-07-19T20:30:56.367+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 131.0 in stage 3.0 (TID 91). 9339 bytes result sent to driver
[2025-07-19T20:30:56.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.1.delta.23b35567-d2e2-4f88-ae3b-c6408720b617.TID92.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta
[2025-07-19T20:30:56.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta
[2025-07-19T20:30:56.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 144.0 in stage 3.0 (TID 99) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.373+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 92, attempt 0, stage 3.0)
[2025-07-19T20:30:56.374+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 135.0 in stage 3.0 (TID 93). 9339 bytes result sent to driver
[2025-07-19T20:30:56.375+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 131.0 in stage 3.0 (TID 91) in 191 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:30:56.375+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 144.0 in stage 3.0 (TID 99)
[2025-07-19T20:30:56.376+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 145.0 in stage 3.0 (TID 100) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.376+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 135.0 in stage 3.0 (TID 93) in 173 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:30:56.376+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 145.0 in stage 3.0 (TID 100)
[2025-07-19T20:30:56.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.381+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fbe077c
[2025-07-19T20:30:56.381+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.382+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144] for update
[2025-07-19T20:30:56.382+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.1.delta.76aa3af1-5c53-493e-ad46-8ceaa2149af1.TID94.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta
[2025-07-19T20:30:56.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta
[2025-07-19T20:30:56.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 94, attempt 0, stage 3.0)
[2025-07-19T20:30:56.385+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.1.delta.96731072-50d7-47dc-8fbd-b8875c50864b.TID98.tmp
[2025-07-19T20:30:56.385+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.386+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.1.delta.bd314625-dd4c-458f-9ff3-78638433e4bd.TID95.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta
[2025-07-19T20:30:56.386+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta
[2025-07-19T20:30:56.391+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 95, attempt 0, stage 3.0)
[2025-07-19T20:30:56.391+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47ad52d8
[2025-07-19T20:30:56.391+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.392+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145] for update
[2025-07-19T20:30:56.395+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.410+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.1.delta.2ce44353-f2e2-4527-aa35-f31333c5c982.TID99.tmp
[2025-07-19T20:30:56.410+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.1.delta.b1e6759f-9ec1-4a69-b010-866bb4a8ed1a.TID100.tmp
[2025-07-19T20:30:56.410+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 134 (task 92, attempt 0, stage 3.0)
[2025-07-19T20:30:56.413+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 134.0 in stage 3.0 (TID 92). 9290 bytes result sent to driver
[2025-07-19T20:30:56.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 147.0 in stage 3.0 (TID 101) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 147.0 in stage 3.0 (TID 101)
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 134.0 in stage 3.0 (TID 92) in 230 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 136 (task 94, attempt 0, stage 3.0)
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 136.0 in stage 3.0 (TID 94). 9305 bytes result sent to driver
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 148.0 in stage 3.0 (TID 102) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 148.0 in stage 3.0 (TID 102)
[2025-07-19T20:30:56.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.416+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.418+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 136.0 in stage 3.0 (TID 94) in 216 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:30:56.422+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:56.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fa9bdd6
[2025-07-19T20:30:56.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147] for update
[2025-07-19T20:30:56.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.1.delta.ebf8f587-d503-4ecd-be06-06933362dd6c.TID97.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta
[2025-07-19T20:30:56.426+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta
[2025-07-19T20:30:56.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 97, attempt 0, stage 3.0)
[2025-07-19T20:30:56.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.1.delta.e5f09e32-7239-48fb-a760-079c41ccf513.TID96.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta
[2025-07-19T20:30:56.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta
[2025-07-19T20:30:56.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 137 (task 95, attempt 0, stage 3.0)
[2025-07-19T20:30:56.429+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 96, attempt 0, stage 3.0)
[2025-07-19T20:30:56.432+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 137.0 in stage 3.0 (TID 95). 9258 bytes result sent to driver
[2025-07-19T20:30:56.433+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 149.0 in stage 3.0 (TID 103) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.433+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 149.0 in stage 3.0 (TID 103)
[2025-07-19T20:30:56.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 137.0 in stage 3.0 (TID 95) in 177 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:30:56.444+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.1.delta.611fbaad-e29f-4223-a285-2df59aa73236.TID101.tmp
[2025-07-19T20:30:56.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.447+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21fa89c7
[2025-07-19T20:30:56.449+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.450+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148] for update
[2025-07-19T20:30:56.451+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.460+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 141 (task 97, attempt 0, stage 3.0)
[2025-07-19T20:30:56.461+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 141.0 in stage 3.0 (TID 97). 9222 bytes result sent to driver
[2025-07-19T20:30:56.461+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.1.delta.48a5d81a-e1fa-4abf-99a5-4d9c1afff9d4.TID102.tmp
[2025-07-19T20:30:56.462+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 151.0 in stage 3.0 (TID 104) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f96bd14
[2025-07-19T20:30:56.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149] for update
[2025-07-19T20:30:56.465+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 141.0 in stage 3.0 (TID 97) in 179 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:30:56.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 151.0 in stage 3.0 (TID 104)
[2025-07-19T20:30:56.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.1.delta.96731072-50d7-47dc-8fbd-b8875c50864b.TID98.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta
[2025-07-19T20:30:56.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta
[2025-07-19T20:30:56.468+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 98, attempt 0, stage 3.0)
[2025-07-19T20:30:56.468+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.469+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.476+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f05eb45
[2025-07-19T20:30:56.476+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.477+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151] for update
[2025-07-19T20:30:56.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.1.delta.b1e6759f-9ec1-4a69-b010-866bb4a8ed1a.TID100.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta
[2025-07-19T20:30:56.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.1.delta.2ce44353-f2e2-4527-aa35-f31333c5c982.TID99.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta
[2025-07-19T20:30:56.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.1.delta.73971ba3-fefd-418c-863c-b1eed59704f5.TID103.tmp
[2025-07-19T20:30:56.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta
[2025-07-19T20:30:56.483+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta
[2025-07-19T20:30:56.483+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 100, attempt 0, stage 3.0)
[2025-07-19T20:30:56.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 99, attempt 0, stage 3.0)
[2025-07-19T20:30:56.497+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.1.delta.9a970717-2d94-480e-8816-79767a2156ee.TID104.tmp
[2025-07-19T20:30:56.498+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.1.delta.611fbaad-e29f-4223-a285-2df59aa73236.TID101.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta
[2025-07-19T20:30:56.499+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta
[2025-07-19T20:30:56.500+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 142 (task 98, attempt 0, stage 3.0)
[2025-07-19T20:30:56.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 101, attempt 0, stage 3.0)
[2025-07-19T20:30:56.502+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 142.0 in stage 3.0 (TID 98). 9242 bytes result sent to driver
[2025-07-19T20:30:56.503+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 152.0 in stage 3.0 (TID 105) (8b44f3d35cfa, executor driver, partition 152, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.504+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 152.0 in stage 3.0 (TID 105)
[2025-07-19T20:30:56.505+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 142.0 in stage 3.0 (TID 98) in 160 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:30:56.507+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 140 (task 96, attempt 0, stage 3.0)
[2025-07-19T20:30:56.507+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 145 (task 100, attempt 0, stage 3.0)
[2025-07-19T20:30:56.508+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 145.0 in stage 3.0 (TID 100). 9252 bytes result sent to driver
[2025-07-19T20:30:56.509+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.509+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.510+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 140.0 in stage 3.0 (TID 96). 9226 bytes result sent to driver
[2025-07-19T20:30:56.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 153.0 in stage 3.0 (TID 106) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.514+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 155.0 in stage 3.0 (TID 107) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 145.0 in stage 3.0 (TID 100) in 143 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:30:56.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@adf6f33
[2025-07-19T20:30:56.517+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 140.0 in stage 3.0 (TID 96) in 236 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:30:56.519+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 153.0 in stage 3.0 (TID 106)
[2025-07-19T20:30:56.519+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 155.0 in stage 3.0 (TID 107)
[2025-07-19T20:30:56.522+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.523+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152] for update
[2025-07-19T20:30:56.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 144 (task 99, attempt 0, stage 3.0)
[2025-07-19T20:30:56.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.526+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 144.0 in stage 3.0 (TID 99). 9269 bytes result sent to driver
[2025-07-19T20:30:56.527+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.528+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.529+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 147 (task 101, attempt 0, stage 3.0)
[2025-07-19T20:30:56.529+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 156.0 in stage 3.0 (TID 108) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 147.0 in stage 3.0 (TID 101). 9239 bytes result sent to driver
[2025-07-19T20:30:56.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 144.0 in stage 3.0 (TID 99) in 153 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:30:56.531+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 156.0 in stage 3.0 (TID 108)
[2025-07-19T20:30:56.531+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 157.0 in stage 3.0 (TID 109) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.531+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:56.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 147.0 in stage 3.0 (TID 101) in 113 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:30:56.536+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.1.delta.48a5d81a-e1fa-4abf-99a5-4d9c1afff9d4.TID102.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta
[2025-07-19T20:30:56.537+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 157.0 in stage 3.0 (TID 109)
[2025-07-19T20:30:56.537+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta
[2025-07-19T20:30:56.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 102, attempt 0, stage 3.0)
[2025-07-19T20:30:56.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.540+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:56.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6483710
[2025-07-19T20:30:56.543+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.543+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155] for update
[2025-07-19T20:30:56.544+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.545+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.1.delta.73971ba3-fefd-418c-863c-b1eed59704f5.TID103.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta
[2025-07-19T20:30:56.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta
[2025-07-19T20:30:56.549+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 103, attempt 0, stage 3.0)
[2025-07-19T20:30:56.549+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f3bf07c
[2025-07-19T20:30:56.549+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.550+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157] for update
[2025-07-19T20:30:56.551+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.1.delta.aae2622f-4f7e-4227-847b-64a30d5b9a85.TID105.tmp
[2025-07-19T20:30:56.558+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.561+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.1.delta.9a970717-2d94-480e-8816-79767a2156ee.TID104.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta
[2025-07-19T20:30:56.561+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta
[2025-07-19T20:30:56.563+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 148 (task 102, attempt 0, stage 3.0)
[2025-07-19T20:30:56.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e2e2226
[2025-07-19T20:30:56.566+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 148.0 in stage 3.0 (TID 102). 9263 bytes result sent to driver
[2025-07-19T20:30:56.567+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 104, attempt 0, stage 3.0)
[2025-07-19T20:30:56.567+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.1.delta.46af693b-f085-4c16-bb23-337732b0b78d.TID107.tmp
[2025-07-19T20:30:56.569+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.570+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156] for update
[2025-07-19T20:30:56.570+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.574+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.1.delta.b53cceab-cebc-43f9-95ab-cb5e6409e5e7.TID109.tmp
[2025-07-19T20:30:56.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 149 (task 103, attempt 0, stage 3.0)
[2025-07-19T20:30:56.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 160.0 in stage 3.0 (TID 110) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 148.0 in stage 3.0 (TID 102) in 158 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:30:56.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 149.0 in stage 3.0 (TID 103). 9264 bytes result sent to driver
[2025-07-19T20:30:56.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 160.0 in stage 3.0 (TID 110)
[2025-07-19T20:30:56.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 162.0 in stage 3.0 (TID 111) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 162.0 in stage 3.0 (TID 111)
[2025-07-19T20:30:56.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 149.0 in stage 3.0 (TID 103) in 148 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:30:56.580+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@747984b5
[2025-07-19T20:30:56.581+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153] for update
[2025-07-19T20:30:56.584+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.586+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.586+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:56.589+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e1129b1
[2025-07-19T20:30:56.593+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.1.delta.a01a62aa-77a5-45b6-819f-e6688bc14aeb.TID108.tmp
[2025-07-19T20:30:56.599+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.600+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162] for update
[2025-07-19T20:30:56.603+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.605+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 151 (task 104, attempt 0, stage 3.0)
[2025-07-19T20:30:56.605+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.1.delta.db52c195-b53c-44c1-8cff-7c7a3f08e497.TID106.tmp
[2025-07-19T20:30:56.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 151.0 in stage 3.0 (TID 104). 9259 bytes result sent to driver
[2025-07-19T20:30:56.611+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f65ca79
[2025-07-19T20:30:56.611+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.612+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160] for update
[2025-07-19T20:30:56.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.1.delta.aae2622f-4f7e-4227-847b-64a30d5b9a85.TID105.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta
[2025-07-19T20:30:56.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta
[2025-07-19T20:30:56.614+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 165.0 in stage 3.0 (TID 112) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 105, attempt 0, stage 3.0)
[2025-07-19T20:30:56.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 151.0 in stage 3.0 (TID 104) in 149 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:30:56.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 165.0 in stage 3.0 (TID 112)
[2025-07-19T20:30:56.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.618+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.1.delta.59041563-91f6-4cc5-b340-57b9ac531a0c.TID111.tmp
[2025-07-19T20:30:56.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:56.634+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.1.delta.f340601d-4004-4864-86e6-b57ca647a8a2.TID110.tmp
[2025-07-19T20:30:56.635+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.1.delta.46af693b-f085-4c16-bb23-337732b0b78d.TID107.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta
[2025-07-19T20:30:56.636+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta
[2025-07-19T20:30:56.636+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 107, attempt 0, stage 3.0)
[2025-07-19T20:30:56.637+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.1.delta.b53cceab-cebc-43f9-95ab-cb5e6409e5e7.TID109.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta
[2025-07-19T20:30:56.637+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta
[2025-07-19T20:30:56.638+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 109, attempt 0, stage 3.0)
[2025-07-19T20:30:56.638+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@760b04c1
[2025-07-19T20:30:56.639+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.640+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165] for update
[2025-07-19T20:30:56.641+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.643+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.1.delta.a01a62aa-77a5-45b6-819f-e6688bc14aeb.TID108.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta
[2025-07-19T20:30:56.643+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta
[2025-07-19T20:30:56.644+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 108, attempt 0, stage 3.0)
[2025-07-19T20:30:56.657+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.1.delta.db52c195-b53c-44c1-8cff-7c7a3f08e497.TID106.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta
[2025-07-19T20:30:56.658+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta
[2025-07-19T20:30:56.658+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 106, attempt 0, stage 3.0)
[2025-07-19T20:30:56.661+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 152 (task 105, attempt 0, stage 3.0)
[2025-07-19T20:30:56.662+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 152.0 in stage 3.0 (TID 105). 9302 bytes result sent to driver
[2025-07-19T20:30:56.663+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 166.0 in stage 3.0 (TID 113) (8b44f3d35cfa, executor driver, partition 166, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.663+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.1.delta.9d7cc96c-7cef-4ae7-9ddc-005249c9f967.TID112.tmp
[2025-07-19T20:30:56.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 166.0 in stage 3.0 (TID 113)
[2025-07-19T20:30:56.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 152.0 in stage 3.0 (TID 105) in 163 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:30:56.670+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.671+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.679+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@de8a767
[2025-07-19T20:30:56.681+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 157 (task 109, attempt 0, stage 3.0)
[2025-07-19T20:30:56.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.684+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166] for update
[2025-07-19T20:30:56.685+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.688+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 157.0 in stage 3.0 (TID 109). 9331 bytes result sent to driver
[2025-07-19T20:30:56.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 155 (task 107, attempt 0, stage 3.0)
[2025-07-19T20:30:56.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 155.0 in stage 3.0 (TID 107). 9276 bytes result sent to driver
[2025-07-19T20:30:56.690+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 157.0 in stage 3.0 (TID 109) in 163 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:30:56.694+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.1.delta.f340601d-4004-4864-86e6-b57ca647a8a2.TID110.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta
[2025-07-19T20:30:56.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 156 (task 108, attempt 0, stage 3.0)
[2025-07-19T20:30:56.696+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta
[2025-07-19T20:30:56.696+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 168.0 in stage 3.0 (TID 114) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.697+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 153 (task 106, attempt 0, stage 3.0)
[2025-07-19T20:30:56.697+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 156.0 in stage 3.0 (TID 108). 9305 bytes result sent to driver
[2025-07-19T20:30:56.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 153.0 in stage 3.0 (TID 106). 9302 bytes result sent to driver
[2025-07-19T20:30:56.699+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 110, attempt 0, stage 3.0)
[2025-07-19T20:30:56.700+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 168.0 in stage 3.0 (TID 114)
[2025-07-19T20:30:56.701+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 169.0 in stage 3.0 (TID 115) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.701+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 174.0 in stage 3.0 (TID 116) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.701+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 174.0 in stage 3.0 (TID 116)
[2025-07-19T20:30:56.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 175.0 in stage 3.0 (TID 117) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 156.0 in stage 3.0 (TID 108) in 170 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:30:56.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 153.0 in stage 3.0 (TID 106) in 181 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:30:56.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 169.0 in stage 3.0 (TID 115)
[2025-07-19T20:30:56.703+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 155.0 in stage 3.0 (TID 107) in 181 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:30:56.703+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 175.0 in stage 3.0 (TID 117)
[2025-07-19T20:30:56.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.1.delta.3e8f4577-31f2-4317-97bb-d7163aa9380d.TID113.tmp
[2025-07-19T20:30:56.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:56.706+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.707+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.707+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.1.delta.59041563-91f6-4cc5-b340-57b9ac531a0c.TID111.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta
[2025-07-19T20:30:56.708+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta
[2025-07-19T20:30:56.708+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 111, attempt 0, stage 3.0)
[2025-07-19T20:30:56.709+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e360d52
[2025-07-19T20:30:56.710+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.711+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.715+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168] for update
[2025-07-19T20:30:56.715+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.717+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2fcb9101
[2025-07-19T20:30:56.718+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.719+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175] for update
[2025-07-19T20:30:56.720+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.1.delta.9d7cc96c-7cef-4ae7-9ddc-005249c9f967.TID112.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta
[2025-07-19T20:30:56.721+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta
[2025-07-19T20:30:56.721+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 112, attempt 0, stage 3.0)
[2025-07-19T20:30:56.721+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.722+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 160 (task 110, attempt 0, stage 3.0)
[2025-07-19T20:30:56.725+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 160.0 in stage 3.0 (TID 110). 9291 bytes result sent to driver
[2025-07-19T20:30:56.728+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.1.delta.ce4f0278-5bf7-4dde-abc5-395fef6615b2.TID114.tmp
[2025-07-19T20:30:56.729+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 176.0 in stage 3.0 (TID 118) (8b44f3d35cfa, executor driver, partition 176, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 176.0 in stage 3.0 (TID 118)
[2025-07-19T20:30:56.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 160.0 in stage 3.0 (TID 110) in 167 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:30:56.732+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d891d6
[2025-07-19T20:30:56.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.734+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169] for update
[2025-07-19T20:30:56.736+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.737+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.1.delta.a9302a91-4896-491a-acb8-5e26272a3359.TID117.tmp
[2025-07-19T20:30:56.737+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.737+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.742+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@371754cc
[2025-07-19T20:30:56.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 162 (task 111, attempt 0, stage 3.0)
[2025-07-19T20:30:56.748+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 165 (task 112, attempt 0, stage 3.0)
[2025-07-19T20:30:56.749+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174] for update
[2025-07-19T20:30:56.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 162.0 in stage 3.0 (TID 111). 9310 bytes result sent to driver
[2025-07-19T20:30:56.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 165.0 in stage 3.0 (TID 112). 9300 bytes result sent to driver
[2025-07-19T20:30:56.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 178.0 in stage 3.0 (TID 119) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.751+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.1.delta.dd99ce3c-75fa-4e80-b7ef-5af9577e1a59.TID115.tmp
[2025-07-19T20:30:56.755+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 165.0 in stage 3.0 (TID 112) in 134 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:30:56.760+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 178.0 in stage 3.0 (TID 119)
[2025-07-19T20:30:56.761+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 179.0 in stage 3.0 (TID 120) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.762+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.762+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 162.0 in stage 3.0 (TID 111) in 171 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:30:56.763+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 179.0 in stage 3.0 (TID 120)
[2025-07-19T20:30:56.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.766+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.767+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.767+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.768+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27f5e5a1
[2025-07-19T20:30:56.771+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.772+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176] for update
[2025-07-19T20:30:56.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.1.delta.5af77190-968d-4139-82b6-24265b8af93d.TID116.tmp
[2025-07-19T20:30:56.775+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.1.delta.3e8f4577-31f2-4317-97bb-d7163aa9380d.TID113.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta
[2025-07-19T20:30:56.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta
[2025-07-19T20:30:56.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 113, attempt 0, stage 3.0)
[2025-07-19T20:30:56.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@634560da
[2025-07-19T20:30:56.777+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.777+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179] for update
[2025-07-19T20:30:56.777+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.780+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.1.delta.869ccdc0-b9d3-4a33-8cb1-2b19260c2b27.TID118.tmp
[2025-07-19T20:30:56.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.1.delta.ce4f0278-5bf7-4dde-abc5-395fef6615b2.TID114.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta
[2025-07-19T20:30:56.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9f08d1d
[2025-07-19T20:30:56.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta
[2025-07-19T20:30:56.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 114, attempt 0, stage 3.0)
[2025-07-19T20:30:56.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.786+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178] for update
[2025-07-19T20:30:56.786+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.1.delta.a9302a91-4896-491a-acb8-5e26272a3359.TID117.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta
[2025-07-19T20:30:56.789+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta
[2025-07-19T20:30:56.796+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 117, attempt 0, stage 3.0)
[2025-07-19T20:30:56.798+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.1.delta.d0d1b529-c271-428c-a13c-7aba194c639e.TID120.tmp
[2025-07-19T20:30:56.804+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.1.delta.dd99ce3c-75fa-4e80-b7ef-5af9577e1a59.TID115.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta
[2025-07-19T20:30:56.809+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta
[2025-07-19T20:30:56.809+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 115, attempt 0, stage 3.0)
[2025-07-19T20:30:56.818+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 166 (task 113, attempt 0, stage 3.0)
[2025-07-19T20:30:56.825+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 166.0 in stage 3.0 (TID 113). 9350 bytes result sent to driver
[2025-07-19T20:30:56.830+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 182.0 in stage 3.0 (TID 121) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.831+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.1.delta.5cb0916a-0de2-4852-906f-b1f4b84e2359.TID119.tmp
[2025-07-19T20:30:56.834+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 175 (task 117, attempt 0, stage 3.0)
[2025-07-19T20:30:56.840+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 175.0 in stage 3.0 (TID 117). 9244 bytes result sent to driver
[2025-07-19T20:30:56.841+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 182.0 in stage 3.0 (TID 121)
[2025-07-19T20:30:56.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 166.0 in stage 3.0 (TID 113) in 171 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:30:56.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 168 (task 114, attempt 0, stage 3.0)
[2025-07-19T20:30:56.844+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 168.0 in stage 3.0 (TID 114). 9251 bytes result sent to driver
[2025-07-19T20:30:56.846+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 183.0 in stage 3.0 (TID 122) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.847+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 184.0 in stage 3.0 (TID 123) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.847+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 184.0 in stage 3.0 (TID 123)
[2025-07-19T20:30:56.848+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 175.0 in stage 3.0 (TID 117) in 156 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:30:56.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 168.0 in stage 3.0 (TID 114) in 159 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:30:56.851+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 183.0 in stage 3.0 (TID 122)
[2025-07-19T20:30:56.854+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.1.delta.5af77190-968d-4139-82b6-24265b8af93d.TID116.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta
[2025-07-19T20:30:56.855+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.1.delta.869ccdc0-b9d3-4a33-8cb1-2b19260c2b27.TID118.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta
[2025-07-19T20:30:56.856+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta
[2025-07-19T20:30:56.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta
[2025-07-19T20:30:56.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 118, attempt 0, stage 3.0)
[2025-07-19T20:30:56.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 116, attempt 0, stage 3.0)
[2025-07-19T20:30:56.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:56.860+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.864+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:56.866+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 169 (task 115, attempt 0, stage 3.0)
[2025-07-19T20:30:56.866+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.1.delta.d0d1b529-c271-428c-a13c-7aba194c639e.TID120.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta
[2025-07-19T20:30:56.867+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta
[2025-07-19T20:30:56.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fbd09b0
[2025-07-19T20:30:56.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 169.0 in stage 3.0 (TID 115). 9257 bytes result sent to driver
[2025-07-19T20:30:56.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 120, attempt 0, stage 3.0)
[2025-07-19T20:30:56.870+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 185.0 in stage 3.0 (TID 124) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.871+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 169.0 in stage 3.0 (TID 115) in 179 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:30:56.872+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 185.0 in stage 3.0 (TID 124)
[2025-07-19T20:30:56.874+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.875+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184] for update
[2025-07-19T20:30:56.879+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 174 (task 116, attempt 0, stage 3.0)
[2025-07-19T20:30:56.880+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 174.0 in stage 3.0 (TID 116). 9219 bytes result sent to driver
[2025-07-19T20:30:56.886+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.886+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 187.0 in stage 3.0 (TID 125) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43d126bc
[2025-07-19T20:30:56.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 174.0 in stage 3.0 (TID 116) in 193 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:30:56.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 187.0 in stage 3.0 (TID 125)
[2025-07-19T20:30:56.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:56.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.889+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.889+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183] for update
[2025-07-19T20:30:56.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 176 (task 118, attempt 0, stage 3.0)
[2025-07-19T20:30:56.894+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.898+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6309fd34
[2025-07-19T20:30:56.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182] for update
[2025-07-19T20:30:56.901+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.1.delta.5cb0916a-0de2-4852-906f-b1f4b84e2359.TID119.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta
[2025-07-19T20:30:56.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta
[2025-07-19T20:30:56.903+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 119, attempt 0, stage 3.0)
[2025-07-19T20:30:56.904+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 176.0 in stage 3.0 (TID 118). 9260 bytes result sent to driver
[2025-07-19T20:30:56.904+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.1.delta.66e7cc81-b866-45a7-87e9-724cb16c1d2e.TID123.tmp
[2025-07-19T20:30:56.904+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28a13fb7
[2025-07-19T20:30:56.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 188.0 in stage 3.0 (TID 126) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 188.0 in stage 3.0 (TID 126)
[2025-07-19T20:30:56.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 176.0 in stage 3.0 (TID 118) in 178 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:30:56.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187] for update
[2025-07-19T20:30:56.913+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:56.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 179 (task 120, attempt 0, stage 3.0)
[2025-07-19T20:30:56.925+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.1.delta.ec9c81d8-8e64-4a6c-8b87-9d6febc7683a.TID122.tmp
[2025-07-19T20:30:56.925+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.1.delta.75adc4b1-e044-49e0-a277-d7259d328cdf.TID121.tmp
[2025-07-19T20:30:56.925+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 179.0 in stage 3.0 (TID 120). 9261 bytes result sent to driver
[2025-07-19T20:30:56.930+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 191.0 in stage 3.0 (TID 127) (8b44f3d35cfa, executor driver, partition 191, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bf7ee0f
[2025-07-19T20:30:56.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.933+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 191.0 in stage 3.0 (TID 127)
[2025-07-19T20:30:56.933+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 178 (task 119, attempt 0, stage 3.0)
[2025-07-19T20:30:56.934+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185] for update
[2025-07-19T20:30:56.936+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.1.delta.e4f7be37-445a-42ef-a7b8-8707afe5b6dc.TID125.tmp
[2025-07-19T20:30:56.937+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 179.0 in stage 3.0 (TID 120) in 188 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:30:56.937+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.937+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.939+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Finished task 178.0 in stage 3.0 (TID 119). 9264 bytes result sent to driver
[2025-07-19T20:30:56.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Starting task 194.0 in stage 3.0 (TID 128) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:56.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO TaskSetManager: Finished task 178.0 in stage 3.0 (TID 119) in 197 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:30:56.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO Executor: Running task 194.0 in stage 3.0 (TID 128)
[2025-07-19T20:30:56.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:56.950+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:56.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@503a2039
[2025-07-19T20:30:56.952+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.953+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188] for update
[2025-07-19T20:30:56.954+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.954+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.958+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@be5defd
[2025-07-19T20:30:56.961+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.961+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191] for update
[2025-07-19T20:30:56.962+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.1.delta.d2f12b4f-ece5-4c6f-81a7-059b4dc77b8e.TID126.tmp
[2025-07-19T20:30:56.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.1.delta.c577d639-1ace-44e9-b0a5-fd04dd0b4c65.TID124.tmp
[2025-07-19T20:30:56.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76a32930
[2025-07-19T20:30:56.973+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:56.973+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194] for update
[2025-07-19T20:30:56.976+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:56.976+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.1.delta.cca56dff-bb63-421f-b692-2237dbe532e3.TID127.tmp
[2025-07-19T20:30:56.977+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.1.delta.66e7cc81-b866-45a7-87e9-724cb16c1d2e.TID123.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta
[2025-07-19T20:30:56.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta
[2025-07-19T20:30:56.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.1.delta.75adc4b1-e044-49e0-a277-d7259d328cdf.TID121.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta
[2025-07-19T20:30:56.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta
[2025-07-19T20:30:56.979+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 123, attempt 0, stage 3.0)
[2025-07-19T20:30:56.980+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 121, attempt 0, stage 3.0)
[2025-07-19T20:30:56.983+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.1.delta.ec9c81d8-8e64-4a6c-8b87-9d6febc7683a.TID122.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta
[2025-07-19T20:30:56.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta
[2025-07-19T20:30:56.985+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 122, attempt 0, stage 3.0)
[2025-07-19T20:30:56.986+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.1.delta.e4f7be37-445a-42ef-a7b8-8707afe5b6dc.TID125.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta
[2025-07-19T20:30:56.986+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta
[2025-07-19T20:30:56.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 125, attempt 0, stage 3.0)
[2025-07-19T20:30:56.991+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.1.delta.15824f66-a408-4edc-92b6-6f050d44e4fa.TID128.tmp
[2025-07-19T20:30:57.001+0000] {subprocess.py:93} INFO - 25/07/19 20:30:56 INFO DataWritingSparkTask: Committed partition 183 (task 122, attempt 0, stage 3.0)
[2025-07-19T20:30:57.002+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 183.0 in stage 3.0 (TID 122). 9252 bytes result sent to driver
[2025-07-19T20:30:57.005+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 196.0 in stage 3.0 (TID 129) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.006+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 196.0 in stage 3.0 (TID 129)
[2025-07-19T20:30:57.007+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 183.0 in stage 3.0 (TID 122) in 158 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:30:57.010+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.012+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 187 (task 125, attempt 0, stage 3.0)
[2025-07-19T20:30:57.013+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 187.0 in stage 3.0 (TID 125). 9257 bytes result sent to driver
[2025-07-19T20:30:57.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.1.delta.d2f12b4f-ece5-4c6f-81a7-059b4dc77b8e.TID126.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta
[2025-07-19T20:30:57.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta
[2025-07-19T20:30:57.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 182 (task 121, attempt 0, stage 3.0)
[2025-07-19T20:30:57.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 184 (task 123, attempt 0, stage 3.0)
[2025-07-19T20:30:57.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 182.0 in stage 3.0 (TID 121). 9263 bytes result sent to driver
[2025-07-19T20:30:57.015+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 197.0 in stage 3.0 (TID 130) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.015+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 197.0 in stage 3.0 (TID 130)
[2025-07-19T20:30:57.018+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 198.0 in stage 3.0 (TID 131) (8b44f3d35cfa, executor driver, partition 198, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.019+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 126, attempt 0, stage 3.0)
[2025-07-19T20:30:57.019+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 184.0 in stage 3.0 (TID 123). 9248 bytes result sent to driver
[2025-07-19T20:30:57.019+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 187.0 in stage 3.0 (TID 125) in 128 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:30:57.021+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 182.0 in stage 3.0 (TID 121) in 184 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:30:57.022+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 199.0 in stage 3.0 (TID 132) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.023+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 184.0 in stage 3.0 (TID 123) in 168 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:30:57.024+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 198.0 in stage 3.0 (TID 131)
[2025-07-19T20:30:57.025+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.026+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:57.026+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 199.0 in stage 3.0 (TID 132)
[2025-07-19T20:30:57.026+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2805fd9c
[2025-07-19T20:30:57.027+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.027+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196] for update
[2025-07-19T20:30:57.028+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.028+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.028+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.040+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.1.delta.c577d639-1ace-44e9-b0a5-fd04dd0b4c65.TID124.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta
[2025-07-19T20:30:57.041+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta
[2025-07-19T20:30:57.042+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 124, attempt 0, stage 3.0)
[2025-07-19T20:30:57.043+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.045+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.047+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79d44f20
[2025-07-19T20:30:57.049+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.051+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197] for update
[2025-07-19T20:30:57.051+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.051+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.1.delta.cca56dff-bb63-421f-b692-2237dbe532e3.TID127.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta
[2025-07-19T20:30:57.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta
[2025-07-19T20:30:57.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e46e3d
[2025-07-19T20:30:57.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.1.delta.6d831e54-4f6f-4c16-aeb1-491fc8854bf4.TID129.tmp
[2025-07-19T20:30:57.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198] for update
[2025-07-19T20:30:57.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 127, attempt 0, stage 3.0)
[2025-07-19T20:30:57.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.055+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 188 (task 126, attempt 0, stage 3.0)
[2025-07-19T20:30:57.055+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33e2ed32
[2025-07-19T20:30:57.063+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 188.0 in stage 3.0 (TID 126). 9343 bytes result sent to driver
[2025-07-19T20:30:57.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199] for update
[2025-07-19T20:30:57.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 133) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.1.delta.15824f66-a408-4edc-92b6-6f050d44e4fa.TID128.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta
[2025-07-19T20:30:57.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta
[2025-07-19T20:30:57.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 0.0 in stage 3.0 (TID 133)
[2025-07-19T20:30:57.065+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.065+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 128, attempt 0, stage 3.0)
[2025-07-19T20:30:57.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.1.delta.928ddc6a-93d8-49ac-a431-5d71e88b020c.TID131.tmp
[2025-07-19T20:30:57.073+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 188.0 in stage 3.0 (TID 126) in 167 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:30:57.079+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.1.delta.feb262b3-1cf8-477c-a959-5cc7323c5edd.TID130.tmp
[2025-07-19T20:30:57.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 185 (task 124, attempt 0, stage 3.0)
[2025-07-19T20:30:57.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 185.0 in stage 3.0 (TID 124). 9300 bytes result sent to driver
[2025-07-19T20:30:57.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 134) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.1.delta.3045520e-1423-408b-a3d8-15440d463de3.TID132.tmp
[2025-07-19T20:30:57.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 3.0 in stage 3.0 (TID 134)
[2025-07-19T20:30:57.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 185.0 in stage 3.0 (TID 124) in 214 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:30:57.100+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.101+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
[2025-07-19T20:30:57.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 191 (task 127, attempt 0, stage 3.0)
[2025-07-19T20:30:57.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.1.delta.6d831e54-4f6f-4c16-aeb1-491fc8854bf4.TID129.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta
[2025-07-19T20:30:57.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta
[2025-07-19T20:30:57.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 129, attempt 0, stage 3.0)
[2025-07-19T20:30:57.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 194 (task 128, attempt 0, stage 3.0)
[2025-07-19T20:30:57.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 191.0 in stage 3.0 (TID 127). 9306 bytes result sent to driver
[2025-07-19T20:30:57.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 194.0 in stage 3.0 (TID 128). 9293 bytes result sent to driver
[2025-07-19T20:30:57.110+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 135) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.116+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 136) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.117+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 9.0 in stage 3.0 (TID 136)
[2025-07-19T20:30:57.118+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 4.0 in stage 3.0 (TID 135)
[2025-07-19T20:30:57.120+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 191.0 in stage 3.0 (TID 127) in 189 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:30:57.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 194.0 in stage 3.0 (TID 128) in 180 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:30:57.122+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.122+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.123+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.123+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.136+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/.schema.ff6142d6-86a0-4115-9118-a2028189061b.TID133.tmp
[2025-07-19T20:30:57.137+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.1.delta.928ddc6a-93d8-49ac-a431-5d71e88b020c.TID131.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta
[2025-07-19T20:30:57.137+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta
[2025-07-19T20:30:57.137+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 131, attempt 0, stage 3.0)
[2025-07-19T20:30:57.139+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.1.delta.feb262b3-1cf8-477c-a959-5cc7323c5edd.TID130.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta
[2025-07-19T20:30:57.140+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta
[2025-07-19T20:30:57.143+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 130, attempt 0, stage 3.0)
[2025-07-19T20:30:57.144+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 196 (task 129, attempt 0, stage 3.0)
[2025-07-19T20:30:57.146+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 196.0 in stage 3.0 (TID 129). 9300 bytes result sent to driver
[2025-07-19T20:30:57.146+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 137) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.147+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.1.delta.3045520e-1423-408b-a3d8-15440d463de3.TID132.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta
[2025-07-19T20:30:57.147+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta
[2025-07-19T20:30:57.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 13.0 in stage 3.0 (TID 137)
[2025-07-19T20:30:57.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 196.0 in stage 3.0 (TID 129) in 144 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:30:57.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 132, attempt 0, stage 3.0)
[2025-07-19T20:30:57.153+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.154+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 198 (task 131, attempt 0, stage 3.0)
[2025-07-19T20:30:57.169+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/.schema.ff6142d6-86a0-4115-9118-a2028189061b.TID133.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/schema
[2025-07-19T20:30:57.170+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 197 (task 130, attempt 0, stage 3.0)
[2025-07-19T20:30:57.172+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 197.0 in stage 3.0 (TID 130). 9296 bytes result sent to driver
[2025-07-19T20:30:57.173+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 199 (task 132, attempt 0, stage 3.0)
[2025-07-19T20:30:57.174+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 199.0 in stage 3.0 (TID 132). 9320 bytes result sent to driver
[2025-07-19T20:30:57.174+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@af53004
[2025-07-19T20:30:57.175+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.175+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 197.0 in stage 3.0 (TID 130) in 160 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:30:57.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 198.0 in stage 3.0 (TID 131). 9302 bytes result sent to driver
[2025-07-19T20:30:57.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0] for update
[2025-07-19T20:30:57.177+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 21.0 in stage 3.0 (TID 138) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.178+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 22.0 in stage 3.0 (TID 139) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.178+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 22.0 in stage 3.0 (TID 139)
[2025-07-19T20:30:57.178+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 23.0 in stage 3.0 (TID 140) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 21.0 in stage 3.0 (TID 138)
[2025-07-19T20:30:57.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 23.0 in stage 3.0 (TID 140)
[2025-07-19T20:30:57.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 198.0 in stage 3.0 (TID 131) in 163 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:30:57.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.180+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.180+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.180+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.180+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 199.0 in stage 3.0 (TID 132) in 164 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:30:57.180+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.181+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.181+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:57.189+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31841913
[2025-07-19T20:30:57.190+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.1.delta.73c0086d-4643-44dc-876d-0bf95337107a.TID133.tmp
[2025-07-19T20:30:57.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22] for update
[2025-07-19T20:30:57.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74d2b663
[2025-07-19T20:30:57.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13] for update
[2025-07-19T20:30:57.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.195+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6673df35
[2025-07-19T20:30:57.196+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.198+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4] for update
[2025-07-19T20:30:57.198+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.1.delta.268ee1e0-4530-4052-b8f2-ef9bfd0c4b05.TID139.tmp
[2025-07-19T20:30:57.206+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c16d216
[2025-07-19T20:30:57.206+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.1.delta.c738b613-64d6-4ac5-ad68-5f3416409dae.TID137.tmp
[2025-07-19T20:30:57.207+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.207+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9] for update
[2025-07-19T20:30:57.208+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.1.delta.e69647a4-caee-441d-892c-ab3b849a618a.TID135.tmp
[2025-07-19T20:30:57.208+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.209+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37779ef6
[2025-07-19T20:30:57.210+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.211+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3] for update
[2025-07-19T20:30:57.217+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.220+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1573de80
[2025-07-19T20:30:57.222+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.223+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21] for update
[2025-07-19T20:30:57.228+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.230+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.1.delta.8ef3ec31-a31b-4abd-85af-779c3f94a900.TID136.tmp
[2025-07-19T20:30:57.230+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.1.delta.096679ce-0503-4c1a-8c04-dce515b7ec83.TID134.tmp
[2025-07-19T20:30:57.233+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.1.delta.73c0086d-4643-44dc-876d-0bf95337107a.TID133.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta
[2025-07-19T20:30:57.233+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67c79d30
[2025-07-19T20:30:57.233+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta
[2025-07-19T20:30:57.234+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.234+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23] for update
[2025-07-19T20:30:57.237+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.237+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 133, attempt 0, stage 3.0)
[2025-07-19T20:30:57.237+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.1.delta.8c5f669c-a6b1-4415-adaf-a986fa45e786.TID138.tmp
[2025-07-19T20:30:57.247+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.1.delta.268ee1e0-4530-4052-b8f2-ef9bfd0c4b05.TID139.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta
[2025-07-19T20:30:57.249+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta
[2025-07-19T20:30:57.250+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 0 (task 133, attempt 0, stage 3.0)
[2025-07-19T20:30:57.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 139, attempt 0, stage 3.0)
[2025-07-19T20:30:57.255+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 0.0 in stage 3.0 (TID 133). 6200 bytes result sent to driver
[2025-07-19T20:30:57.256+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 25.0 in stage 3.0 (TID 141) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 25.0 in stage 3.0 (TID 141)
[2025-07-19T20:30:57.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.1.delta.762c0208-482d-4294-8029-e52d13252f7e.TID140.tmp
[2025-07-19T20:30:57.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 133) in 189 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:30:57.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 22 (task 139, attempt 0, stage 3.0)
[2025-07-19T20:30:57.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.260+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 22.0 in stage 3.0 (TID 139). 6200 bytes result sent to driver
[2025-07-19T20:30:57.261+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 37.0 in stage 3.0 (TID 142) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.262+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 22.0 in stage 3.0 (TID 139) in 89 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:30:57.263+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 37.0 in stage 3.0 (TID 142)
[2025-07-19T20:30:57.266+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.1.delta.c738b613-64d6-4ac5-ad68-5f3416409dae.TID137.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta
[2025-07-19T20:30:57.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta
[2025-07-19T20:30:57.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 137, attempt 0, stage 3.0)
[2025-07-19T20:30:57.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.1.delta.e69647a4-caee-441d-892c-ab3b849a618a.TID135.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta
[2025-07-19T20:30:57.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fc930fa
[2025-07-19T20:30:57.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta
[2025-07-19T20:30:57.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.268+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25] for update
[2025-07-19T20:30:57.268+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 135, attempt 0, stage 3.0)
[2025-07-19T20:30:57.269+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.272+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 13 (task 137, attempt 0, stage 3.0)
[2025-07-19T20:30:57.273+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.276+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 13.0 in stage 3.0 (TID 137). 6200 bytes result sent to driver
[2025-07-19T20:30:57.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 38.0 in stage 3.0 (TID 143) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:30:57.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 4 (task 135, attempt 0, stage 3.0)
[2025-07-19T20:30:57.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 137) in 127 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:30:57.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 38.0 in stage 3.0 (TID 143)
[2025-07-19T20:30:57.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 4.0 in stage 3.0 (TID 135). 6200 bytes result sent to driver
[2025-07-19T20:30:57.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 43.0 in stage 3.0 (TID 144) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 135) in 166 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:30:57.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 43.0 in stage 3.0 (TID 144)
[2025-07-19T20:30:57.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.285+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.1.delta.096679ce-0503-4c1a-8c04-dce515b7ec83.TID134.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta
[2025-07-19T20:30:57.286+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@221ed621
[2025-07-19T20:30:57.286+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta
[2025-07-19T20:30:57.289+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.289+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 134, attempt 0, stage 3.0)
[2025-07-19T20:30:57.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37] for update
[2025-07-19T20:30:57.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.1.delta.8ef3ec31-a31b-4abd-85af-779c3f94a900.TID136.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta
[2025-07-19T20:30:57.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta
[2025-07-19T20:30:57.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 136, attempt 0, stage 3.0)
[2025-07-19T20:30:57.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.292+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.1.delta.8c5f669c-a6b1-4415-adaf-a986fa45e786.TID138.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta
[2025-07-19T20:30:57.294+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta
[2025-07-19T20:30:57.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 3 (task 134, attempt 0, stage 3.0)
[2025-07-19T20:30:57.296+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.1.delta.4adb705b-da34-413b-a618-19c4e5ddf104.TID141.tmp
[2025-07-19T20:30:57.296+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 3.0 in stage 3.0 (TID 134). 6200 bytes result sent to driver
[2025-07-19T20:30:57.297+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 138, attempt 0, stage 3.0)
[2025-07-19T20:30:57.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 45.0 in stage 3.0 (TID 145) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.299+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 9 (task 136, attempt 0, stage 3.0)
[2025-07-19T20:30:57.301+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 134) in 215 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:30:57.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 9.0 in stage 3.0 (TID 136). 6200 bytes result sent to driver
[2025-07-19T20:30:57.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 45.0 in stage 3.0 (TID 145)
[2025-07-19T20:30:57.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@566fd2e3
[2025-07-19T20:30:57.306+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 50.0 in stage 3.0 (TID 146) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.307+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 21 (task 138, attempt 0, stage 3.0)
[2025-07-19T20:30:57.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 50.0 in stage 3.0 (TID 146)
[2025-07-19T20:30:57.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 21.0 in stage 3.0 (TID 138). 6200 bytes result sent to driver
[2025-07-19T20:30:57.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43] for update
[2025-07-19T20:30:57.309+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.1.delta.5811ee52-50e2-48f3-a5f6-8fedb9465ac8.TID142.tmp
[2025-07-19T20:30:57.309+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 136) in 184 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:30:57.309+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 52.0 in stage 3.0 (TID 147) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.310+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 52.0 in stage 3.0 (TID 147)
[2025-07-19T20:30:57.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 21.0 in stage 3.0 (TID 138) in 129 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:30:57.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.313+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.313+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:30:57.314+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.315+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.315+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.1.delta.762c0208-482d-4294-8029-e52d13252f7e.TID140.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta
[2025-07-19T20:30:57.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta
[2025-07-19T20:30:57.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b064571
[2025-07-19T20:30:57.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38] for update
[2025-07-19T20:30:57.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 140, attempt 0, stage 3.0)
[2025-07-19T20:30:57.317+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.319+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.1.delta.f06ef807-5e15-45aa-a748-7ff0b64bd7e8.TID144.tmp
[2025-07-19T20:30:57.326+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cb69e61
[2025-07-19T20:30:57.327+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.327+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50] for update
[2025-07-19T20:30:57.327+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 23 (task 140, attempt 0, stage 3.0)
[2025-07-19T20:30:57.327+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 23.0 in stage 3.0 (TID 140). 6157 bytes result sent to driver
[2025-07-19T20:30:57.332+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.333+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.1.delta.7b9056a7-6435-4e7e-b251-c4c6ec13173d.TID143.tmp
[2025-07-19T20:30:57.334+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 23.0 in stage 3.0 (TID 140) in 155 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:30:57.334+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a99b7de
[2025-07-19T20:30:57.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45] for update
[2025-07-19T20:30:57.335+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 53.0 in stage 3.0 (TID 148) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 53.0 in stage 3.0 (TID 148)
[2025-07-19T20:30:57.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.339+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.1.delta.dc2f16bd-87ed-474f-9203-71ba96c22ee1.TID145.tmp
[2025-07-19T20:30:57.340+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.1.delta.71222d09-67a9-4086-bb11-c46e6f0205cb.TID146.tmp
[2025-07-19T20:30:57.342+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37694ca2
[2025-07-19T20:30:57.342+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52] for update
[2025-07-19T20:30:57.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@eed9132
[2025-07-19T20:30:57.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53] for update
[2025-07-19T20:30:57.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.1.delta.4adb705b-da34-413b-a618-19c4e5ddf104.TID141.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta
[2025-07-19T20:30:57.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta
[2025-07-19T20:30:57.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.1.delta.5811ee52-50e2-48f3-a5f6-8fedb9465ac8.TID142.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta
[2025-07-19T20:30:57.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta
[2025-07-19T20:30:57.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.351+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 141, attempt 0, stage 3.0)
[2025-07-19T20:30:57.351+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 142, attempt 0, stage 3.0)
[2025-07-19T20:30:57.358+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.1.delta.ddea82c9-2300-4559-997e-96df32eed172.TID148.tmp
[2025-07-19T20:30:57.359+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 37 (task 142, attempt 0, stage 3.0)
[2025-07-19T20:30:57.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 25 (task 141, attempt 0, stage 3.0)
[2025-07-19T20:30:57.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 25.0 in stage 3.0 (TID 141). 6200 bytes result sent to driver
[2025-07-19T20:30:57.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 56.0 in stage 3.0 (TID 149) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 56.0 in stage 3.0 (TID 149)
[2025-07-19T20:30:57.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 25.0 in stage 3.0 (TID 141) in 112 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:30:57.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.1.delta.f06ef807-5e15-45aa-a748-7ff0b64bd7e8.TID144.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta
[2025-07-19T20:30:57.363+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta
[2025-07-19T20:30:57.363+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 144, attempt 0, stage 3.0)
[2025-07-19T20:30:57.364+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 37.0 in stage 3.0 (TID 142). 6200 bytes result sent to driver
[2025-07-19T20:30:57.365+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.366+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.367+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 59.0 in stage 3.0 (TID 150) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.367+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 37.0 in stage 3.0 (TID 142) in 106 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:30:57.367+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 59.0 in stage 3.0 (TID 150)
[2025-07-19T20:30:57.368+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.1.delta.c8aaa168-70d5-4f0f-86ed-ac033f99f833.TID147.tmp
[2025-07-19T20:30:57.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 43 (task 144, attempt 0, stage 3.0)
[2025-07-19T20:30:57.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 43.0 in stage 3.0 (TID 144). 6200 bytes result sent to driver
[2025-07-19T20:30:57.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 61.0 in stage 3.0 (TID 151) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.371+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4da5273b
[2025-07-19T20:30:57.373+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 43.0 in stage 3.0 (TID 144) in 99 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:30:57.375+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.376+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56] for update
[2025-07-19T20:30:57.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 61.0 in stage 3.0 (TID 151)
[2025-07-19T20:30:57.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.1.delta.7b9056a7-6435-4e7e-b251-c4c6ec13173d.TID143.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta
[2025-07-19T20:30:57.379+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta
[2025-07-19T20:30:57.379+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.380+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:57.381+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.382+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 143, attempt 0, stage 3.0)
[2025-07-19T20:30:57.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.384+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.1.delta.71222d09-67a9-4086-bb11-c46e6f0205cb.TID146.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta
[2025-07-19T20:30:57.386+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta
[2025-07-19T20:30:57.386+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 146, attempt 0, stage 3.0)
[2025-07-19T20:30:57.388+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 50 (task 146, attempt 0, stage 3.0)
[2025-07-19T20:30:57.388+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 50.0 in stage 3.0 (TID 146). 6200 bytes result sent to driver
[2025-07-19T20:30:57.392+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d432663
[2025-07-19T20:30:57.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 65.0 in stage 3.0 (TID 152) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 38 (task 143, attempt 0, stage 3.0)
[2025-07-19T20:30:57.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.395+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59] for update
[2025-07-19T20:30:57.395+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 65.0 in stage 3.0 (TID 152)
[2025-07-19T20:30:57.400+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 50.0 in stage 3.0 (TID 146) in 100 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:30:57.403+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 38.0 in stage 3.0 (TID 143). 6200 bytes result sent to driver
[2025-07-19T20:30:57.403+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 67.0 in stage 3.0 (TID 153) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.403+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 67.0 in stage 3.0 (TID 153)
[2025-07-19T20:30:57.403+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@835a6ce
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 38.0 in stage 3.0 (TID 143) in 129 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.1.delta.85566e2c-1ec9-43f0-b81b-8628bcee517c.TID149.tmp
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61] for update
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.404+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.1.delta.dc2f16bd-87ed-474f-9203-71ba96c22ee1.TID145.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta
[2025-07-19T20:30:57.405+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta
[2025-07-19T20:30:57.405+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 145, attempt 0, stage 3.0)
[2025-07-19T20:30:57.406+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.410+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.1.delta.5346db8d-106c-46d7-93e0-25f0274f5448.TID150.tmp
[2025-07-19T20:30:57.411+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 45 (task 145, attempt 0, stage 3.0)
[2025-07-19T20:30:57.411+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 45.0 in stage 3.0 (TID 145). 6243 bytes result sent to driver
[2025-07-19T20:30:57.412+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.1.delta.ddea82c9-2300-4559-997e-96df32eed172.TID148.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta
[2025-07-19T20:30:57.413+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta
[2025-07-19T20:30:57.413+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 148, attempt 0, stage 3.0)
[2025-07-19T20:30:57.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 69.0 in stage 3.0 (TID 154) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cf68e19
[2025-07-19T20:30:57.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65] for update
[2025-07-19T20:30:57.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 45.0 in stage 3.0 (TID 145) in 119 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:30:57.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 69.0 in stage 3.0 (TID 154)
[2025-07-19T20:30:57.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31574c78
[2025-07-19T20:30:57.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.420+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.1.delta.ebfc5818-9c0e-41ff-ba8f-502bc0fe6723.TID151.tmp
[2025-07-19T20:30:57.421+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67] for update
[2025-07-19T20:30:57.421+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 53 (task 148, attempt 0, stage 3.0)
[2025-07-19T20:30:57.421+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.422+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 53.0 in stage 3.0 (TID 148). 6243 bytes result sent to driver
[2025-07-19T20:30:57.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 70.0 in stage 3.0 (TID 155) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 70.0 in stage 3.0 (TID 155)
[2025-07-19T20:30:57.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 53.0 in stage 3.0 (TID 148) in 91 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:30:57.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cef0b11
[2025-07-19T20:30:57.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.431+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69] for update
[2025-07-19T20:30:57.432+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.432+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.1.delta.c8aaa168-70d5-4f0f-86ed-ac033f99f833.TID147.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta
[2025-07-19T20:30:57.433+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta
[2025-07-19T20:30:57.433+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 147, attempt 0, stage 3.0)
[2025-07-19T20:30:57.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62ab2925
[2025-07-19T20:30:57.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.1.delta.4e48045f-49c7-4525-8261-c5c61632870f.TID153.tmp
[2025-07-19T20:30:57.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70] for update
[2025-07-19T20:30:57.447+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.1.delta.d095af09-e64c-4b60-82e7-82cafed7fe52.TID154.tmp
[2025-07-19T20:30:57.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.1.delta.2de86cb8-02fa-4fb7-a704-54cfeb5c03c0.TID152.tmp
[2025-07-19T20:30:57.449+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 52 (task 147, attempt 0, stage 3.0)
[2025-07-19T20:30:57.450+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 52.0 in stage 3.0 (TID 147). 6243 bytes result sent to driver
[2025-07-19T20:30:57.450+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 72.0 in stage 3.0 (TID 156) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.450+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 52.0 in stage 3.0 (TID 147) in 150 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:30:57.451+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 72.0 in stage 3.0 (TID 156)
[2025-07-19T20:30:57.453+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.454+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.459+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@72a51767
[2025-07-19T20:30:57.462+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.463+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72] for update
[2025-07-19T20:30:57.465+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.465+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.1.delta.154bf114-0001-41f5-b72b-e080078ac067.TID155.tmp
[2025-07-19T20:30:57.474+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.1.delta.8fbb27a4-7788-4767-9c59-7c8490d1ad21.TID156.tmp
[2025-07-19T20:30:57.477+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.1.delta.ebfc5818-9c0e-41ff-ba8f-502bc0fe6723.TID151.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta
[2025-07-19T20:30:57.478+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta
[2025-07-19T20:30:57.479+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.1.delta.85566e2c-1ec9-43f0-b81b-8628bcee517c.TID149.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta
[2025-07-19T20:30:57.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta
[2025-07-19T20:30:57.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 149, attempt 0, stage 3.0)
[2025-07-19T20:30:57.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 151, attempt 0, stage 3.0)
[2025-07-19T20:30:57.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.1.delta.5346db8d-106c-46d7-93e0-25f0274f5448.TID150.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta
[2025-07-19T20:30:57.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta
[2025-07-19T20:30:57.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 150, attempt 0, stage 3.0)
[2025-07-19T20:30:57.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 61 (task 151, attempt 0, stage 3.0)
[2025-07-19T20:30:57.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 61.0 in stage 3.0 (TID 151). 6243 bytes result sent to driver
[2025-07-19T20:30:57.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 75.0 in stage 3.0 (TID 157) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 61.0 in stage 3.0 (TID 151) in 112 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:30:57.486+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 75.0 in stage 3.0 (TID 157)
[2025-07-19T20:30:57.488+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 59 (task 150, attempt 0, stage 3.0)
[2025-07-19T20:30:57.489+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 59.0 in stage 3.0 (TID 150). 6243 bytes result sent to driver
[2025-07-19T20:30:57.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 56 (task 149, attempt 0, stage 3.0)
[2025-07-19T20:30:57.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 56.0 in stage 3.0 (TID 149). 6243 bytes result sent to driver
[2025-07-19T20:30:57.492+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.494+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.1.delta.4e48045f-49c7-4525-8261-c5c61632870f.TID153.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta
[2025-07-19T20:30:57.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta
[2025-07-19T20:30:57.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 78.0 in stage 3.0 (TID 158) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.496+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 153, attempt 0, stage 3.0)
[2025-07-19T20:30:57.497+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 81.0 in stage 3.0 (TID 159) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.498+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 78.0 in stage 3.0 (TID 158)
[2025-07-19T20:30:57.498+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 59.0 in stage 3.0 (TID 150) in 126 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:30:57.499+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 81.0 in stage 3.0 (TID 159)
[2025-07-19T20:30:57.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.503+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 56.0 in stage 3.0 (TID 149) in 133 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:30:57.504+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.505+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 67 (task 153, attempt 0, stage 3.0)
[2025-07-19T20:30:57.505+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.1.delta.d095af09-e64c-4b60-82e7-82cafed7fe52.TID154.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta
[2025-07-19T20:30:57.506+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta
[2025-07-19T20:30:57.506+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 67.0 in stage 3.0 (TID 153). 6243 bytes result sent to driver
[2025-07-19T20:30:57.506+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.507+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.507+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 84.0 in stage 3.0 (TID 160) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.508+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 67.0 in stage 3.0 (TID 153) in 102 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:30:57.508+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 84.0 in stage 3.0 (TID 160)
[2025-07-19T20:30:57.509+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e9b67b0
[2025-07-19T20:30:57.509+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 154, attempt 0, stage 3.0)
[2025-07-19T20:30:57.510+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.510+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75] for update
[2025-07-19T20:30:57.511+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.511+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.512+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.1.delta.2de86cb8-02fa-4fb7-a704-54cfeb5c03c0.TID152.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta
[2025-07-19T20:30:57.512+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta
[2025-07-19T20:30:57.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 152, attempt 0, stage 3.0)
[2025-07-19T20:30:57.513+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 69 (task 154, attempt 0, stage 3.0)
[2025-07-19T20:30:57.515+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f46d027
[2025-07-19T20:30:57.515+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 65 (task 152, attempt 0, stage 3.0)
[2025-07-19T20:30:57.515+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81] for update
[2025-07-19T20:30:57.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 69.0 in stage 3.0 (TID 154). 6286 bytes result sent to driver
[2025-07-19T20:30:57.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 65.0 in stage 3.0 (TID 152). 6243 bytes result sent to driver
[2025-07-19T20:30:57.517+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 85.0 in stage 3.0 (TID 161) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.517+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 89.0 in stage 3.0 (TID 162) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.518+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 85.0 in stage 3.0 (TID 161)
[2025-07-19T20:30:57.518+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.519+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 89.0 in stage 3.0 (TID 162)
[2025-07-19T20:30:57.521+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 65.0 in stage 3.0 (TID 152) in 125 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:30:57.521+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 69.0 in stage 3.0 (TID 154) in 105 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:30:57.522+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.522+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.523+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.1.delta.154bf114-0001-41f5-b72b-e080078ac067.TID155.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta
[2025-07-19T20:30:57.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta
[2025-07-19T20:30:57.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 155, attempt 0, stage 3.0)
[2025-07-19T20:30:57.526+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77269802
[2025-07-19T20:30:57.526+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.526+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78] for update
[2025-07-19T20:30:57.527+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.529+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 70 (task 155, attempt 0, stage 3.0)
[2025-07-19T20:30:57.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 70.0 in stage 3.0 (TID 155). 6243 bytes result sent to driver
[2025-07-19T20:30:57.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.1.delta.fd62ff19-f519-478b-9ed7-c6d46340023d.TID159.tmp
[2025-07-19T20:30:57.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.1.delta.24512524-fccf-4713-842f-74cf890e8f90.TID157.tmp
[2025-07-19T20:30:57.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 91.0 in stage 3.0 (TID 163) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.533+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 70.0 in stage 3.0 (TID 155) in 112 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:30:57.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 91.0 in stage 3.0 (TID 163)
[2025-07-19T20:30:57.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fe980a0
[2025-07-19T20:30:57.535+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.536+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.536+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.1.delta.8fbb27a4-7788-4767-9c59-7c8490d1ad21.TID156.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta
[2025-07-19T20:30:57.537+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta
[2025-07-19T20:30:57.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.1.delta.b77c0d49-1f11-47c1-9de9-ae5b97223c63.TID158.tmp
[2025-07-19T20:30:57.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 156, attempt 0, stage 3.0)
[2025-07-19T20:30:57.540+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.540+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85] for update
[2025-07-19T20:30:57.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.544+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 72 (task 156, attempt 0, stage 3.0)
[2025-07-19T20:30:57.547+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 72.0 in stage 3.0 (TID 156). 6200 bytes result sent to driver
[2025-07-19T20:30:57.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 94.0 in stage 3.0 (TID 164) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 72.0 in stage 3.0 (TID 156) in 97 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:30:57.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 94.0 in stage 3.0 (TID 164)
[2025-07-19T20:30:57.550+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.551+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.552+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46e0c59c
[2025-07-19T20:30:57.553+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.558+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89] for update
[2025-07-19T20:30:57.561+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.566+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.1.delta.c4ac5022-33d6-4041-89b7-435be833e208.TID161.tmp
[2025-07-19T20:30:57.568+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76bf763a
[2025-07-19T20:30:57.569+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.569+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84] for update
[2025-07-19T20:30:57.574+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.1.delta.fd62ff19-f519-478b-9ed7-c6d46340023d.TID159.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta
[2025-07-19T20:30:57.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta
[2025-07-19T20:30:57.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.579+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 159, attempt 0, stage 3.0)
[2025-07-19T20:30:57.579+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@285785a7
[2025-07-19T20:30:57.580+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.580+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94] for update
[2025-07-19T20:30:57.581+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 81 (task 159, attempt 0, stage 3.0)
[2025-07-19T20:30:57.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.1.delta.24512524-fccf-4713-842f-74cf890e8f90.TID157.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta
[2025-07-19T20:30:57.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta
[2025-07-19T20:30:57.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 157, attempt 0, stage 3.0)
[2025-07-19T20:30:57.583+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 75 (task 157, attempt 0, stage 3.0)
[2025-07-19T20:30:57.590+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 81.0 in stage 3.0 (TID 159). 6200 bytes result sent to driver
[2025-07-19T20:30:57.591+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.1.delta.a00527eb-b46e-4308-b23c-8ee799b2d6a3.TID162.tmp
[2025-07-19T20:30:57.592+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 75.0 in stage 3.0 (TID 157). 6200 bytes result sent to driver
[2025-07-19T20:30:57.593+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 95.0 in stage 3.0 (TID 165) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.594+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 98.0 in stage 3.0 (TID 166) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.594+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 81.0 in stage 3.0 (TID 159) in 100 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:30:57.595+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 95.0 in stage 3.0 (TID 165)
[2025-07-19T20:30:57.596+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 75.0 in stage 3.0 (TID 157) in 109 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:30:57.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 98.0 in stage 3.0 (TID 166)
[2025-07-19T20:30:57.600+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77253dc2
[2025-07-19T20:30:57.607+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.608+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91] for update
[2025-07-19T20:30:57.624+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.1.delta.ca8fac66-4a67-4bce-9fc0-8d60b3beefe0.TID160.tmp
[2025-07-19T20:30:57.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:57.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a537f54
[2025-07-19T20:30:57.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.1.delta.382af8b2-99ef-46d6-af19-6691ed4999c1.TID164.tmp
[2025-07-19T20:30:57.630+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.1.delta.b77c0d49-1f11-47c1-9de9-ae5b97223c63.TID158.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta
[2025-07-19T20:30:57.630+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta
[2025-07-19T20:30:57.639+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.1.delta.af987f7b-6cf3-4f4d-9926-942623757c34.TID163.tmp
[2025-07-19T20:30:57.640+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.640+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98] for update
[2025-07-19T20:30:57.645+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c4e7aa8
[2025-07-19T20:30:57.645+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.646+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95] for update
[2025-07-19T20:30:57.646+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.647+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 158, attempt 0, stage 3.0)
[2025-07-19T20:30:57.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.653+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.1.delta.c4ac5022-33d6-4041-89b7-435be833e208.TID161.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta
[2025-07-19T20:30:57.653+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta
[2025-07-19T20:30:57.653+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 78 (task 158, attempt 0, stage 3.0)
[2025-07-19T20:30:57.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 161, attempt 0, stage 3.0)
[2025-07-19T20:30:57.655+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 78.0 in stage 3.0 (TID 158). 6200 bytes result sent to driver
[2025-07-19T20:30:57.656+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 101.0 in stage 3.0 (TID 167) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.663+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 101.0 in stage 3.0 (TID 167)
[2025-07-19T20:30:57.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 78.0 in stage 3.0 (TID 158) in 169 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:30:57.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:57.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.1.delta.7097b9c1-54c7-4390-97c0-556e062a1c44.TID165.tmp
[2025-07-19T20:30:57.665+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 85 (task 161, attempt 0, stage 3.0)
[2025-07-19T20:30:57.667+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 85.0 in stage 3.0 (TID 161). 6200 bytes result sent to driver
[2025-07-19T20:30:57.667+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 104.0 in stage 3.0 (TID 168) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.668+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 104.0 in stage 3.0 (TID 168)
[2025-07-19T20:30:57.669+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.671+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.671+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 85.0 in stage 3.0 (TID 161) in 158 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:30:57.675+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11f4a8b8
[2025-07-19T20:30:57.676+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.676+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101] for update
[2025-07-19T20:30:57.677+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.682+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.1.delta.a00527eb-b46e-4308-b23c-8ee799b2d6a3.TID162.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta
[2025-07-19T20:30:57.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta
[2025-07-19T20:30:57.683+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 162, attempt 0, stage 3.0)
[2025-07-19T20:30:57.685+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34a60e4f
[2025-07-19T20:30:57.686+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104] for update
[2025-07-19T20:30:57.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.1.delta.b4ebd9e9-63e9-49e8-a0ea-e46cd7cf5367.TID166.tmp
[2025-07-19T20:30:57.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 89 (task 162, attempt 0, stage 3.0)
[2025-07-19T20:30:57.692+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 89.0 in stage 3.0 (TID 162). 6200 bytes result sent to driver
[2025-07-19T20:30:57.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 107.0 in stage 3.0 (TID 169) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.697+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 89.0 in stage 3.0 (TID 162) in 180 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:30:57.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.1.delta.ca8fac66-4a67-4bce-9fc0-8d60b3beefe0.TID160.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta
[2025-07-19T20:30:57.700+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta
[2025-07-19T20:30:57.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 160, attempt 0, stage 3.0)
[2025-07-19T20:30:57.703+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 107.0 in stage 3.0 (TID 169)
[2025-07-19T20:30:57.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.1.delta.60417a5e-20c3-4f49-99e2-4c408c995926.TID167.tmp
[2025-07-19T20:30:57.706+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 84 (task 160, attempt 0, stage 3.0)
[2025-07-19T20:30:57.708+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 84.0 in stage 3.0 (TID 160). 6200 bytes result sent to driver
[2025-07-19T20:30:57.709+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 108.0 in stage 3.0 (TID 170) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.710+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 84.0 in stage 3.0 (TID 160) in 203 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:30:57.710+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.711+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 108.0 in stage 3.0 (TID 170)
[2025-07-19T20:30:57.711+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.711+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.712+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.1.delta.382af8b2-99ef-46d6-af19-6691ed4999c1.TID164.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta
[2025-07-19T20:30:57.715+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta
[2025-07-19T20:30:57.715+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 164, attempt 0, stage 3.0)
[2025-07-19T20:30:57.716+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.1.delta.af987f7b-6cf3-4f4d-9926-942623757c34.TID163.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta
[2025-07-19T20:30:57.719+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta
[2025-07-19T20:30:57.721+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 163, attempt 0, stage 3.0)
[2025-07-19T20:30:57.721+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 94 (task 164, attempt 0, stage 3.0)
[2025-07-19T20:30:57.722+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a004848
[2025-07-19T20:30:57.722+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.723+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107] for update
[2025-07-19T20:30:57.723+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 94.0 in stage 3.0 (TID 164). 6200 bytes result sent to driver
[2025-07-19T20:30:57.724+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 115.0 in stage 3.0 (TID 171) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.724+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 91 (task 163, attempt 0, stage 3.0)
[2025-07-19T20:30:57.724+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 115.0 in stage 3.0 (TID 171)
[2025-07-19T20:30:57.724+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 94.0 in stage 3.0 (TID 164) in 179 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:30:57.728+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 91.0 in stage 3.0 (TID 163). 6243 bytes result sent to driver
[2025-07-19T20:30:57.728+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78a97a7f
[2025-07-19T20:30:57.729+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.1.delta.7097b9c1-54c7-4390-97c0-556e062a1c44.TID165.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta
[2025-07-19T20:30:57.732+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta
[2025-07-19T20:30:57.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 165, attempt 0, stage 3.0)
[2025-07-19T20:30:57.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.734+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 121.0 in stage 3.0 (TID 172) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.735+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:57.736+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.736+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108] for update
[2025-07-19T20:30:57.739+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 91.0 in stage 3.0 (TID 163) in 201 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:30:57.740+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 121.0 in stage 3.0 (TID 172)
[2025-07-19T20:30:57.742+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.1.delta.0178b50c-8b11-4e10-9b22-effc567606c4.TID168.tmp
[2025-07-19T20:30:57.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 95 (task 165, attempt 0, stage 3.0)
[2025-07-19T20:30:57.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 95.0 in stage 3.0 (TID 165). 6200 bytes result sent to driver
[2025-07-19T20:30:57.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 122.0 in stage 3.0 (TID 173) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 122.0 in stage 3.0 (TID 173)
[2025-07-19T20:30:57.745+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.745+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.747+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 95.0 in stage 3.0 (TID 165) in 151 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:30:57.747+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@699fdfe2
[2025-07-19T20:30:57.748+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.748+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115] for update
[2025-07-19T20:30:57.749+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.749+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.750+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.751+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.1.delta.60417a5e-20c3-4f49-99e2-4c408c995926.TID167.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta
[2025-07-19T20:30:57.753+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta
[2025-07-19T20:30:57.754+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.1.delta.05a94b5b-3037-4922-bd05-de3f6c134caa.TID169.tmp
[2025-07-19T20:30:57.754+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 167, attempt 0, stage 3.0)
[2025-07-19T20:30:57.756+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d664892
[2025-07-19T20:30:57.756+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122] for update
[2025-07-19T20:30:57.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.1.delta.b4ebd9e9-63e9-49e8-a0ea-e46cd7cf5367.TID166.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta
[2025-07-19T20:30:57.758+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta
[2025-07-19T20:30:57.760+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 166, attempt 0, stage 3.0)
[2025-07-19T20:30:57.762+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.1.delta.3483a8c0-fd92-4ed8-8aee-e056b9d5f794.TID170.tmp
[2025-07-19T20:30:57.763+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 101 (task 167, attempt 0, stage 3.0)
[2025-07-19T20:30:57.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a60b4a3
[2025-07-19T20:30:57.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 101.0 in stage 3.0 (TID 167). 6200 bytes result sent to driver
[2025-07-19T20:30:57.766+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.767+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 123.0 in stage 3.0 (TID 174) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.768+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121] for update
[2025-07-19T20:30:57.769+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 98 (task 166, attempt 0, stage 3.0)
[2025-07-19T20:30:57.769+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 98.0 in stage 3.0 (TID 166). 6200 bytes result sent to driver
[2025-07-19T20:30:57.770+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 123.0 in stage 3.0 (TID 174)
[2025-07-19T20:30:57.772+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 129.0 in stage 3.0 (TID 175) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.772+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 129.0 in stage 3.0 (TID 175)
[2025-07-19T20:30:57.773+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.773+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 101.0 in stage 3.0 (TID 167) in 109 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:30:57.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 98.0 in stage 3.0 (TID 166) in 174 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:30:57.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.775+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.1.delta.241192fd-cdc0-4e0a-a6b8-a947fad5c7d4.TID171.tmp
[2025-07-19T20:30:57.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.1.delta.1247e05f-d4dc-4cef-95e6-8a06f0f05538.TID173.tmp
[2025-07-19T20:30:57.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15384ecf
[2025-07-19T20:30:57.777+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.778+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129] for update
[2025-07-19T20:30:57.779+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43194f9c
[2025-07-19T20:30:57.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123] for update
[2025-07-19T20:30:57.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.1.delta.b37af1e3-039a-483a-b412-7f13ff9f8fa7.TID172.tmp
[2025-07-19T20:30:57.791+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.806+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.1.delta.6f6053e3-d246-48fa-aafc-72d9d7081b30.TID175.tmp
[2025-07-19T20:30:57.809+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.1.delta.0178b50c-8b11-4e10-9b22-effc567606c4.TID168.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta
[2025-07-19T20:30:57.810+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta
[2025-07-19T20:30:57.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 168, attempt 0, stage 3.0)
[2025-07-19T20:30:57.818+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 104 (task 168, attempt 0, stage 3.0)
[2025-07-19T20:30:57.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 104.0 in stage 3.0 (TID 168). 6243 bytes result sent to driver
[2025-07-19T20:30:57.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 132.0 in stage 3.0 (TID 176) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 132.0 in stage 3.0 (TID 176)
[2025-07-19T20:30:57.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 104.0 in stage 3.0 (TID 168) in 153 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:30:57.822+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.1.delta.e7a78b42-4430-4196-a80b-d88eb37ad9c9.TID174.tmp
[2025-07-19T20:30:57.830+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.1.delta.05a94b5b-3037-4922-bd05-de3f6c134caa.TID169.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta
[2025-07-19T20:30:57.830+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta
[2025-07-19T20:30:57.831+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 169, attempt 0, stage 3.0)
[2025-07-19T20:30:57.831+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.831+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:57.832+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 107 (task 169, attempt 0, stage 3.0)
[2025-07-19T20:30:57.832+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 107.0 in stage 3.0 (TID 169). 6243 bytes result sent to driver
[2025-07-19T20:30:57.832+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 133.0 in stage 3.0 (TID 177) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.835+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 107.0 in stage 3.0 (TID 169) in 141 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:30:57.836+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 133.0 in stage 3.0 (TID 177)
[2025-07-19T20:30:57.837+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ef8f2dd
[2025-07-19T20:30:57.838+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.1.delta.3483a8c0-fd92-4ed8-8aee-e056b9d5f794.TID170.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta
[2025-07-19T20:30:57.839+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta
[2025-07-19T20:30:57.840+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 170, attempt 0, stage 3.0)
[2025-07-19T20:30:57.841+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.853+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.854+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.1.delta.241192fd-cdc0-4e0a-a6b8-a947fad5c7d4.TID171.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta
[2025-07-19T20:30:57.855+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta
[2025-07-19T20:30:57.856+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132] for update
[2025-07-19T20:30:57.864+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 171, attempt 0, stage 3.0)
[2025-07-19T20:30:57.866+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.866+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@203256be
[2025-07-19T20:30:57.867+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.867+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133] for update
[2025-07-19T20:30:57.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.1.delta.1247e05f-d4dc-4cef-95e6-8a06f0f05538.TID173.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta
[2025-07-19T20:30:57.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta
[2025-07-19T20:30:57.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 173, attempt 0, stage 3.0)
[2025-07-19T20:30:57.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 115 (task 171, attempt 0, stage 3.0)
[2025-07-19T20:30:57.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 115.0 in stage 3.0 (TID 171). 6243 bytes result sent to driver
[2025-07-19T20:30:57.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 138.0 in stage 3.0 (TID 178) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 115.0 in stage 3.0 (TID 171) in 130 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:30:57.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 108 (task 170, attempt 0, stage 3.0)
[2025-07-19T20:30:57.870+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 108.0 in stage 3.0 (TID 170). 6243 bytes result sent to driver
[2025-07-19T20:30:57.871+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 138.0 in stage 3.0 (TID 178)
[2025-07-19T20:30:57.874+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 122 (task 173, attempt 0, stage 3.0)
[2025-07-19T20:30:57.876+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 139.0 in stage 3.0 (TID 179) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.878+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 122.0 in stage 3.0 (TID 173). 6243 bytes result sent to driver
[2025-07-19T20:30:57.881+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 143.0 in stage 3.0 (TID 180) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.882+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.1.delta.9cb888ae-a9ea-4d88-9659-60912bb7f5b2.TID176.tmp
[2025-07-19T20:30:57.886+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 143.0 in stage 3.0 (TID 180)
[2025-07-19T20:30:57.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 139.0 in stage 3.0 (TID 179)
[2025-07-19T20:30:57.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.1.delta.6f6053e3-d246-48fa-aafc-72d9d7081b30.TID175.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta
[2025-07-19T20:30:57.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta
[2025-07-19T20:30:57.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 108.0 in stage 3.0 (TID 170) in 154 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:30:57.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 122.0 in stage 3.0 (TID 173) in 119 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:30:57.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 175, attempt 0, stage 3.0)
[2025-07-19T20:30:57.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.896+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.897+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.898+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.1.delta.b37af1e3-039a-483a-b412-7f13ff9f8fa7.TID172.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta
[2025-07-19T20:30:57.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta
[2025-07-19T20:30:57.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.911+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 172, attempt 0, stage 3.0)
[2025-07-19T20:30:57.912+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:57.914+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3154038
[2025-07-19T20:30:57.916+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138] for update
[2025-07-19T20:30:57.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 129 (task 175, attempt 0, stage 3.0)
[2025-07-19T20:30:57.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 121 (task 172, attempt 0, stage 3.0)
[2025-07-19T20:30:57.927+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 121.0 in stage 3.0 (TID 172). 6243 bytes result sent to driver
[2025-07-19T20:30:57.930+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.1.delta.9acd9224-a024-4e2e-8bd6-874176e8ec55.TID177.tmp
[2025-07-19T20:30:57.933+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 146.0 in stage 3.0 (TID 181) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.934+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 146.0 in stage 3.0 (TID 181)
[2025-07-19T20:30:57.938+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 121.0 in stage 3.0 (TID 172) in 156 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:30:57.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53543428
[2025-07-19T20:30:57.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.944+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139] for update
[2025-07-19T20:30:57.945+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.1.delta.1664d61a-ffac-4cb3-b248-40e299a5a62f.TID178.tmp
[2025-07-19T20:30:57.948+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.1.delta.e7a78b42-4430-4196-a80b-d88eb37ad9c9.TID174.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta
[2025-07-19T20:30:57.950+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta
[2025-07-19T20:30:57.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 174, attempt 0, stage 3.0)
[2025-07-19T20:30:57.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 129.0 in stage 3.0 (TID 175). 6286 bytes result sent to driver
[2025-07-19T20:30:57.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 150.0 in stage 3.0 (TID 182) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 129.0 in stage 3.0 (TID 175) in 146 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:30:57.952+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 150.0 in stage 3.0 (TID 182)
[2025-07-19T20:30:57.953+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b9558d5
[2025-07-19T20:30:57.955+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.956+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143] for update
[2025-07-19T20:30:57.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.958+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.959+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.959+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 123 (task 174, attempt 0, stage 3.0)
[2025-07-19T20:30:57.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 123.0 in stage 3.0 (TID 174). 6243 bytes result sent to driver
[2025-07-19T20:30:57.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28968707
[2025-07-19T20:30:57.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.965+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 154.0 in stage 3.0 (TID 183) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.966+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146] for update
[2025-07-19T20:30:57.967+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 123.0 in stage 3.0 (TID 174) in 172 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:30:57.967+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 154.0 in stage 3.0 (TID 183)
[2025-07-19T20:30:57.967+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.968+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.1.delta.9cb888ae-a9ea-4d88-9659-60912bb7f5b2.TID176.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta
[2025-07-19T20:30:57.969+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta
[2025-07-19T20:30:57.969+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 176, attempt 0, stage 3.0)
[2025-07-19T20:30:57.970+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.970+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.970+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7af1057f
[2025-07-19T20:30:57.970+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150] for update
[2025-07-19T20:30:57.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.1.delta.230b7ab0-2eed-4248-99a0-7be5e2b4c738.TID179.tmp
[2025-07-19T20:30:57.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.1.delta.6ef908fc-9bb1-4cbf-935d-d83d27715b86.TID180.tmp
[2025-07-19T20:30:57.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 132 (task 176, attempt 0, stage 3.0)
[2025-07-19T20:30:57.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.1.delta.9acd9224-a024-4e2e-8bd6-874176e8ec55.TID177.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta
[2025-07-19T20:30:57.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta
[2025-07-19T20:30:57.980+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 132.0 in stage 3.0 (TID 176). 6286 bytes result sent to driver
[2025-07-19T20:30:57.982+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12a809e7
[2025-07-19T20:30:57.982+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:57.982+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 158.0 in stage 3.0 (TID 184) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:57.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154] for update
[2025-07-19T20:30:57.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 132.0 in stage 3.0 (TID 176) in 159 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:30:57.989+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 158.0 in stage 3.0 (TID 184)
[2025-07-19T20:30:57.989+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 177, attempt 0, stage 3.0)
[2025-07-19T20:30:57.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:57.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:57.991+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:57.991+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.1.delta.f5a8c773-9777-4435-a785-392e5159f43f.TID181.tmp
[2025-07-19T20:30:57.999+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71107fce
[2025-07-19T20:30:58.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.002+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158] for update
[2025-07-19T20:30:58.003+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.1.delta.66c18068-3908-447e-ade3-e86a861b0f7f.TID182.tmp
[2025-07-19T20:30:58.003+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO DataWritingSparkTask: Committed partition 133 (task 177, attempt 0, stage 3.0)
[2025-07-19T20:30:58.004+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.004+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Finished task 133.0 in stage 3.0 (TID 177). 6243 bytes result sent to driver
[2025-07-19T20:30:58.005+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Starting task 159.0 in stage 3.0 (TID 185) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.006+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO TaskSetManager: Finished task 133.0 in stage 3.0 (TID 177) in 168 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:30:58.006+0000] {subprocess.py:93} INFO - 25/07/19 20:30:57 INFO Executor: Running task 159.0 in stage 3.0 (TID 185)
[2025-07-19T20:30:58.019+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.021+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.1.delta.1664d61a-ffac-4cb3-b248-40e299a5a62f.TID178.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta
[2025-07-19T20:30:58.022+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta
[2025-07-19T20:30:58.022+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.1.delta.4509a7c1-2b64-4159-b018-06db3b4f5590.TID183.tmp
[2025-07-19T20:30:58.022+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:58.022+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 178, attempt 0, stage 3.0)
[2025-07-19T20:30:58.023+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 138 (task 178, attempt 0, stage 3.0)
[2025-07-19T20:30:58.023+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 138.0 in stage 3.0 (TID 178). 6243 bytes result sent to driver
[2025-07-19T20:30:58.024+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 161.0 in stage 3.0 (TID 186) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.024+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 161.0 in stage 3.0 (TID 186)
[2025-07-19T20:30:58.024+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.1.delta.cf9cb540-56a0-4bb1-8553-973bceb68c25.TID184.tmp
[2025-07-19T20:30:58.025+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 138.0 in stage 3.0 (TID 178) in 170 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:30:58.025+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.025+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:58.027+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@760d12a1
[2025-07-19T20:30:58.028+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.030+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159] for update
[2025-07-19T20:30:58.030+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.043+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f3129db
[2025-07-19T20:30:58.043+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.044+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161] for update
[2025-07-19T20:30:58.050+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.053+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.1.delta.230b7ab0-2eed-4248-99a0-7be5e2b4c738.TID179.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta
[2025-07-19T20:30:58.054+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta
[2025-07-19T20:30:58.056+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 179, attempt 0, stage 3.0)
[2025-07-19T20:30:58.057+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.1.delta.64495696-b516-4182-8d53-815686ad766e.TID185.tmp
[2025-07-19T20:30:58.058+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.1.delta.f5a8c773-9777-4435-a785-392e5159f43f.TID181.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta
[2025-07-19T20:30:58.058+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 139 (task 179, attempt 0, stage 3.0)
[2025-07-19T20:30:58.059+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta
[2025-07-19T20:30:58.061+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 181, attempt 0, stage 3.0)
[2025-07-19T20:30:58.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 139.0 in stage 3.0 (TID 179). 6243 bytes result sent to driver
[2025-07-19T20:30:58.066+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.1.delta.6ef908fc-9bb1-4cbf-935d-d83d27715b86.TID180.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta
[2025-07-19T20:30:58.067+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta
[2025-07-19T20:30:58.068+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 163.0 in stage 3.0 (TID 187) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.069+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 180, attempt 0, stage 3.0)
[2025-07-19T20:30:58.070+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 139.0 in stage 3.0 (TID 179) in 205 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:30:58.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 163.0 in stage 3.0 (TID 187)
[2025-07-19T20:30:58.077+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 143 (task 180, attempt 0, stage 3.0)
[2025-07-19T20:30:58.078+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 143.0 in stage 3.0 (TID 180). 6243 bytes result sent to driver
[2025-07-19T20:30:58.078+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.1.delta.4509a7c1-2b64-4159-b018-06db3b4f5590.TID183.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta
[2025-07-19T20:30:58.079+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 143.0 in stage 3.0 (TID 180) in 212 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:30:58.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 164.0 in stage 3.0 (TID 188) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 164.0 in stage 3.0 (TID 188)
[2025-07-19T20:30:58.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 146 (task 181, attempt 0, stage 3.0)
[2025-07-19T20:30:58.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 146.0 in stage 3.0 (TID 181). 6243 bytes result sent to driver
[2025-07-19T20:30:58.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta
[2025-07-19T20:30:58.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 183, attempt 0, stage 3.0)
[2025-07-19T20:30:58.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.1.delta.66c18068-3908-447e-ade3-e86a861b0f7f.TID182.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta
[2025-07-19T20:30:58.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta
[2025-07-19T20:30:58.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 182, attempt 0, stage 3.0)
[2025-07-19T20:30:58.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34bee9fb
[2025-07-19T20:30:58.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 167.0 in stage 3.0 (TID 189) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 154 (task 183, attempt 0, stage 3.0)
[2025-07-19T20:30:58.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164] for update
[2025-07-19T20:30:58.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 146.0 in stage 3.0 (TID 181) in 207 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:30:58.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.090+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 154.0 in stage 3.0 (TID 183). 6243 bytes result sent to driver
[2025-07-19T20:30:58.094+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.1.delta.40283972-d6ab-49fe-8ffc-51560721a5ce.TID186.tmp
[2025-07-19T20:30:58.096+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 150 (task 182, attempt 0, stage 3.0)
[2025-07-19T20:30:58.097+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 167.0 in stage 3.0 (TID 189)
[2025-07-19T20:30:58.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 170.0 in stage 3.0 (TID 190) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b6af8bb
[2025-07-19T20:30:58.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 150.0 in stage 3.0 (TID 182). 6243 bytes result sent to driver
[2025-07-19T20:30:58.101+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 171.0 in stage 3.0 (TID 191) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 171.0 in stage 3.0 (TID 191)
[2025-07-19T20:30:58.102+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 154.0 in stage 3.0 (TID 183) in 172 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:30:58.103+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 150.0 in stage 3.0 (TID 182) in 196 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:30:58.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.1.delta.cf9cb540-56a0-4bb1-8553-973bceb68c25.TID184.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta
[2025-07-19T20:30:58.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta
[2025-07-19T20:30:58.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 170.0 in stage 3.0 (TID 190)
[2025-07-19T20:30:58.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163] for update
[2025-07-19T20:30:58.106+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:58.106+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 184, attempt 0, stage 3.0)
[2025-07-19T20:30:58.106+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.106+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.109+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.110+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.110+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.1.delta.6bcc8000-0e33-4545-a0ae-10718192d8da.TID188.tmp
[2025-07-19T20:30:58.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 158 (task 184, attempt 0, stage 3.0)
[2025-07-19T20:30:58.126+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a6b1149
[2025-07-19T20:30:58.127+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.127+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167] for update
[2025-07-19T20:30:58.128+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 158.0 in stage 3.0 (TID 184). 6243 bytes result sent to driver
[2025-07-19T20:30:58.128+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 158.0 in stage 3.0 (TID 184) in 145 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:30:58.129+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 172.0 in stage 3.0 (TID 192) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 172.0 in stage 3.0 (TID 192)
[2025-07-19T20:30:58.131+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.131+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:58.131+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.1.delta.ee7ca644-23fa-42c3-a4ca-f45485d4757d.TID187.tmp
[2025-07-19T20:30:58.133+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.1.delta.64495696-b516-4182-8d53-815686ad766e.TID185.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta
[2025-07-19T20:30:58.134+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta
[2025-07-19T20:30:58.135+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 185, attempt 0, stage 3.0)
[2025-07-19T20:30:58.141+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66508e68
[2025-07-19T20:30:58.142+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.145+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170] for update
[2025-07-19T20:30:58.146+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.153+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.1.delta.3d5c3d72-9561-402f-9b6c-5c9f898d6b85.TID189.tmp
[2025-07-19T20:30:58.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 159 (task 185, attempt 0, stage 3.0)
[2025-07-19T20:30:58.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 159.0 in stage 3.0 (TID 185). 6243 bytes result sent to driver
[2025-07-19T20:30:58.157+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 173.0 in stage 3.0 (TID 193) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.158+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 159.0 in stage 3.0 (TID 185) in 159 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:30:58.160+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.1.delta.40283972-d6ab-49fe-8ffc-51560721a5ce.TID186.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta
[2025-07-19T20:30:58.165+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta
[2025-07-19T20:30:58.165+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 186, attempt 0, stage 3.0)
[2025-07-19T20:30:58.166+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4074004e
[2025-07-19T20:30:58.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.167+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171] for update
[2025-07-19T20:30:58.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 173.0 in stage 3.0 (TID 193)
[2025-07-19T20:30:58.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.169+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.169+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.172+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 161 (task 186, attempt 0, stage 3.0)
[2025-07-19T20:30:58.175+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 161.0 in stage 3.0 (TID 186). 6243 bytes result sent to driver
[2025-07-19T20:30:58.175+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.1.delta.0e7beaf1-8edc-41d0-b834-82151b86c883.TID190.tmp
[2025-07-19T20:30:58.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.1.delta.6bcc8000-0e33-4545-a0ae-10718192d8da.TID188.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta
[2025-07-19T20:30:58.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta
[2025-07-19T20:30:58.177+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67089fba
[2025-07-19T20:30:58.178+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 177.0 in stage 3.0 (TID 194) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 161.0 in stage 3.0 (TID 186) in 164 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:30:58.179+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172] for update
[2025-07-19T20:30:58.182+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 188, attempt 0, stage 3.0)
[2025-07-19T20:30:58.184+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.188+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 177.0 in stage 3.0 (TID 194)
[2025-07-19T20:30:58.189+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 164 (task 188, attempt 0, stage 3.0)
[2025-07-19T20:30:58.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 164.0 in stage 3.0 (TID 188). 6243 bytes result sent to driver
[2025-07-19T20:30:58.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 180.0 in stage 3.0 (TID 195) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.196+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 164.0 in stage 3.0 (TID 188) in 121 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:30:58.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.1.delta.fc5852bd-afe6-4615-acc9-f0b596a10e6c.TID191.tmp
[2025-07-19T20:30:58.202+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 180.0 in stage 3.0 (TID 195)
[2025-07-19T20:30:58.203+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.203+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.203+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78486dfc
[2025-07-19T20:30:58.207+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.209+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173] for update
[2025-07-19T20:30:58.209+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.210+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.211+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.1.delta.f5dded4d-982d-413c-9f07-81443516d873.TID192.tmp
[2025-07-19T20:30:58.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e2cd3fc
[2025-07-19T20:30:58.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180] for update
[2025-07-19T20:30:58.218+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.1.delta.ee7ca644-23fa-42c3-a4ca-f45485d4757d.TID187.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta
[2025-07-19T20:30:58.222+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta
[2025-07-19T20:30:58.222+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 187, attempt 0, stage 3.0)
[2025-07-19T20:30:58.222+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f4ebb35
[2025-07-19T20:30:58.223+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.223+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177] for update
[2025-07-19T20:30:58.224+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 163 (task 187, attempt 0, stage 3.0)
[2025-07-19T20:30:58.226+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.227+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 163.0 in stage 3.0 (TID 187). 6243 bytes result sent to driver
[2025-07-19T20:30:58.230+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 181.0 in stage 3.0 (TID 196) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 163.0 in stage 3.0 (TID 187) in 170 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:30:58.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 181.0 in stage 3.0 (TID 196)
[2025-07-19T20:30:58.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.1.delta.34a086cf-a820-4403-92df-299253029ad4.TID195.tmp
[2025-07-19T20:30:58.232+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.232+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.232+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.1.delta.64ea89ed-58e6-44a7-98cf-93f525ea134f.TID193.tmp
[2025-07-19T20:30:58.235+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.1.delta.3d5c3d72-9561-402f-9b6c-5c9f898d6b85.TID189.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta
[2025-07-19T20:30:58.235+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta
[2025-07-19T20:30:58.237+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 189, attempt 0, stage 3.0)
[2025-07-19T20:30:58.237+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.1.delta.5bedfe14-8198-4f1f-a17d-06dc02716d5d.TID194.tmp
[2025-07-19T20:30:58.239+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45a55e62
[2025-07-19T20:30:58.240+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.244+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181] for update
[2025-07-19T20:30:58.247+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.249+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 167 (task 189, attempt 0, stage 3.0)
[2025-07-19T20:30:58.249+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 167.0 in stage 3.0 (TID 189). 6243 bytes result sent to driver
[2025-07-19T20:30:58.250+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 186.0 in stage 3.0 (TID 197) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 167.0 in stage 3.0 (TID 189) in 174 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:30:58.254+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.1.delta.0e7beaf1-8edc-41d0-b834-82151b86c883.TID190.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta
[2025-07-19T20:30:58.255+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 186.0 in stage 3.0 (TID 197)
[2025-07-19T20:30:58.256+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta
[2025-07-19T20:30:58.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 190, attempt 0, stage 3.0)
[2025-07-19T20:30:58.258+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.1.delta.fc5852bd-afe6-4615-acc9-f0b596a10e6c.TID191.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta
[2025-07-19T20:30:58.260+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta
[2025-07-19T20:30:58.261+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.1.delta.49f589d8-fa57-4e0e-b556-f388121459e3.TID196.tmp
[2025-07-19T20:30:58.262+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 191, attempt 0, stage 3.0)
[2025-07-19T20:30:58.264+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 170 (task 190, attempt 0, stage 3.0)
[2025-07-19T20:30:58.265+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e248414
[2025-07-19T20:30:58.266+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 170.0 in stage 3.0 (TID 190). 6243 bytes result sent to driver
[2025-07-19T20:30:58.267+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 171 (task 191, attempt 0, stage 3.0)
[2025-07-19T20:30:58.269+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 189.0 in stage 3.0 (TID 198) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.269+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 189.0 in stage 3.0 (TID 198)
[2025-07-19T20:30:58.270+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.270+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186] for update
[2025-07-19T20:30:58.271+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 170.0 in stage 3.0 (TID 190) in 171 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:30:58.279+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.280+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.281+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.1.delta.f5dded4d-982d-413c-9f07-81443516d873.TID192.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta
[2025-07-19T20:30:58.281+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta
[2025-07-19T20:30:58.282+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 171.0 in stage 3.0 (TID 191). 6286 bytes result sent to driver
[2025-07-19T20:30:58.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 190.0 in stage 3.0 (TID 199) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.285+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 192, attempt 0, stage 3.0)
[2025-07-19T20:30:58.286+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 190.0 in stage 3.0 (TID 199)
[2025-07-19T20:30:58.286+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 171.0 in stage 3.0 (TID 191) in 179 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:30:58.288+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73f08bb2
[2025-07-19T20:30:58.289+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.289+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189] for update
[2025-07-19T20:30:58.290+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 172 (task 192, attempt 0, stage 3.0)
[2025-07-19T20:30:58.292+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 172.0 in stage 3.0 (TID 192). 6243 bytes result sent to driver
[2025-07-19T20:30:58.294+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.1.delta.58aca0b9-a43c-4c0c-9720-5bc89912952a.TID197.tmp
[2025-07-19T20:30:58.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 192.0 in stage 3.0 (TID 200) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.296+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 172.0 in stage 3.0 (TID 192) in 170 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:30:58.297+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:58.301+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.1.delta.5bedfe14-8198-4f1f-a17d-06dc02716d5d.TID194.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta
[2025-07-19T20:30:58.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 192.0 in stage 3.0 (TID 200)
[2025-07-19T20:30:58.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta
[2025-07-19T20:30:58.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.1.delta.34a086cf-a820-4403-92df-299253029ad4.TID195.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta
[2025-07-19T20:30:58.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta
[2025-07-19T20:30:58.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.1.delta.64ea89ed-58e6-44a7-98cf-93f525ea134f.TID193.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta
[2025-07-19T20:30:58.308+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta
[2025-07-19T20:30:58.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 194, attempt 0, stage 3.0)
[2025-07-19T20:30:58.313+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 195, attempt 0, stage 3.0)
[2025-07-19T20:30:58.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.322+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.323+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 180 (task 195, attempt 0, stage 3.0)
[2025-07-19T20:30:58.325+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 177 (task 194, attempt 0, stage 3.0)
[2025-07-19T20:30:58.325+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.1.delta.8f13337b-fc96-46d6-985d-84e52defe2c7.TID198.tmp
[2025-07-19T20:30:58.326+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 177.0 in stage 3.0 (TID 194). 6243 bytes result sent to driver
[2025-07-19T20:30:58.327+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 180.0 in stage 3.0 (TID 195). 6243 bytes result sent to driver
[2025-07-19T20:30:58.329+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@683ee568
[2025-07-19T20:30:58.332+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.1.delta.49f589d8-fa57-4e0e-b556-f388121459e3.TID196.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta
[2025-07-19T20:30:58.333+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta
[2025-07-19T20:30:58.334+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 193, attempt 0, stage 3.0)
[2025-07-19T20:30:58.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 193.0 in stage 3.0 (TID 201) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.338+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 193.0 in stage 3.0 (TID 201)
[2025-07-19T20:30:58.340+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 196, attempt 0, stage 3.0)
[2025-07-19T20:30:58.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.345+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190] for update
[2025-07-19T20:30:58.346+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 173 (task 193, attempt 0, stage 3.0)
[2025-07-19T20:30:58.346+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.348+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 195.0 in stage 3.0 (TID 202) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.351+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 173.0 in stage 3.0 (TID 193). 6243 bytes result sent to driver
[2025-07-19T20:30:58.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 177.0 in stage 3.0 (TID 194) in 155 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:30:58.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 181 (task 196, attempt 0, stage 3.0)
[2025-07-19T20:30:58.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 195.0 in stage 3.0 (TID 202)
[2025-07-19T20:30:58.353+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 181.0 in stage 3.0 (TID 196). 6243 bytes result sent to driver
[2025-07-19T20:30:58.354+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 203) (8b44f3d35cfa, executor driver, partition 0, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 204) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 180.0 in stage 3.0 (TID 195) in 147 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:30:58.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 173.0 in stage 3.0 (TID 193) in 180 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:30:58.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 181.0 in stage 3.0 (TID 196) in 109 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:30:58.356+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 203)
[2025-07-19T20:30:58.357+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 204)
[2025-07-19T20:30:58.358+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.358+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.359+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.359+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.1.delta.8a0b0002-8f25-4e02-8b7d-2d66958f8569.TID199.tmp
[2025-07-19T20:30:58.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:58.360+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15408d6d
[2025-07-19T20:30:58.361+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192] for update
[2025-07-19T20:30:58.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.363+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.364+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.364+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.1.delta.58aca0b9-a43c-4c0c-9720-5bc89912952a.TID197.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta
[2025-07-19T20:30:58.364+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta
[2025-07-19T20:30:58.365+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.1.delta.11d4bcc6-3977-483b-9b6b-d942d4620c45.TID200.tmp
[2025-07-19T20:30:58.366+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 197, attempt 0, stage 3.0)
[2025-07-19T20:30:58.368+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 186 (task 197, attempt 0, stage 3.0)
[2025-07-19T20:30:58.369+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 186.0 in stage 3.0 (TID 197). 6243 bytes result sent to driver
[2025-07-19T20:30:58.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 205) (8b44f3d35cfa, executor driver, partition 2, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 2.0 in stage 1.0 (TID 205)
[2025-07-19T20:30:58.372+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.373+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.374+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.1.delta.8f13337b-fc96-46d6-985d-84e52defe2c7.TID198.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta
[2025-07-19T20:30:58.374+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta
[2025-07-19T20:30:58.377+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 186.0 in stage 3.0 (TID 197) in 129 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:30:58.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 198, attempt 0, stage 3.0)
[2025-07-19T20:30:58.382+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 189 (task 198, attempt 0, stage 3.0)
[2025-07-19T20:30:58.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/.schema.298c1f45-c2a2-47fa-83e7-34b7ce6f2862.TID203.tmp
[2025-07-19T20:30:58.385+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 189.0 in stage 3.0 (TID 198). 6243 bytes result sent to driver
[2025-07-19T20:30:58.387+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 206) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.387+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 189.0 in stage 3.0 (TID 198) in 119 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:30:58.389+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 3.0 in stage 1.0 (TID 206)
[2025-07-19T20:30:58.396+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.396+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.399+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.1.delta.8a0b0002-8f25-4e02-8b7d-2d66958f8569.TID199.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta
[2025-07-19T20:30:58.399+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta
[2025-07-19T20:30:58.400+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 199, attempt 0, stage 3.0)
[2025-07-19T20:30:58.418+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 190 (task 199, attempt 0, stage 3.0)
[2025-07-19T20:30:58.420+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 190.0 in stage 3.0 (TID 199). 6200 bytes result sent to driver
[2025-07-19T20:30:58.422+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 207) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 190.0 in stage 3.0 (TID 199) in 140 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:30:58.423+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.1.delta.11d4bcc6-3977-483b-9b6b-d942d4620c45.TID200.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta
[2025-07-19T20:30:58.424+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta
[2025-07-19T20:30:58.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 200, attempt 0, stage 3.0)
[2025-07-19T20:30:58.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 4.0 in stage 1.0 (TID 207)
[2025-07-19T20:30:58.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.430+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 192 (task 200, attempt 0, stage 3.0)
[2025-07-19T20:30:58.434+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 192.0 in stage 3.0 (TID 200). 6286 bytes result sent to driver
[2025-07-19T20:30:58.435+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 208) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.436+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 192.0 in stage 3.0 (TID 200) in 144 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:30:58.436+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 7.0 in stage 1.0 (TID 208)
[2025-07-19T20:30:58.440+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.440+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.440+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/.schema.298c1f45-c2a2-47fa-83e7-34b7ce6f2862.TID203.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/schema
[2025-07-19T20:30:58.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e8da38e
[2025-07-19T20:30:58.442+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.442+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0] for update
[2025-07-19T20:30:58.447+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@15812601
[2025-07-19T20:30:58.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1] for update
[2025-07-19T20:30:58.454+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ae9c132
[2025-07-19T20:30:58.457+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.458+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193] for update
[2025-07-19T20:30:58.458+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodeGenerator: Code generated in 17.166042 ms
[2025-07-19T20:30:58.468+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b7649e3
[2025-07-19T20:30:58.469+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.469+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7] for update
[2025-07-19T20:30:58.471+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodeGenerator: Code generated in 4.529667 ms
[2025-07-19T20:30:58.472+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64afafb9
[2025-07-19T20:30:58.473+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.1.delta.48ec8b9e-3a6e-4027-87a6-4fc6b20e2e5d.TID201.tmp
[2025-07-19T20:30:58.474+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.477+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4] for update
[2025-07-19T20:30:58.479+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.481+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e581840
[2025-07-19T20:30:58.491+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.494+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3] for update
[2025-07-19T20:30:58.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.1.delta.db650665-bc92-4c69-bc53-64192676ea5c.TID204.tmp
[2025-07-19T20:30:58.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.1.delta.58d02510-ce04-4378-bafd-848a0a4b48cc.TID203.tmp
[2025-07-19T20:30:58.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.1.delta.829d3e52-6d8b-4564-b580-0243eec7761a.TID207.tmp
[2025-07-19T20:30:58.496+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.1.delta.fc6a4fcd-0275-4050-a704-7cb7c0c64aa6.TID208.tmp
[2025-07-19T20:30:58.499+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.499+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@279a4e5
[2025-07-19T20:30:58.504+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.504+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2] for update
[2025-07-19T20:30:58.504+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.512+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.1.delta.dd423371-fc90-4c06-ba8c-3b484a5f743a.TID206.tmp
[2025-07-19T20:30:58.516+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.1.delta.c4df4249-b32f-48a8-b23d-4130562bbf77.TID205.tmp
[2025-07-19T20:30:58.519+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@255ccba0
[2025-07-19T20:30:58.519+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:30:58.520+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195] for update
[2025-07-19T20:30:58.520+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.523+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.1.delta.48ec8b9e-3a6e-4027-87a6-4fc6b20e2e5d.TID201.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta
[2025-07-19T20:30:58.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta
[2025-07-19T20:30:58.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 201, attempt 0, stage 3.0)
[2025-07-19T20:30:58.528+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.1.delta.d0b7aab0-994a-4b1e-9740-5cdb287c8486.TID202.tmp
[2025-07-19T20:30:58.529+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 193 (task 201, attempt 0, stage 3.0)
[2025-07-19T20:30:58.531+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 193.0 in stage 3.0 (TID 201). 6243 bytes result sent to driver
[2025-07-19T20:30:58.532+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 209) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.533+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 193.0 in stage 3.0 (TID 201) in 216 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:30:58.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 9.0 in stage 1.0 (TID 209)
[2025-07-19T20:30:58.537+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.1.delta.db650665-bc92-4c69-bc53-64192676ea5c.TID204.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta
[2025-07-19T20:30:58.538+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta
[2025-07-19T20:30:58.539+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 204, attempt 0, stage 1.0)
[2025-07-19T20:30:58.540+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.1.delta.fc6a4fcd-0275-4050-a704-7cb7c0c64aa6.TID208.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta
[2025-07-19T20:30:58.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d8ecee2
[2025-07-19T20:30:58.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta
[2025-07-19T20:30:58.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9] for update
[2025-07-19T20:30:58.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 208, attempt 0, stage 1.0)
[2025-07-19T20:30:58.542+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.1.delta.829d3e52-6d8b-4564-b580-0243eec7761a.TID207.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta
[2025-07-19T20:30:58.543+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta
[2025-07-19T20:30:58.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.1.delta.58d02510-ce04-4378-bafd-848a0a4b48cc.TID203.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta
[2025-07-19T20:30:58.549+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta
[2025-07-19T20:30:58.554+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 207, attempt 0, stage 1.0)
[2025-07-19T20:30:58.555+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 203, attempt 0, stage 1.0)
[2025-07-19T20:30:58.561+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.1.delta.7e015e25-c2ab-45ca-ad42-6187a498d8cd.TID209.tmp
[2025-07-19T20:30:58.562+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.1.delta.dd423371-fc90-4c06-ba8c-3b484a5f743a.TID206.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta
[2025-07-19T20:30:58.562+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta
[2025-07-19T20:30:58.563+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 206, attempt 0, stage 1.0)
[2025-07-19T20:30:58.568+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 1 (task 204, attempt 0, stage 1.0)
[2025-07-19T20:30:58.569+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 204). 9167 bytes result sent to driver
[2025-07-19T20:30:58.571+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.1.delta.c4df4249-b32f-48a8-b23d-4130562bbf77.TID205.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta
[2025-07-19T20:30:58.571+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta
[2025-07-19T20:30:58.573+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 210) (8b44f3d35cfa, executor driver, partition 10, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.574+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 205, attempt 0, stage 1.0)
[2025-07-19T20:30:58.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 10.0 in stage 1.0 (TID 210)
[2025-07-19T20:30:58.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 204) in 235 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:30:58.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 0 (task 203, attempt 0, stage 1.0)
[2025-07-19T20:30:58.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.578+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.578+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 203). 9156 bytes result sent to driver
[2025-07-19T20:30:58.580+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 211) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.581+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 11.0 in stage 1.0 (TID 211)
[2025-07-19T20:30:58.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 203) in 240 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:30:58.582+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 4 (task 207, attempt 0, stage 1.0)
[2025-07-19T20:30:58.583+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 4.0 in stage 1.0 (TID 207). 9158 bytes result sent to driver
[2025-07-19T20:30:58.583+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b1ee733
[2025-07-19T20:30:58.584+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 212) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.584+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10] for update
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 12.0 in stage 1.0 (TID 212)
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 3 (task 206, attempt 0, stage 1.0)
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 207) in 164 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 3.0 in stage 1.0 (TID 206). 9152 bytes result sent to driver
[2025-07-19T20:30:58.585+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 213) (8b44f3d35cfa, executor driver, partition 13, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.586+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 206) in 200 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:30:58.587+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 7 (task 208, attempt 0, stage 1.0)
[2025-07-19T20:30:58.587+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 7.0 in stage 1.0 (TID 208). 9148 bytes result sent to driver
[2025-07-19T20:30:58.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23138e65
[2025-07-19T20:30:58.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.593+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11] for update
[2025-07-19T20:30:58.594+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 13.0 in stage 1.0 (TID 213)
[2025-07-19T20:30:58.595+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.1.delta.d0b7aab0-994a-4b1e-9740-5cdb287c8486.TID202.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta
[2025-07-19T20:30:58.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 214) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.598+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 208) in 153 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:30:58.598+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.599+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta
[2025-07-19T20:30:58.599+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 14.0 in stage 1.0 (TID 214)
[2025-07-19T20:30:58.599+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.603+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.604+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.604+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 202, attempt 0, stage 3.0)
[2025-07-19T20:30:58.605+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:58.605+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.606+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:30:58.606+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 195 (task 202, attempt 0, stage 3.0)
[2025-07-19T20:30:58.607+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.1.delta.76f8a9ad-7f85-44d9-89ac-e3470e163e19.TID211.tmp
[2025-07-19T20:30:58.607+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 195.0 in stage 3.0 (TID 202). 6243 bytes result sent to driver
[2025-07-19T20:30:58.607+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 215) (8b44f3d35cfa, executor driver, partition 15, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.608+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 2 (task 205, attempt 0, stage 1.0)
[2025-07-19T20:30:58.608+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 195.0 in stage 3.0 (TID 202) in 272 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:30:58.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-07-19T20:30:58.610+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43f4f81b
[2025-07-19T20:30:58.611+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.612+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12] for update
[2025-07-19T20:30:58.612+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 2.0 in stage 1.0 (TID 205). 9156 bytes result sent to driver
[2025-07-19T20:30:58.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 216) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 16.0 in stage 1.0 (TID 216)
[2025-07-19T20:30:58.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DAGScheduler: ResultStage 3 (start at <unknown>:0) finished in 5.720 s
[2025-07-19T20:30:58.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.614+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:30:58.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-07-19T20:30:58.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 15.0 in stage 1.0 (TID 215)
[2025-07-19T20:30:58.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.618+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 205) in 251 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:30:58.620+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.1.delta.addbe97e-68be-4db0-aca7-e1211b4cabde.TID210.tmp
[2025-07-19T20:30:58.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3ed2be3b
[2025-07-19T20:30:58.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 7.426760 s
[2025-07-19T20:30:58.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13] for update
[2025-07-19T20:30:58.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T20:30:58.630+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO SparkWrite: Committing epoch 0 for query 1436cd49-bf2f-4720-8c9f-d251355ec5cf in append mode
[2025-07-19T20:30:58.630+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.1.delta.a8d2ba46-1a07-4398-b436-7adf11890902.TID212.tmp
[2025-07-19T20:30:58.632+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.1.delta.7e015e25-c2ab-45ca-ad42-6187a498d8cd.TID209.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta
[2025-07-19T20:30:58.634+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta
[2025-07-19T20:30:58.635+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 209, attempt 0, stage 1.0)
[2025-07-19T20:30:58.640+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@577c87d
[2025-07-19T20:30:58.640+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.641+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14] for update
[2025-07-19T20:30:58.642+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.1.delta.3ea479de-b58a-4c7f-bdbc-ffa09dc904fb.TID213.tmp
[2025-07-19T20:30:58.642+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.650+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47e26fb9
[2025-07-19T20:30:58.651+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15] for update
[2025-07-19T20:30:58.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.1.delta.76f8a9ad-7f85-44d9-89ac-e3470e163e19.TID211.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta
[2025-07-19T20:30:58.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta
[2025-07-19T20:30:58.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 211, attempt 0, stage 1.0)
[2025-07-19T20:30:58.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.656+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 9 (task 209, attempt 0, stage 1.0)
[2025-07-19T20:30:58.662+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.1.delta.2af6993c-e0bd-4f6f-a735-bacc3a599e00.TID214.tmp
[2025-07-19T20:30:58.664+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 9.0 in stage 1.0 (TID 209). 9216 bytes result sent to driver
[2025-07-19T20:30:58.666+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 217) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.666+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 209) in 134 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:30:58.666+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 18.0 in stage 1.0 (TID 217)
[2025-07-19T20:30:58.667+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ef5adf3
[2025-07-19T20:30:58.670+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.670+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.671+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16] for update
[2025-07-19T20:30:58.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.677+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.1.delta.42230d0c-4e74-4ab5-9595-ad77235efdf4.TID215.tmp
[2025-07-19T20:30:58.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b26cec6
[2025-07-19T20:30:58.681+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.681+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18] for update
[2025-07-19T20:30:58.684+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.686+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 11 (task 211, attempt 0, stage 1.0)
[2025-07-19T20:30:58.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 11.0 in stage 1.0 (TID 211). 9149 bytes result sent to driver
[2025-07-19T20:30:58.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.1.delta.b619cf4e-c9cd-41b0-9417-a25e33610db2.TID216.tmp
[2025-07-19T20:30:58.688+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 218) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 20.0 in stage 1.0 (TID 218)
[2025-07-19T20:30:58.692+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 211) in 117 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:30:58.693+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.693+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.693+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.1.delta.addbe97e-68be-4db0-aca7-e1211b4cabde.TID210.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta
[2025-07-19T20:30:58.694+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta
[2025-07-19T20:30:58.694+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO SparkWrite: Committing streaming append with 130 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:58.695+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 210, attempt 0, stage 1.0)
[2025-07-19T20:30:58.700+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.1.delta.a8d2ba46-1a07-4398-b436-7adf11890902.TID212.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta
[2025-07-19T20:30:58.701+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24880aba
[2025-07-19T20:30:58.701+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.701+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20] for update
[2025-07-19T20:30:58.702+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.1.delta.44ce926c-10dc-4cfe-a229-34fa01daf81f.TID217.tmp
[2025-07-19T20:30:58.703+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta
[2025-07-19T20:30:58.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 212, attempt 0, stage 1.0)
[2025-07-19T20:30:58.712+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.1.delta.3ea479de-b58a-4c7f-bdbc-ffa09dc904fb.TID213.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta
[2025-07-19T20:30:58.713+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 10 (task 210, attempt 0, stage 1.0)
[2025-07-19T20:30:58.714+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta
[2025-07-19T20:30:58.715+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 10.0 in stage 1.0 (TID 210). 9144 bytes result sent to driver
[2025-07-19T20:30:58.716+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 219) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.716+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 213, attempt 0, stage 1.0)
[2025-07-19T20:30:58.716+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 210) in 148 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:30:58.718+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 22.0 in stage 1.0 (TID 219)
[2025-07-19T20:30:58.718+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.718+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.725+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 12 (task 212, attempt 0, stage 1.0)
[2025-07-19T20:30:58.728+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 12.0 in stage 1.0 (TID 212). 9170 bytes result sent to driver
[2025-07-19T20:30:58.729+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7555ac08
[2025-07-19T20:30:58.729+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 220) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 23.0 in stage 1.0 (TID 220)
[2025-07-19T20:30:58.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 212) in 146 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:30:58.730+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22] for update
[2025-07-19T20:30:58.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.1.delta.2af6993c-e0bd-4f6f-a735-bacc3a599e00.TID214.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta
[2025-07-19T20:30:58.731+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta
[2025-07-19T20:30:58.732+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.1.delta.e2aac33b-f88e-446f-b9e4-044aae5c6cb8.TID218.tmp
[2025-07-19T20:30:58.732+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.732+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 214, attempt 0, stage 1.0)
[2025-07-19T20:30:58.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.1.delta.42230d0c-4e74-4ab5-9595-ad77235efdf4.TID215.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta
[2025-07-19T20:30:58.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta
[2025-07-19T20:30:58.733+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 215, attempt 0, stage 1.0)
[2025-07-19T20:30:58.739+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.743+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:30:58.744+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.1.delta.1f9ebde7-dab8-4fd4-95ee-00e532249b17.TID219.tmp
[2025-07-19T20:30:58.745+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 13 (task 213, attempt 0, stage 1.0)
[2025-07-19T20:30:58.754+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 13.0 in stage 1.0 (TID 213). 9215 bytes result sent to driver
[2025-07-19T20:30:58.755+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 221) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.756+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 213) in 170 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:30:58.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 26.0 in stage 1.0 (TID 221)
[2025-07-19T20:30:58.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.1.delta.b619cf4e-c9cd-41b0-9417-a25e33610db2.TID216.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta
[2025-07-19T20:30:58.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta
[2025-07-19T20:30:58.758+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b4329d5
[2025-07-19T20:30:58.759+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 216, attempt 0, stage 1.0)
[2025-07-19T20:30:58.759+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.760+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23] for update
[2025-07-19T20:30:58.763+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:58.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 15 (task 215, attempt 0, stage 1.0)
[2025-07-19T20:30:58.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 15.0 in stage 1.0 (TID 215). 9157 bytes result sent to driver
[2025-07-19T20:30:58.766+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 222) (8b44f3d35cfa, executor driver, partition 27, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.767+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.1.delta.44ce926c-10dc-4cfe-a229-34fa01daf81f.TID217.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta
[2025-07-19T20:30:58.767+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta
[2025-07-19T20:30:58.767+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 217, attempt 0, stage 1.0)
[2025-07-19T20:30:58.770+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 215) in 167 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:30:58.774+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 27.0 in stage 1.0 (TID 222)
[2025-07-19T20:30:58.775+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.775+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 14 (task 214, attempt 0, stage 1.0)
[2025-07-19T20:30:58.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@624bc9
[2025-07-19T20:30:58.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26] for update
[2025-07-19T20:30:58.778+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.1.delta.e2aac33b-f88e-446f-b9e4-044aae5c6cb8.TID218.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta
[2025-07-19T20:30:58.779+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta
[2025-07-19T20:30:58.779+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.780+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 14.0 in stage 1.0 (TID 214). 9193 bytes result sent to driver
[2025-07-19T20:30:58.783+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 218, attempt 0, stage 1.0)
[2025-07-19T20:30:58.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 16 (task 216, attempt 0, stage 1.0)
[2025-07-19T20:30:58.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 16.0 in stage 1.0 (TID 216). 9184 bytes result sent to driver
[2025-07-19T20:30:58.786+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 223) (8b44f3d35cfa, executor driver, partition 28, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.787+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 214) in 198 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:30:58.788+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 28.0 in stage 1.0 (TID 223)
[2025-07-19T20:30:58.788+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 216) in 180 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:30:58.789+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 224) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.789+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.1.delta.c95db13f-b5fa-4b63-8b20-1e881a6a8ca7.TID220.tmp
[2025-07-19T20:30:58.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c79c741
[2025-07-19T20:30:58.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 30.0 in stage 1.0 (TID 224)
[2025-07-19T20:30:58.792+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.792+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27] for update
[2025-07-19T20:30:58.793+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 18 (task 217, attempt 0, stage 1.0)
[2025-07-19T20:30:58.794+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 18.0 in stage 1.0 (TID 217). 9156 bytes result sent to driver
[2025-07-19T20:30:58.794+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.795+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.795+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 225) (8b44f3d35cfa, executor driver, partition 31, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.796+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.798+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:58.798+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 217) in 128 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:30:58.799+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.800+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 31.0 in stage 1.0 (TID 225)
[2025-07-19T20:30:58.800+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.1.delta.b3b27723-37bb-4a36-a01a-4772484888eb.TID221.tmp
[2025-07-19T20:30:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.1.delta.1f9ebde7-dab8-4fd4-95ee-00e532249b17.TID219.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta
[2025-07-19T20:30:58.801+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta
[2025-07-19T20:30:58.802+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21d23167
[2025-07-19T20:30:58.803+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 219, attempt 0, stage 1.0)
[2025-07-19T20:30:58.803+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.804+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.805+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.806+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28] for update
[2025-07-19T20:30:58.807+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 20 (task 218, attempt 0, stage 1.0)
[2025-07-19T20:30:58.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 20.0 in stage 1.0 (TID 218). 9152 bytes result sent to driver
[2025-07-19T20:30:58.812+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 226) (8b44f3d35cfa, executor driver, partition 33, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 218) in 126 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:30:58.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.1.delta.a272b921-8cb3-4a38-a1b0-b7561ebe5375.TID223.tmp
[2025-07-19T20:30:58.815+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.1.delta.0410706c-00a0-49ec-bbb4-ba759e186fc9.TID222.tmp
[2025-07-19T20:30:58.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 22 (task 219, attempt 0, stage 1.0)
[2025-07-19T20:30:58.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 22.0 in stage 1.0 (TID 219). 9127 bytes result sent to driver
[2025-07-19T20:30:58.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 33.0 in stage 1.0 (TID 226)
[2025-07-19T20:30:58.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 227) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 219) in 105 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:30:58.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 35.0 in stage 1.0 (TID 227)
[2025-07-19T20:30:58.822+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.822+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.823+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aa65990
[2025-07-19T20:30:58.824+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.824+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31] for update
[2025-07-19T20:30:58.824+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.825+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.828+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.833+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2233c14e
[2025-07-19T20:30:58.834+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.836+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35] for update
[2025-07-19T20:30:58.840+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c822743
[2025-07-19T20:30:58.843+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.845+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30] for update
[2025-07-19T20:30:58.850+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.1.delta.062dd351-5d31-4992-bc9d-efb4154b7cf4.TID225.tmp
[2025-07-19T20:30:58.851+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.855+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.1.delta.b3b27723-37bb-4a36-a01a-4772484888eb.TID221.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta
[2025-07-19T20:30:58.856+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta
[2025-07-19T20:30:58.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1783a4aa
[2025-07-19T20:30:58.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 221, attempt 0, stage 1.0)
[2025-07-19T20:30:58.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33] for update
[2025-07-19T20:30:58.861+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.1.delta.e91bca7f-7f85-4eef-8006-e792f3e5a597.TID227.tmp
[2025-07-19T20:30:58.861+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.863+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.1.delta.c95db13f-b5fa-4b63-8b20-1e881a6a8ca7.TID220.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta
[2025-07-19T20:30:58.864+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta
[2025-07-19T20:30:58.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 220, attempt 0, stage 1.0)
[2025-07-19T20:30:58.876+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.1.delta.5128923a-eb04-4c54-8404-bd628d2893ef.TID224.tmp
[2025-07-19T20:30:58.877+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.1.delta.a272b921-8cb3-4a38-a1b0-b7561ebe5375.TID223.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta
[2025-07-19T20:30:58.877+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta
[2025-07-19T20:30:58.879+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 223, attempt 0, stage 1.0)
[2025-07-19T20:30:58.880+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.1.delta.81a6c324-ed9f-4ff1-a607-29e37804c3ca.TID226.tmp
[2025-07-19T20:30:58.881+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.1.delta.0410706c-00a0-49ec-bbb4-ba759e186fc9.TID222.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta
[2025-07-19T20:30:58.881+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta
[2025-07-19T20:30:58.883+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 222, attempt 0, stage 1.0)
[2025-07-19T20:30:58.891+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 26 (task 221, attempt 0, stage 1.0)
[2025-07-19T20:30:58.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 23 (task 220, attempt 0, stage 1.0)
[2025-07-19T20:30:58.896+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 23.0 in stage 1.0 (TID 220). 9214 bytes result sent to driver
[2025-07-19T20:30:58.897+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 26.0 in stage 1.0 (TID 221). 9117 bytes result sent to driver
[2025-07-19T20:30:58.901+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.1.delta.062dd351-5d31-4992-bc9d-efb4154b7cf4.TID225.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta
[2025-07-19T20:30:58.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta
[2025-07-19T20:30:58.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 225, attempt 0, stage 1.0)
[2025-07-19T20:30:58.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 228) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 37.0 in stage 1.0 (TID 228)
[2025-07-19T20:30:58.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 229) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 39.0 in stage 1.0 (TID 229)
[2025-07-19T20:30:58.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 220) in 182 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:30:58.910+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 221) in 155 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:30:58.910+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.910+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.910+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.910+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.911+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 27 (task 222, attempt 0, stage 1.0)
[2025-07-19T20:30:58.915+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 28 (task 223, attempt 0, stage 1.0)
[2025-07-19T20:30:58.917+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 28.0 in stage 1.0 (TID 223). 9128 bytes result sent to driver
[2025-07-19T20:30:58.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 27.0 in stage 1.0 (TID 222). 9113 bytes result sent to driver
[2025-07-19T20:30:58.918+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33175471
[2025-07-19T20:30:58.919+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 230) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.920+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 231) (8b44f3d35cfa, executor driver, partition 42, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 41.0 in stage 1.0 (TID 230)
[2025-07-19T20:30:58.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39] for update
[2025-07-19T20:30:58.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.1.delta.81a6c324-ed9f-4ff1-a607-29e37804c3ca.TID226.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta
[2025-07-19T20:30:58.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta
[2025-07-19T20:30:58.923+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 226, attempt 0, stage 1.0)
[2025-07-19T20:30:58.925+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 223) in 138 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:30:58.926+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 222) in 155 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:30:58.926+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 42.0 in stage 1.0 (TID 231)
[2025-07-19T20:30:58.930+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.931+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.1.delta.5128923a-eb04-4c54-8404-bd628d2893ef.TID224.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta
[2025-07-19T20:30:58.939+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta
[2025-07-19T20:30:58.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 224, attempt 0, stage 1.0)
[2025-07-19T20:30:58.940+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.1.delta.e91bca7f-7f85-4eef-8006-e792f3e5a597.TID227.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 227, attempt 0, stage 1.0)
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 31 (task 225, attempt 0, stage 1.0)
[2025-07-19T20:30:58.941+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 31.0 in stage 1.0 (TID 225). 9125 bytes result sent to driver
[2025-07-19T20:30:58.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 232) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.942+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 43.0 in stage 1.0 (TID 232)
[2025-07-19T20:30:58.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e64ea39
[2025-07-19T20:30:58.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 225) in 145 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:30:58.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37] for update
[2025-07-19T20:30:58.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:58.943+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:58.944+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.1.delta.ccf4ffaa-d954-419d-9712-cffdfbb42e21.TID229.tmp
[2025-07-19T20:30:58.946+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.952+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@270533d0
[2025-07-19T20:30:58.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43] for update
[2025-07-19T20:30:58.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.1.delta.151f0863-31ac-4fa9-a06d-df4bb9361855.TID228.tmp
[2025-07-19T20:30:58.961+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23d4cc15
[2025-07-19T20:30:58.962+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42] for update
[2025-07-19T20:30:58.963+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.968+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.1.delta.c1c99250-082f-489e-863b-2b42abb02d56.TID232.tmp
[2025-07-19T20:30:58.971+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58226b59
[2025-07-19T20:30:58.974+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:58.975+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41] for update
[2025-07-19T20:30:58.976+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.1.delta.48926561-9fa5-4df4-8fa6-9c95f974fe8f.TID231.tmp
[2025-07-19T20:30:58.978+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:58.983+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 30 (task 224, attempt 0, stage 1.0)
[2025-07-19T20:30:58.984+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 30.0 in stage 1.0 (TID 224). 9120 bytes result sent to driver
[2025-07-19T20:30:58.985+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 233) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:58.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 45.0 in stage 1.0 (TID 233)
[2025-07-19T20:30:58.992+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.1.delta.75403f82-97ab-40f9-aaf2-13cc7e79db7e.TID230.tmp
[2025-07-19T20:30:58.993+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.1.delta.ccf4ffaa-d954-419d-9712-cffdfbb42e21.TID229.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta
[2025-07-19T20:30:58.993+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta
[2025-07-19T20:30:58.998+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 229, attempt 0, stage 1.0)
[2025-07-19T20:30:58.999+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 224) in 206 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:30:59.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:59.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 33 (task 226, attempt 0, stage 1.0)
[2025-07-19T20:30:59.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Finished task 33.0 in stage 1.0 (TID 226). 9148 bytes result sent to driver
[2025-07-19T20:30:59.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 234) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.000+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO Executor: Running task 47.0 in stage 1.0 (TID 234)
[2025-07-19T20:30:59.001+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 226) in 184 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:30:59.001+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.001+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.001+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18b913f7
[2025-07-19T20:30:59.001+0000] {subprocess.py:93} INFO - 25/07/19 20:30:58 INFO DataWritingSparkTask: Committed partition 35 (task 227, attempt 0, stage 1.0)
[2025-07-19T20:30:59.014+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.015+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 35.0 in stage 1.0 (TID 227). 9191 bytes result sent to driver
[2025-07-19T20:30:59.015+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45] for update
[2025-07-19T20:30:59.017+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.017+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 235) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.017+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 48.0 in stage 1.0 (TID 235)
[2025-07-19T20:30:59.017+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5246b066
[2025-07-19T20:30:59.018+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 227) in 200 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:30:59.022+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.023+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47] for update
[2025-07-19T20:30:59.029+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 39 (task 229, attempt 0, stage 1.0)
[2025-07-19T20:30:59.030+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.031+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.032+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 39.0 in stage 1.0 (TID 229). 9146 bytes result sent to driver
[2025-07-19T20:30:59.032+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 236) (8b44f3d35cfa, executor driver, partition 50, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.032+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:59.032+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 229) in 124 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:30:59.032+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 50.0 in stage 1.0 (TID 236)
[2025-07-19T20:30:59.035+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.036+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.037+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.1.delta.151f0863-31ac-4fa9-a06d-df4bb9361855.TID228.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta
[2025-07-19T20:30:59.038+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta
[2025-07-19T20:30:59.038+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.1.delta.50ecc34c-9525-4f34-8be0-92985366a016.TID233.tmp
[2025-07-19T20:30:59.038+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 228, attempt 0, stage 1.0)
[2025-07-19T20:30:59.040+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.1.delta.e75c35a1-1eb7-4fc5-b1be-a043c5998639.TID234.tmp
[2025-07-19T20:30:59.040+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@200c541
[2025-07-19T20:30:59.042+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.1.delta.48926561-9fa5-4df4-8fa6-9c95f974fe8f.TID231.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta
[2025-07-19T20:30:59.043+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta
[2025-07-19T20:30:59.045+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.045+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48] for update
[2025-07-19T20:30:59.047+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 231, attempt 0, stage 1.0)
[2025-07-19T20:30:59.048+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.1.delta.c1c99250-082f-489e-863b-2b42abb02d56.TID232.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta
[2025-07-19T20:30:59.048+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta
[2025-07-19T20:30:59.049+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 232, attempt 0, stage 1.0)
[2025-07-19T20:30:59.049+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.1.delta.75403f82-97ab-40f9-aaf2-13cc7e79db7e.TID230.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta
[2025-07-19T20:30:59.052+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta
[2025-07-19T20:30:59.055+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 230, attempt 0, stage 1.0)
[2025-07-19T20:30:59.056+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e889b1c
[2025-07-19T20:30:59.056+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.057+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50] for update
[2025-07-19T20:30:59.064+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.1.delta.7847a88e-b76d-4628-9259-f73a0f3272f6.TID235.tmp
[2025-07-19T20:30:59.065+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 42 (task 231, attempt 0, stage 1.0)
[2025-07-19T20:30:59.068+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 42.0 in stage 1.0 (TID 231). 9160 bytes result sent to driver
[2025-07-19T20:30:59.070+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 37 (task 228, attempt 0, stage 1.0)
[2025-07-19T20:30:59.071+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 237) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 37.0 in stage 1.0 (TID 228). 9156 bytes result sent to driver
[2025-07-19T20:30:59.072+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.073+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 231) in 150 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:30:59.073+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 228) in 164 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:30:59.074+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 43 (task 232, attempt 0, stage 1.0)
[2025-07-19T20:30:59.074+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 238) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.074+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 43.0 in stage 1.0 (TID 232). 9137 bytes result sent to driver
[2025-07-19T20:30:59.075+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 51.0 in stage 1.0 (TID 237)
[2025-07-19T20:30:59.075+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 239) (8b44f3d35cfa, executor driver, partition 54, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.075+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 232) in 137 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:30:59.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 54.0 in stage 1.0 (TID 239)
[2025-07-19T20:30:59.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.076+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 52.0 in stage 1.0 (TID 238)
[2025-07-19T20:30:59.080+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:59.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:59.081+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.1.delta.9e275615-0e36-4ff7-ba98-0765ec4229b0.TID236.tmp
[2025-07-19T20:30:59.082+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 41 (task 230, attempt 0, stage 1.0)
[2025-07-19T20:30:59.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e7c7a8
[2025-07-19T20:30:59.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 41.0 in stage 1.0 (TID 230). 9173 bytes result sent to driver
[2025-07-19T20:30:59.083+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54] for update
[2025-07-19T20:30:59.085+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.086+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.1.delta.50ecc34c-9525-4f34-8be0-92985366a016.TID233.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta
[2025-07-19T20:30:59.087+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 240) (8b44f3d35cfa, executor driver, partition 55, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.087+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta
[2025-07-19T20:30:59.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 55.0 in stage 1.0 (TID 240)
[2025-07-19T20:30:59.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 230) in 170 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:30:59.088+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 233, attempt 0, stage 1.0)
[2025-07-19T20:30:59.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.089+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.093+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a54b3b3
[2025-07-19T20:30:59.097+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52] for update
[2025-07-19T20:30:59.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.1.delta.e75c35a1-1eb7-4fc5-b1be-a043c5998639.TID234.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta
[2025-07-19T20:30:59.098+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta
[2025-07-19T20:30:59.099+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 234, attempt 0, stage 1.0)
[2025-07-19T20:30:59.099+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.1.delta.60d5e2b5-08c7-48a8-bb0f-7d1da3e26c4e.TID239.tmp
[2025-07-19T20:30:59.103+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ad765c4
[2025-07-19T20:30:59.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.104+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51] for update
[2025-07-19T20:30:59.105+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 45 (task 233, attempt 0, stage 1.0)
[2025-07-19T20:30:59.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 45.0 in stage 1.0 (TID 233). 9148 bytes result sent to driver
[2025-07-19T20:30:59.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 241) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.107+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 56.0 in stage 1.0 (TID 241)
[2025-07-19T20:30:59.108+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 233) in 123 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:30:59.109+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.109+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.113+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d1caf58
[2025-07-19T20:30:59.114+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.116+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55] for update
[2025-07-19T20:30:59.120+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.1.delta.654d436c-0239-4ebb-a6e1-ab75e21dbdfd.TID238.tmp
[2025-07-19T20:30:59.120+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73c1d0fb
[2025-07-19T20:30:59.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56] for update
[2025-07-19T20:30:59.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.1.delta.9e275615-0e36-4ff7-ba98-0765ec4229b0.TID236.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta
[2025-07-19T20:30:59.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta
[2025-07-19T20:30:59.121+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 236, attempt 0, stage 1.0)
[2025-07-19T20:30:59.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.1.delta.b16d1cfe-68fe-42f3-9375-c72a4dbefc12.TID237.tmp
[2025-07-19T20:30:59.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.1.delta.7847a88e-b76d-4628-9259-f73a0f3272f6.TID235.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta
[2025-07-19T20:30:59.124+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta
[2025-07-19T20:30:59.126+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 235, attempt 0, stage 1.0)
[2025-07-19T20:30:59.129+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 47 (task 234, attempt 0, stage 1.0)
[2025-07-19T20:30:59.130+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.131+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 47.0 in stage 1.0 (TID 234). 9144 bytes result sent to driver
[2025-07-19T20:30:59.131+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 242) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.132+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 58.0 in stage 1.0 (TID 242)
[2025-07-19T20:30:59.132+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 234) in 136 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:30:59.134+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.135+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.140+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.1.delta.60d5e2b5-08c7-48a8-bb0f-7d1da3e26c4e.TID239.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta
[2025-07-19T20:30:59.140+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta
[2025-07-19T20:30:59.140+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 239, attempt 0, stage 1.0)
[2025-07-19T20:30:59.142+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3634e89b
[2025-07-19T20:30:59.146+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.147+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58] for update
[2025-07-19T20:30:59.147+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.1.delta.ce65311a-c158-4b63-b3d4-084895ce8ccc.TID240.tmp
[2025-07-19T20:30:59.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 50 (task 236, attempt 0, stage 1.0)
[2025-07-19T20:30:59.148+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 50.0 in stage 1.0 (TID 236). 9117 bytes result sent to driver
[2025-07-19T20:30:59.150+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.151+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.1.delta.3a1fa6fa-cbbc-424b-8c82-2b1633ce75fd.TID241.tmp
[2025-07-19T20:30:59.151+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 243) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.151+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 236) in 124 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:30:59.155+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.1.delta.654d436c-0239-4ebb-a6e1-ab75e21dbdfd.TID238.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta
[2025-07-19T20:30:59.156+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta
[2025-07-19T20:30:59.157+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.1.delta.90f117b4-a82a-4d4b-8e50-a0117b988f54.TID242.tmp
[2025-07-19T20:30:59.158+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 238, attempt 0, stage 1.0)
[2025-07-19T20:30:59.161+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 59.0 in stage 1.0 (TID 243)
[2025-07-19T20:30:59.164+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 54 (task 239, attempt 0, stage 1.0)
[2025-07-19T20:30:59.164+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 54.0 in stage 1.0 (TID 239). 9121 bytes result sent to driver
[2025-07-19T20:30:59.165+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.166+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 239) in 93 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:30:59.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 48 (task 235, attempt 0, stage 1.0)
[2025-07-19T20:30:59.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 244) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 48.0 in stage 1.0 (TID 235). 9109 bytes result sent to driver
[2025-07-19T20:30:59.168+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 60.0 in stage 1.0 (TID 244)
[2025-07-19T20:30:59.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.1.delta.b16d1cfe-68fe-42f3-9375-c72a4dbefc12.TID237.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta
[2025-07-19T20:30:59.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta
[2025-07-19T20:30:59.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 237, attempt 0, stage 1.0)
[2025-07-19T20:30:59.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 235) in 154 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:30:59.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 245) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.171+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.172+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.172+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c142d90
[2025-07-19T20:30:59.172+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.173+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59] for update
[2025-07-19T20:30:59.174+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.176+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 62.0 in stage 1.0 (TID 245)
[2025-07-19T20:30:59.186+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57c7a176
[2025-07-19T20:30:59.187+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.188+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 52 (task 238, attempt 0, stage 1.0)
[2025-07-19T20:30:59.188+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 52.0 in stage 1.0 (TID 238). 9148 bytes result sent to driver
[2025-07-19T20:30:59.191+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.192+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 246) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60] for update
[2025-07-19T20:30:59.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 63.0 in stage 1.0 (TID 246)
[2025-07-19T20:30:59.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.1.delta.ce65311a-c158-4b63-b3d4-084895ce8ccc.TID240.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta
[2025-07-19T20:30:59.193+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta
[2025-07-19T20:30:59.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 238) in 120 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:30:59.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 240, attempt 0, stage 1.0)
[2025-07-19T20:30:59.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.194+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.195+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.201+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 51 (task 237, attempt 0, stage 1.0)
[2025-07-19T20:30:59.202+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 51.0 in stage 1.0 (TID 237). 9150 bytes result sent to driver
[2025-07-19T20:30:59.202+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 247) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.204+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 237) in 135 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:30:59.205+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 66.0 in stage 1.0 (TID 247)
[2025-07-19T20:30:59.210+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.1.delta.3f2493f9-69be-46a1-8412-53e60c8826a2.TID243.tmp
[2025-07-19T20:30:59.212+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.1.delta.d56e82e0-dfc1-4a20-a257-0284727dfe3d.TID244.tmp
[2025-07-19T20:30:59.214+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d46fd28
[2025-07-19T20:30:59.214+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.214+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62] for update
[2025-07-19T20:30:59.216+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.217+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a5592f3
[2025-07-19T20:30:59.217+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.218+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66] for update
[2025-07-19T20:30:59.221+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.223+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.1.delta.3a1fa6fa-cbbc-424b-8c82-2b1633ce75fd.TID241.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta
[2025-07-19T20:30:59.224+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta
[2025-07-19T20:30:59.224+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.1.delta.90f117b4-a82a-4d4b-8e50-a0117b988f54.TID242.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta
[2025-07-19T20:30:59.225+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta
[2025-07-19T20:30:59.226+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 241, attempt 0, stage 1.0)
[2025-07-19T20:30:59.227+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 242, attempt 0, stage 1.0)
[2025-07-19T20:30:59.228+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@832cc95
[2025-07-19T20:30:59.228+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.228+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 55 (task 240, attempt 0, stage 1.0)
[2025-07-19T20:30:59.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 55.0 in stage 1.0 (TID 240). 9152 bytes result sent to driver
[2025-07-19T20:30:59.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63] for update
[2025-07-19T20:30:59.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 248) (8b44f3d35cfa, executor driver, partition 67, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.229+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 67.0 in stage 1.0 (TID 248)
[2025-07-19T20:30:59.230+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 240) in 142 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:30:59.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.231+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.233+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.1.delta.15682d40-cc41-4d3d-9602-8bc42cfb62f6.TID245.tmp
[2025-07-19T20:30:59.242+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.1.delta.2a3a080e-4143-444f-aee2-84297f047da0.TID246.tmp
[2025-07-19T20:30:59.242+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.1.delta.cdea88c2-085b-4d0c-abf4-400d41f23ae3.TID247.tmp
[2025-07-19T20:30:59.247+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 56 (task 241, attempt 0, stage 1.0)
[2025-07-19T20:30:59.247+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 58 (task 242, attempt 0, stage 1.0)
[2025-07-19T20:30:59.249+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 56.0 in stage 1.0 (TID 241). 9152 bytes result sent to driver
[2025-07-19T20:30:59.250+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 249) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.250+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 68.0 in stage 1.0 (TID 249)
[2025-07-19T20:30:59.251+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 58.0 in stage 1.0 (TID 242). 9141 bytes result sent to driver
[2025-07-19T20:30:59.251+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 250) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 242) in 121 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:30:59.252+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55f7ee6d
[2025-07-19T20:30:59.253+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.254+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67] for update
[2025-07-19T20:30:59.254+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 241) in 147 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:30:59.257+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.259+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 71.0 in stage 1.0 (TID 250)
[2025-07-19T20:30:59.262+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.263+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.263+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.264+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.271+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.1.delta.ee068893-565f-4975-82a5-651a8b5baa34.TID248.tmp
[2025-07-19T20:30:59.275+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.1.delta.15682d40-cc41-4d3d-9602-8bc42cfb62f6.TID245.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta
[2025-07-19T20:30:59.276+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta
[2025-07-19T20:30:59.277+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.1.delta.d56e82e0-dfc1-4a20-a257-0284727dfe3d.TID244.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta
[2025-07-19T20:30:59.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta
[2025-07-19T20:30:59.278+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 245, attempt 0, stage 1.0)
[2025-07-19T20:30:59.279+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.1.delta.3f2493f9-69be-46a1-8412-53e60c8826a2.TID243.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta
[2025-07-19T20:30:59.279+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta
[2025-07-19T20:30:59.279+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 244, attempt 0, stage 1.0)
[2025-07-19T20:30:59.280+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 243, attempt 0, stage 1.0)
[2025-07-19T20:30:59.280+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@765bb478
[2025-07-19T20:30:59.283+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.285+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68] for update
[2025-07-19T20:30:59.286+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.291+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d58e56d
[2025-07-19T20:30:59.294+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.295+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71] for update
[2025-07-19T20:30:59.298+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 60 (task 244, attempt 0, stage 1.0)
[2025-07-19T20:30:59.299+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 60.0 in stage 1.0 (TID 244). 9170 bytes result sent to driver
[2025-07-19T20:30:59.299+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 251) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.300+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 72.0 in stage 1.0 (TID 251)
[2025-07-19T20:30:59.301+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 244) in 129 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:30:59.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 59 (task 243, attempt 0, stage 1.0)
[2025-07-19T20:30:59.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.302+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.303+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 59.0 in stage 1.0 (TID 243). 9162 bytes result sent to driver
[2025-07-19T20:30:59.305+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 62 (task 245, attempt 0, stage 1.0)
[2025-07-19T20:30:59.306+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 62.0 in stage 1.0 (TID 245). 9144 bytes result sent to driver
[2025-07-19T20:30:59.306+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 252) (8b44f3d35cfa, executor driver, partition 74, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.307+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 243) in 153 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:30:59.307+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 74.0 in stage 1.0 (TID 252)
[2025-07-19T20:30:59.309+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@692f21d8
[2025-07-19T20:30:59.310+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 253) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.310+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 245) in 135 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:30:59.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72] for update
[2025-07-19T20:30:59.311+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.312+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.313+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 75.0 in stage 1.0 (TID 253)
[2025-07-19T20:30:59.314+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.314+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.315+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.1.delta.5f2e19b9-79c3-4650-aaf7-430ebdaf0858.TID249.tmp
[2025-07-19T20:30:59.315+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.315+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.1.delta.2a3a080e-4143-444f-aee2-84297f047da0.TID246.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta
[2025-07-19T20:30:59.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta
[2025-07-19T20:30:59.316+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 246, attempt 0, stage 1.0)
[2025-07-19T20:30:59.318+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.1.delta.cdea88c2-085b-4d0c-abf4-400d41f23ae3.TID247.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta
[2025-07-19T20:30:59.318+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta
[2025-07-19T20:30:59.320+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 247, attempt 0, stage 1.0)
[2025-07-19T20:30:59.320+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.1.delta.cfde2117-942b-4b47-82ca-90367608d962.TID250.tmp
[2025-07-19T20:30:59.321+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3147dc8e
[2025-07-19T20:30:59.323+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.325+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74] for update
[2025-07-19T20:30:59.326+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.334+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 63 (task 246, attempt 0, stage 1.0)
[2025-07-19T20:30:59.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57b92555
[2025-07-19T20:30:59.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.336+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75] for update
[2025-07-19T20:30:59.342+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 63.0 in stage 1.0 (TID 246). 9203 bytes result sent to driver
[2025-07-19T20:30:59.343+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 254) (8b44f3d35cfa, executor driver, partition 76, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.345+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.347+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 76.0 in stage 1.0 (TID 254)
[2025-07-19T20:30:59.347+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.1.delta.60f89141-a0cc-4ffc-8d15-4542ac15e541.TID251.tmp
[2025-07-19T20:30:59.348+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 246) in 159 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:30:59.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 66 (task 247, attempt 0, stage 1.0)
[2025-07-19T20:30:59.349+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 66.0 in stage 1.0 (TID 247). 9142 bytes result sent to driver
[2025-07-19T20:30:59.350+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.1.delta.813020d0-6836-4c1d-b6eb-8a6745b8c250.TID252.tmp
[2025-07-19T20:30:59.351+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 255) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 77.0 in stage 1.0 (TID 255)
[2025-07-19T20:30:59.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:59.352+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 247) in 152 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:30:59.354+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.355+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b4de9c3
[2025-07-19T20:30:59.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.362+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76] for update
[2025-07-19T20:30:59.365+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.1.delta.828fe29e-80f6-485b-99e5-a1d23036f779.TID253.tmp
[2025-07-19T20:30:59.366+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.369+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.1.delta.ee068893-565f-4975-82a5-651a8b5baa34.TID248.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta
[2025-07-19T20:30:59.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta
[2025-07-19T20:30:59.370+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 248, attempt 0, stage 1.0)
[2025-07-19T20:30:59.374+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b97f1ad
[2025-07-19T20:30:59.374+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.375+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77] for update
[2025-07-19T20:30:59.378+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.1.delta.5f2e19b9-79c3-4650-aaf7-430ebdaf0858.TID249.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta
[2025-07-19T20:30:59.379+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta
[2025-07-19T20:30:59.379+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 249, attempt 0, stage 1.0)
[2025-07-19T20:30:59.382+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v110.metadata.json
[2025-07-19T20:30:59.383+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.1.delta.cebf36af-0020-4022-9427-d168926f6ae2.TID254.tmp
[2025-07-19T20:30:59.389+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.1.delta.cfde2117-942b-4b47-82ca-90367608d962.TID250.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta
[2025-07-19T20:30:59.392+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta
[2025-07-19T20:30:59.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 67 (task 248, attempt 0, stage 1.0)
[2025-07-19T20:30:59.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 250, attempt 0, stage 1.0)
[2025-07-19T20:30:59.393+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 67.0 in stage 1.0 (TID 248). 9160 bytes result sent to driver
[2025-07-19T20:30:59.394+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 256) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.394+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 248) in 168 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:30:59.394+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 78.0 in stage 1.0 (TID 256)
[2025-07-19T20:30:59.401+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.1.delta.2090b446-4303-43c9-aa43-d91024fa8a6b.TID255.tmp
[2025-07-19T20:30:59.403+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.405+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 68 (task 249, attempt 0, stage 1.0)
[2025-07-19T20:30:59.405+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:59.405+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 68.0 in stage 1.0 (TID 249). 9162 bytes result sent to driver
[2025-07-19T20:30:59.408+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 257) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.409+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 249) in 159 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:30:59.411+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 79.0 in stage 1.0 (TID 257)
[2025-07-19T20:30:59.412+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.1.delta.813020d0-6836-4c1d-b6eb-8a6745b8c250.TID252.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta
[2025-07-19T20:30:59.413+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta
[2025-07-19T20:30:59.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@89b3750
[2025-07-19T20:30:59.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.414+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78] for update
[2025-07-19T20:30:59.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.1.delta.60f89141-a0cc-4ffc-8d15-4542ac15e541.TID251.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta
[2025-07-19T20:30:59.415+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta
[2025-07-19T20:30:59.417+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.418+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 252, attempt 0, stage 1.0)
[2025-07-19T20:30:59.419+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 251, attempt 0, stage 1.0)
[2025-07-19T20:30:59.420+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.421+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.421+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 71 (task 250, attempt 0, stage 1.0)
[2025-07-19T20:30:59.422+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 71.0 in stage 1.0 (TID 250). 9165 bytes result sent to driver
[2025-07-19T20:30:59.425+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.1.delta.828fe29e-80f6-485b-99e5-a1d23036f779.TID253.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta
[2025-07-19T20:30:59.426+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta
[2025-07-19T20:30:59.426+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 258) (8b44f3d35cfa, executor driver, partition 80, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 253, attempt 0, stage 1.0)
[2025-07-19T20:30:59.427+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 80.0 in stage 1.0 (TID 258)
[2025-07-19T20:30:59.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 250) in 176 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:30:59.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.428+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.432+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.1.delta.f734e586-8c3b-4f81-a66c-1480ad7d46a5.TID256.tmp
[2025-07-19T20:30:59.433+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58479717
[2025-07-19T20:30:59.436+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.438+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79] for update
[2025-07-19T20:30:59.439+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 74 (task 252, attempt 0, stage 1.0)
[2025-07-19T20:30:59.439+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.1.delta.cebf36af-0020-4022-9427-d168926f6ae2.TID254.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta
[2025-07-19T20:30:59.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta
[2025-07-19T20:30:59.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 254, attempt 0, stage 1.0)
[2025-07-19T20:30:59.441+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 74.0 in stage 1.0 (TID 252). 9156 bytes result sent to driver
[2025-07-19T20:30:59.442+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 259) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.442+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 82.0 in stage 1.0 (TID 259)
[2025-07-19T20:30:59.443+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 252) in 141 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:30:59.444+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50a7c015
[2025-07-19T20:30:59.444+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80] for update
[2025-07-19T20:30:59.445+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.446+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.447+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.447+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 72 (task 251, attempt 0, stage 1.0)
[2025-07-19T20:30:59.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 72.0 in stage 1.0 (TID 251). 9162 bytes result sent to driver
[2025-07-19T20:30:59.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 260) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.448+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 83.0 in stage 1.0 (TID 260)
[2025-07-19T20:30:59.453+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 251) in 156 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:30:59.456+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bef9d6a
[2025-07-19T20:30:59.457+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.459+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.1.delta.2090b446-4303-43c9-aa43-d91024fa8a6b.TID255.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta
[2025-07-19T20:30:59.460+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta
[2025-07-19T20:30:59.462+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.464+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:30:59.465+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.1.delta.52a680a2-ecf3-4185-ad47-39073a8f5ce1.TID257.tmp
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.1.delta.44653a28-8278-4808-b652-32f8e8063c49.TID258.tmp
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 75 (task 253, attempt 0, stage 1.0)
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82] for update
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 255, attempt 0, stage 1.0)
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 75.0 in stage 1.0 (TID 253). 9178 bytes result sent to driver
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 261) (8b44f3d35cfa, executor driver, partition 84, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.466+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 84.0 in stage 1.0 (TID 261)
[2025-07-19T20:30:59.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 253) in 159 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:30:59.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57752799
[2025-07-19T20:30:59.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83] for update
[2025-07-19T20:30:59.467+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.477+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.477+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.480+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SnapshotProducer: Committed snapshot 8021126758952694570 (FastAppend)
[2025-07-19T20:30:59.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 76 (task 254, attempt 0, stage 1.0)
[2025-07-19T20:30:59.482+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 76.0 in stage 1.0 (TID 254). 9170 bytes result sent to driver
[2025-07-19T20:30:59.484+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 262) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.485+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 254) in 141 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:30:59.486+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 85.0 in stage 1.0 (TID 262)
[2025-07-19T20:30:59.488+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5039314b
[2025-07-19T20:30:59.489+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.490+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.1.delta.65e4a8d8-b054-42e5-a07a-b95060df830a.TID259.tmp
[2025-07-19T20:30:59.491+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.492+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84] for update
[2025-07-19T20:30:59.495+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 77 (task 255, attempt 0, stage 1.0)
[2025-07-19T20:30:59.496+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.496+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 77.0 in stage 1.0 (TID 255). 9175 bytes result sent to driver
[2025-07-19T20:30:59.497+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 263) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.498+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 87.0 in stage 1.0 (TID 263)
[2025-07-19T20:30:59.499+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.499+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.500+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 255) in 149 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:30:59.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.1.delta.0418891d-5ddd-4d25-a314-08ddb7bd7c37.TID260.tmp
[2025-07-19T20:30:59.501+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.1.delta.f734e586-8c3b-4f81-a66c-1480ad7d46a5.TID256.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta
[2025-07-19T20:30:59.502+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta
[2025-07-19T20:30:59.502+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 256, attempt 0, stage 1.0)
[2025-07-19T20:30:59.504+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@543766df
[2025-07-19T20:30:59.507+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.508+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85] for update
[2025-07-19T20:30:59.508+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.1.delta.ff9484a0-55f5-49d3-8ce9-0d7e7da390b3.TID261.tmp
[2025-07-19T20:30:59.509+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.521+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c3aaa05
[2025-07-19T20:30:59.522+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.524+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87] for update
[2025-07-19T20:30:59.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.1.delta.6c8eb135-354a-477e-b741-ad146bc7efc3.TID262.tmp
[2025-07-19T20:30:59.525+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 78 (task 256, attempt 0, stage 1.0)
[2025-07-19T20:30:59.526+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 78.0 in stage 1.0 (TID 256). 9172 bytes result sent to driver
[2025-07-19T20:30:59.530+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 264) (8b44f3d35cfa, executor driver, partition 88, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 256) in 141 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:30:59.534+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 88.0 in stage 1.0 (TID 264)
[2025-07-19T20:30:59.535+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.1.delta.52a680a2-ecf3-4185-ad47-39073a8f5ce1.TID257.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta
[2025-07-19T20:30:59.536+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta
[2025-07-19T20:30:59.536+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 257, attempt 0, stage 1.0)
[2025-07-19T20:30:59.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.1.delta.44653a28-8278-4808-b652-32f8e8063c49.TID258.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta
[2025-07-19T20:30:59.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.541+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:59.545+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta
[2025-07-19T20:30:59.546+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 258, attempt 0, stage 1.0)
[2025-07-19T20:30:59.546+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.1.delta.ee17cb1d-417f-408e-8f63-297cde9b5285.TID263.tmp
[2025-07-19T20:30:59.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d2c46af
[2025-07-19T20:30:59.548+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.549+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88] for update
[2025-07-19T20:30:59.551+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.554+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.1.delta.65e4a8d8-b054-42e5-a07a-b95060df830a.TID259.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta
[2025-07-19T20:30:59.554+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta
[2025-07-19T20:30:59.555+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.1.delta.0418891d-5ddd-4d25-a314-08ddb7bd7c37.TID260.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta
[2025-07-19T20:30:59.557+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 259, attempt 0, stage 1.0)
[2025-07-19T20:30:59.558+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta
[2025-07-19T20:30:59.558+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 260, attempt 0, stage 1.0)
[2025-07-19T20:30:59.564+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.1.delta.500a0d11-ed2d-4add-b981-38a63c518308.TID264.tmp
[2025-07-19T20:30:59.565+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 79 (task 257, attempt 0, stage 1.0)
[2025-07-19T20:30:59.567+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=8021126758952694570, sequenceNumber=109, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.847798S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=130}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5047}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=207}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=6930}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=422306}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=16331514}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752957046551, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:30:59.568+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Committed in 871 ms
[2025-07-19T20:30:59.569+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.1.delta.ff9484a0-55f5-49d3-8ce9-0d7e7da390b3.TID261.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta
[2025-07-19T20:30:59.570+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta
[2025-07-19T20:30:59.570+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 261, attempt 0, stage 1.0)
[2025-07-19T20:30:59.571+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T20:30:59.573+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 79.0 in stage 1.0 (TID 257). 9152 bytes result sent to driver
[2025-07-19T20:30:59.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 265) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 94.0 in stage 1.0 (TID 265)
[2025-07-19T20:30:59.575+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.1.delta.6c8eb135-354a-477e-b741-ad146bc7efc3.TID262.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta
[2025-07-19T20:30:59.576+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta
[2025-07-19T20:30:59.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 257) in 167 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:30:59.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 262, attempt 0, stage 1.0)
[2025-07-19T20:30:59.577+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.578+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.587+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 82 (task 259, attempt 0, stage 1.0)
[2025-07-19T20:30:59.588+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 82.0 in stage 1.0 (TID 259). 9148 bytes result sent to driver
[2025-07-19T20:30:59.589+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.1.delta.ee17cb1d-417f-408e-8f63-297cde9b5285.TID263.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta
[2025-07-19T20:30:59.589+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta
[2025-07-19T20:30:59.589+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 83 (task 260, attempt 0, stage 1.0)
[2025-07-19T20:30:59.590+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 80 (task 258, attempt 0, stage 1.0)
[2025-07-19T20:30:59.590+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 80.0 in stage 1.0 (TID 258). 9162 bytes result sent to driver
[2025-07-19T20:30:59.594+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e4ade66
[2025-07-19T20:30:59.596+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 84 (task 261, attempt 0, stage 1.0)
[2025-07-19T20:30:59.596+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 83.0 in stage 1.0 (TID 260). 9199 bytes result sent to driver
[2025-07-19T20:30:59.597+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752783060000 ms
[2025-07-19T20:30:59.598+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.598+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94] for update
[2025-07-19T20:30:59.599+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 263, attempt 0, stage 1.0)
[2025-07-19T20:30:59.600+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.600+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 266) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.600+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 267) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.602+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 95.0 in stage 1.0 (TID 266)
[2025-07-19T20:30:59.603+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 84.0 in stage 1.0 (TID 261). 9154 bytes result sent to driver
[2025-07-19T20:30:59.606+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 96.0 in stage 1.0 (TID 267)
[2025-07-19T20:30:59.607+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 268) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.608+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.1.delta.b58f6b8d-6413-43f6-8699-7945267ca87f.TID265.tmp
[2025-07-19T20:30:59.609+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 269) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.611+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 259) in 165 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:30:59.611+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 97.0 in stage 1.0 (TID 268)
[2025-07-19T20:30:59.612+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/0 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/.0.ceb491fc-a10c-4045-bee7-a9833d78dc9c.tmp
[2025-07-19T20:30:59.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 261) in 145 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:30:59.613+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.614+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 99.0 in stage 1.0 (TID 269)
[2025-07-19T20:30:59.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.615+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 85 (task 262, attempt 0, stage 1.0)
[2025-07-19T20:30:59.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 85.0 in stage 1.0 (TID 262). 9129 bytes result sent to driver
[2025-07-19T20:30:59.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.616+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.617+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 270) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.618+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 258) in 188 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:30:59.618+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 260) in 163 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:30:59.619+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 262) in 128 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:30:59.619+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 100.0 in stage 1.0 (TID 270)
[2025-07-19T20:30:59.619+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.622+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:30:59.622+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:59.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.623+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.624+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 87 (task 263, attempt 0, stage 1.0)
[2025-07-19T20:30:59.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 87.0 in stage 1.0 (TID 263). 9113 bytes result sent to driver
[2025-07-19T20:30:59.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.1.delta.500a0d11-ed2d-4add-b981-38a63c518308.TID264.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta
[2025-07-19T20:30:59.625+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta
[2025-07-19T20:30:59.626+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e3083ac
[2025-07-19T20:30:59.626+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 271) (8b44f3d35cfa, executor driver, partition 101, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.626+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.626+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96] for update
[2025-07-19T20:30:59.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 263) in 125 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:30:59.627+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 264, attempt 0, stage 1.0)
[2025-07-19T20:30:59.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 101.0 in stage 1.0 (TID 271)
[2025-07-19T20:30:59.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@357c69d9
[2025-07-19T20:30:59.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.628+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100] for update
[2025-07-19T20:30:59.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.629+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.639+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21d401c9
[2025-07-19T20:30:59.640+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.641+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95] for update
[2025-07-19T20:30:59.642+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.1.delta.6ff1ec61-be3e-4eec-84d5-6b2321cd97c4.TID267.tmp
[2025-07-19T20:30:59.643+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.643+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 88 (task 264, attempt 0, stage 1.0)
[2025-07-19T20:30:59.644+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 88.0 in stage 1.0 (TID 264). 9162 bytes result sent to driver
[2025-07-19T20:30:59.648+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@263634d8
[2025-07-19T20:30:59.648+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 272) (8b44f3d35cfa, executor driver, partition 103, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.649+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.651+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 103.0 in stage 1.0 (TID 272)
[2025-07-19T20:30:59.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97] for update
[2025-07-19T20:30:59.652+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 264) in 117 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:30:59.653+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.1.delta.52c3dcfc-717b-42b1-9236-94a519419f0b.TID270.tmp
[2025-07-19T20:30:59.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.654+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.655+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.1.delta.31f65c28-4eb3-4649-9b1b-bb1e07ba0c78.TID266.tmp
[2025-07-19T20:30:59.655+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f3791df
[2025-07-19T20:30:59.655+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.656+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99] for update
[2025-07-19T20:30:59.658+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.660+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.1.delta.b58f6b8d-6413-43f6-8699-7945267ca87f.TID265.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta
[2025-07-19T20:30:59.661+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta
[2025-07-19T20:30:59.661+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.1.delta.1cff681c-b94a-492f-b946-fd4d134ec894.TID268.tmp
[2025-07-19T20:30:59.661+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 265, attempt 0, stage 1.0)
[2025-07-19T20:30:59.666+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4bd436b7
[2025-07-19T20:30:59.668+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.669+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103] for update
[2025-07-19T20:30:59.670+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.1.delta.ac0cdd20-6d78-4c51-90f2-a3bffd96a1eb.TID269.tmp
[2025-07-19T20:30:59.672+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11974e4d
[2025-07-19T20:30:59.673+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.674+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.674+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101] for update
[2025-07-19T20:30:59.675+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/.0.ceb491fc-a10c-4045-bee7-a9833d78dc9c.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/0
[2025-07-19T20:30:59.680+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.684+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 94 (task 265, attempt 0, stage 1.0)
[2025-07-19T20:30:59.686+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 94.0 in stage 1.0 (TID 265). 9163 bytes result sent to driver
[2025-07-19T20:30:59.686+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 273) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 104.0 in stage 1.0 (TID 273)
[2025-07-19T20:30:59.687+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 265) in 110 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:30:59.688+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.688+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.689+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.1.delta.c6d52c33-fd2c-4e9f-8d1e-1e373da4e6a0.TID272.tmp
[2025-07-19T20:30:59.694+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51ca67f0
[2025-07-19T20:30:59.697+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104] for update
[2025-07-19T20:30:59.698+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.1.delta.02cf617a-cae2-48d3-bc8f-834b0e6c3a0b.TID271.tmp
[2025-07-19T20:30:59.699+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.704+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.1.delta.31f65c28-4eb3-4649-9b1b-bb1e07ba0c78.TID266.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta
[2025-07-19T20:30:59.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta
[2025-07-19T20:30:59.705+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 266, attempt 0, stage 1.0)
[2025-07-19T20:30:59.706+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.1.delta.52c3dcfc-717b-42b1-9236-94a519419f0b.TID270.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta
[2025-07-19T20:30:59.707+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta
[2025-07-19T20:30:59.707+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 270, attempt 0, stage 1.0)
[2025-07-19T20:30:59.709+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:30:59.710+0000] {subprocess.py:93} INFO -   "id" : "1436cd49-bf2f-4720-8c9f-d251355ec5cf",
[2025-07-19T20:30:59.711+0000] {subprocess.py:93} INFO -   "runId" : "0211514f-45c6-4006-a76e-be2d80eeafa5",
[2025-07-19T20:30:59.711+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:30:59.711+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:30:49.253Z",
[2025-07-19T20:30:59.712+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T20:30:59.712+0000] {subprocess.py:93} INFO -   "numInputRows" : 207,
[2025-07-19T20:30:59.713+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:30:59.713+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 19.863736685538818,
[2025-07-19T20:30:59.714+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:30:59.714+0000] {subprocess.py:93} INFO -     "addBatch" : 9252,
[2025-07-19T20:30:59.715+0000] {subprocess.py:93} INFO -     "commitOffsets" : 81,
[2025-07-19T20:30:59.715+0000] {subprocess.py:93} INFO -     "getBatch" : 9,
[2025-07-19T20:30:59.716+0000] {subprocess.py:93} INFO -     "latestOffset" : 434,
[2025-07-19T20:30:59.716+0000] {subprocess.py:93} INFO -     "queryPlanning" : 564,
[2025-07-19T20:30:59.717+0000] {subprocess.py:93} INFO -     "triggerExecution" : 10421,
[2025-07-19T20:30:59.718+0000] {subprocess.py:93} INFO -     "walCommit" : 56
[2025-07-19T20:30:59.719+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:30:59.719+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:30:59.719+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T18:02:22.898Z",
[2025-07-19T20:30:59.720+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T20:11:00.000Z",
[2025-07-19T20:30:59.720+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T16:04:00.000Z",
[2025-07-19T20:30:59.720+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T20:30:59.720+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:30:59.721+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:30:59.721+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:30:59.722+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 207,
[2025-07-19T20:30:59.722+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 207,
[2025-07-19T20:30:59.722+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 5873,
[2025-07-19T20:30:59.722+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:30:59.723+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 468,
[2025-07-19T20:30:59.723+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 16825,
[2025-07-19T20:30:59.723+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 96488,
[2025-07-19T20:30:59.723+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:30:59.724+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:30:59.724+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:30:59.725+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:30:59.725+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T20:30:59.726+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:30:59.726+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:30:59.727+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 67688
[2025-07-19T20:30:59.728+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:30:59.728+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:30:59.728+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:30:59.729+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T20:30:59.731+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T20:30:59.732+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:30:59.734+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:30:59.734+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:30:59.735+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:30:59.736+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:30:59.736+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:30:59.736+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:30:59.737+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:30:59.738+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:30:59.738+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:30:59.739+0000] {subprocess.py:93} INFO -     "numInputRows" : 207,
[2025-07-19T20:30:59.739+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:30:59.739+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 19.863736685538818,
[2025-07-19T20:30:59.740+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:30:59.740+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:30:59.740+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:30:59.740+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:30:59.741+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:30:59.742+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:30:59.742+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:30:59.743+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T20:30:59.746+0000] {subprocess.py:93} INFO -     "numOutputRows" : 207
[2025-07-19T20:30:59.748+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:30:59.751+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:30:59.752+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.1.delta.6ff1ec61-be3e-4eec-84d5-6b2321cd97c4.TID267.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta
[2025-07-19T20:30:59.752+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta
[2025-07-19T20:30:59.755+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 267, attempt 0, stage 1.0)
[2025-07-19T20:30:59.756+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.1.delta.a9c64e87-3455-4a1a-9db0-cb64c0984b98.TID273.tmp
[2025-07-19T20:30:59.757+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.1.delta.1cff681c-b94a-492f-b946-fd4d134ec894.TID268.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta
[2025-07-19T20:30:59.758+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta
[2025-07-19T20:30:59.759+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 268, attempt 0, stage 1.0)
[2025-07-19T20:30:59.759+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.1.delta.ac0cdd20-6d78-4c51-90f2-a3bffd96a1eb.TID269.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta
[2025-07-19T20:30:59.760+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta
[2025-07-19T20:30:59.761+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 269, attempt 0, stage 1.0)
[2025-07-19T20:30:59.761+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 95 (task 266, attempt 0, stage 1.0)
[2025-07-19T20:30:59.761+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 100 (task 270, attempt 0, stage 1.0)
[2025-07-19T20:30:59.761+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 96 (task 267, attempt 0, stage 1.0)
[2025-07-19T20:30:59.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 95.0 in stage 1.0 (TID 266). 9156 bytes result sent to driver
[2025-07-19T20:30:59.764+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 96.0 in stage 1.0 (TID 267). 9170 bytes result sent to driver
[2025-07-19T20:30:59.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 274) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 275) (8b44f3d35cfa, executor driver, partition 108, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 106.0 in stage 1.0 (TID 274)
[2025-07-19T20:30:59.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 108.0 in stage 1.0 (TID 275)
[2025-07-19T20:30:59.765+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 266) in 135 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:30:59.766+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 100.0 in stage 1.0 (TID 270). 9163 bytes result sent to driver
[2025-07-19T20:30:59.770+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 267) in 134 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:30:59.771+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 276) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.771+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.1.delta.c6d52c33-fd2c-4e9f-8d1e-1e373da4e6a0.TID272.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta
[2025-07-19T20:30:59.772+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 270) in 121 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:30:59.776+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta
[2025-07-19T20:30:59.777+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.778+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.778+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 272, attempt 0, stage 1.0)
[2025-07-19T20:30:59.778+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.779+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.779+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 110.0 in stage 1.0 (TID 276)
[2025-07-19T20:30:59.780+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@639c54cb
[2025-07-19T20:30:59.780+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.781+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.782+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.783+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108] for update
[2025-07-19T20:30:59.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.784+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.1.delta.02cf617a-cae2-48d3-bc8f-834b0e6c3a0b.TID271.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta
[2025-07-19T20:30:59.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta
[2025-07-19T20:30:59.785+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 271, attempt 0, stage 1.0)
[2025-07-19T20:30:59.787+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 97 (task 268, attempt 0, stage 1.0)
[2025-07-19T20:30:59.788+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 97.0 in stage 1.0 (TID 268). 9141 bytes result sent to driver
[2025-07-19T20:30:59.789+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 99 (task 269, attempt 0, stage 1.0)
[2025-07-19T20:30:59.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 99.0 in stage 1.0 (TID 269). 9158 bytes result sent to driver
[2025-07-19T20:30:59.790+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 277) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.791+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 278) (8b44f3d35cfa, executor driver, partition 112, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.791+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e95c8c5
[2025-07-19T20:30:59.791+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 112.0 in stage 1.0 (TID 278)
[2025-07-19T20:30:59.792+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 268) in 147 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:30:59.793+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 269) in 147 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:30:59.793+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.794+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106] for update
[2025-07-19T20:30:59.794+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 111.0 in stage 1.0 (TID 277)
[2025-07-19T20:30:59.795+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.1.delta.a9c64e87-3455-4a1a-9db0-cb64c0984b98.TID273.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta
[2025-07-19T20:30:59.796+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta
[2025-07-19T20:30:59.796+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 273, attempt 0, stage 1.0)
[2025-07-19T20:30:59.798+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.798+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:59.799+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.799+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:30:59.800+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.801+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.1.delta.56610c9e-6b90-4d97-8317-da6cbab412e7.TID275.tmp
[2025-07-19T20:30:59.802+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@521fe7f2
[2025-07-19T20:30:59.802+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.803+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110] for update
[2025-07-19T20:30:59.803+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.804+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/.1.9b40d947-4ae6-42db-9ca8-71c1a2f6c45f.tmp
[2025-07-19T20:30:59.804+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21d407cb
[2025-07-19T20:30:59.805+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.1.delta.ac20954c-4e99-466a-9e66-00c516bd3edf.TID274.tmp
[2025-07-19T20:30:59.805+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.805+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111] for update
[2025-07-19T20:30:59.806+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.806+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.1.delta.9b223d77-991e-489c-9e97-029c7d0c5427.TID276.tmp
[2025-07-19T20:30:59.807+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 103 (task 272, attempt 0, stage 1.0)
[2025-07-19T20:30:59.808+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 101 (task 271, attempt 0, stage 1.0)
[2025-07-19T20:30:59.809+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 104 (task 273, attempt 0, stage 1.0)
[2025-07-19T20:30:59.810+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 103.0 in stage 1.0 (TID 272). 9148 bytes result sent to driver
[2025-07-19T20:30:59.810+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 104.0 in stage 1.0 (TID 273). 9160 bytes result sent to driver
[2025-07-19T20:30:59.810+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 279) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 101.0 in stage 1.0 (TID 271). 9148 bytes result sent to driver
[2025-07-19T20:30:59.811+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 113.0 in stage 1.0 (TID 279)
[2025-07-19T20:30:59.812+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 280) (8b44f3d35cfa, executor driver, partition 114, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.812+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 281) (8b44f3d35cfa, executor driver, partition 115, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 272) in 141 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:30:59.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 115.0 in stage 1.0 (TID 281)
[2025-07-19T20:30:59.813+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 271) in 169 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:30:59.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 273) in 105 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:30:59.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 114.0 in stage 1.0 (TID 280)
[2025-07-19T20:30:59.814+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39691230
[2025-07-19T20:30:59.815+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.815+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.815+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.817+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.817+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.818+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.818+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112] for update
[2025-07-19T20:30:59.819+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.820+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.1.delta.1857e482-a3d3-44ba-9c8c-a7e52609d237.TID277.tmp
[2025-07-19T20:30:59.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32335ce8
[2025-07-19T20:30:59.821+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.822+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115] for update
[2025-07-19T20:30:59.822+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.823+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.1.delta.5528e8f3-697e-4f05-aabb-b44df5c6bfab.TID278.tmp
[2025-07-19T20:30:59.824+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6014a93c
[2025-07-19T20:30:59.826+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.826+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113] for update
[2025-07-19T20:30:59.828+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.829+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.1.delta.920de87e-2a16-4c12-8ab5-170b37dc8f7a.TID281.tmp
[2025-07-19T20:30:59.830+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.1.delta.ac20954c-4e99-466a-9e66-00c516bd3edf.TID274.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta
[2025-07-19T20:30:59.830+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta
[2025-07-19T20:30:59.831+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 274, attempt 0, stage 1.0)
[2025-07-19T20:30:59.831+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.1.delta.56610c9e-6b90-4d97-8317-da6cbab412e7.TID275.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta
[2025-07-19T20:30:59.832+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta
[2025-07-19T20:30:59.832+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 275, attempt 0, stage 1.0)
[2025-07-19T20:30:59.833+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5065be6e
[2025-07-19T20:30:59.833+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.833+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114] for update
[2025-07-19T20:30:59.834+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.1.delta.6ddce26f-cbb9-41bb-859b-be94dcd3a160.TID279.tmp
[2025-07-19T20:30:59.835+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.837+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.1.delta.9b223d77-991e-489c-9e97-029c7d0c5427.TID276.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta
[2025-07-19T20:30:59.837+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta
[2025-07-19T20:30:59.837+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/.1.9b40d947-4ae6-42db-9ca8-71c1a2f6c45f.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/offsets/1
[2025-07-19T20:30:59.837+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752783060000,1752957059724,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:30:59.838+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 276, attempt 0, stage 1.0)
[2025-07-19T20:30:59.838+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.1.delta.7a9c2f9d-7bda-4023-ab08-7e54e11bb9f9.TID280.tmp
[2025-07-19T20:30:59.845+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 108 (task 275, attempt 0, stage 1.0)
[2025-07-19T20:30:59.846+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 108.0 in stage 1.0 (TID 275). 9140 bytes result sent to driver
[2025-07-19T20:30:59.846+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 282) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.848+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 275) in 118 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:30:59.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 117.0 in stage 1.0 (TID 282)
[2025-07-19T20:30:59.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 106 (task 274, attempt 0, stage 1.0)
[2025-07-19T20:30:59.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 106.0 in stage 1.0 (TID 274). 9156 bytes result sent to driver
[2025-07-19T20:30:59.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.849+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.856+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 110 (task 276, attempt 0, stage 1.0)
[2025-07-19T20:30:59.857+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 110.0 in stage 1.0 (TID 276). 9156 bytes result sent to driver
[2025-07-19T20:30:59.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.1.delta.5528e8f3-697e-4f05-aabb-b44df5c6bfab.TID278.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta
[2025-07-19T20:30:59.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta
[2025-07-19T20:30:59.858+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 283) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 284) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 278, attempt 0, stage 1.0)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 119.0 in stage 1.0 (TID 284)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 274) in 128 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 276) in 126 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 118.0 in stage 1.0 (TID 283)
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.1.delta.1857e482-a3d3-44ba-9c8c-a7e52609d237.TID277.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta
[2025-07-19T20:30:59.859+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta
[2025-07-19T20:30:59.860+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 277, attempt 0, stage 1.0)
[2025-07-19T20:30:59.868+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.869+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@106fef4b
[2025-07-19T20:30:59.870+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.870+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117] for update
[2025-07-19T20:30:59.870+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.1.delta.920de87e-2a16-4c12-8ab5-170b37dc8f7a.TID281.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta
[2025-07-19T20:30:59.873+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta
[2025-07-19T20:30:59.873+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 281, attempt 0, stage 1.0)
[2025-07-19T20:30:59.873+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.878+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.1.delta.6ddce26f-cbb9-41bb-859b-be94dcd3a160.TID279.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta
[2025-07-19T20:30:59.879+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta
[2025-07-19T20:30:59.879+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 279, attempt 0, stage 1.0)
[2025-07-19T20:30:59.879+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e252b12
[2025-07-19T20:30:59.883+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.885+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 112 (task 278, attempt 0, stage 1.0)
[2025-07-19T20:30:59.886+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.1.delta.7a9c2f9d-7bda-4023-ab08-7e54e11bb9f9.TID280.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta
[2025-07-19T20:30:59.887+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta
[2025-07-19T20:30:59.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 280, attempt 0, stage 1.0)
[2025-07-19T20:30:59.888+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119] for update
[2025-07-19T20:30:59.889+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 112.0 in stage 1.0 (TID 278). 9166 bytes result sent to driver
[2025-07-19T20:30:59.889+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 285) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.889+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 111 (task 277, attempt 0, stage 1.0)
[2025-07-19T20:30:59.890+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 278) in 135 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:30:59.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 120.0 in stage 1.0 (TID 285)
[2025-07-19T20:30:59.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 111.0 in stage 1.0 (TID 277). 9167 bytes result sent to driver
[2025-07-19T20:30:59.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.892+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 286) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 121.0 in stage 1.0 (TID 286)
[2025-07-19T20:30:59.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@387b9f74
[2025-07-19T20:30:59.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118] for update
[2025-07-19T20:30:59.893+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 277) in 142 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:30:59.895+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.896+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.1.delta.7729c5c6-7aeb-427c-8d17-064b6ab71ed7.TID282.tmp
[2025-07-19T20:30:59.897+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.1.delta.74ba62ce-ccd2-4137-a416-b3611a68dbef.TID284.tmp
[2025-07-19T20:30:59.898+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fd6e186
[2025-07-19T20:30:59.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120] for update
[2025-07-19T20:30:59.899+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.900+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.902+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:59.905+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 113 (task 279, attempt 0, stage 1.0)
[2025-07-19T20:30:59.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 114 (task 280, attempt 0, stage 1.0)
[2025-07-19T20:30:59.906+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 115 (task 281, attempt 0, stage 1.0)
[2025-07-19T20:30:59.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:59.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 114.0 in stage 1.0 (TID 280). 9168 bytes result sent to driver
[2025-07-19T20:30:59.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 287) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.1.delta.e21719ae-41c2-4c77-8ac3-051742ab39a0.TID283.tmp
[2025-07-19T20:30:59.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 122.0 in stage 1.0 (TID 287)
[2025-07-19T20:30:59.907+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 113.0 in stage 1.0 (TID 279). 9158 bytes result sent to driver
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 288) (8b44f3d35cfa, executor driver, partition 125, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 125.0 in stage 1.0 (TID 288)
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 115.0 in stage 1.0 (TID 281). 9142 bytes result sent to driver
[2025-07-19T20:30:59.908+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 279) in 121 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:30:59.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 289) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 280) in 121 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:30:59.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.909+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.911+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28f5768f
[2025-07-19T20:30:59.912+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.913+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121] for update
[2025-07-19T20:30:59.914+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.920+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 128.0 in stage 1.0 (TID 289)
[2025-07-19T20:30:59.921+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.1.delta.93d73eb4-e8af-4f3d-a0d1-9ce74fb64d3b.TID285.tmp
[2025-07-19T20:30:59.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.922+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:30:59.923+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2aa2123c
[2025-07-19T20:30:59.923+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.924+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125] for update
[2025-07-19T20:30:59.924+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.926+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.1.delta.c06cc887-43d0-46cd-aed8-77d837c997af.TID286.tmp
[2025-07-19T20:30:59.927+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45e2f9c6
[2025-07-19T20:30:59.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 281) in 142 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:30:59.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122] for update
[2025-07-19T20:30:59.932+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.948+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1664c6a0
[2025-07-19T20:30:59.950+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.1.delta.d404f5a9-1c58-4c92-85a0-6474e6535f74.TID288.tmp
[2025-07-19T20:30:59.951+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.1.delta.7729c5c6-7aeb-427c-8d17-064b6ab71ed7.TID282.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta
[2025-07-19T20:30:59.954+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta
[2025-07-19T20:30:59.956+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 282, attempt 0, stage 1.0)
[2025-07-19T20:30:59.957+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:30:59.958+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128] for update
[2025-07-19T20:30:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:30:59.959+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.1.delta.74ba62ce-ccd2-4137-a416-b3611a68dbef.TID284.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta
[2025-07-19T20:30:59.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta
[2025-07-19T20:30:59.960+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 284, attempt 0, stage 1.0)
[2025-07-19T20:30:59.966+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.1.delta.27040fc9-9a80-41d5-8cce-55b769e9f5ad.TID287.tmp
[2025-07-19T20:30:59.972+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.1.delta.e21719ae-41c2-4c77-8ac3-051742ab39a0.TID283.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta
[2025-07-19T20:30:59.974+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta
[2025-07-19T20:30:59.975+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 283, attempt 0, stage 1.0)
[2025-07-19T20:30:59.977+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 117 (task 282, attempt 0, stage 1.0)
[2025-07-19T20:30:59.983+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 117.0 in stage 1.0 (TID 282). 9162 bytes result sent to driver
[2025-07-19T20:30:59.988+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 290) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 282) in 133 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:30:59.990+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 129.0 in stage 1.0 (TID 290)
[2025-07-19T20:30:59.992+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.1.delta.8162fd0c-57ae-4627-8097-04e3690b61c6.TID289.tmp
[2025-07-19T20:30:59.992+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:30:59.992+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:30:59.993+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Committed partition 119 (task 284, attempt 0, stage 1.0)
[2025-07-19T20:30:59.993+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Finished task 119.0 in stage 1.0 (TID 284). 9152 bytes result sent to driver
[2025-07-19T20:30:59.996+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 284) in 141 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:30:59.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:59.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.1.delta.93d73eb4-e8af-4f3d-a0d1-9ce74fb64d3b.TID285.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta
[2025-07-19T20:30:59.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta
[2025-07-19T20:30:59.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:59.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:30:59.997+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 291) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:30:59.998+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 285, attempt 0, stage 1.0)
[2025-07-19T20:31:00.005+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@771c52b3
[2025-07-19T20:31:00.006+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.007+0000] {subprocess.py:93} INFO - 25/07/19 20:30:59 INFO Executor: Running task 130.0 in stage 1.0 (TID 291)
[2025-07-19T20:31:00.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129] for update
[2025-07-19T20:31:00.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.1.delta.c06cc887-43d0-46cd-aed8-77d837c997af.TID286.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta
[2025-07-19T20:31:00.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta
[2025-07-19T20:31:00.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 286, attempt 0, stage 1.0)
[2025-07-19T20:31:00.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:00.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.1.delta.d404f5a9-1c58-4c92-85a0-6474e6535f74.TID288.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta
[2025-07-19T20:31:00.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta
[2025-07-19T20:31:00.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.1.delta.ae549222-eba1-4416-966c-411443d90aa8.TID290.tmp
[2025-07-19T20:31:00.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 118 (task 283, attempt 0, stage 1.0)
[2025-07-19T20:31:00.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 118.0 in stage 1.0 (TID 283). 9156 bytes result sent to driver
[2025-07-19T20:31:00.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 292) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 283) in 165 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:31:00.039+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 131.0 in stage 1.0 (TID 292)
[2025-07-19T20:31:00.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 288, attempt 0, stage 1.0)
[2025-07-19T20:31:00.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.048+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:00.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22ef9f6b
[2025-07-19T20:31:00.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130] for update
[2025-07-19T20:31:00.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 121 (task 286, attempt 0, stage 1.0)
[2025-07-19T20:31:00.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 121.0 in stage 1.0 (TID 286). 9152 bytes result sent to driver
[2025-07-19T20:31:00.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 120 (task 285, attempt 0, stage 1.0)
[2025-07-19T20:31:00.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 120.0 in stage 1.0 (TID 285). 9169 bytes result sent to driver
[2025-07-19T20:31:00.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 293) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 294) (8b44f3d35cfa, executor driver, partition 134, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 133.0 in stage 1.0 (TID 293)
[2025-07-19T20:31:00.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 286) in 166 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:31:00.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6272a61f
[2025-07-19T20:31:00.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 285) in 170 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:31:00.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131] for update
[2025-07-19T20:31:00.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 134.0 in stage 1.0 (TID 294)
[2025-07-19T20:31:00.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:31:00.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:31:00.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Checkins_raw
[2025-07-19T20:31:00.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e0aea3e
[2025-07-19T20:31:00.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133] for update
[2025-07-19T20:31:00.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.1.delta.8162fd0c-57ae-4627-8097-04e3690b61c6.TID289.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta
[2025-07-19T20:31:00.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta
[2025-07-19T20:31:00.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.1.delta.27040fc9-9a80-41d5-8cce-55b769e9f5ad.TID287.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta
[2025-07-19T20:31:00.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta
[2025-07-19T20:31:00.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 287, attempt 0, stage 1.0)
[2025-07-19T20:31:00.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.1.delta.c4e604f3-7566-45d1-86f1-35fc69d293f3.TID291.tmp
[2025-07-19T20:31:00.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 289, attempt 0, stage 1.0)
[2025-07-19T20:31:00.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11596378
[2025-07-19T20:31:00.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134] for update
[2025-07-19T20:31:00.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 125 (task 288, attempt 0, stage 1.0)
[2025-07-19T20:31:00.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 125.0 in stage 1.0 (TID 288). 9158 bytes result sent to driver
[2025-07-19T20:31:00.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.1.delta.7c05c560-db5b-4d3e-9eed-e6728b221ffa.TID293.tmp
[2025-07-19T20:31:00.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.1.delta.06b325cc-1d7a-4173-9b0a-20db609c248e.TID292.tmp
[2025-07-19T20:31:00.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 295) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 288) in 187 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:31:00.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 128 (task 289, attempt 0, stage 1.0)
[2025-07-19T20:31:00.097+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.1.delta.fd8b2367-6da4-4346-8162-20b8c5d65306.TID294.tmp
[2025-07-19T20:31:00.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 128.0 in stage 1.0 (TID 289). 9169 bytes result sent to driver
[2025-07-19T20:31:00.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 135.0 in stage 1.0 (TID 295)
[2025-07-19T20:31:00.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 122 (task 287, attempt 0, stage 1.0)
[2025-07-19T20:31:00.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 122.0 in stage 1.0 (TID 287). 9152 bytes result sent to driver
[2025-07-19T20:31:00.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 296) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 287) in 193 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:31:00.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 297) (8b44f3d35cfa, executor driver, partition 139, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 139.0 in stage 1.0 (TID 297)
[2025-07-19T20:31:00.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 137.0 in stage 1.0 (TID 296)
[2025-07-19T20:31:00.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 289) in 192 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:31:00.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.1.delta.ae549222-eba1-4416-966c-411443d90aa8.TID290.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta
[2025-07-19T20:31:00.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta
[2025-07-19T20:31:00.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 290, attempt 0, stage 1.0)
[2025-07-19T20:31:00.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 209.0 KiB, free 433.1 MiB)
[2025-07-19T20:31:00.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52f89318
[2025-07-19T20:31:00.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135] for update
[2025-07-19T20:31:00.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.1.delta.c4e604f3-7566-45d1-86f1-35fc69d293f3.TID291.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta
[2025-07-19T20:31:00.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta
[2025-07-19T20:31:00.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 291, attempt 0, stage 1.0)
[2025-07-19T20:31:00.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@793956e1
[2025-07-19T20:31:00.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137] for update
[2025-07-19T20:31:00.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 129 (task 290, attempt 0, stage 1.0)
[2025-07-19T20:31:00.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 129.0 in stage 1.0 (TID 290). 9149 bytes result sent to driver
[2025-07-19T20:31:00.142+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 298) (8b44f3d35cfa, executor driver, partition 141, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 290) in 163 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.1 MiB)
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.1.delta.7c05c560-db5b-4d3e-9eed-e6728b221ffa.TID293.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 141.0 in stage 1.0 (TID 298)
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.1.delta.06b325cc-1d7a-4173-9b0a-20db609c248e.TID292.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta
[2025-07-19T20:31:00.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta
[2025-07-19T20:31:00.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 8b44f3d35cfa:36593 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T20:31:00.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkContext: Created broadcast 12 from start at <unknown>:0
[2025-07-19T20:31:00.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T20:31:00.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 292, attempt 0, stage 1.0)
[2025-07-19T20:31:00.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@692552f1
[2025-07-19T20:31:00.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 130 (task 291, attempt 0, stage 1.0)
[2025-07-19T20:31:00.152+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139] for update
[2025-07-19T20:31:00.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 293, attempt 0, stage 1.0)
[2025-07-19T20:31:00.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 433.0 MiB)
[2025-07-19T20:31:00.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 8b44f3d35cfa:36593 (size: 29.6 KiB, free: 434.1 MiB)
[2025-07-19T20:31:00.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkContext: Created broadcast 13 from start at <unknown>:0
[2025-07-19T20:31:00.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:31:00.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.1.delta.1db7e377-2da4-495c-bba3-aef097e53f18.TID295.tmp
[2025-07-19T20:31:00.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:31:00.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 130.0 in stage 1.0 (TID 291). 9174 bytes result sent to driver
[2025-07-19T20:31:00.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 299) (8b44f3d35cfa, executor driver, partition 142, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 142.0 in stage 1.0 (TID 299)
[2025-07-19T20:31:00.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.1.delta.fd8b2367-6da4-4346-8162-20b8c5d65306.TID294.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta
[2025-07-19T20:31:00.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta
[2025-07-19T20:31:00.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 294, attempt 0, stage 1.0)
[2025-07-19T20:31:00.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 291) in 159 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:31:00.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Registering RDD 27 (start at <unknown>:0) as input to shuffle 3
[2025-07-19T20:31:00.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.1.delta.caea3ab5-0006-4b7b-9ac9-f7580137cd8f.TID296.tmp
[2025-07-19T20:31:00.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Got job 3 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:31:00.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Final stage: ResultStage 7 (start at <unknown>:0)
[2025-07-19T20:31:00.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
[2025-07-19T20:31:00.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Missing parents: List()
[2025-07-19T20:31:00.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Submitting ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:31:00.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@495ae791
[2025-07-19T20:31:00.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141] for update
[2025-07-19T20:31:00.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 131 (task 292, attempt 0, stage 1.0)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 131.0 in stage 1.0 (TID 292). 9152 bytes result sent to driver
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 300) (8b44f3d35cfa, executor driver, partition 143, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 133 (task 293, attempt 0, stage 1.0)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 292) in 150 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 143.0 in stage 1.0 (TID 300)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 133.0 in stage 1.0 (TID 293). 9160 bytes result sent to driver
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 301) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 144.0 in stage 1.0 (TID 301)
[2025-07-19T20:31:00.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 293) in 117 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:31:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@202a46e6
[2025-07-19T20:31:00.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142] for update
[2025-07-19T20:31:00.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.1.delta.034dbfb1-05bc-49e4-ab9d-e05cda4ccdc9.TID297.tmp
[2025-07-19T20:31:00.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.188+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 134 (task 294, attempt 0, stage 1.0)
[2025-07-19T20:31:00.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3c21c600
[2025-07-19T20:31:00.191+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143] for update
[2025-07-19T20:31:00.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 134.0 in stage 1.0 (TID 294). 9162 bytes result sent to driver
[2025-07-19T20:31:00.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 302) (8b44f3d35cfa, executor driver, partition 146, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 294) in 139 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:31:00.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.1.delta.dca237c9-541c-4323-a889-a2eeb8c69e49.TID298.tmp
[2025-07-19T20:31:00.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 146.0 in stage 1.0 (TID 302)
[2025-07-19T20:31:00.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a5716ee
[2025-07-19T20:31:00.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144] for update
[2025-07-19T20:31:00.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.200+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2edc47cb
[2025-07-19T20:31:00.203+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146] for update
[2025-07-19T20:31:00.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.1.delta.8eedc07d-f490-4447-8339-60b4aa2ee267.TID299.tmp
[2025-07-19T20:31:00.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.1.delta.1dfe7191-e32f-4b10-a476-4bc43014bcbc.TID301.tmp
[2025-07-19T20:31:00.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.1.delta.d1348743-656a-49fa-91d9-84cddcefecb0.TID300.tmp
[2025-07-19T20:31:00.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.1.delta.61a7cd56-405a-432d-8f32-f44ce61235eb.TID302.tmp
[2025-07-19T20:31:00.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.1.delta.1db7e377-2da4-495c-bba3-aef097e53f18.TID295.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta
[2025-07-19T20:31:00.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta
[2025-07-19T20:31:00.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 295, attempt 0, stage 1.0)
[2025-07-19T20:31:00.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.1.delta.caea3ab5-0006-4b7b-9ac9-f7580137cd8f.TID296.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta
[2025-07-19T20:31:00.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta
[2025-07-19T20:31:00.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 296, attempt 0, stage 1.0)
[2025-07-19T20:31:00.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 32.0 KiB, free 433.0 MiB)
[2025-07-19T20:31:00.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.0 MiB)
[2025-07-19T20:31:00.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 8b44f3d35cfa:36593 (size: 15.9 KiB, free: 434.1 MiB)
[2025-07-19T20:31:00.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:31:00.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 7 (StateStoreRDD[29] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:31:00.247+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 200 tasks resource profile 0
[2025-07-19T20:31:00.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 135 (task 295, attempt 0, stage 1.0)
[2025-07-19T20:31:00.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 135.0 in stage 1.0 (TID 295). 9164 bytes result sent to driver
[2025-07-19T20:31:00.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 303) (8b44f3d35cfa, executor driver, partition 147, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 147.0 in stage 1.0 (TID 303)
[2025-07-19T20:31:00.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 295) in 159 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:31:00.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.1.delta.034dbfb1-05bc-49e4-ab9d-e05cda4ccdc9.TID297.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta
[2025-07-19T20:31:00.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta
[2025-07-19T20:31:00.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 297, attempt 0, stage 1.0)
[2025-07-19T20:31:00.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.1.delta.dca237c9-541c-4323-a889-a2eeb8c69e49.TID298.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta
[2025-07-19T20:31:00.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta
[2025-07-19T20:31:00.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 298, attempt 0, stage 1.0)
[2025-07-19T20:31:00.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.1.delta.d1348743-656a-49fa-91d9-84cddcefecb0.TID300.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta
[2025-07-19T20:31:00.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta
[2025-07-19T20:31:00.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 300, attempt 0, stage 1.0)
[2025-07-19T20:31:00.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fb5245f
[2025-07-19T20:31:00.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147] for update
[2025-07-19T20:31:00.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 137 (task 296, attempt 0, stage 1.0)
[2025-07-19T20:31:00.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.1.delta.1dfe7191-e32f-4b10-a476-4bc43014bcbc.TID301.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta
[2025-07-19T20:31:00.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta
[2025-07-19T20:31:00.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 137.0 in stage 1.0 (TID 296). 9164 bytes result sent to driver
[2025-07-19T20:31:00.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.1.delta.8eedc07d-f490-4447-8339-60b4aa2ee267.TID299.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta
[2025-07-19T20:31:00.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta
[2025-07-19T20:31:00.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 299, attempt 0, stage 1.0)
[2025-07-19T20:31:00.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 304) (8b44f3d35cfa, executor driver, partition 148, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 301, attempt 0, stage 1.0)
[2025-07-19T20:31:00.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 296) in 169 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:31:00.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 141 (task 298, attempt 0, stage 1.0)
[2025-07-19T20:31:00.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 148.0 in stage 1.0 (TID 304)
[2025-07-19T20:31:00.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 141.0 in stage 1.0 (TID 298). 9146 bytes result sent to driver
[2025-07-19T20:31:00.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 305) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 298) in 131 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:31:00.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 149.0 in stage 1.0 (TID 305)
[2025-07-19T20:31:00.276+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.276+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.276+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.1.delta.dfac32a5-56e2-4e60-8cba-af067d76c0ba.TID303.tmp
[2025-07-19T20:31:00.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.1.delta.61a7cd56-405a-432d-8f32-f44ce61235eb.TID302.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta
[2025-07-19T20:31:00.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta
[2025-07-19T20:31:00.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 302, attempt 0, stage 1.0)
[2025-07-19T20:31:00.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 143 (task 300, attempt 0, stage 1.0)
[2025-07-19T20:31:00.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 139 (task 297, attempt 0, stage 1.0)
[2025-07-19T20:31:00.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 143.0 in stage 1.0 (TID 300). 9207 bytes result sent to driver
[2025-07-19T20:31:00.294+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 306) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 150.0 in stage 1.0 (TID 306)
[2025-07-19T20:31:00.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 300) in 125 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:31:00.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d3dbae5
[2025-07-19T20:31:00.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 139.0 in stage 1.0 (TID 297). 9201 bytes result sent to driver
[2025-07-19T20:31:00.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149] for update
[2025-07-19T20:31:00.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 307) (8b44f3d35cfa, executor driver, partition 151, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 151.0 in stage 1.0 (TID 307)
[2025-07-19T20:31:00.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 297) in 200 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:31:00.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 142 (task 299, attempt 0, stage 1.0)
[2025-07-19T20:31:00.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 142.0 in stage 1.0 (TID 299). 9164 bytes result sent to driver
[2025-07-19T20:31:00.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 308) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 299) in 145 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:31:00.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29643206
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 153.0 in stage 1.0 (TID 308)
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148] for update
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 144 (task 301, attempt 0, stage 1.0)
[2025-07-19T20:31:00.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 144.0 in stage 1.0 (TID 301). 9137 bytes result sent to driver
[2025-07-19T20:31:00.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 309) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 146 (task 302, attempt 0, stage 1.0)
[2025-07-19T20:31:00.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 301) in 140 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:31:00.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 154.0 in stage 1.0 (TID 309)
[2025-07-19T20:31:00.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 146.0 in stage 1.0 (TID 302). 9146 bytes result sent to driver
[2025-07-19T20:31:00.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 310) (8b44f3d35cfa, executor driver, partition 156, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 156.0 in stage 1.0 (TID 310)
[2025-07-19T20:31:00.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 302) in 122 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:31:00.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@273ebb78
[2025-07-19T20:31:00.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.1.delta.87d95d82-d4ea-45ef-b99f-608a5f4b9be0.TID305.tmp
[2025-07-19T20:31:00.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151] for update
[2025-07-19T20:31:00.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.1.delta.578c31b2-7ba6-4654-af7e-086dffd92739.TID304.tmp
[2025-07-19T20:31:00.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66b547bb
[2025-07-19T20:31:00.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154] for update
[2025-07-19T20:31:00.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@553cc9b6
[2025-07-19T20:31:00.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153] for update
[2025-07-19T20:31:00.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.1.delta.3c978800-a6c4-4729-b907-fc57d28e9283.TID307.tmp
[2025-07-19T20:31:00.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30c1d542
[2025-07-19T20:31:00.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150] for update
[2025-07-19T20:31:00.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.1.delta.2aed0ad8-0412-40ae-ad60-f5f7d053b3da.TID309.tmp
[2025-07-19T20:31:00.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12bb9979
[2025-07-19T20:31:00.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156] for update
[2025-07-19T20:31:00.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.1.delta.dfac32a5-56e2-4e60-8cba-af067d76c0ba.TID303.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta
[2025-07-19T20:31:00.353+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta
[2025-07-19T20:31:00.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.1.delta.3a21b611-6310-484d-a147-5daf72ec15cc.TID308.tmp
[2025-07-19T20:31:00.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 303, attempt 0, stage 1.0)
[2025-07-19T20:31:00.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.1.delta.afb7aa2b-2ecd-468d-b24d-b05a1ed44a37.TID306.tmp
[2025-07-19T20:31:00.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.1.delta.0d4e216d-0944-4768-9588-d3bc6add4722.TID310.tmp
[2025-07-19T20:31:00.374+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.1.delta.87d95d82-d4ea-45ef-b99f-608a5f4b9be0.TID305.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta
[2025-07-19T20:31:00.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta
[2025-07-19T20:31:00.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 305, attempt 0, stage 1.0)
[2025-07-19T20:31:00.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 147 (task 303, attempt 0, stage 1.0)
[2025-07-19T20:31:00.380+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.1.delta.578c31b2-7ba6-4654-af7e-086dffd92739.TID304.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta
[2025-07-19T20:31:00.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta
[2025-07-19T20:31:00.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 304, attempt 0, stage 1.0)
[2025-07-19T20:31:00.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 147.0 in stage 1.0 (TID 303). 9197 bytes result sent to driver
[2025-07-19T20:31:00.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 311) (8b44f3d35cfa, executor driver, partition 157, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 157.0 in stage 1.0 (TID 311)
[2025-07-19T20:31:00.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 303) in 138 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:31:00.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.1.delta.3c978800-a6c4-4729-b907-fc57d28e9283.TID307.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta
[2025-07-19T20:31:00.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7998785a
[2025-07-19T20:31:00.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta
[2025-07-19T20:31:00.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157] for update
[2025-07-19T20:31:00.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 149 (task 305, attempt 0, stage 1.0)
[2025-07-19T20:31:00.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 149.0 in stage 1.0 (TID 305). 9154 bytes result sent to driver
[2025-07-19T20:31:00.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 307, attempt 0, stage 1.0)
[2025-07-19T20:31:00.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 312) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 158.0 in stage 1.0 (TID 312)
[2025-07-19T20:31:00.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.1.delta.2aed0ad8-0412-40ae-ad60-f5f7d053b3da.TID309.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta
[2025-07-19T20:31:00.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta
[2025-07-19T20:31:00.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 305) in 131 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:31:00.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 309, attempt 0, stage 1.0)
[2025-07-19T20:31:00.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.1.delta.3a21b611-6310-484d-a147-5daf72ec15cc.TID308.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta
[2025-07-19T20:31:00.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta
[2025-07-19T20:31:00.414+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 148 (task 304, attempt 0, stage 1.0)
[2025-07-19T20:31:00.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 148.0 in stage 1.0 (TID 304). 9160 bytes result sent to driver
[2025-07-19T20:31:00.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 313) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 308, attempt 0, stage 1.0)
[2025-07-19T20:31:00.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 304) in 145 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:31:00.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 159.0 in stage 1.0 (TID 313)
[2025-07-19T20:31:00.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.1.delta.0d4e216d-0944-4768-9588-d3bc6add4722.TID310.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta
[2025-07-19T20:31:00.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta
[2025-07-19T20:31:00.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 310, attempt 0, stage 1.0)
[2025-07-19T20:31:00.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67308dbf
[2025-07-19T20:31:00.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.1.delta.afb7aa2b-2ecd-468d-b24d-b05a1ed44a37.TID306.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta
[2025-07-19T20:31:00.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta
[2025-07-19T20:31:00.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.1.delta.19edce3b-7b67-4a74-8690-511c9f59d9e1.TID311.tmp
[2025-07-19T20:31:00.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 306, attempt 0, stage 1.0)
[2025-07-19T20:31:00.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158] for update
[2025-07-19T20:31:00.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33516886
[2025-07-19T20:31:00.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159] for update
[2025-07-19T20:31:00.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.1.delta.31092633-40f3-43df-b082-09d62c50d16e.TID312.tmp
[2025-07-19T20:31:00.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 151 (task 307, attempt 0, stage 1.0)
[2025-07-19T20:31:00.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 154 (task 309, attempt 0, stage 1.0)
[2025-07-19T20:31:00.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 151.0 in stage 1.0 (TID 307). 9148 bytes result sent to driver
[2025-07-19T20:31:00.448+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 154.0 in stage 1.0 (TID 309). 9160 bytes result sent to driver
[2025-07-19T20:31:00.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 314) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 315) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 307) in 149 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:31:00.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 153 (task 308, attempt 0, stage 1.0)
[2025-07-19T20:31:00.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 162.0 in stage 1.0 (TID 314)
[2025-07-19T20:31:00.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 165.0 in stage 1.0 (TID 315)
[2025-07-19T20:31:00.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 309) in 136 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:31:00.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 153.0 in stage 1.0 (TID 308). 9166 bytes result sent to driver
[2025-07-19T20:31:00.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 316) (8b44f3d35cfa, executor driver, partition 167, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 167.0 in stage 1.0 (TID 316)
[2025-07-19T20:31:00.456+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 308) in 148 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:31:00.456+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.1.delta.f48d6d45-8b52-4b3c-a37f-7d1b4a35e818.TID313.tmp
[2025-07-19T20:31:00.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 156 (task 310, attempt 0, stage 1.0)
[2025-07-19T20:31:00.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 156.0 in stage 1.0 (TID 310). 9166 bytes result sent to driver
[2025-07-19T20:31:00.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 317) (8b44f3d35cfa, executor driver, partition 168, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 310) in 142 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:31:00.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 168.0 in stage 1.0 (TID 317)
[2025-07-19T20:31:00.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 150 (task 306, attempt 0, stage 1.0)
[2025-07-19T20:31:00.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55cf3505
[2025-07-19T20:31:00.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 150.0 in stage 1.0 (TID 306). 9175 bytes result sent to driver
[2025-07-19T20:31:00.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 318) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 169.0 in stage 1.0 (TID 318)
[2025-07-19T20:31:00.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167] for update
[2025-07-19T20:31:00.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 306) in 168 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:31:00.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@255e0d9b
[2025-07-19T20:31:00.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165] for update
[2025-07-19T20:31:00.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@309da222
[2025-07-19T20:31:00.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162] for update
[2025-07-19T20:31:00.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.1.delta.b4522dac-7b86-4e6b-aa8d-94d7ec45935d.TID316.tmp
[2025-07-19T20:31:00.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.1.delta.10a7f483-f16f-4fad-8f58-ce0022163b97.TID315.tmp
[2025-07-19T20:31:00.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.1.delta.31092633-40f3-43df-b082-09d62c50d16e.TID312.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta
[2025-07-19T20:31:00.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5757ae69
[2025-07-19T20:31:00.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta
[2025-07-19T20:31:00.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 312, attempt 0, stage 1.0)
[2025-07-19T20:31:00.486+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.1.delta.3e260cfb-5310-4a65-89ae-58f8262e33bd.TID314.tmp
[2025-07-19T20:31:00.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169] for update
[2025-07-19T20:31:00.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.1.delta.19edce3b-7b67-4a74-8690-511c9f59d9e1.TID311.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta
[2025-07-19T20:31:00.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta
[2025-07-19T20:31:00.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 311, attempt 0, stage 1.0)
[2025-07-19T20:31:00.490+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.1.delta.f48d6d45-8b52-4b3c-a37f-7d1b4a35e818.TID313.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta
[2025-07-19T20:31:00.492+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta
[2025-07-19T20:31:00.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 313, attempt 0, stage 1.0)
[2025-07-19T20:31:00.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40c0c2a2
[2025-07-19T20:31:00.498+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.498+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168] for update
[2025-07-19T20:31:00.500+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.1.delta.6bda7e84-fece-4549-a80a-6fe1b73cec26.TID318.tmp
[2025-07-19T20:31:00.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.504+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 158 (task 312, attempt 0, stage 1.0)
[2025-07-19T20:31:00.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 158.0 in stage 1.0 (TID 312). 9165 bytes result sent to driver
[2025-07-19T20:31:00.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 319) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 170.0 in stage 1.0 (TID 319)
[2025-07-19T20:31:00.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 312) in 109 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:31:00.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.516+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 159 (task 313, attempt 0, stage 1.0)
[2025-07-19T20:31:00.517+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 157 (task 311, attempt 0, stage 1.0)
[2025-07-19T20:31:00.517+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 157.0 in stage 1.0 (TID 311). 9167 bytes result sent to driver
[2025-07-19T20:31:00.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 320) (8b44f3d35cfa, executor driver, partition 171, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 171.0 in stage 1.0 (TID 320)
[2025-07-19T20:31:00.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e433455
[2025-07-19T20:31:00.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 159.0 in stage 1.0 (TID 313). 9165 bytes result sent to driver
[2025-07-19T20:31:00.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 311) in 137 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:31:00.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 321) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 172.0 in stage 1.0 (TID 321)
[2025-07-19T20:31:00.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 313) in 113 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:31:00.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170] for update
[2025-07-19T20:31:00.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.1.delta.7d88addb-06ee-4ad3-aa03-4c8ebdf2c5e9.TID317.tmp
[2025-07-19T20:31:00.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:00.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47df26e6
[2025-07-19T20:31:00.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171] for update
[2025-07-19T20:31:00.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.1.delta.10a7f483-f16f-4fad-8f58-ce0022163b97.TID315.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta
[2025-07-19T20:31:00.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta
[2025-07-19T20:31:00.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 315, attempt 0, stage 1.0)
[2025-07-19T20:31:00.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.1.delta.b4522dac-7b86-4e6b-aa8d-94d7ec45935d.TID316.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta
[2025-07-19T20:31:00.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta
[2025-07-19T20:31:00.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 316, attempt 0, stage 1.0)
[2025-07-19T20:31:00.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.1.delta.ab37574d-3de0-44fd-84a9-28beb9671483.TID319.tmp
[2025-07-19T20:31:00.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62794000
[2025-07-19T20:31:00.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.1.delta.c78e8b99-2311-4341-835d-349711716d55.TID320.tmp
[2025-07-19T20:31:00.540+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.540+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172] for update
[2025-07-19T20:31:00.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.1.delta.3e260cfb-5310-4a65-89ae-58f8262e33bd.TID314.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta
[2025-07-19T20:31:00.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta
[2025-07-19T20:31:00.542+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 314, attempt 0, stage 1.0)
[2025-07-19T20:31:00.544+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 165 (task 315, attempt 0, stage 1.0)
[2025-07-19T20:31:00.552+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 165.0 in stage 1.0 (TID 315). 9109 bytes result sent to driver
[2025-07-19T20:31:00.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 322) (8b44f3d35cfa, executor driver, partition 173, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 173.0 in stage 1.0 (TID 322)
[2025-07-19T20:31:00.554+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 315) in 110 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:31:00.557+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.558+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.558+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.1.delta.76d59475-a49c-4a32-8cb9-3a7e56313a54.TID321.tmp
[2025-07-19T20:31:00.559+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 167 (task 316, attempt 0, stage 1.0)
[2025-07-19T20:31:00.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 162 (task 314, attempt 0, stage 1.0)
[2025-07-19T20:31:00.564+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 167.0 in stage 1.0 (TID 316). 9207 bytes result sent to driver
[2025-07-19T20:31:00.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 162.0 in stage 1.0 (TID 314). 9146 bytes result sent to driver
[2025-07-19T20:31:00.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.1.delta.6bda7e84-fece-4549-a80a-6fe1b73cec26.TID318.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta
[2025-07-19T20:31:00.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta
[2025-07-19T20:31:00.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a57e40d
[2025-07-19T20:31:00.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 318, attempt 0, stage 1.0)
[2025-07-19T20:31:00.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 323) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 174.0 in stage 1.0 (TID 323)
[2025-07-19T20:31:00.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173] for update
[2025-07-19T20:31:00.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 324) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 316) in 124 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:31:00.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 314) in 130 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:31:00.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 175.0 in stage 1.0 (TID 324)
[2025-07-19T20:31:00.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.1.delta.7d88addb-06ee-4ad3-aa03-4c8ebdf2c5e9.TID317.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta
[2025-07-19T20:31:00.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta
[2025-07-19T20:31:00.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 317, attempt 0, stage 1.0)
[2025-07-19T20:31:00.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3aab4bc6
[2025-07-19T20:31:00.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175] for update
[2025-07-19T20:31:00.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d0a4f5f
[2025-07-19T20:31:00.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.1.delta.602a531f-593d-4053-8f00-e8dd8939ae90.TID322.tmp
[2025-07-19T20:31:00.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174] for update
[2025-07-19T20:31:00.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.1.delta.c78e8b99-2311-4341-835d-349711716d55.TID320.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta
[2025-07-19T20:31:00.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta
[2025-07-19T20:31:00.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 320, attempt 0, stage 1.0)
[2025-07-19T20:31:00.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.1.delta.beb4a220-9922-4387-ac3e-e455b4e80e83.TID324.tmp
[2025-07-19T20:31:00.597+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 169 (task 318, attempt 0, stage 1.0)
[2025-07-19T20:31:00.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.1.delta.ab37574d-3de0-44fd-84a9-28beb9671483.TID319.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta
[2025-07-19T20:31:00.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta
[2025-07-19T20:31:00.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 169.0 in stage 1.0 (TID 318). 9154 bytes result sent to driver
[2025-07-19T20:31:00.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 319, attempt 0, stage 1.0)
[2025-07-19T20:31:00.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 325) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 318) in 146 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:31:00.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 178.0 in stage 1.0 (TID 325)
[2025-07-19T20:31:00.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 168 (task 317, attempt 0, stage 1.0)
[2025-07-19T20:31:00.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 168.0 in stage 1.0 (TID 317). 9167 bytes result sent to driver
[2025-07-19T20:31:00.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 326) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 170 (task 319, attempt 0, stage 1.0)
[2025-07-19T20:31:00.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 317) in 161 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:31:00.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 179.0 in stage 1.0 (TID 326)
[2025-07-19T20:31:00.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 170.0 in stage 1.0 (TID 319). 9154 bytes result sent to driver
[2025-07-19T20:31:00.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.1.delta.cccc4404-bd9b-4408-96c6-3eda2fc78c24.TID323.tmp
[2025-07-19T20:31:00.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 327) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.617+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 171 (task 320, attempt 0, stage 1.0)
[2025-07-19T20:31:00.617+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 171.0 in stage 1.0 (TID 320). 9152 bytes result sent to driver
[2025-07-19T20:31:00.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 180.0 in stage 1.0 (TID 327)
[2025-07-19T20:31:00.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 319) in 111 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:31:00.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:00.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 328) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 320) in 102 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:31:00.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 181.0 in stage 1.0 (TID 328)
[2025-07-19T20:31:00.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:00.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:00.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@108207dc
[2025-07-19T20:31:00.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.1.delta.76d59475-a49c-4a32-8cb9-3a7e56313a54.TID321.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta
[2025-07-19T20:31:00.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta
[2025-07-19T20:31:00.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178] for update
[2025-07-19T20:31:00.630+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.630+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 321, attempt 0, stage 1.0)
[2025-07-19T20:31:00.633+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75bc3759
[2025-07-19T20:31:00.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.1.delta.602a531f-593d-4053-8f00-e8dd8939ae90.TID322.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta
[2025-07-19T20:31:00.635+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta
[2025-07-19T20:31:00.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.637+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180] for update
[2025-07-19T20:31:00.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 322, attempt 0, stage 1.0)
[2025-07-19T20:31:00.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.1.delta.beb4a220-9922-4387-ac3e-e455b4e80e83.TID324.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta
[2025-07-19T20:31:00.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta
[2025-07-19T20:31:00.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49fcd888
[2025-07-19T20:31:00.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 324, attempt 0, stage 1.0)
[2025-07-19T20:31:00.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181] for update
[2025-07-19T20:31:00.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.1.delta.cc2e4be7-1442-4129-a92b-dbd646a80e94.TID325.tmp
[2025-07-19T20:31:00.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 172 (task 321, attempt 0, stage 1.0)
[2025-07-19T20:31:00.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 172.0 in stage 1.0 (TID 321). 9153 bytes result sent to driver
[2025-07-19T20:31:00.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.1.delta.cccc4404-bd9b-4408-96c6-3eda2fc78c24.TID323.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta
[2025-07-19T20:31:00.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta
[2025-07-19T20:31:00.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 323, attempt 0, stage 1.0)
[2025-07-19T20:31:00.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 329) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 321) in 131 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:31:00.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3699810c
[2025-07-19T20:31:00.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 182.0 in stage 1.0 (TID 329)
[2025-07-19T20:31:00.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.1.delta.6094faa5-88db-4814-82c7-d47bae603d40.TID327.tmp
[2025-07-19T20:31:00.663+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179] for update
[2025-07-19T20:31:00.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:00.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.1.delta.ab12095b-4513-422a-be5b-a17705aa3079.TID328.tmp
[2025-07-19T20:31:00.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a306c5c
[2025-07-19T20:31:00.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182] for update
[2025-07-19T20:31:00.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 173 (task 322, attempt 0, stage 1.0)
[2025-07-19T20:31:00.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 173.0 in stage 1.0 (TID 322). 9158 bytes result sent to driver
[2025-07-19T20:31:00.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 175 (task 324, attempt 0, stage 1.0)
[2025-07-19T20:31:00.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 330) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 183.0 in stage 1.0 (TID 330)
[2025-07-19T20:31:00.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 175.0 in stage 1.0 (TID 324). 9195 bytes result sent to driver
[2025-07-19T20:31:00.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 331) (8b44f3d35cfa, executor driver, partition 184, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 324) in 114 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:31:00.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.707+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 184.0 in stage 1.0 (TID 331)
[2025-07-19T20:31:00.708+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 322) in 139 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:31:00.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.711+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.1.delta.ef78c802-761e-4586-bf5c-23e6ff7f5334.TID326.tmp
[2025-07-19T20:31:00.711+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 174 (task 323, attempt 0, stage 1.0)
[2025-07-19T20:31:00.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 174.0 in stage 1.0 (TID 323). 9144 bytes result sent to driver
[2025-07-19T20:31:00.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ab6d382
[2025-07-19T20:31:00.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.1.delta.d500abb8-125b-4d6d-bf77-0bd6669b7c19.TID329.tmp
[2025-07-19T20:31:00.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183] for update
[2025-07-19T20:31:00.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 332) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 185.0 in stage 1.0 (TID 332)
[2025-07-19T20:31:00.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 323) in 152 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:31:00.733+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@412fa3f4
[2025-07-19T20:31:00.733+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184] for update
[2025-07-19T20:31:00.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.1.delta.cbfd6431-a7a7-4870-b010-5654cf8ce321.TID330.tmp
[2025-07-19T20:31:00.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27e75243
[2025-07-19T20:31:00.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185] for update
[2025-07-19T20:31:00.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.1.delta.cc2e4be7-1442-4129-a92b-dbd646a80e94.TID325.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta
[2025-07-19T20:31:00.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta
[2025-07-19T20:31:00.742+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.1.delta.dfca8c7e-c8e2-4d98-8f0a-21d9959d80bc.TID331.tmp
[2025-07-19T20:31:00.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 325, attempt 0, stage 1.0)
[2025-07-19T20:31:00.744+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.1.delta.6094faa5-88db-4814-82c7-d47bae603d40.TID327.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta
[2025-07-19T20:31:00.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta
[2025-07-19T20:31:00.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 327, attempt 0, stage 1.0)
[2025-07-19T20:31:00.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.1.delta.d4166ecc-221d-494b-b3a6-8e11344b289c.TID332.tmp
[2025-07-19T20:31:00.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.1.delta.ef78c802-761e-4586-bf5c-23e6ff7f5334.TID326.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta
[2025-07-19T20:31:00.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta
[2025-07-19T20:31:00.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.1.delta.ab12095b-4513-422a-be5b-a17705aa3079.TID328.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta
[2025-07-19T20:31:00.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta
[2025-07-19T20:31:00.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 326, attempt 0, stage 1.0)
[2025-07-19T20:31:00.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 328, attempt 0, stage 1.0)
[2025-07-19T20:31:00.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.1.delta.d500abb8-125b-4d6d-bf77-0bd6669b7c19.TID329.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta
[2025-07-19T20:31:00.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 178 (task 325, attempt 0, stage 1.0)
[2025-07-19T20:31:00.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta
[2025-07-19T20:31:00.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 178.0 in stage 1.0 (TID 325). 9156 bytes result sent to driver
[2025-07-19T20:31:00.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 329, attempt 0, stage 1.0)
[2025-07-19T20:31:00.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 180 (task 327, attempt 0, stage 1.0)
[2025-07-19T20:31:00.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 180.0 in stage 1.0 (TID 327). 9150 bytes result sent to driver
[2025-07-19T20:31:00.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 333) (8b44f3d35cfa, executor driver, partition 187, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 187.0 in stage 1.0 (TID 333)
[2025-07-19T20:31:00.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 334) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 325) in 167 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:31:00.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 188.0 in stage 1.0 (TID 334)
[2025-07-19T20:31:00.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 327) in 151 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:31:00.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 179 (task 326, attempt 0, stage 1.0)
[2025-07-19T20:31:00.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 179.0 in stage 1.0 (TID 326). 9150 bytes result sent to driver
[2025-07-19T20:31:00.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 181 (task 328, attempt 0, stage 1.0)
[2025-07-19T20:31:00.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 181.0 in stage 1.0 (TID 328). 9156 bytes result sent to driver
[2025-07-19T20:31:00.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 335) (8b44f3d35cfa, executor driver, partition 189, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2461ab01
[2025-07-19T20:31:00.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187] for update
[2025-07-19T20:31:00.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 189.0 in stage 1.0 (TID 335)
[2025-07-19T20:31:00.783+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 336) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.1.delta.dfca8c7e-c8e2-4d98-8f0a-21d9959d80bc.TID331.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta
[2025-07-19T20:31:00.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 192.0 in stage 1.0 (TID 336)
[2025-07-19T20:31:00.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta
[2025-07-19T20:31:00.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 326) in 165 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:31:00.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 328) in 159 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:31:00.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 331, attempt 0, stage 1.0)
[2025-07-19T20:31:00.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.1.delta.cbfd6431-a7a7-4870-b010-5654cf8ce321.TID330.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta
[2025-07-19T20:31:00.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta
[2025-07-19T20:31:00.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 182 (task 329, attempt 0, stage 1.0)
[2025-07-19T20:31:00.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 330, attempt 0, stage 1.0)
[2025-07-19T20:31:00.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 182.0 in stage 1.0 (TID 329). 9161 bytes result sent to driver
[2025-07-19T20:31:00.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 337) (8b44f3d35cfa, executor driver, partition 194, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 194.0 in stage 1.0 (TID 337)
[2025-07-19T20:31:00.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@676d6a5a
[2025-07-19T20:31:00.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.1.delta.d4166ecc-221d-494b-b3a6-8e11344b289c.TID332.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta
[2025-07-19T20:31:00.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta
[2025-07-19T20:31:00.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 329) in 134 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:31:00.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 332, attempt 0, stage 1.0)
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188] for update
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.1.delta.77e086c8-514a-4aa9-bbfc-1032204fbf26.TID333.tmp
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d5a91a3
[2025-07-19T20:31:00.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194] for update
[2025-07-19T20:31:00.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.1.delta.1803ecc7-da1f-47c2-ab8e-beb254511846.TID334.tmp
[2025-07-19T20:31:00.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 185 (task 332, attempt 0, stage 1.0)
[2025-07-19T20:31:00.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 184 (task 331, attempt 0, stage 1.0)
[2025-07-19T20:31:00.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 183 (task 330, attempt 0, stage 1.0)
[2025-07-19T20:31:00.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 185.0 in stage 1.0 (TID 332). 9199 bytes result sent to driver
[2025-07-19T20:31:00.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 183.0 in stage 1.0 (TID 330). 9184 bytes result sent to driver
[2025-07-19T20:31:00.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60105d85
[2025-07-19T20:31:00.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 338) (8b44f3d35cfa, executor driver, partition 196, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 184.0 in stage 1.0 (TID 331). 9193 bytes result sent to driver
[2025-07-19T20:31:00.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 339) (8b44f3d35cfa, executor driver, partition 197, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192] for update
[2025-07-19T20:31:00.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 340) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 197.0 in stage 1.0 (TID 339)
[2025-07-19T20:31:00.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.1.delta.e3b85aac-4d92-41e3-80a0-268a2af774ba.TID337.tmp
[2025-07-19T20:31:00.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 332) in 94 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:31:00.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 330) in 141 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:31:00.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 331) in 131 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:31:00.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 199.0 in stage 1.0 (TID 340)
[2025-07-19T20:31:00.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 196.0 in stage 1.0 (TID 338)
[2025-07-19T20:31:00.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:00.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:00.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78a9d9d4
[2025-07-19T20:31:00.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189] for update
[2025-07-19T20:31:00.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64d98f29
[2025-07-19T20:31:00.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:00.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199] for update
[2025-07-19T20:31:00.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.1.delta.efa14071-d5e9-49a5-b98d-186216e69f8f.TID336.tmp
[2025-07-19T20:31:00.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.1.delta.77e086c8-514a-4aa9-bbfc-1032204fbf26.TID333.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta
[2025-07-19T20:31:00.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta
[2025-07-19T20:31:00.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 333, attempt 0, stage 1.0)
[2025-07-19T20:31:00.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.1.delta.4fd0a742-3031-4dbe-aec2-78203b0de19b.TID340.tmp
[2025-07-19T20:31:00.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64a67605
[2025-07-19T20:31:00.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197] for update
[2025-07-19T20:31:00.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.1.delta.74268a8d-171d-4a98-b870-e536bacc6040.TID335.tmp
[2025-07-19T20:31:00.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36a7b3a7
[2025-07-19T20:31:00.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196] for update
[2025-07-19T20:31:00.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.1.delta.1803ecc7-da1f-47c2-ab8e-beb254511846.TID334.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta
[2025-07-19T20:31:00.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta
[2025-07-19T20:31:00.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 334, attempt 0, stage 1.0)
[2025-07-19T20:31:00.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.1.delta.3d195011-8d62-4535-ba8f-4eada2b8e2ba.TID339.tmp
[2025-07-19T20:31:00.865+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.1.delta.e3b85aac-4d92-41e3-80a0-268a2af774ba.TID337.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta
[2025-07-19T20:31:00.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta
[2025-07-19T20:31:00.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.1.delta.5964e008-9c8c-45af-8163-bd95e6eeae07.TID338.tmp
[2025-07-19T20:31:00.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 187 (task 333, attempt 0, stage 1.0)
[2025-07-19T20:31:00.868+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 187.0 in stage 1.0 (TID 333). 9171 bytes result sent to driver
[2025-07-19T20:31:00.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 337, attempt 0, stage 1.0)
[2025-07-19T20:31:00.870+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 341) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 333) in 106 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:31:00.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 5.0 in stage 1.0 (TID 341)
[2025-07-19T20:31:00.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 188 (task 334, attempt 0, stage 1.0)
[2025-07-19T20:31:00.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 188.0 in stage 1.0 (TID 334). 9163 bytes result sent to driver
[2025-07-19T20:31:00.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 342) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 6.0 in stage 1.0 (TID 342)
[2025-07-19T20:31:00.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 334) in 113 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:31:00.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1100585e
[2025-07-19T20:31:00.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5] for update
[2025-07-19T20:31:00.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.1.delta.efa14071-d5e9-49a5-b98d-186216e69f8f.TID336.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta
[2025-07-19T20:31:00.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta
[2025-07-19T20:31:00.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 336, attempt 0, stage 1.0)
[2025-07-19T20:31:00.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28364db
[2025-07-19T20:31:00.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.1.delta.74268a8d-171d-4a98-b870-e536bacc6040.TID335.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta
[2025-07-19T20:31:00.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta
[2025-07-19T20:31:00.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 335, attempt 0, stage 1.0)
[2025-07-19T20:31:00.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6] for update
[2025-07-19T20:31:00.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.1.delta.4fd0a742-3031-4dbe-aec2-78203b0de19b.TID340.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta
[2025-07-19T20:31:00.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta
[2025-07-19T20:31:00.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 340, attempt 0, stage 1.0)
[2025-07-19T20:31:00.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 194 (task 337, attempt 0, stage 1.0)
[2025-07-19T20:31:00.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 194.0 in stage 1.0 (TID 337). 9144 bytes result sent to driver
[2025-07-19T20:31:00.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 343) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 8.0 in stage 1.0 (TID 343)
[2025-07-19T20:31:00.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 337) in 117 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:31:00.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.1.delta.eaf81cd1-1bb6-49b6-9308-51395ee187d2.TID341.tmp
[2025-07-19T20:31:00.905+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 192 (task 336, attempt 0, stage 1.0)
[2025-07-19T20:31:00.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f5826df
[2025-07-19T20:31:00.910+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 192.0 in stage 1.0 (TID 336). 9150 bytes result sent to driver
[2025-07-19T20:31:00.910+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8] for update
[2025-07-19T20:31:00.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 344) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 336) in 133 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:31:00.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 17.0 in stage 1.0 (TID 344)
[2025-07-19T20:31:00.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.1.delta.a0d98e83-4d60-40bf-b141-10935ed4302c.TID342.tmp
[2025-07-19T20:31:00.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 199 (task 340, attempt 0, stage 1.0)
[2025-07-19T20:31:00.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 199.0 in stage 1.0 (TID 340). 9111 bytes result sent to driver
[2025-07-19T20:31:00.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 345) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 19.0 in stage 1.0 (TID 345)
[2025-07-19T20:31:00.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.1.delta.3d195011-8d62-4535-ba8f-4eada2b8e2ba.TID339.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta
[2025-07-19T20:31:00.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.1.delta.5964e008-9c8c-45af-8163-bd95e6eeae07.TID338.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta
[2025-07-19T20:31:00.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta
[2025-07-19T20:31:00.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta
[2025-07-19T20:31:00.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.923+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 338, attempt 0, stage 1.0)
[2025-07-19T20:31:00.924+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 340) in 105 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:31:00.924+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 339, attempt 0, stage 1.0)
[2025-07-19T20:31:00.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 189 (task 335, attempt 0, stage 1.0)
[2025-07-19T20:31:00.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 189.0 in stage 1.0 (TID 335). 9158 bytes result sent to driver
[2025-07-19T20:31:00.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:00.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 346) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 335) in 145 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:31:00.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 21.0 in stage 1.0 (TID 346)
[2025-07-19T20:31:00.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.1.delta.15b7656b-6645-4297-aa26-8fb1461ea344.TID343.tmp
[2025-07-19T20:31:00.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18add63e
[2025-07-19T20:31:00.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17] for update
[2025-07-19T20:31:00.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 196 (task 338, attempt 0, stage 1.0)
[2025-07-19T20:31:00.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d1cd309
[2025-07-19T20:31:00.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 196.0 in stage 1.0 (TID 338). 9107 bytes result sent to driver
[2025-07-19T20:31:00.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19] for update
[2025-07-19T20:31:00.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 347) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 24.0 in stage 1.0 (TID 347)
[2025-07-19T20:31:00.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 197 (task 339, attempt 0, stage 1.0)
[2025-07-19T20:31:00.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 197.0 in stage 1.0 (TID 339). 9113 bytes result sent to driver
[2025-07-19T20:31:00.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 348) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 338) in 136 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:31:00.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 25.0 in stage 1.0 (TID 348)
[2025-07-19T20:31:00.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.1.delta.908f580e-c9b3-4405-85f5-ab2281e2de66.TID344.tmp
[2025-07-19T20:31:00.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 339) in 131 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:31:00.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59e03f80
[2025-07-19T20:31:00.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.1.delta.ff3dcff1-3b97-4d88-854d-7f93a914a2bd.TID345.tmp
[2025-07-19T20:31:00.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21] for update
[2025-07-19T20:31:00.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:00.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:00.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.1.delta.a0d98e83-4d60-40bf-b141-10935ed4302c.TID342.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta
[2025-07-19T20:31:00.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta
[2025-07-19T20:31:00.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.1.delta.eaf81cd1-1bb6-49b6-9308-51395ee187d2.TID341.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta
[2025-07-19T20:31:00.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta
[2025-07-19T20:31:00.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 342, attempt 0, stage 1.0)
[2025-07-19T20:31:00.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 341, attempt 0, stage 1.0)
[2025-07-19T20:31:00.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ba708bb
[2025-07-19T20:31:00.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25] for update
[2025-07-19T20:31:00.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 5 (task 341, attempt 0, stage 1.0)
[2025-07-19T20:31:00.969+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 5.0 in stage 1.0 (TID 341). 6243 bytes result sent to driver
[2025-07-19T20:31:00.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.1.delta.15b7656b-6645-4297-aa26-8fb1461ea344.TID343.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta
[2025-07-19T20:31:00.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta
[2025-07-19T20:31:00.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 349) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 29.0 in stage 1.0 (TID 349)
[2025-07-19T20:31:00.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 343, attempt 0, stage 1.0)
[2025-07-19T20:31:00.978+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 341) in 104 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:31:00.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.1.delta.64ad6884-551f-46e9-95d5-76063bebaec2.TID346.tmp
[2025-07-19T20:31:00.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 8 (task 343, attempt 0, stage 1.0)
[2025-07-19T20:31:00.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35f17f01
[2025-07-19T20:31:00.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24] for update
[2025-07-19T20:31:00.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 8.0 in stage 1.0 (TID 343). 6243 bytes result sent to driver
[2025-07-19T20:31:00.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 350) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 32.0 in stage 1.0 (TID 350)
[2025-07-19T20:31:00.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 343) in 80 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:31:00.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:00.987+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO DataWritingSparkTask: Committed partition 6 (task 342, attempt 0, stage 1.0)
[2025-07-19T20:31:00.987+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Finished task 6.0 in stage 1.0 (TID 342). 6243 bytes result sent to driver
[2025-07-19T20:31:00.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.1.delta.4d97b8d5-3442-48b3-8201-7240a67b3922.TID348.tmp
[2025-07-19T20:31:00.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 351) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:00.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 342) in 107 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:31:00.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO Executor: Running task 34.0 in stage 1.0 (TID 351)
[2025-07-19T20:31:00.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:00.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:00.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@123c3ee1
[2025-07-19T20:31:00.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:00.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29] for update
[2025-07-19T20:31:00.999+0000] {subprocess.py:93} INFO - 25/07/19 20:31:00 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.1.delta.71462dc6-2ecd-4d39-8d9b-cdc7ab682565.TID347.tmp
[2025-07-19T20:31:01.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.1.delta.908f580e-c9b3-4405-85f5-ab2281e2de66.TID344.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta
[2025-07-19T20:31:01.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta
[2025-07-19T20:31:01.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 344, attempt 0, stage 1.0)
[2025-07-19T20:31:01.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42c8a49c
[2025-07-19T20:31:01.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 17 (task 344, attempt 0, stage 1.0)
[2025-07-19T20:31:01.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 17.0 in stage 1.0 (TID 344). 6243 bytes result sent to driver
[2025-07-19T20:31:01.011+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.1.delta.ff3dcff1-3b97-4d88-854d-7f93a914a2bd.TID345.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta
[2025-07-19T20:31:01.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta
[2025-07-19T20:31:01.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 352) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 345, attempt 0, stage 1.0)
[2025-07-19T20:31:01.015+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 344) in 102 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:31:01.015+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 36.0 in stage 1.0 (TID 352)
[2025-07-19T20:31:01.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32] for update
[2025-07-19T20:31:01.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.1.delta.1869dd4f-c015-4814-8a32-4ea64e06b02b.TID349.tmp
[2025-07-19T20:31:01.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 19 (task 345, attempt 0, stage 1.0)
[2025-07-19T20:31:01.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 19.0 in stage 1.0 (TID 345). 6243 bytes result sent to driver
[2025-07-19T20:31:01.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 353) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 345) in 107 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:31:01.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11c75816
[2025-07-19T20:31:01.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36] for update
[2025-07-19T20:31:01.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 38.0 in stage 1.0 (TID 353)
[2025-07-19T20:31:01.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a0fd4d2
[2025-07-19T20:31:01.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34] for update
[2025-07-19T20:31:01.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.1.delta.d58495f0-ccb8-41d3-b5b0-d1c4d3278d6a.TID350.tmp
[2025-07-19T20:31:01.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.1.delta.64ad6884-551f-46e9-95d5-76063bebaec2.TID346.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta
[2025-07-19T20:31:01.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta
[2025-07-19T20:31:01.034+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 346, attempt 0, stage 1.0)
[2025-07-19T20:31:01.034+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.1.delta.5bec5566-36ed-4eab-8788-1725094eb2f5.TID352.tmp
[2025-07-19T20:31:01.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.1.delta.9268c6eb-f4c1-419c-a4a8-0481e48653f2.TID351.tmp
[2025-07-19T20:31:01.049+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@644b0338
[2025-07-19T20:31:01.049+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.1.delta.4d97b8d5-3442-48b3-8201-7240a67b3922.TID348.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta
[2025-07-19T20:31:01.049+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta
[2025-07-19T20:31:01.052+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38] for update
[2025-07-19T20:31:01.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 348, attempt 0, stage 1.0)
[2025-07-19T20:31:01.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.1.delta.71462dc6-2ecd-4d39-8d9b-cdc7ab682565.TID347.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta
[2025-07-19T20:31:01.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta
[2025-07-19T20:31:01.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 347, attempt 0, stage 1.0)
[2025-07-19T20:31:01.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.1.delta.087b4bf3-d6fa-439e-a96e-eabf2cbf1c5d.TID353.tmp
[2025-07-19T20:31:01.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 25 (task 348, attempt 0, stage 1.0)
[2025-07-19T20:31:01.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 24 (task 347, attempt 0, stage 1.0)
[2025-07-19T20:31:01.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.1.delta.1869dd4f-c015-4814-8a32-4ea64e06b02b.TID349.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta
[2025-07-19T20:31:01.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta
[2025-07-19T20:31:01.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 21 (task 346, attempt 0, stage 1.0)
[2025-07-19T20:31:01.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 349, attempt 0, stage 1.0)
[2025-07-19T20:31:01.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 29 (task 349, attempt 0, stage 1.0)
[2025-07-19T20:31:01.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 21.0 in stage 1.0 (TID 346). 6286 bytes result sent to driver
[2025-07-19T20:31:01.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 29.0 in stage 1.0 (TID 349). 6286 bytes result sent to driver
[2025-07-19T20:31:01.110+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 354) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.112+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 24.0 in stage 1.0 (TID 347). 6286 bytes result sent to driver
[2025-07-19T20:31:01.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 25.0 in stage 1.0 (TID 348). 6286 bytes result sent to driver
[2025-07-19T20:31:01.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 355) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 356) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 349) in 124 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:31:01.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 348) in 155 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:31:01.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 44.0 in stage 1.0 (TID 355)
[2025-07-19T20:31:01.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 46.0 in stage 1.0 (TID 356)
[2025-07-19T20:31:01.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 346) in 179 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:31:01.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 40.0 in stage 1.0 (TID 354)
[2025-07-19T20:31:01.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:01.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 357) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 49.0 in stage 1.0 (TID 357)
[2025-07-19T20:31:01.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.1.delta.5bec5566-36ed-4eab-8788-1725094eb2f5.TID352.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta
[2025-07-19T20:31:01.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta
[2025-07-19T20:31:01.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 347) in 182 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:31:01.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 352, attempt 0, stage 1.0)
[2025-07-19T20:31:01.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cab4b45
[2025-07-19T20:31:01.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46] for update
[2025-07-19T20:31:01.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.1.delta.087b4bf3-d6fa-439e-a96e-eabf2cbf1c5d.TID353.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta
[2025-07-19T20:31:01.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta
[2025-07-19T20:31:01.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 36 (task 352, attempt 0, stage 1.0)
[2025-07-19T20:31:01.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 36.0 in stage 1.0 (TID 352). 6243 bytes result sent to driver
[2025-07-19T20:31:01.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 358) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 353, attempt 0, stage 1.0)
[2025-07-19T20:31:01.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 53.0 in stage 1.0 (TID 358)
[2025-07-19T20:31:01.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 352) in 123 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:31:01.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3931bdbd
[2025-07-19T20:31:01.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 38 (task 353, attempt 0, stage 1.0)
[2025-07-19T20:31:01.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.1.delta.9268c6eb-f4c1-419c-a4a8-0481e48653f2.TID351.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta
[2025-07-19T20:31:01.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta
[2025-07-19T20:31:01.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49] for update
[2025-07-19T20:31:01.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.1.delta.e56e5477-2f8c-4d24-b213-58bce4405122.TID356.tmp
[2025-07-19T20:31:01.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 38.0 in stage 1.0 (TID 353). 6243 bytes result sent to driver
[2025-07-19T20:31:01.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 351, attempt 0, stage 1.0)
[2025-07-19T20:31:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 359) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 57.0 in stage 1.0 (TID 359)
[2025-07-19T20:31:01.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 353) in 129 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:31:01.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.152+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 34 (task 351, attempt 0, stage 1.0)
[2025-07-19T20:31:01.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 34.0 in stage 1.0 (TID 351). 6243 bytes result sent to driver
[2025-07-19T20:31:01.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 360) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 61.0 in stage 1.0 (TID 360)
[2025-07-19T20:31:01.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 351) in 170 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:31:01.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.1.delta.d58495f0-ccb8-41d3-b5b0-d1c4d3278d6a.TID350.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta
[2025-07-19T20:31:01.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta
[2025-07-19T20:31:01.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 350, attempt 0, stage 1.0)
[2025-07-19T20:31:01.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6568f8c1
[2025-07-19T20:31:01.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40] for update
[2025-07-19T20:31:01.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@221b9632
[2025-07-19T20:31:01.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44] for update
[2025-07-19T20:31:01.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.1.delta.11e856d5-6ba1-47f8-b2e7-f39ed797156c.TID357.tmp
[2025-07-19T20:31:01.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 8b44f3d35cfa:36593 in memory (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T20:31:01.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.1.delta.aed60562-e21d-4ca7-b0bb-277a265b529d.TID354.tmp
[2025-07-19T20:31:01.202+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 32 (task 350, attempt 0, stage 1.0)
[2025-07-19T20:31:01.203+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 32.0 in stage 1.0 (TID 350). 6243 bytes result sent to driver
[2025-07-19T20:31:01.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 350) in 220 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:31:01.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 361) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 64.0 in stage 1.0 (TID 361)
[2025-07-19T20:31:01.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8b44f3d35cfa:36593 in memory (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T20:31:01.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26647564
[2025-07-19T20:31:01.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61] for update
[2025-07-19T20:31:01.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.1.delta.1a87b092-791c-462f-9226-8bfd7a5dc441.TID355.tmp
[2025-07-19T20:31:01.232+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57332223
[2025-07-19T20:31:01.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57] for update
[2025-07-19T20:31:01.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 8b44f3d35cfa:36593 in memory (size: 19.9 KiB, free: 434.2 MiB)
[2025-07-19T20:31:01.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.1.delta.cd075c48-62bc-402b-9376-9d3fe0a6af1e.TID360.tmp
[2025-07-19T20:31:01.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.1.delta.e56e5477-2f8c-4d24-b213-58bce4405122.TID356.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta
[2025-07-19T20:31:01.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta
[2025-07-19T20:31:01.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 356, attempt 0, stage 1.0)
[2025-07-19T20:31:01.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31efd389
[2025-07-19T20:31:01.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53] for update
[2025-07-19T20:31:01.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.1.delta.81257037-0ed5-4abc-88d8-cd825daddfbb.TID359.tmp
[2025-07-19T20:31:01.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 46 (task 356, attempt 0, stage 1.0)
[2025-07-19T20:31:01.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 46.0 in stage 1.0 (TID 356). 6200 bytes result sent to driver
[2025-07-19T20:31:01.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 362) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 65.0 in stage 1.0 (TID 362)
[2025-07-19T20:31:01.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 356) in 165 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:31:01.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.1.delta.11e856d5-6ba1-47f8-b2e7-f39ed797156c.TID357.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta
[2025-07-19T20:31:01.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta
[2025-07-19T20:31:01.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 357, attempt 0, stage 1.0)
[2025-07-19T20:31:01.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@472445ed
[2025-07-19T20:31:01.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64] for update
[2025-07-19T20:31:01.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 49 (task 357, attempt 0, stage 1.0)
[2025-07-19T20:31:01.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 49.0 in stage 1.0 (TID 357). 6200 bytes result sent to driver
[2025-07-19T20:31:01.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 363) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 357) in 161 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:31:01.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 69.0 in stage 1.0 (TID 363)
[2025-07-19T20:31:01.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.1.delta.aed60562-e21d-4ca7-b0bb-277a265b529d.TID354.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta
[2025-07-19T20:31:01.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta
[2025-07-19T20:31:01.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35a3712f
[2025-07-19T20:31:01.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65] for update
[2025-07-19T20:31:01.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 354, attempt 0, stage 1.0)
[2025-07-19T20:31:01.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.1.delta.9b36d529-3426-45ef-9d97-5664b4445d4f.TID358.tmp
[2025-07-19T20:31:01.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 40 (task 354, attempt 0, stage 1.0)
[2025-07-19T20:31:01.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 40.0 in stage 1.0 (TID 354). 6200 bytes result sent to driver
[2025-07-19T20:31:01.294+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 364) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26602b52
[2025-07-19T20:31:01.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69] for update
[2025-07-19T20:31:01.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 70.0 in stage 1.0 (TID 364)
[2025-07-19T20:31:01.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.1.delta.eef03f07-9f8c-4624-a9f8-e28cf865b49d.TID361.tmp
[2025-07-19T20:31:01.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 354) in 200 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:31:01.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.1.delta.ed991754-2e21-421e-a944-6e473a5e75ce.TID362.tmp
[2025-07-19T20:31:01.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.1.delta.2170ed12-9df0-484a-ad3d-032457f03646.TID363.tmp
[2025-07-19T20:31:01.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2697cf17
[2025-07-19T20:31:01.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70] for update
[2025-07-19T20:31:01.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.310+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.1.delta.1a87b092-791c-462f-9226-8bfd7a5dc441.TID355.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta
[2025-07-19T20:31:01.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta
[2025-07-19T20:31:01.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 355, attempt 0, stage 1.0)
[2025-07-19T20:31:01.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 44 (task 355, attempt 0, stage 1.0)
[2025-07-19T20:31:01.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 44.0 in stage 1.0 (TID 355). 6200 bytes result sent to driver
[2025-07-19T20:31:01.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 365) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 73.0 in stage 1.0 (TID 365)
[2025-07-19T20:31:01.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 355) in 224 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:31:01.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.1.delta.81257037-0ed5-4abc-88d8-cd825daddfbb.TID359.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta
[2025-07-19T20:31:01.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta
[2025-07-19T20:31:01.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.1.delta.cd075c48-62bc-402b-9376-9d3fe0a6af1e.TID360.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta
[2025-07-19T20:31:01.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta
[2025-07-19T20:31:01.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 360, attempt 0, stage 1.0)
[2025-07-19T20:31:01.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 359, attempt 0, stage 1.0)
[2025-07-19T20:31:01.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.1.delta.36107bc1-8b9f-452e-93aa-ac50d0dc01a4.TID364.tmp
[2025-07-19T20:31:01.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 57 (task 359, attempt 0, stage 1.0)
[2025-07-19T20:31:01.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 57.0 in stage 1.0 (TID 359). 6200 bytes result sent to driver
[2025-07-19T20:31:01.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 366) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 81.0 in stage 1.0 (TID 366)
[2025-07-19T20:31:01.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 359) in 186 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:31:01.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@571e24bc
[2025-07-19T20:31:01.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73] for update
[2025-07-19T20:31:01.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.1.delta.9b36d529-3426-45ef-9d97-5664b4445d4f.TID358.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta
[2025-07-19T20:31:01.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta
[2025-07-19T20:31:01.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.1.delta.eef03f07-9f8c-4624-a9f8-e28cf865b49d.TID361.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta
[2025-07-19T20:31:01.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta
[2025-07-19T20:31:01.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.1.delta.ed991754-2e21-421e-a944-6e473a5e75ce.TID362.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta
[2025-07-19T20:31:01.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta
[2025-07-19T20:31:01.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7da82690
[2025-07-19T20:31:01.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 358, attempt 0, stage 1.0)
[2025-07-19T20:31:01.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 61 (task 360, attempt 0, stage 1.0)
[2025-07-19T20:31:01.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 361, attempt 0, stage 1.0)
[2025-07-19T20:31:01.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 362, attempt 0, stage 1.0)
[2025-07-19T20:31:01.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 61.0 in stage 1.0 (TID 360). 6200 bytes result sent to driver
[2025-07-19T20:31:01.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81] for update
[2025-07-19T20:31:01.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 367) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 360) in 193 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:31:01.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.1.delta.d427c173-765e-47ec-8359-42ddd97630f3.TID365.tmp
[2025-07-19T20:31:01.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 86.0 in stage 1.0 (TID 367)
[2025-07-19T20:31:01.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.1.delta.2170ed12-9df0-484a-ad3d-032457f03646.TID363.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta
[2025-07-19T20:31:01.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta
[2025-07-19T20:31:01.363+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 65 (task 362, attempt 0, stage 1.0)
[2025-07-19T20:31:01.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 64 (task 361, attempt 0, stage 1.0)
[2025-07-19T20:31:01.365+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 363, attempt 0, stage 1.0)
[2025-07-19T20:31:01.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.1.delta.36107bc1-8b9f-452e-93aa-ac50d0dc01a4.TID364.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta
[2025-07-19T20:31:01.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta
[2025-07-19T20:31:01.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 64.0 in stage 1.0 (TID 361). 6200 bytes result sent to driver
[2025-07-19T20:31:01.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 364, attempt 0, stage 1.0)
[2025-07-19T20:31:01.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 53 (task 358, attempt 0, stage 1.0)
[2025-07-19T20:31:01.373+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.373+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 65.0 in stage 1.0 (TID 362). 6200 bytes result sent to driver
[2025-07-19T20:31:01.374+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 53.0 in stage 1.0 (TID 358). 6243 bytes result sent to driver
[2025-07-19T20:31:01.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 368) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 369) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 370) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.380+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 91.0 in stage 1.0 (TID 370)
[2025-07-19T20:31:01.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 361) in 163 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:31:01.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 358) in 231 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:31:01.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 89.0 in stage 1.0 (TID 368)
[2025-07-19T20:31:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53451732
[2025-07-19T20:31:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 362) in 105 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:31:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 90.0 in stage 1.0 (TID 369)
[2025-07-19T20:31:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86] for update
[2025-07-19T20:31:01.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:01.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 69 (task 363, attempt 0, stage 1.0)
[2025-07-19T20:31:01.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 69.0 in stage 1.0 (TID 363). 6200 bytes result sent to driver
[2025-07-19T20:31:01.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 371) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 363) in 101 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:31:01.389+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.1.delta.ac9f8d88-a8a9-4a85-960a-87ee4f1bee77.TID366.tmp
[2025-07-19T20:31:01.389+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 92.0 in stage 1.0 (TID 371)
[2025-07-19T20:31:01.389+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 70 (task 364, attempt 0, stage 1.0)
[2025-07-19T20:31:01.390+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 70.0 in stage 1.0 (TID 364). 6200 bytes result sent to driver
[2025-07-19T20:31:01.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:31:01.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 372) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 364) in 88 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:31:01.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36b1bb4a
[2025-07-19T20:31:01.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91] for update
[2025-07-19T20:31:01.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:01.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 93.0 in stage 1.0 (TID 372)
[2025-07-19T20:31:01.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.1.delta.5483562e-dd14-461f-a8e7-ac7811700e4a.TID367.tmp
[2025-07-19T20:31:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.1.delta.b38cd294-9916-4487-a5ac-a44ded37258c.TID370.tmp
[2025-07-19T20:31:01.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d1ef88f
[2025-07-19T20:31:01.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92] for update
[2025-07-19T20:31:01.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.1.delta.d427c173-765e-47ec-8359-42ddd97630f3.TID365.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta
[2025-07-19T20:31:01.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta
[2025-07-19T20:31:01.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@460650da
[2025-07-19T20:31:01.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 365, attempt 0, stage 1.0)
[2025-07-19T20:31:01.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90] for update
[2025-07-19T20:31:01.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.1.delta.389a3963-cb43-4a2e-bc3a-da4ad5051711.TID371.tmp
[2025-07-19T20:31:01.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 73 (task 365, attempt 0, stage 1.0)
[2025-07-19T20:31:01.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 73.0 in stage 1.0 (TID 365). 6200 bytes result sent to driver
[2025-07-19T20:31:01.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 373) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 98.0 in stage 1.0 (TID 373)
[2025-07-19T20:31:01.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 365) in 102 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:31:01.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@318b25d5
[2025-07-19T20:31:01.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89] for update
[2025-07-19T20:31:01.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.1.delta.ac9f8d88-a8a9-4a85-960a-87ee4f1bee77.TID366.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta
[2025-07-19T20:31:01.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.1.delta.b4d9d6a9-b40b-4bbb-a56e-b5ba36592514.TID369.tmp
[2025-07-19T20:31:01.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta
[2025-07-19T20:31:01.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5385fd1a
[2025-07-19T20:31:01.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 366, attempt 0, stage 1.0)
[2025-07-19T20:31:01.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98] for update
[2025-07-19T20:31:01.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 81 (task 366, attempt 0, stage 1.0)
[2025-07-19T20:31:01.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 81.0 in stage 1.0 (TID 366). 6200 bytes result sent to driver
[2025-07-19T20:31:01.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 366) in 113 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:31:01.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.1.delta.b38cd294-9916-4487-a5ac-a44ded37258c.TID370.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta
[2025-07-19T20:31:01.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta
[2025-07-19T20:31:01.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 370, attempt 0, stage 1.0)
[2025-07-19T20:31:01.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.1.delta.5483562e-dd14-461f-a8e7-ac7811700e4a.TID367.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta
[2025-07-19T20:31:01.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.1.delta.07a4228d-ec30-478c-be94-16fef62c2bc6.TID368.tmp
[2025-07-19T20:31:01.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta
[2025-07-19T20:31:01.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 367, attempt 0, stage 1.0)
[2025-07-19T20:31:01.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 374) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.448+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 102.0 in stage 1.0 (TID 374)
[2025-07-19T20:31:01.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 91 (task 370, attempt 0, stage 1.0)
[2025-07-19T20:31:01.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 91.0 in stage 1.0 (TID 370). 6200 bytes result sent to driver
[2025-07-19T20:31:01.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b588fcf
[2025-07-19T20:31:01.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 375) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.456+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 370) in 89 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:31:01.456+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 86 (task 367, attempt 0, stage 1.0)
[2025-07-19T20:31:01.456+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93] for update
[2025-07-19T20:31:01.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 86.0 in stage 1.0 (TID 367). 6200 bytes result sent to driver
[2025-07-19T20:31:01.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 376) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 367) in 110 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:31:01.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 105.0 in stage 1.0 (TID 375)
[2025-07-19T20:31:01.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 107.0 in stage 1.0 (TID 376)
[2025-07-19T20:31:01.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.1.delta.faf9e6bf-a31d-4c7c-acf0-aef4bc8d2b4b.TID373.tmp
[2025-07-19T20:31:01.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-07-19T20:31:01.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.1.delta.8420d6de-1851-49f6-932f-396d39c0cbe3.TID372.tmp
[2025-07-19T20:31:01.482+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@301242e3
[2025-07-19T20:31:01.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.1.delta.389a3963-cb43-4a2e-bc3a-da4ad5051711.TID371.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta
[2025-07-19T20:31:01.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta
[2025-07-19T20:31:01.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 371, attempt 0, stage 1.0)
[2025-07-19T20:31:01.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102] for update
[2025-07-19T20:31:01.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 92 (task 371, attempt 0, stage 1.0)
[2025-07-19T20:31:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 92.0 in stage 1.0 (TID 371). 6200 bytes result sent to driver
[2025-07-19T20:31:01.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 377) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.492+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 371) in 119 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:31:01.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 109.0 in stage 1.0 (TID 377)
[2025-07-19T20:31:01.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6873fe16
[2025-07-19T20:31:01.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107] for update
[2025-07-19T20:31:01.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.1.delta.b4d9d6a9-b40b-4bbb-a56e-b5ba36592514.TID369.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta
[2025-07-19T20:31:01.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta
[2025-07-19T20:31:01.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 369, attempt 0, stage 1.0)
[2025-07-19T20:31:01.504+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.504+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 90 (task 369, attempt 0, stage 1.0)
[2025-07-19T20:31:01.505+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 90.0 in stage 1.0 (TID 369). 6200 bytes result sent to driver
[2025-07-19T20:31:01.508+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 378) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.508+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 369) in 141 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:31:01.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.1.delta.0178bcb4-46e6-479b-8a7e-43430244c038.TID374.tmp
[2025-07-19T20:31:01.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 116.0 in stage 1.0 (TID 378)
[2025-07-19T20:31:01.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3fa0f3fa
[2025-07-19T20:31:01.515+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.515+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105] for update
[2025-07-19T20:31:01.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.1.delta.07a4228d-ec30-478c-be94-16fef62c2bc6.TID368.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta
[2025-07-19T20:31:01.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta
[2025-07-19T20:31:01.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.1.delta.4b2be6ff-4628-44ef-8293-849daed885d8.TID376.tmp
[2025-07-19T20:31:01.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.1.delta.faf9e6bf-a31d-4c7c-acf0-aef4bc8d2b4b.TID373.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta
[2025-07-19T20:31:01.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta
[2025-07-19T20:31:01.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 368, attempt 0, stage 1.0)
[2025-07-19T20:31:01.524+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 373, attempt 0, stage 1.0)
[2025-07-19T20:31:01.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@688b2a16
[2025-07-19T20:31:01.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116] for update
[2025-07-19T20:31:01.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 89 (task 368, attempt 0, stage 1.0)
[2025-07-19T20:31:01.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 89.0 in stage 1.0 (TID 368). 6200 bytes result sent to driver
[2025-07-19T20:31:01.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 98 (task 373, attempt 0, stage 1.0)
[2025-07-19T20:31:01.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 98.0 in stage 1.0 (TID 373). 6200 bytes result sent to driver
[2025-07-19T20:31:01.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 379) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 368) in 163 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:31:01.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62886e13
[2025-07-19T20:31:01.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 380) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 373) in 108 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:31:01.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 124.0 in stage 1.0 (TID 380)
[2025-07-19T20:31:01.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 123.0 in stage 1.0 (TID 379)
[2025-07-19T20:31:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109] for update
[2025-07-19T20:31:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.1.delta.1aba4569-442a-4af3-bd4f-99a87a7d0494.TID375.tmp
[2025-07-19T20:31:01.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.1.delta.d11de541-ecc2-4373-bcc6-62b3ff2007d1.TID378.tmp
[2025-07-19T20:31:01.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cea3b80
[2025-07-19T20:31:01.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.1.delta.8420d6de-1851-49f6-932f-396d39c0cbe3.TID372.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta
[2025-07-19T20:31:01.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta
[2025-07-19T20:31:01.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123] for update
[2025-07-19T20:31:01.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 372, attempt 0, stage 1.0)
[2025-07-19T20:31:01.545+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 93 (task 372, attempt 0, stage 1.0)
[2025-07-19T20:31:01.546+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.546+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 93.0 in stage 1.0 (TID 372). 6200 bytes result sent to driver
[2025-07-19T20:31:01.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 381) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 126.0 in stage 1.0 (TID 381)
[2025-07-19T20:31:01.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73ae0869
[2025-07-19T20:31:01.552+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.1.delta.450ab82f-cac2-46e9-88d2-0561903dfb2c.TID377.tmp
[2025-07-19T20:31:01.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124] for update
[2025-07-19T20:31:01.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 372) in 174 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:31:01.558+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.559+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.1.delta.0178bcb4-46e6-479b-8a7e-43430244c038.TID374.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta
[2025-07-19T20:31:01.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta
[2025-07-19T20:31:01.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 374, attempt 0, stage 1.0)
[2025-07-19T20:31:01.564+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.1.delta.fff4cb98-f339-45d3-86ef-1a83c9773613.TID379.tmp
[2025-07-19T20:31:01.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 102 (task 374, attempt 0, stage 1.0)
[2025-07-19T20:31:01.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 102.0 in stage 1.0 (TID 374). 6200 bytes result sent to driver
[2025-07-19T20:31:01.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 382) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 374) in 121 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:31:01.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 127.0 in stage 1.0 (TID 382)
[2025-07-19T20:31:01.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7677d22a
[2025-07-19T20:31:01.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.1.delta.5859993c-04a2-484b-b920-c929285b137a.TID380.tmp
[2025-07-19T20:31:01.574+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.1.delta.4b2be6ff-4628-44ef-8293-849daed885d8.TID376.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta
[2025-07-19T20:31:01.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta
[2025-07-19T20:31:01.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:01.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126] for update
[2025-07-19T20:31:01.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 376, attempt 0, stage 1.0)
[2025-07-19T20:31:01.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.1.delta.1aba4569-442a-4af3-bd4f-99a87a7d0494.TID375.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta
[2025-07-19T20:31:01.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta
[2025-07-19T20:31:01.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 375, attempt 0, stage 1.0)
[2025-07-19T20:31:01.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 107 (task 376, attempt 0, stage 1.0)
[2025-07-19T20:31:01.591+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 105 (task 375, attempt 0, stage 1.0)
[2025-07-19T20:31:01.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 107.0 in stage 1.0 (TID 376). 6200 bytes result sent to driver
[2025-07-19T20:31:01.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 105.0 in stage 1.0 (TID 375). 6200 bytes result sent to driver
[2025-07-19T20:31:01.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 383) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.1.delta.d11de541-ecc2-4373-bcc6-62b3ff2007d1.TID378.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta
[2025-07-19T20:31:01.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta
[2025-07-19T20:31:01.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.1.delta.2a56a37b-7abd-4fa8-8b5d-e37ffb1583c0.TID381.tmp
[2025-07-19T20:31:01.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 132.0 in stage 1.0 (TID 383)
[2025-07-19T20:31:01.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 384) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 136.0 in stage 1.0 (TID 384)
[2025-07-19T20:31:01.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 378, attempt 0, stage 1.0)
[2025-07-19T20:31:01.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 375) in 150 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:31:01.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 376) in 148 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:31:01.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3abc5951
[2025-07-19T20:31:01.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127] for update
[2025-07-19T20:31:01.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.1.delta.450ab82f-cac2-46e9-88d2-0561903dfb2c.TID377.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta
[2025-07-19T20:31:01.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta
[2025-07-19T20:31:01.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 377, attempt 0, stage 1.0)
[2025-07-19T20:31:01.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 116 (task 378, attempt 0, stage 1.0)
[2025-07-19T20:31:01.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 116.0 in stage 1.0 (TID 378). 6200 bytes result sent to driver
[2025-07-19T20:31:01.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 385) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 138.0 in stage 1.0 (TID 385)
[2025-07-19T20:31:01.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18cb6c6b
[2025-07-19T20:31:01.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 378) in 113 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:31:01.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 109 (task 377, attempt 0, stage 1.0)
[2025-07-19T20:31:01.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132] for update
[2025-07-19T20:31:01.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 109.0 in stage 1.0 (TID 377). 6200 bytes result sent to driver
[2025-07-19T20:31:01.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 386) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 377) in 132 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:31:01.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 140.0 in stage 1.0 (TID 386)
[2025-07-19T20:31:01.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.1.delta.571a6eff-a08b-4519-b24e-6b45f1d3ef55.TID382.tmp
[2025-07-19T20:31:01.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.1.delta.fff4cb98-f339-45d3-86ef-1a83c9773613.TID379.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta
[2025-07-19T20:31:01.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta
[2025-07-19T20:31:01.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 379, attempt 0, stage 1.0)
[2025-07-19T20:31:01.631+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4cfa065e
[2025-07-19T20:31:01.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136] for update
[2025-07-19T20:31:01.633+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.637+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 123 (task 379, attempt 0, stage 1.0)
[2025-07-19T20:31:01.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 123.0 in stage 1.0 (TID 379). 6200 bytes result sent to driver
[2025-07-19T20:31:01.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 387) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 145.0 in stage 1.0 (TID 387)
[2025-07-19T20:31:01.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.1.delta.2c39cf8c-0005-4562-89f8-e4d9e4c7590a.TID383.tmp
[2025-07-19T20:31:01.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 379) in 112 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:31:01.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f23160e
[2025-07-19T20:31:01.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140] for update
[2025-07-19T20:31:01.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.1.delta.7aaff93b-339f-45fa-83cd-c823994076e3.TID384.tmp
[2025-07-19T20:31:01.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.1.delta.5859993c-04a2-484b-b920-c929285b137a.TID380.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta
[2025-07-19T20:31:01.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta
[2025-07-19T20:31:01.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 380, attempt 0, stage 1.0)
[2025-07-19T20:31:01.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51a572d7
[2025-07-19T20:31:01.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138] for update
[2025-07-19T20:31:01.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 124 (task 380, attempt 0, stage 1.0)
[2025-07-19T20:31:01.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.1.delta.786c2b1f-cdad-44df-b773-c5dba81fcda5.TID386.tmp
[2025-07-19T20:31:01.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 124.0 in stage 1.0 (TID 380). 6243 bytes result sent to driver
[2025-07-19T20:31:01.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.1.delta.2a56a37b-7abd-4fa8-8b5d-e37ffb1583c0.TID381.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta
[2025-07-19T20:31:01.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta
[2025-07-19T20:31:01.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 381, attempt 0, stage 1.0)
[2025-07-19T20:31:01.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 388) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ec9e5ae
[2025-07-19T20:31:01.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 152.0 in stage 1.0 (TID 388)
[2025-07-19T20:31:01.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 380) in 144 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:31:01.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145] for update
[2025-07-19T20:31:01.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 126 (task 381, attempt 0, stage 1.0)
[2025-07-19T20:31:01.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 126.0 in stage 1.0 (TID 381). 6243 bytes result sent to driver
[2025-07-19T20:31:01.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 389) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 155.0 in stage 1.0 (TID 389)
[2025-07-19T20:31:01.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 381) in 132 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:31:01.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.1.delta.21b85ec3-88cf-46ee-9587-45c4557ef05d.TID387.tmp
[2025-07-19T20:31:01.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@590f4f0c
[2025-07-19T20:31:01.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.1.delta.a86820cb-2d38-40a6-b9b4-a36bf43593c9.TID385.tmp
[2025-07-19T20:31:01.695+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152] for update
[2025-07-19T20:31:01.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.1.delta.571a6eff-a08b-4519-b24e-6b45f1d3ef55.TID382.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta
[2025-07-19T20:31:01.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta
[2025-07-19T20:31:01.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 382, attempt 0, stage 1.0)
[2025-07-19T20:31:01.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64010b0f
[2025-07-19T20:31:01.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155] for update
[2025-07-19T20:31:01.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.708+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 127 (task 382, attempt 0, stage 1.0)
[2025-07-19T20:31:01.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 127.0 in stage 1.0 (TID 382). 6243 bytes result sent to driver
[2025-07-19T20:31:01.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 390) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 160.0 in stage 1.0 (TID 390)
[2025-07-19T20:31:01.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 382) in 147 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:31:01.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.1.delta.7aaff93b-339f-45fa-83cd-c823994076e3.TID384.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta
[2025-07-19T20:31:01.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta
[2025-07-19T20:31:01.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 384, attempt 0, stage 1.0)
[2025-07-19T20:31:01.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.1.delta.f3715f77-58d9-4d9b-b74b-fc05e631ee4a.TID388.tmp
[2025-07-19T20:31:01.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.1.delta.2c39cf8c-0005-4562-89f8-e4d9e4c7590a.TID383.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta
[2025-07-19T20:31:01.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta
[2025-07-19T20:31:01.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 383, attempt 0, stage 1.0)
[2025-07-19T20:31:01.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:01.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.1.delta.8fa8b1c4-af1f-4b9b-af3c-5d5d56fa036b.TID389.tmp
[2025-07-19T20:31:01.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 136 (task 384, attempt 0, stage 1.0)
[2025-07-19T20:31:01.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 136.0 in stage 1.0 (TID 384). 6243 bytes result sent to driver
[2025-07-19T20:31:01.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 391) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.731+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 384) in 129 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:31:01.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 161.0 in stage 1.0 (TID 391)
[2025-07-19T20:31:01.733+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f6e28c
[2025-07-19T20:31:01.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 132 (task 383, attempt 0, stage 1.0)
[2025-07-19T20:31:01.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 132.0 in stage 1.0 (TID 383). 6243 bytes result sent to driver
[2025-07-19T20:31:01.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 392) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160] for update
[2025-07-19T20:31:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.1.delta.786c2b1f-cdad-44df-b773-c5dba81fcda5.TID386.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta
[2025-07-19T20:31:01.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta
[2025-07-19T20:31:01.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 163.0 in stage 1.0 (TID 392)
[2025-07-19T20:31:01.744+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 386, attempt 0, stage 1.0)
[2025-07-19T20:31:01.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 383) in 142 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:31:01.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 140 (task 386, attempt 0, stage 1.0)
[2025-07-19T20:31:01.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.1.delta.a86820cb-2d38-40a6-b9b4-a36bf43593c9.TID385.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta
[2025-07-19T20:31:01.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta
[2025-07-19T20:31:01.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c36ab75
[2025-07-19T20:31:01.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 140.0 in stage 1.0 (TID 386). 6243 bytes result sent to driver
[2025-07-19T20:31:01.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.1.delta.21b85ec3-88cf-46ee-9587-45c4557ef05d.TID387.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta
[2025-07-19T20:31:01.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta
[2025-07-19T20:31:01.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161] for update
[2025-07-19T20:31:01.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 393) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 164.0 in stage 1.0 (TID 393)
[2025-07-19T20:31:01.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 385, attempt 0, stage 1.0)
[2025-07-19T20:31:01.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 386) in 134 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:31:01.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 387, attempt 0, stage 1.0)
[2025-07-19T20:31:01.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.1.delta.5dc6bd3f-211a-4984-b832-918a7ba483cf.TID390.tmp
[2025-07-19T20:31:01.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33cbd49f
[2025-07-19T20:31:01.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163] for update
[2025-07-19T20:31:01.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 145 (task 387, attempt 0, stage 1.0)
[2025-07-19T20:31:01.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 138 (task 385, attempt 0, stage 1.0)
[2025-07-19T20:31:01.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 145.0 in stage 1.0 (TID 387). 6243 bytes result sent to driver
[2025-07-19T20:31:01.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:01.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 138.0 in stage 1.0 (TID 385). 6243 bytes result sent to driver
[2025-07-19T20:31:01.783+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 394) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 395) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 166.0 in stage 1.0 (TID 394)
[2025-07-19T20:31:01.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 176.0 in stage 1.0 (TID 395)
[2025-07-19T20:31:01.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 385) in 163 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:31:01.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 387) in 141 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:31:01.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.1.delta.f3715f77-58d9-4d9b-b74b-fc05e631ee4a.TID388.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta
[2025-07-19T20:31:01.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta
[2025-07-19T20:31:01.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.1.delta.81f864cb-fe5f-4200-87b5-118d765eb3d8.TID392.tmp
[2025-07-19T20:31:01.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.1.delta.52b2a3aa-01ea-4b6f-9851-f4f15321f90b.TID391.tmp
[2025-07-19T20:31:01.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 388, attempt 0, stage 1.0)
[2025-07-19T20:31:01.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@581a96d6
[2025-07-19T20:31:01.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.1.delta.8fa8b1c4-af1f-4b9b-af3c-5d5d56fa036b.TID389.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta
[2025-07-19T20:31:01.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164] for update
[2025-07-19T20:31:01.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta
[2025-07-19T20:31:01.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 389, attempt 0, stage 1.0)
[2025-07-19T20:31:01.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 155 (task 389, attempt 0, stage 1.0)
[2025-07-19T20:31:01.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 152 (task 388, attempt 0, stage 1.0)
[2025-07-19T20:31:01.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 155.0 in stage 1.0 (TID 389). 6243 bytes result sent to driver
[2025-07-19T20:31:01.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77859c58
[2025-07-19T20:31:01.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 152.0 in stage 1.0 (TID 388). 6243 bytes result sent to driver
[2025-07-19T20:31:01.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 396) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 177.0 in stage 1.0 (TID 396)
[2025-07-19T20:31:01.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 389) in 121 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:31:01.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 397) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 388) in 136 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:31:01.801+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 186.0 in stage 1.0 (TID 397)
[2025-07-19T20:31:01.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176] for update
[2025-07-19T20:31:01.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.1.delta.521fbf2f-0224-4efd-a163-f094a032a7df.TID393.tmp
[2025-07-19T20:31:01.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:01.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c1cbece
[2025-07-19T20:31:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166] for update
[2025-07-19T20:31:01.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.1.delta.73bd9785-ec30-4a08-a16f-d3543f9bda4b.TID395.tmp
[2025-07-19T20:31:01.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57fa156d
[2025-07-19T20:31:01.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177] for update
[2025-07-19T20:31:01.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@50586592
[2025-07-19T20:31:01.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.1.delta.5dc6bd3f-211a-4984-b832-918a7ba483cf.TID390.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta
[2025-07-19T20:31:01.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta
[2025-07-19T20:31:01.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186] for update
[2025-07-19T20:31:01.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.1.delta.e3cae7b0-b675-4a8f-b86f-00defe485095.TID394.tmp
[2025-07-19T20:31:01.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 390, attempt 0, stage 1.0)
[2025-07-19T20:31:01.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.1.delta.52b2a3aa-01ea-4b6f-9851-f4f15321f90b.TID391.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta
[2025-07-19T20:31:01.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta
[2025-07-19T20:31:01.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 160 (task 390, attempt 0, stage 1.0)
[2025-07-19T20:31:01.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 391, attempt 0, stage 1.0)
[2025-07-19T20:31:01.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 160.0 in stage 1.0 (TID 390). 6243 bytes result sent to driver
[2025-07-19T20:31:01.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 398) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 190.0 in stage 1.0 (TID 398)
[2025-07-19T20:31:01.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 390) in 122 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:31:01.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.1.delta.81f864cb-fe5f-4200-87b5-118d765eb3d8.TID392.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta
[2025-07-19T20:31:01.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta
[2025-07-19T20:31:01.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 392, attempt 0, stage 1.0)
[2025-07-19T20:31:01.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.1.delta.298faa1c-62b6-4ae2-ac2a-f950dbba16ec.TID397.tmp
[2025-07-19T20:31:01.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 161 (task 391, attempt 0, stage 1.0)
[2025-07-19T20:31:01.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 161.0 in stage 1.0 (TID 391). 6243 bytes result sent to driver
[2025-07-19T20:31:01.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.1.delta.58d746bd-89c8-45c5-910e-31814c37b68a.TID396.tmp
[2025-07-19T20:31:01.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 399) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 191.0 in stage 1.0 (TID 399)
[2025-07-19T20:31:01.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 391) in 110 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:31:01.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 163 (task 392, attempt 0, stage 1.0)
[2025-07-19T20:31:01.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7148d625
[2025-07-19T20:31:01.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 163.0 in stage 1.0 (TID 392). 6243 bytes result sent to driver
[2025-07-19T20:31:01.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190] for update
[2025-07-19T20:31:01.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 400) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 193.0 in stage 1.0 (TID 400)
[2025-07-19T20:31:01.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 392) in 111 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:31:01.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@626b1962
[2025-07-19T20:31:01.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191] for update
[2025-07-19T20:31:01.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.1.delta.521fbf2f-0224-4efd-a163-f094a032a7df.TID393.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta
[2025-07-19T20:31:01.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta
[2025-07-19T20:31:01.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.1.delta.01b6ba11-220e-4928-a1f9-93f9e942f9a2.TID398.tmp
[2025-07-19T20:31:01.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 393, attempt 0, stage 1.0)
[2025-07-19T20:31:01.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69fa5708
[2025-07-19T20:31:01.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193] for update
[2025-07-19T20:31:01.864+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.865+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 164 (task 393, attempt 0, stage 1.0)
[2025-07-19T20:31:01.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 164.0 in stage 1.0 (TID 393). 6243 bytes result sent to driver
[2025-07-19T20:31:01.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 401) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 195.0 in stage 1.0 (TID 401)
[2025-07-19T20:31:01.870+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.1.delta.73bd9785-ec30-4a08-a16f-d3543f9bda4b.TID395.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta
[2025-07-19T20:31:01.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta
[2025-07-19T20:31:01.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 393) in 117 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:31:01.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 395, attempt 0, stage 1.0)
[2025-07-19T20:31:01.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.1.delta.8fa7463a-9343-4712-9e3a-09673b8f95db.TID399.tmp
[2025-07-19T20:31:01.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.1.delta.298faa1c-62b6-4ae2-ac2a-f950dbba16ec.TID397.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta
[2025-07-19T20:31:01.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta
[2025-07-19T20:31:01.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 397, attempt 0, stage 1.0)
[2025-07-19T20:31:01.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.1.delta.85c5a367-b68d-46fa-a901-42aa62abc3e1.TID400.tmp
[2025-07-19T20:31:01.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dfe524a
[2025-07-19T20:31:01.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 176 (task 395, attempt 0, stage 1.0)
[2025-07-19T20:31:01.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 176.0 in stage 1.0 (TID 395). 6200 bytes result sent to driver
[2025-07-19T20:31:01.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195] for update
[2025-07-19T20:31:01.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.1.delta.e3cae7b0-b675-4a8f-b86f-00defe485095.TID394.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta
[2025-07-19T20:31:01.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta
[2025-07-19T20:31:01.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 186 (task 397, attempt 0, stage 1.0)
[2025-07-19T20:31:01.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 402) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 394, attempt 0, stage 1.0)
[2025-07-19T20:31:01.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 395) in 110 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:31:01.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.1.delta.58d746bd-89c8-45c5-910e-31814c37b68a.TID396.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta
[2025-07-19T20:31:01.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta
[2025-07-19T20:31:01.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 186.0 in stage 1.0 (TID 397). 6200 bytes result sent to driver
[2025-07-19T20:31:01.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 198.0 in stage 1.0 (TID 402)
[2025-07-19T20:31:01.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 403) (8b44f3d35cfa, executor driver, partition 1, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 396, attempt 0, stage 1.0)
[2025-07-19T20:31:01.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 1.0 in stage 5.0 (TID 403)
[2025-07-19T20:31:01.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 397) in 88 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:31:01.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 166 (task 394, attempt 0, stage 1.0)
[2025-07-19T20:31:01.901+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 166.0 in stage 1.0 (TID 394). 6200 bytes result sent to driver
[2025-07-19T20:31:01.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.904+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.905+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 404) (8b44f3d35cfa, executor driver, partition 3, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 394) in 119 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 3.0 in stage 5.0 (TID 404)
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 177 (task 396, attempt 0, stage 1.0)
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1280f3dc
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:01.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198] for update
[2025-07-19T20:31:01.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 177.0 in stage 1.0 (TID 396). 6200 bytes result sent to driver
[2025-07-19T20:31:01.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 405) (8b44f3d35cfa, executor driver, partition 4, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 396) in 105 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:31:01.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 4.0 in stage 5.0 (TID 405)
[2025-07-19T20:31:01.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.1.delta.46cb3b79-099d-4ad9-9b92-13c94801b486.TID401.tmp
[2025-07-19T20:31:01.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (368.0 B) non-empty blocks including 1 (368.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.911+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:01.911+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.1.delta.53c02897-af76-41d8-a58f-efee83387367.TID402.tmp
[2025-07-19T20:31:01.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.1.delta.01b6ba11-220e-4928-a1f9-93f9e942f9a2.TID398.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta
[2025-07-19T20:31:01.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta
[2025-07-19T20:31:01.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 398, attempt 0, stage 1.0)
[2025-07-19T20:31:01.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.1.delta.8fa7463a-9343-4712-9e3a-09673b8f95db.TID399.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta
[2025-07-19T20:31:01.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta
[2025-07-19T20:31:01.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 399, attempt 0, stage 1.0)
[2025-07-19T20:31:01.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f54f1aa
[2025-07-19T20:31:01.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3] for update
[2025-07-19T20:31:01.927+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.1.delta.85c5a367-b68d-46fa-a901-42aa62abc3e1.TID400.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta
[2025-07-19T20:31:01.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta
[2025-07-19T20:31:01.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38c9971c
[2025-07-19T20:31:01.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 400, attempt 0, stage 1.0)
[2025-07-19T20:31:01.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1] for update
[2025-07-19T20:31:01.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 191 (task 399, attempt 0, stage 1.0)
[2025-07-19T20:31:01.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 190 (task 398, attempt 0, stage 1.0)
[2025-07-19T20:31:01.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 190.0 in stage 1.0 (TID 398). 6200 bytes result sent to driver
[2025-07-19T20:31:01.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 191.0 in stage 1.0 (TID 399). 6243 bytes result sent to driver
[2025-07-19T20:31:01.932+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 406) (8b44f3d35cfa, executor driver, partition 5, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.932+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 5.0 in stage 5.0 (TID 406)
[2025-07-19T20:31:01.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 407) (8b44f3d35cfa, executor driver, partition 6, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 6.0 in stage 5.0 (TID 407)
[2025-07-19T20:31:01.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 399) in 93 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:31:01.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 398) in 101 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:31:01.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 193 (task 400, attempt 0, stage 1.0)
[2025-07-19T20:31:01.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 193.0 in stage 1.0 (TID 400). 6200 bytes result sent to driver
[2025-07-19T20:31:01.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d85ae55
[2025-07-19T20:31:01.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:01.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 408) (8b44f3d35cfa, executor driver, partition 7, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4] for update
[2025-07-19T20:31:01.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 400) in 95 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:31:01.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 7.0 in stage 5.0 (TID 408)
[2025-07-19T20:31:01.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.1.delta.46cb3b79-099d-4ad9-9b92-13c94801b486.TID401.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta
[2025-07-19T20:31:01.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta
[2025-07-19T20:31:01.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 401, attempt 0, stage 1.0)
[2025-07-19T20:31:01.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.1.delta.53c02897-af76-41d8-a58f-efee83387367.TID402.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta
[2025-07-19T20:31:01.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta
[2025-07-19T20:31:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43830dae
[2025-07-19T20:31:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5] for update
[2025-07-19T20:31:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:01.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 402, attempt 0, stage 1.0)
[2025-07-19T20:31:01.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 195 (task 401, attempt 0, stage 1.0)
[2025-07-19T20:31:01.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 195.0 in stage 1.0 (TID 401). 6200 bytes result sent to driver
[2025-07-19T20:31:01.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 409) (8b44f3d35cfa, executor driver, partition 9, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4acf6332
[2025-07-19T20:31:01.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 9.0 in stage 5.0 (TID 409)
[2025-07-19T20:31:01.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7] for update
[2025-07-19T20:31:01.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 401) in 88 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:31:01.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DataWritingSparkTask: Committed partition 198 (task 402, attempt 0, stage 1.0)
[2025-07-19T20:31:01.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Finished task 198.0 in stage 1.0 (TID 402). 6200 bytes result sent to driver
[2025-07-19T20:31:01.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 410) (8b44f3d35cfa, executor driver, partition 11, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:01.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 402) in 79 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:31:01.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-07-19T20:31:01.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@697c5ab1
[2025-07-19T20:31:01.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 8.914 s
[2025-07-19T20:31:01.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:31:01.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6] for update
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO Executor: Running task 11.0 in stage 5.0 (TID 410)
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 10.768206 s
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.1.delta.d627c817-810a-4e2b-91eb-da5e235683a6.TID405.tmp
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T20:31:01.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO SparkWrite: Committing epoch 0 for query 60d03bb1-c474-4483-93df-474e93ff0d37 in append mode
[2025-07-19T20:31:01.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:01.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:01.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.1.delta.8eaccf01-1dd0-4c9a-9b66-b0f9ae6f6e24.TID404.tmp
[2025-07-19T20:31:01.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.1.delta.42bd1c39-3a5c-4655-a37e-74ed63773387.TID406.tmp
[2025-07-19T20:31:01.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.1.delta.8de66ee0-ea00-4784-bb2f-dc90f84b7f68.TID403.tmp
[2025-07-19T20:31:01.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.1.delta.0f35b837-6750-4c86-8b64-1316b0b45a36.TID408.tmp
[2025-07-19T20:31:01.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@672d5e2f
[2025-07-19T20:31:01.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9] for update
[2025-07-19T20:31:01.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:01.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.1.delta.df1b6638-c48f-4521-a6f3-301c38046000.TID407.tmp
[2025-07-19T20:31:01.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c4eb129
[2025-07-19T20:31:01.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.1.delta.2862ae4b-48d7-49a3-988e-426de40e398b.TID409.tmp
[2025-07-19T20:31:01.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:01.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11] for update
[2025-07-19T20:31:01.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:01 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Committing streaming append with 138 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.010+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.1.delta.98e3ef21-9ce3-4e8a-9726-8334e6ac1f0d.TID410.tmp
[2025-07-19T20:31:02.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.1.delta.d627c817-810a-4e2b-91eb-da5e235683a6.TID405.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta
[2025-07-19T20:31:02.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/4/1.delta
[2025-07-19T20:31:02.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.1.delta.0f35b837-6750-4c86-8b64-1316b0b45a36.TID408.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta
[2025-07-19T20:31:02.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/7/1.delta
[2025-07-19T20:31:02.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 405, attempt 0, stage 5.0)
[2025-07-19T20:31:02.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 408, attempt 0, stage 5.0)
[2025-07-19T20:31:02.039+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.1.delta.8eaccf01-1dd0-4c9a-9b66-b0f9ae6f6e24.TID404.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta
[2025-07-19T20:31:02.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/3/1.delta
[2025-07-19T20:31:02.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 404, attempt 0, stage 5.0)
[2025-07-19T20:31:02.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.1.delta.df1b6638-c48f-4521-a6f3-301c38046000.TID407.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta
[2025-07-19T20:31:02.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/6/1.delta
[2025-07-19T20:31:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.1.delta.8de66ee0-ea00-4784-bb2f-dc90f84b7f68.TID403.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta
[2025-07-19T20:31:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/1/1.delta
[2025-07-19T20:31:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 403, attempt 0, stage 5.0)
[2025-07-19T20:31:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 407, attempt 0, stage 5.0)
[2025-07-19T20:31:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.1.delta.42bd1c39-3a5c-4655-a37e-74ed63773387.TID406.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta
[2025-07-19T20:31:02.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/5/1.delta
[2025-07-19T20:31:02.046+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 406, attempt 0, stage 5.0)
[2025-07-19T20:31:02.052+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.1.delta.2862ae4b-48d7-49a3-988e-426de40e398b.TID409.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta
[2025-07-19T20:31:02.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/9/1.delta
[2025-07-19T20:31:02.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 409, attempt 0, stage 5.0)
[2025-07-19T20:31:02.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.1.delta.98e3ef21-9ce3-4e8a-9726-8334e6ac1f0d.TID410.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta
[2025-07-19T20:31:02.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/11/1.delta
[2025-07-19T20:31:02.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 410, attempt 0, stage 5.0)
[2025-07-19T20:31:02.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 4 (task 405, attempt 0, stage 5.0)
[2025-07-19T20:31:02.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 7 (task 408, attempt 0, stage 5.0)
[2025-07-19T20:31:02.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 5 (task 406, attempt 0, stage 5.0)
[2025-07-19T20:31:02.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 5.0 in stage 5.0 (TID 406). 9033 bytes result sent to driver
[2025-07-19T20:31:02.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 4.0 in stage 5.0 (TID 405). 9044 bytes result sent to driver
[2025-07-19T20:31:02.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 7.0 in stage 5.0 (TID 408). 9034 bytes result sent to driver
[2025-07-19T20:31:02.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 411) (8b44f3d35cfa, executor driver, partition 12, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 412) (8b44f3d35cfa, executor driver, partition 14, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 16.0 in stage 5.0 (TID 413) (8b44f3d35cfa, executor driver, partition 16, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 406) in 142 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:31:02.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 408) in 133 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:31:02.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 12.0 in stage 5.0 (TID 411)
[2025-07-19T20:31:02.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 405) in 171 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:31:02.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 16.0 in stage 5.0 (TID 413)
[2025-07-19T20:31:02.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 3 (task 404, attempt 0, stage 5.0)
[2025-07-19T20:31:02.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 3.0 in stage 5.0 (TID 404). 9035 bytes result sent to driver
[2025-07-19T20:31:02.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 14.0 in stage 5.0 (TID 412)
[2025-07-19T20:31:02.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5585cf17
[2025-07-19T20:31:02.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12] for update
[2025-07-19T20:31:02.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 6 (task 407, attempt 0, stage 5.0)
[2025-07-19T20:31:02.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 6.0 in stage 5.0 (TID 407). 9035 bytes result sent to driver
[2025-07-19T20:31:02.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 404) in 198 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:31:02.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 11 (task 410, attempt 0, stage 5.0)
[2025-07-19T20:31:02.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 18.0 in stage 5.0 (TID 414) (8b44f3d35cfa, executor driver, partition 18, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a8d940
[2025-07-19T20:31:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 19.0 in stage 5.0 (TID 415) (8b44f3d35cfa, executor driver, partition 19, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 18.0 in stage 5.0 (TID 414)
[2025-07-19T20:31:02.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14] for update
[2025-07-19T20:31:02.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 407) in 164 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:31:02.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 1 (task 403, attempt 0, stage 5.0)
[2025-07-19T20:31:02.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 19.0 in stage 5.0 (TID 415)
[2025-07-19T20:31:02.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 1.0 in stage 5.0 (TID 403). 9074 bytes result sent to driver
[2025-07-19T20:31:02.112+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 20.0 in stage 5.0 (TID 416) (8b44f3d35cfa, executor driver, partition 20, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 20.0 in stage 5.0 (TID 416)
[2025-07-19T20:31:02.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.1.delta.5395e35a-f024-4bab-a810-5dd489609e89.TID411.tmp
[2025-07-19T20:31:02.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 403) in 223 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:31:02.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 11.0 in stage 5.0 (TID 410). 9018 bytes result sent to driver
[2025-07-19T20:31:02.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 21.0 in stage 5.0 (TID 417) (8b44f3d35cfa, executor driver, partition 21, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53453571
[2025-07-19T20:31:02.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16] for update
[2025-07-19T20:31:02.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 410) in 150 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:31:02.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 21.0 in stage 5.0 (TID 417)
[2025-07-19T20:31:02.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:02.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:02.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.1.delta.c0654d22-4f84-4f1f-9203-ba9c48f9a62a.TID412.tmp
[2025-07-19T20:31:02.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1dc653b6
[2025-07-19T20:31:02.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19] for update
[2025-07-19T20:31:02.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 9 (task 409, attempt 0, stage 5.0)
[2025-07-19T20:31:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a39217
[2025-07-19T20:31:02.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20] for update
[2025-07-19T20:31:02.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.1.delta.785e42b1-f327-4b27-99c1-ea48393b3fab.TID413.tmp
[2025-07-19T20:31:02.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 9.0 in stage 5.0 (TID 409). 9086 bytes result sent to driver
[2025-07-19T20:31:02.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 409) in 181 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:31:02.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 22.0 in stage 5.0 (TID 418) (8b44f3d35cfa, executor driver, partition 22, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 22.0 in stage 5.0 (TID 418)
[2025-07-19T20:31:02.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.1.delta.f846d098-9544-4f07-bf8e-728e37126cb1.TID415.tmp
[2025-07-19T20:31:02.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4afc31e4
[2025-07-19T20:31:02.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21] for update
[2025-07-19T20:31:02.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.1.delta.d707c1d0-0003-47ec-b53b-3648efdc1d88.TID416.tmp
[2025-07-19T20:31:02.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62dae72
[2025-07-19T20:31:02.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18] for update
[2025-07-19T20:31:02.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.1.delta.5395e35a-f024-4bab-a810-5dd489609e89.TID411.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta
[2025-07-19T20:31:02.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/12/1.delta
[2025-07-19T20:31:02.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a4f06b7
[2025-07-19T20:31:02.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 411, attempt 0, stage 5.0)
[2025-07-19T20:31:02.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22] for update
[2025-07-19T20:31:02.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.1.delta.35decfba-9a0b-42a8-a02f-33f95c553939.TID417.tmp
[2025-07-19T20:31:02.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.1.delta.c0654d22-4f84-4f1f-9203-ba9c48f9a62a.TID412.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta
[2025-07-19T20:31:02.181+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/14/1.delta
[2025-07-19T20:31:02.182+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 412, attempt 0, stage 5.0)
[2025-07-19T20:31:02.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.1.delta.20c6ec32-c70e-403b-a4ad-1958ddcbaf25.TID414.tmp
[2025-07-19T20:31:02.189+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.1.delta.785e42b1-f327-4b27-99c1-ea48393b3fab.TID413.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta
[2025-07-19T20:31:02.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/16/1.delta
[2025-07-19T20:31:02.191+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 413, attempt 0, stage 5.0)
[2025-07-19T20:31:02.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.1.delta.aa15fc81-b862-49f6-9f87-acb0edeee1a0.TID418.tmp
[2025-07-19T20:31:02.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 12 (task 411, attempt 0, stage 5.0)
[2025-07-19T20:31:02.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 14 (task 412, attempt 0, stage 5.0)
[2025-07-19T20:31:02.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 14.0 in stage 5.0 (TID 412). 9055 bytes result sent to driver
[2025-07-19T20:31:02.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 12.0 in stage 5.0 (TID 411). 9056 bytes result sent to driver
[2025-07-19T20:31:02.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 23.0 in stage 5.0 (TID 419) (8b44f3d35cfa, executor driver, partition 23, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 23.0 in stage 5.0 (TID 419)
[2025-07-19T20:31:02.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 412) in 123 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:31:02.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 24.0 in stage 5.0 (TID 420) (8b44f3d35cfa, executor driver, partition 24, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 24.0 in stage 5.0 (TID 420)
[2025-07-19T20:31:02.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 411) in 127 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:31:02.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.1.delta.f846d098-9544-4f07-bf8e-728e37126cb1.TID415.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta
[2025-07-19T20:31:02.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/19/1.delta
[2025-07-19T20:31:02.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 415, attempt 0, stage 5.0)
[2025-07-19T20:31:02.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 16 (task 413, attempt 0, stage 5.0)
[2025-07-19T20:31:02.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 16.0 in stage 5.0 (TID 413). 9037 bytes result sent to driver
[2025-07-19T20:31:02.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 25.0 in stage 5.0 (TID 421) (8b44f3d35cfa, executor driver, partition 25, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 16.0 in stage 5.0 (TID 413) in 141 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:31:02.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 25.0 in stage 5.0 (TID 421)
[2025-07-19T20:31:02.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ee67b41
[2025-07-19T20:31:02.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.1.delta.d707c1d0-0003-47ec-b53b-3648efdc1d88.TID416.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta
[2025-07-19T20:31:02.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/20/1.delta
[2025-07-19T20:31:02.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23] for update
[2025-07-19T20:31:02.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 416, attempt 0, stage 5.0)
[2025-07-19T20:31:02.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e29d970
[2025-07-19T20:31:02.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.226+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24] for update
[2025-07-19T20:31:02.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 19 (task 415, attempt 0, stage 5.0)
[2025-07-19T20:31:02.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 19.0 in stage 5.0 (TID 415). 9033 bytes result sent to driver
[2025-07-19T20:31:02.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 26.0 in stage 5.0 (TID 422) (8b44f3d35cfa, executor driver, partition 26, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 19.0 in stage 5.0 (TID 415) in 134 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:31:02.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.1.delta.35decfba-9a0b-42a8-a02f-33f95c553939.TID417.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta
[2025-07-19T20:31:02.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/21/1.delta
[2025-07-19T20:31:02.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 26.0 in stage 5.0 (TID 422)
[2025-07-19T20:31:02.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59c006d7
[2025-07-19T20:31:02.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25] for update
[2025-07-19T20:31:02.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 417, attempt 0, stage 5.0)
[2025-07-19T20:31:02.232+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.234+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.1.delta.20c6ec32-c70e-403b-a4ad-1958ddcbaf25.TID414.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta
[2025-07-19T20:31:02.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/18/1.delta
[2025-07-19T20:31:02.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fcc0620
[2025-07-19T20:31:02.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v110.metadata.json
[2025-07-19T20:31:02.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26] for update
[2025-07-19T20:31:02.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 20 (task 416, attempt 0, stage 5.0)
[2025-07-19T20:31:02.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.1.delta.1510ba1e-7bd8-45dc-a848-bec11f6248f1.TID421.tmp
[2025-07-19T20:31:02.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 20.0 in stage 5.0 (TID 416). 9044 bytes result sent to driver
[2025-07-19T20:31:02.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.1.delta.1ffdba09-2477-4b3c-9f17-d03f5e73f866.TID419.tmp
[2025-07-19T20:31:02.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 414, attempt 0, stage 5.0)
[2025-07-19T20:31:02.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 29.0 in stage 5.0 (TID 423) (8b44f3d35cfa, executor driver, partition 29, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 29.0 in stage 5.0 (TID 423)
[2025-07-19T20:31:02.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 20.0 in stage 5.0 (TID 416) in 137 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:31:02.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.1.delta.60cb0039-bfe6-4089-8579-c60b81a72038.TID420.tmp
[2025-07-19T20:31:02.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 21 (task 417, attempt 0, stage 5.0)
[2025-07-19T20:31:02.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c633591
[2025-07-19T20:31:02.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.1.delta.44b88a79-c4a6-4d4d-9ff3-6f62d4e4a9e5.TID422.tmp
[2025-07-19T20:31:02.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.1.delta.aa15fc81-b862-49f6-9f87-acb0edeee1a0.TID418.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta
[2025-07-19T20:31:02.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/22/1.delta
[2025-07-19T20:31:02.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 418, attempt 0, stage 5.0)
[2025-07-19T20:31:02.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 21.0 in stage 5.0 (TID 417). 9083 bytes result sent to driver
[2025-07-19T20:31:02.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29] for update
[2025-07-19T20:31:02.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 30.0 in stage 5.0 (TID 424) (8b44f3d35cfa, executor driver, partition 30, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 30.0 in stage 5.0 (TID 424)
[2025-07-19T20:31:02.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 21.0 in stage 5.0 (TID 417) in 147 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:31:02.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 18 (task 414, attempt 0, stage 5.0)
[2025-07-19T20:31:02.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 18.0 in stage 5.0 (TID 414). 9033 bytes result sent to driver
[2025-07-19T20:31:02.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 32.0 in stage 5.0 (TID 425) (8b44f3d35cfa, executor driver, partition 32, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 18.0 in stage 5.0 (TID 414) in 177 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:31:02.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 32.0 in stage 5.0 (TID 425)
[2025-07-19T20:31:02.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f002d1c
[2025-07-19T20:31:02.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30] for update
[2025-07-19T20:31:02.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:02.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 22 (task 418, attempt 0, stage 5.0)
[2025-07-19T20:31:02.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 22.0 in stage 5.0 (TID 418). 9043 bytes result sent to driver
[2025-07-19T20:31:02.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 35.0 in stage 5.0 (TID 426) (8b44f3d35cfa, executor driver, partition 35, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 35.0 in stage 5.0 (TID 426)
[2025-07-19T20:31:02.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 22.0 in stage 5.0 (TID 418) in 149 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:31:02.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.1.delta.9e35f983-3dfe-4fb2-a141-b1e015d0325e.TID423.tmp
[2025-07-19T20:31:02.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34ded277
[2025-07-19T20:31:02.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32] for update
[2025-07-19T20:31:02.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.1.delta.ecdde706-17c3-40a0-a157-f368d1f530fb.TID424.tmp
[2025-07-19T20:31:02.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3db459a4
[2025-07-19T20:31:02.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35] for update
[2025-07-19T20:31:02.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.1.delta.1ffdba09-2477-4b3c-9f17-d03f5e73f866.TID419.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta
[2025-07-19T20:31:02.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/23/1.delta
[2025-07-19T20:31:02.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 419, attempt 0, stage 5.0)
[2025-07-19T20:31:02.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.1.delta.1510ba1e-7bd8-45dc-a848-bec11f6248f1.TID421.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta
[2025-07-19T20:31:02.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/25/1.delta
[2025-07-19T20:31:02.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 421, attempt 0, stage 5.0)
[2025-07-19T20:31:02.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SnapshotProducer: Committed snapshot 7901210845885969229 (FastAppend)
[2025-07-19T20:31:02.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.1.delta.60cb0039-bfe6-4089-8579-c60b81a72038.TID420.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta
[2025-07-19T20:31:02.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/24/1.delta
[2025-07-19T20:31:02.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 420, attempt 0, stage 5.0)
[2025-07-19T20:31:02.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.1.delta.14923eef-f734-427b-b413-e6de6c954a19.TID425.tmp
[2025-07-19T20:31:02.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.1.delta.44b88a79-c4a6-4d4d-9ff3-6f62d4e4a9e5.TID422.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta
[2025-07-19T20:31:02.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/26/1.delta
[2025-07-19T20:31:02.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 422, attempt 0, stage 5.0)
[2025-07-19T20:31:02.310+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.1.delta.056a7294-ca80-4319-bddd-45e1a10fb625.TID426.tmp
[2025-07-19T20:31:02.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 23 (task 419, attempt 0, stage 5.0)
[2025-07-19T20:31:02.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 23.0 in stage 5.0 (TID 419). 9039 bytes result sent to driver
[2025-07-19T20:31:02.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 37.0 in stage 5.0 (TID 427) (8b44f3d35cfa, executor driver, partition 37, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 23.0 in stage 5.0 (TID 419) in 121 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:31:02.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 37.0 in stage 5.0 (TID 427)
[2025-07-19T20:31:02.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 24 (task 420, attempt 0, stage 5.0)
[2025-07-19T20:31:02.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:02.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 25 (task 421, attempt 0, stage 5.0)
[2025-07-19T20:31:02.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 25.0 in stage 5.0 (TID 421). 9037 bytes result sent to driver
[2025-07-19T20:31:02.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 24.0 in stage 5.0 (TID 420). 9041 bytes result sent to driver
[2025-07-19T20:31:02.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 38.0 in stage 5.0 (TID 428) (8b44f3d35cfa, executor driver, partition 38, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 39.0 in stage 5.0 (TID 429) (8b44f3d35cfa, executor driver, partition 39, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 39.0 in stage 5.0 (TID 429)
[2025-07-19T20:31:02.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 38.0 in stage 5.0 (TID 428)
[2025-07-19T20:31:02.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 24.0 in stage 5.0 (TID 420) in 127 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:31:02.329+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 25.0 in stage 5.0 (TID 421) in 116 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:31:02.329+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 26 (task 422, attempt 0, stage 5.0)
[2025-07-19T20:31:02.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 26.0 in stage 5.0 (TID 422). 9030 bytes result sent to driver
[2025-07-19T20:31:02.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 41.0 in stage 5.0 (TID 430) (8b44f3d35cfa, executor driver, partition 41, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 41.0 in stage 5.0 (TID 430)
[2025-07-19T20:31:02.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 26.0 in stage 5.0 (TID 422) in 103 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:31:02.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4915012e
[2025-07-19T20:31:02.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37] for update
[2025-07-19T20:31:02.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.1.delta.9e35f983-3dfe-4fb2-a141-b1e015d0325e.TID423.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta
[2025-07-19T20:31:02.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/29/1.delta
[2025-07-19T20:31:02.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 423, attempt 0, stage 5.0)
[2025-07-19T20:31:02.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51be41ae
[2025-07-19T20:31:02.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.1.delta.ecdde706-17c3-40a0-a157-f368d1f530fb.TID424.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta
[2025-07-19T20:31:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41] for update
[2025-07-19T20:31:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.1.delta.1f8f44c8-1eab-4e65-9e3d-fda1841f94c8.TID427.tmp
[2025-07-19T20:31:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/30/1.delta
[2025-07-19T20:31:02.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 424, attempt 0, stage 5.0)
[2025-07-19T20:31:02.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@397a4e81
[2025-07-19T20:31:02.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38] for update
[2025-07-19T20:31:02.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.1.delta.c8e1efd2-e6a7-414b-90c8-a6f4e96fd938.TID430.tmp
[2025-07-19T20:31:02.353+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.1.delta.14923eef-f734-427b-b413-e6de6c954a19.TID425.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta
[2025-07-19T20:31:02.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/32/1.delta
[2025-07-19T20:31:02.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 425, attempt 0, stage 5.0)
[2025-07-19T20:31:02.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.1.delta.056a7294-ca80-4319-bddd-45e1a10fb625.TID426.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta
[2025-07-19T20:31:02.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=7901210845885969229, sequenceNumber=109, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.3535785S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=138}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5124}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=207}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=6930}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=399080}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=14751161}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752957046551, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:31:02.363+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/35/1.delta
[2025-07-19T20:31:02.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Committed in 355 ms
[2025-07-19T20:31:02.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T20:31:02.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 426, attempt 0, stage 5.0)
[2025-07-19T20:31:02.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b106a62
[2025-07-19T20:31:02.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39] for update
[2025-07-19T20:31:02.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO WatermarkTracker: Updating event-time watermark from 0 to 1752784240000 ms
[2025-07-19T20:31:02.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 29 (task 423, attempt 0, stage 5.0)
[2025-07-19T20:31:02.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 29.0 in stage 5.0 (TID 423). 9068 bytes result sent to driver
[2025-07-19T20:31:02.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.1.delta.eb1b0cae-0340-4620-8f47-ecf41e922fd5.TID428.tmp
[2025-07-19T20:31:02.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 30 (task 424, attempt 0, stage 5.0)
[2025-07-19T20:31:02.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 43.0 in stage 5.0 (TID 431) (8b44f3d35cfa, executor driver, partition 43, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 43.0 in stage 5.0 (TID 431)
[2025-07-19T20:31:02.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 29.0 in stage 5.0 (TID 423) in 137 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:31:02.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/0 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/.0.faec6d06-f204-4e13-8eb2-9d14f55f31cc.tmp
[2025-07-19T20:31:02.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 32 (task 425, attempt 0, stage 5.0)
[2025-07-19T20:31:02.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 30.0 in stage 5.0 (TID 424). 9121 bytes result sent to driver
[2025-07-19T20:31:02.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 32.0 in stage 5.0 (TID 425). 9123 bytes result sent to driver
[2025-07-19T20:31:02.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 45.0 in stage 5.0 (TID 432) (8b44f3d35cfa, executor driver, partition 45, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.1.delta.5d46821c-5f79-47fe-80f3-13c6d0b9581f.TID429.tmp
[2025-07-19T20:31:02.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 30.0 in stage 5.0 (TID 424) in 133 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:31:02.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 46.0 in stage 5.0 (TID 433) (8b44f3d35cfa, executor driver, partition 46, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:02.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 45.0 in stage 5.0 (TID 432)
[2025-07-19T20:31:02.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.1.delta.1f8f44c8-1eab-4e65-9e3d-fda1841f94c8.TID427.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta
[2025-07-19T20:31:02.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/37/1.delta
[2025-07-19T20:31:02.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 427, attempt 0, stage 5.0)
[2025-07-19T20:31:02.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 32.0 in stage 5.0 (TID 425) in 126 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:31:02.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 46.0 in stage 5.0 (TID 433)
[2025-07-19T20:31:02.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c0a20d
[2025-07-19T20:31:02.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 35 (task 426, attempt 0, stage 5.0)
[2025-07-19T20:31:02.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 35.0 in stage 5.0 (TID 426). 9089 bytes result sent to driver
[2025-07-19T20:31:02.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43] for update
[2025-07-19T20:31:02.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 47.0 in stage 5.0 (TID 434) (8b44f3d35cfa, executor driver, partition 47, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.414+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 47.0 in stage 5.0 (TID 434)
[2025-07-19T20:31:02.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 35.0 in stage 5.0 (TID 426) in 121 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:31:02.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@296a73d
[2025-07-19T20:31:02.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46] for update
[2025-07-19T20:31:02.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 37 (task 427, attempt 0, stage 5.0)
[2025-07-19T20:31:02.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 37.0 in stage 5.0 (TID 427). 9086 bytes result sent to driver
[2025-07-19T20:31:02.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 48.0 in stage 5.0 (TID 435) (8b44f3d35cfa, executor driver, partition 48, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 48.0 in stage 5.0 (TID 435)
[2025-07-19T20:31:02.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@751e51a0
[2025-07-19T20:31:02.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45] for update
[2025-07-19T20:31:02.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 37.0 in stage 5.0 (TID 427) in 109 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:31:02.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.1.delta.c8e1efd2-e6a7-414b-90c8-a6f4e96fd938.TID430.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta
[2025-07-19T20:31:02.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/41/1.delta
[2025-07-19T20:31:02.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.1.delta.18e883df-d021-4c9e-84c7-69c6a1dd4ae8.TID431.tmp
[2025-07-19T20:31:02.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 430, attempt 0, stage 5.0)
[2025-07-19T20:31:02.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41797f04
[2025-07-19T20:31:02.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.1.delta.60b8d71a-2582-48d1-9072-3015ed2adbe2.TID433.tmp
[2025-07-19T20:31:02.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48] for update
[2025-07-19T20:31:02.438+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.1.delta.eb1b0cae-0340-4620-8f47-ecf41e922fd5.TID428.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta
[2025-07-19T20:31:02.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/38/1.delta
[2025-07-19T20:31:02.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 428, attempt 0, stage 5.0)
[2025-07-19T20:31:02.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 41 (task 430, attempt 0, stage 5.0)
[2025-07-19T20:31:02.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 41.0 in stage 5.0 (TID 430). 9076 bytes result sent to driver
[2025-07-19T20:31:02.451+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 51.0 in stage 5.0 (TID 436) (8b44f3d35cfa, executor driver, partition 51, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.1.delta.e8062658-4c74-426a-89da-bb188f9e2c22.TID432.tmp
[2025-07-19T20:31:02.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19bc68bc
[2025-07-19T20:31:02.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 51.0 in stage 5.0 (TID 436)
[2025-07-19T20:31:02.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 41.0 in stage 5.0 (TID 430) in 119 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:31:02.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47] for update
[2025-07-19T20:31:02.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.1.delta.0a6a5a22-d465-47fe-9443-c8338aa1c471.TID435.tmp
[2025-07-19T20:31:02.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.1.delta.5d46821c-5f79-47fe-80f3-13c6d0b9581f.TID429.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta
[2025-07-19T20:31:02.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/39/1.delta
[2025-07-19T20:31:02.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 429, attempt 0, stage 5.0)
[2025-07-19T20:31:02.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20a62ad
[2025-07-19T20:31:02.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/.0.faec6d06-f204-4e13-8eb2-9d14f55f31cc.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/0
[2025-07-19T20:31:02.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51] for update
[2025-07-19T20:31:02.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 38 (task 428, attempt 0, stage 5.0)
[2025-07-19T20:31:02.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 38.0 in stage 5.0 (TID 428). 9074 bytes result sent to driver
[2025-07-19T20:31:02.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:31:02.468+0000] {subprocess.py:93} INFO -   "id" : "60d03bb1-c474-4483-93df-474e93ff0d37",
[2025-07-19T20:31:02.468+0000] {subprocess.py:93} INFO -   "runId" : "949692c4-67e9-4193-b7c5-0e7f8bd5bdfd",
[2025-07-19T20:31:02.468+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:31:02.469+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:30:49.463Z",
[2025-07-19T20:31:02.469+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T20:31:02.469+0000] {subprocess.py:93} INFO -   "numInputRows" : 207,
[2025-07-19T20:31:02.469+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:02.469+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 15.925527004154485,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "addBatch" : 12033,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "commitOffsets" : 99,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "getBatch" : 10,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "latestOffset" : 223,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "queryPlanning" : 564,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "triggerExecution" : 12998,
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -     "walCommit" : 55
[2025-07-19T20:31:02.470+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:02.471+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:31:02.471+0000] {subprocess.py:93} INFO -     "avg" : "2025-07-19T19:02:48.594Z",
[2025-07-19T20:31:02.471+0000] {subprocess.py:93} INFO -     "max" : "2025-07-19T20:30:40.000Z",
[2025-07-19T20:31:02.471+0000] {subprocess.py:93} INFO -     "min" : "2025-07-19T18:00:01.000Z",
[2025-07-19T20:31:02.471+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T20:31:02.472+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:02.473+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:31:02.475+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:31:02.476+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 207,
[2025-07-19T20:31:02.476+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 207,
[2025-07-19T20:31:02.478+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 2640,
[2025-07-19T20:31:02.479+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:31:02.480+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 141,
[2025-07-19T20:31:02.480+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 12588,
[2025-07-19T20:31:02.481+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 97128,
[2025-07-19T20:31:02.481+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:31:02.482+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:31:02.483+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:31:02.484+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:31:02.484+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T20:31:02.485+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:31:02.485+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:31:02.485+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 68328
[2025-07-19T20:31:02.486+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:02.486+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:02.486+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:31:02.487+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T20:31:02.487+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T20:31:02.487+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:31:02.487+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:31:02.488+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:02.488+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:02.488+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:02.491+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:31:02.491+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:31:02.491+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:02.491+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:02.491+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:02.492+0000] {subprocess.py:93} INFO -     "numInputRows" : 207,
[2025-07-19T20:31:02.493+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:02.494+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 15.925527004154485,
[2025-07-19T20:31:02.495+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:31:02.497+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:31:02.497+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:31:02.498+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:31:02.498+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:02.498+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:02.499+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:31:02.499+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T20:31:02.500+0000] {subprocess.py:93} INFO -     "numOutputRows" : 207
[2025-07-19T20:31:02.500+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:31:02.501+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:31:02.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 52.0 in stage 5.0 (TID 437) (8b44f3d35cfa, executor driver, partition 52, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.1.delta.71812f58-2da5-45d2-81fb-fbb4eabd447b.TID434.tmp
[2025-07-19T20:31:02.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 52.0 in stage 5.0 (TID 437)
[2025-07-19T20:31:02.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 38.0 in stage 5.0 (TID 428) in 151 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:31:02.505+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.507+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 39 (task 429, attempt 0, stage 5.0)
[2025-07-19T20:31:02.508+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 39.0 in stage 5.0 (TID 429). 9068 bytes result sent to driver
[2025-07-19T20:31:02.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.1.delta.d9716d08-d439-4876-b96c-fc7ee0684fa3.TID436.tmp
[2025-07-19T20:31:02.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a8e3b3f
[2025-07-19T20:31:02.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 53.0 in stage 5.0 (TID 438) (8b44f3d35cfa, executor driver, partition 53, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.511+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.511+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52] for update
[2025-07-19T20:31:02.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 53.0 in stage 5.0 (TID 438)
[2025-07-19T20:31:02.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 39.0 in stage 5.0 (TID 429) in 159 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:31:02.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.1.delta.18e883df-d021-4c9e-84c7-69c6a1dd4ae8.TID431.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta
[2025-07-19T20:31:02.515+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/43/1.delta
[2025-07-19T20:31:02.515+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.1.delta.60b8d71a-2582-48d1-9072-3015ed2adbe2.TID433.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta
[2025-07-19T20:31:02.516+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/46/1.delta
[2025-07-19T20:31:02.517+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 433, attempt 0, stage 5.0)
[2025-07-19T20:31:02.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 431, attempt 0, stage 5.0)
[2025-07-19T20:31:02.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@772636d2
[2025-07-19T20:31:02.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53] for update
[2025-07-19T20:31:02.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/.1.bd8c9f8b-9645-4e61-b7f7-df015b290d3b.tmp
[2025-07-19T20:31:02.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.1.delta.2820fd74-9f6a-4846-9506-2c7f82f9e1ef.TID437.tmp
[2025-07-19T20:31:02.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.1.delta.e8062658-4c74-426a-89da-bb188f9e2c22.TID432.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta
[2025-07-19T20:31:02.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/45/1.delta
[2025-07-19T20:31:02.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 46 (task 433, attempt 0, stage 5.0)
[2025-07-19T20:31:02.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 432, attempt 0, stage 5.0)
[2025-07-19T20:31:02.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 46.0 in stage 5.0 (TID 433). 9054 bytes result sent to driver
[2025-07-19T20:31:02.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 56.0 in stage 5.0 (TID 439) (8b44f3d35cfa, executor driver, partition 56, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.524+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 46.0 in stage 5.0 (TID 433) in 118 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:31:02.524+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 56.0 in stage 5.0 (TID 439)
[2025-07-19T20:31:02.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.1.delta.fd994368-7e31-448b-b7d6-85276b6801ab.TID438.tmp
[2025-07-19T20:31:02.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 43 (task 431, attempt 0, stage 5.0)
[2025-07-19T20:31:02.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 43.0 in stage 5.0 (TID 431). 9076 bytes result sent to driver
[2025-07-19T20:31:02.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 57.0 in stage 5.0 (TID 440) (8b44f3d35cfa, executor driver, partition 57, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.1.delta.0a6a5a22-d465-47fe-9443-c8338aa1c471.TID435.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta
[2025-07-19T20:31:02.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/48/1.delta
[2025-07-19T20:31:02.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 435, attempt 0, stage 5.0)
[2025-07-19T20:31:02.530+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 43.0 in stage 5.0 (TID 431) in 146 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:31:02.530+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 57.0 in stage 5.0 (TID 440)
[2025-07-19T20:31:02.530+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b4cd7d5
[2025-07-19T20:31:02.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.1.delta.71812f58-2da5-45d2-81fb-fbb4eabd447b.TID434.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta
[2025-07-19T20:31:02.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:31:02.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/47/1.delta
[2025-07-19T20:31:02.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.1.delta.d9716d08-d439-4876-b96c-fc7ee0684fa3.TID436.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta
[2025-07-19T20:31:02.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 434, attempt 0, stage 5.0)
[2025-07-19T20:31:02.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/51/1.delta
[2025-07-19T20:31:02.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 436, attempt 0, stage 5.0)
[2025-07-19T20:31:02.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56] for update
[2025-07-19T20:31:02.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 48 (task 435, attempt 0, stage 5.0)
[2025-07-19T20:31:02.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 45 (task 432, attempt 0, stage 5.0)
[2025-07-19T20:31:02.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 45.0 in stage 5.0 (TID 432). 9043 bytes result sent to driver
[2025-07-19T20:31:02.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 48.0 in stage 5.0 (TID 435). 9087 bytes result sent to driver
[2025-07-19T20:31:02.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 58.0 in stage 5.0 (TID 441) (8b44f3d35cfa, executor driver, partition 58, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 59.0 in stage 5.0 (TID 442) (8b44f3d35cfa, executor driver, partition 59, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 59.0 in stage 5.0 (TID 442)
[2025-07-19T20:31:02.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ec1e998
[2025-07-19T20:31:02.543+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 45.0 in stage 5.0 (TID 432) in 149 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:31:02.544+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 58.0 in stage 5.0 (TID 441)
[2025-07-19T20:31:02.545+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.546+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 48.0 in stage 5.0 (TID 435) in 122 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 51 (task 436, attempt 0, stage 5.0)
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/.1.bd8c9f8b-9645-4e61-b7f7-df015b290d3b.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/offsets/1
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(1752784240000,1752957062482,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57] for update
[2025-07-19T20:31:02.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 51.0 in stage 5.0 (TID 436). 9043 bytes result sent to driver
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 60.0 in stage 5.0 (TID 443) (8b44f3d35cfa, executor driver, partition 60, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 51.0 in stage 5.0 (TID 436) in 100 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.1.delta.1d7692a6-f7bb-484a-9930-856aba6f02ec.TID439.tmp
[2025-07-19T20:31:02.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 60.0 in stage 5.0 (TID 443)
[2025-07-19T20:31:02.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.1.delta.2820fd74-9f6a-4846-9506-2c7f82f9e1ef.TID437.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta
[2025-07-19T20:31:02.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/52/1.delta
[2025-07-19T20:31:02.550+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 437, attempt 0, stage 5.0)
[2025-07-19T20:31:02.550+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 47 (task 434, attempt 0, stage 5.0)
[2025-07-19T20:31:02.554+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 47.0 in stage 5.0 (TID 434). 9128 bytes result sent to driver
[2025-07-19T20:31:02.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.557+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 62.0 in stage 5.0 (TID 444) (8b44f3d35cfa, executor driver, partition 62, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.558+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 62.0 in stage 5.0 (TID 444)
[2025-07-19T20:31:02.559+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 47.0 in stage 5.0 (TID 434) in 155 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:31:02.559+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@77873c79
[2025-07-19T20:31:02.563+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59] for update
[2025-07-19T20:31:02.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.1.delta.82b4d57a-8a01-4614-8a35-4d4ead256e68.TID440.tmp
[2025-07-19T20:31:02.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@408f7282
[2025-07-19T20:31:02.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62] for update
[2025-07-19T20:31:02.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.1.delta.fd994368-7e31-448b-b7d6-85276b6801ab.TID438.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta
[2025-07-19T20:31:02.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/53/1.delta
[2025-07-19T20:31:02.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 52 (task 437, attempt 0, stage 5.0)
[2025-07-19T20:31:02.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 52.0 in stage 5.0 (TID 437). 9070 bytes result sent to driver
[2025-07-19T20:31:02.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 63.0 in stage 5.0 (TID 445) (8b44f3d35cfa, executor driver, partition 63, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 438, attempt 0, stage 5.0)
[2025-07-19T20:31:02.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 52.0 in stage 5.0 (TID 437) in 103 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:31:02.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 63.0 in stage 5.0 (TID 445)
[2025-07-19T20:31:02.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.1.delta.40ff9644-e3ef-4029-b3f9-174b4b5eec71.TID442.tmp
[2025-07-19T20:31:02.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ecf3f97
[2025-07-19T20:31:02.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60] for update
[2025-07-19T20:31:02.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 53 (task 438, attempt 0, stage 5.0)
[2025-07-19T20:31:02.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e210165
[2025-07-19T20:31:02.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58] for update
[2025-07-19T20:31:02.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 53.0 in stage 5.0 (TID 438). 9134 bytes result sent to driver
[2025-07-19T20:31:02.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.1.delta.1d7692a6-f7bb-484a-9930-856aba6f02ec.TID439.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta
[2025-07-19T20:31:02.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/56/1.delta
[2025-07-19T20:31:02.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.1.delta.78187115-8e4e-4b66-9bca-7df9440d330c.TID443.tmp
[2025-07-19T20:31:02.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 64.0 in stage 5.0 (TID 446) (8b44f3d35cfa, executor driver, partition 64, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 439, attempt 0, stage 5.0)
[2025-07-19T20:31:02.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@22dd7ac9
[2025-07-19T20:31:02.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.1.delta.4675bd25-9196-4dbb-9225-88da3b95cdee.TID444.tmp
[2025-07-19T20:31:02.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63] for update
[2025-07-19T20:31:02.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 53.0 in stage 5.0 (TID 438) in 133 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:31:02.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 64.0 in stage 5.0 (TID 446)
[2025-07-19T20:31:02.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.1.delta.56cf129a-c411-4c78-a673-2c626c709640.TID441.tmp
[2025-07-19T20:31:02.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.1.delta.2a102140-11b5-4eda-a63b-8501df6216d2.TID445.tmp
[2025-07-19T20:31:02.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 56 (task 439, attempt 0, stage 5.0)
[2025-07-19T20:31:02.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 56.0 in stage 5.0 (TID 439). 9093 bytes result sent to driver
[2025-07-19T20:31:02.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 65.0 in stage 5.0 (TID 447) (8b44f3d35cfa, executor driver, partition 65, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.649+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 65.0 in stage 5.0 (TID 447)
[2025-07-19T20:31:02.649+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 56.0 in stage 5.0 (TID 439) in 139 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:31:02.650+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.1.delta.40ff9644-e3ef-4029-b3f9-174b4b5eec71.TID442.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta
[2025-07-19T20:31:02.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/59/1.delta
[2025-07-19T20:31:02.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 442, attempt 0, stage 5.0)
[2025-07-19T20:31:02.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1eedc7a8
[2025-07-19T20:31:02.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.663+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64] for update
[2025-07-19T20:31:02.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.1.delta.78187115-8e4e-4b66-9bca-7df9440d330c.TID443.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta
[2025-07-19T20:31:02.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/60/1.delta
[2025-07-19T20:31:02.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 443, attempt 0, stage 5.0)
[2025-07-19T20:31:02.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.1.delta.82b4d57a-8a01-4614-8a35-4d4ead256e68.TID440.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta
[2025-07-19T20:31:02.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/57/1.delta
[2025-07-19T20:31:02.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 440, attempt 0, stage 5.0)
[2025-07-19T20:31:02.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.1.delta.56cf129a-c411-4c78-a673-2c626c709640.TID441.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta
[2025-07-19T20:31:02.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/58/1.delta
[2025-07-19T20:31:02.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29c638bc
[2025-07-19T20:31:02.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65] for update
[2025-07-19T20:31:02.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.1.delta.4675bd25-9196-4dbb-9225-88da3b95cdee.TID444.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta
[2025-07-19T20:31:02.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/62/1.delta
[2025-07-19T20:31:02.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 441, attempt 0, stage 5.0)
[2025-07-19T20:31:02.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 444, attempt 0, stage 5.0)
[2025-07-19T20:31:02.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.1.delta.ddb6288e-dff0-4cd8-a9fa-b3be4d1a555f.TID446.tmp
[2025-07-19T20:31:02.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 59 (task 442, attempt 0, stage 5.0)
[2025-07-19T20:31:02.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 59.0 in stage 5.0 (TID 442). 9091 bytes result sent to driver
[2025-07-19T20:31:02.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 66.0 in stage 5.0 (TID 448) (8b44f3d35cfa, executor driver, partition 66, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 66.0 in stage 5.0 (TID 448)
[2025-07-19T20:31:02.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 59.0 in stage 5.0 (TID 442) in 146 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:31:02.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.1.delta.b53cdff9-8536-4357-a194-d138c009c00f.TID447.tmp
[2025-07-19T20:31:02.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a95d65e
[2025-07-19T20:31:02.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 60 (task 443, attempt 0, stage 5.0)
[2025-07-19T20:31:02.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66] for update
[2025-07-19T20:31:02.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 60.0 in stage 5.0 (TID 443). 9080 bytes result sent to driver
[2025-07-19T20:31:02.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 68.0 in stage 5.0 (TID 449) (8b44f3d35cfa, executor driver, partition 68, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 60.0 in stage 5.0 (TID 443) in 149 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:31:02.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 57 (task 440, attempt 0, stage 5.0)
[2025-07-19T20:31:02.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 58 (task 441, attempt 0, stage 5.0)
[2025-07-19T20:31:02.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.1.delta.2a102140-11b5-4eda-a63b-8501df6216d2.TID445.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta
[2025-07-19T20:31:02.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/63/1.delta
[2025-07-19T20:31:02.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 57.0 in stage 5.0 (TID 440). 9127 bytes result sent to driver
[2025-07-19T20:31:02.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 445, attempt 0, stage 5.0)
[2025-07-19T20:31:02.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 69.0 in stage 5.0 (TID 450) (8b44f3d35cfa, executor driver, partition 69, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 58.0 in stage 5.0 (TID 441). 9125 bytes result sent to driver
[2025-07-19T20:31:02.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 71.0 in stage 5.0 (TID 451) (8b44f3d35cfa, executor driver, partition 71, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 69.0 in stage 5.0 (TID 450)
[2025-07-19T20:31:02.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 71.0 in stage 5.0 (TID 451)
[2025-07-19T20:31:02.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 68.0 in stage 5.0 (TID 449)
[2025-07-19T20:31:02.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 57.0 in stage 5.0 (TID 440) in 197 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:31:02.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 62 (task 444, attempt 0, stage 5.0)
[2025-07-19T20:31:02.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 58.0 in stage 5.0 (TID 441) in 177 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:31:02.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 62.0 in stage 5.0 (TID 444). 9086 bytes result sent to driver
[2025-07-19T20:31:02.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 72.0 in stage 5.0 (TID 452) (8b44f3d35cfa, executor driver, partition 72, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting 0 bytes advisory partition size for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting UnspecifiedDistribution as write distribution for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkWrite: Requesting [] as write ordering for table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:02.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 62.0 in stage 5.0 (TID 444) in 160 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:31:02.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:02.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:02.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 72.0 in stage 5.0 (TID 452)
[2025-07-19T20:31:02.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.1.delta.63733090-59cb-4d4d-9027-ac982e7f1e72.TID448.tmp
[2025-07-19T20:31:02.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b41170c
[2025-07-19T20:31:02.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71] for update
[2025-07-19T20:31:02.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.728+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.728+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75f0db85
[2025-07-19T20:31:02.731+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.733+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 63 (task 445, attempt 0, stage 5.0)
[2025-07-19T20:31:02.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69] for update
[2025-07-19T20:31:02.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 63.0 in stage 5.0 (TID 445). 9076 bytes result sent to driver
[2025-07-19T20:31:02.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 73.0 in stage 5.0 (TID 453) (8b44f3d35cfa, executor driver, partition 73, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 73.0 in stage 5.0 (TID 453)
[2025-07-19T20:31:02.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 63.0 in stage 5.0 (TID 445) in 163 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:31:02.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.1.delta.808f5b18-fd9d-47a1-9ad1-4e23513f1f7b.TID451.tmp
[2025-07-19T20:31:02.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.1.delta.ddb6288e-dff0-4cd8-a9fa-b3be4d1a555f.TID446.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta
[2025-07-19T20:31:02.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/64/1.delta
[2025-07-19T20:31:02.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 446, attempt 0, stage 5.0)
[2025-07-19T20:31:02.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@78fd87d4
[2025-07-19T20:31:02.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68] for update
[2025-07-19T20:31:02.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.1.delta.b53cdff9-8536-4357-a194-d138c009c00f.TID447.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta
[2025-07-19T20:31:02.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/65/1.delta
[2025-07-19T20:31:02.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.1.delta.b0910de2-9448-490f-a754-0e0019ce1f8d.TID450.tmp
[2025-07-19T20:31:02.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 447, attempt 0, stage 5.0)
[2025-07-19T20:31:02.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 209.0 KiB, free 433.1 MiB)
[2025-07-19T20:31:02.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c22a886
[2025-07-19T20:31:02.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73] for update
[2025-07-19T20:31:02.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.1.delta.a9a32b48-485c-4538-896d-058279d418ef.TID449.tmp
[2025-07-19T20:31:02.757+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 64 (task 446, attempt 0, stage 5.0)
[2025-07-19T20:31:02.757+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.758+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 64.0 in stage 5.0 (TID 446). 9093 bytes result sent to driver
[2025-07-19T20:31:02.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 75.0 in stage 5.0 (TID 454) (8b44f3d35cfa, executor driver, partition 75, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5daae779
[2025-07-19T20:31:02.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 64.0 in stage 5.0 (TID 446) in 156 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:31:02.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72] for update
[2025-07-19T20:31:02.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 75.0 in stage 5.0 (TID 454)
[2025-07-19T20:31:02.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.1.delta.63733090-59cb-4d4d-9027-ac982e7f1e72.TID448.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta
[2025-07-19T20:31:02.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/66/1.delta
[2025-07-19T20:31:02.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 448, attempt 0, stage 5.0)
[2025-07-19T20:31:02.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 35.4 KiB, free 433.1 MiB)
[2025-07-19T20:31:02.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 8b44f3d35cfa:36593 (size: 35.4 KiB, free: 434.1 MiB)
[2025-07-19T20:31:02.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkContext: Created broadcast 15 from start at <unknown>:0
[2025-07-19T20:31:02.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@262ddc75
[2025-07-19T20:31:02.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 433.1 MiB)
[2025-07-19T20:31:02.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 65 (task 447, attempt 0, stage 5.0)
[2025-07-19T20:31:02.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 65.0 in stage 5.0 (TID 447). 9086 bytes result sent to driver
[2025-07-19T20:31:02.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 433.0 MiB)
[2025-07-19T20:31:02.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75] for update
[2025-07-19T20:31:02.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 77.0 in stage 5.0 (TID 455) (8b44f3d35cfa, executor driver, partition 77, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 65.0 in stage 5.0 (TID 447) in 138 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:31:02.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 77.0 in stage 5.0 (TID 455)
[2025-07-19T20:31:02.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 8b44f3d35cfa:36593 (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T20:31:02.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkContext: Created broadcast 16 from start at <unknown>:0
[2025-07-19T20:31:02.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)]. The input RDD has 200 partitions.
[2025-07-19T20:31:02.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.1.delta.7ec5bba3-11c1-4d16-9124-9b63b43c786a.TID452.tmp
[2025-07-19T20:31:02.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:02.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.1.delta.e697df48-eee9-4fe1-b429-e4dfdd119ed8.TID453.tmp
[2025-07-19T20:31:02.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkContext: Starting job: start at <unknown>:0
[2025-07-19T20:31:02.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.1.delta.808f5b18-fd9d-47a1-9ad1-4e23513f1f7b.TID451.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta
[2025-07-19T20:31:02.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/71/1.delta
[2025-07-19T20:31:02.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 66 (task 448, attempt 0, stage 5.0)
[2025-07-19T20:31:02.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Registering RDD 33 (start at <unknown>:0) as input to shuffle 4
[2025-07-19T20:31:02.801+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.1.delta.b0910de2-9448-490f-a754-0e0019ce1f8d.TID450.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta
[2025-07-19T20:31:02.801+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/69/1.delta
[2025-07-19T20:31:02.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 451, attempt 0, stage 5.0)
[2025-07-19T20:31:02.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 450, attempt 0, stage 5.0)
[2025-07-19T20:31:02.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 66.0 in stage 5.0 (TID 448). 9103 bytes result sent to driver
[2025-07-19T20:31:02.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75a33e7c
[2025-07-19T20:31:02.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.1.delta.94b69036-aa27-4807-be3f-9348011bbe46.TID454.tmp
[2025-07-19T20:31:02.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77] for update
[2025-07-19T20:31:02.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 78.0 in stage 5.0 (TID 456) (8b44f3d35cfa, executor driver, partition 78, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 78.0 in stage 5.0 (TID 456)
[2025-07-19T20:31:02.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Got job 4 (start at <unknown>:0) with 200 output partitions
[2025-07-19T20:31:02.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Final stage: ResultStage 9 (start at <unknown>:0)
[2025-07-19T20:31:02.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-07-19T20:31:02.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Missing parents: List()
[2025-07-19T20:31:02.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Submitting ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0), which has no missing parents
[2025-07-19T20:31:02.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 66.0 in stage 5.0 (TID 448) in 124 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:31:02.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.1.delta.a9a32b48-485c-4538-896d-058279d418ef.TID449.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta
[2025-07-19T20:31:02.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/68/1.delta
[2025-07-19T20:31:02.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 449, attempt 0, stage 5.0)
[2025-07-19T20:31:02.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 69 (task 450, attempt 0, stage 5.0)
[2025-07-19T20:31:02.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 69.0 in stage 5.0 (TID 450). 9066 bytes result sent to driver
[2025-07-19T20:31:02.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 71 (task 451, attempt 0, stage 5.0)
[2025-07-19T20:31:02.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 71.0 in stage 5.0 (TID 451). 9074 bytes result sent to driver
[2025-07-19T20:31:02.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c57e18f
[2025-07-19T20:31:02.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.1.delta.8b794741-a69e-42b2-9929-c6dbc2409a9b.TID455.tmp
[2025-07-19T20:31:02.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 79.0 in stage 5.0 (TID 457) (8b44f3d35cfa, executor driver, partition 79, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 79.0 in stage 5.0 (TID 457)
[2025-07-19T20:31:02.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78] for update
[2025-07-19T20:31:02.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 69.0 in stage 5.0 (TID 450) in 114 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:31:02.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 82.0 in stage 5.0 (TID 458) (8b44f3d35cfa, executor driver, partition 82, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 82.0 in stage 5.0 (TID 458)
[2025-07-19T20:31:02.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 71.0 in stage 5.0 (TID 451) in 118 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:31:02.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:02.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 68 (task 449, attempt 0, stage 5.0)
[2025-07-19T20:31:02.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 68.0 in stage 5.0 (TID 449). 9072 bytes result sent to driver
[2025-07-19T20:31:02.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 83.0 in stage 5.0 (TID 459) (8b44f3d35cfa, executor driver, partition 83, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 83.0 in stage 5.0 (TID 459)
[2025-07-19T20:31:02.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 68.0 in stage 5.0 (TID 449) in 146 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:31:02.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31a6df98
[2025-07-19T20:31:02.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79] for update
[2025-07-19T20:31:02.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.1.delta.9cb6e2cd-1858-488d-b17f-26436a8dcfca.TID456.tmp
[2025-07-19T20:31:02.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.1.delta.7ec5bba3-11c1-4d16-9124-9b63b43c786a.TID452.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta
[2025-07-19T20:31:02.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/72/1.delta
[2025-07-19T20:31:02.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 452, attempt 0, stage 5.0)
[2025-07-19T20:31:02.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.1.delta.e697df48-eee9-4fe1-b429-e4dfdd119ed8.TID453.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta
[2025-07-19T20:31:02.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/73/1.delta
[2025-07-19T20:31:02.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 453, attempt 0, stage 5.0)
[2025-07-19T20:31:02.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 31.7 KiB, free 433.0 MiB)
[2025-07-19T20:31:02.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59a4f662
[2025-07-19T20:31:02.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82] for update
[2025-07-19T20:31:02.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 433.0 MiB)
[2025-07-19T20:31:02.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.1.delta.eaf81961-b80b-47e1-88b4-1ed0b806b765.TID457.tmp
[2025-07-19T20:31:02.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 8b44f3d35cfa:36593 (size: 15.8 KiB, free: 434.1 MiB)
[2025-07-19T20:31:02.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1611
[2025-07-19T20:31:02.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 9 (StateStoreRDD[35] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2025-07-19T20:31:02.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSchedulerImpl: Adding task set 9.0 with 200 tasks resource profile 0
[2025-07-19T20:31:02.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 72 (task 452, attempt 0, stage 5.0)
[2025-07-19T20:31:02.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 72.0 in stage 5.0 (TID 452). 9070 bytes result sent to driver
[2025-07-19T20:31:02.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 85.0 in stage 5.0 (TID 460) (8b44f3d35cfa, executor driver, partition 85, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 72.0 in stage 5.0 (TID 452) in 160 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:31:02.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67d3677f
[2025-07-19T20:31:02.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83] for update
[2025-07-19T20:31:02.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 85.0 in stage 5.0 (TID 460)
[2025-07-19T20:31:02.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.1.delta.8b794741-a69e-42b2-9929-c6dbc2409a9b.TID455.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta
[2025-07-19T20:31:02.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/77/1.delta
[2025-07-19T20:31:02.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 455, attempt 0, stage 5.0)
[2025-07-19T20:31:02.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.1.delta.94b69036-aa27-4807-be3f-9348011bbe46.TID454.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta
[2025-07-19T20:31:02.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/75/1.delta
[2025-07-19T20:31:02.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 454, attempt 0, stage 5.0)
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 73 (task 453, attempt 0, stage 5.0)
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 73.0 in stage 5.0 (TID 453). 9095 bytes result sent to driver
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 86.0 in stage 5.0 (TID 461) (8b44f3d35cfa, executor driver, partition 86, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 73.0 in stage 5.0 (TID 453) in 152 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 86.0 in stage 5.0 (TID 461)
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.1.delta.b85307dc-2e4b-4692-9145-eab8de41bb45.TID458.tmp
[2025-07-19T20:31:02.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53716a44
[2025-07-19T20:31:02.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85] for update
[2025-07-19T20:31:02.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 77 (task 455, attempt 0, stage 5.0)
[2025-07-19T20:31:02.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 77.0 in stage 5.0 (TID 455). 9080 bytes result sent to driver
[2025-07-19T20:31:02.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 87.0 in stage 5.0 (TID 462) (8b44f3d35cfa, executor driver, partition 87, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.1.delta.87513b8f-a55c-4286-8422-51f98f8c8967.TID459.tmp
[2025-07-19T20:31:02.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 75 (task 454, attempt 0, stage 5.0)
[2025-07-19T20:31:02.901+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 77.0 in stage 5.0 (TID 455) in 115 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:31:02.901+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 75.0 in stage 5.0 (TID 454). 9076 bytes result sent to driver
[2025-07-19T20:31:02.901+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19b4efc0
[2025-07-19T20:31:02.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 87.0 in stage 5.0 (TID 462)
[2025-07-19T20:31:02.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 89.0 in stage 5.0 (TID 463) (8b44f3d35cfa, executor driver, partition 89, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.904+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.905+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 75.0 in stage 5.0 (TID 454) in 144 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:31:02.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86] for update
[2025-07-19T20:31:02.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.1.delta.33aeff5d-ba85-4880-a194-146ece7c3e17.TID460.tmp
[2025-07-19T20:31:02.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 89.0 in stage 5.0 (TID 463)
[2025-07-19T20:31:02.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.1.delta.9cb6e2cd-1858-488d-b17f-26436a8dcfca.TID456.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta
[2025-07-19T20:31:02.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/78/1.delta
[2025-07-19T20:31:02.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 456, attempt 0, stage 5.0)
[2025-07-19T20:31:02.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dd21067
[2025-07-19T20:31:02.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87] for update
[2025-07-19T20:31:02.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.1.delta.03d8226c-aaaa-4b2e-853f-ba741f464dc8.TID461.tmp
[2025-07-19T20:31:02.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f8b0fb3
[2025-07-19T20:31:02.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89] for update
[2025-07-19T20:31:02.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.1.delta.23670f34-1074-4f62-b8c6-a63a932f7dab.TID462.tmp
[2025-07-19T20:31:02.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 78 (task 456, attempt 0, stage 5.0)
[2025-07-19T20:31:02.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 78.0 in stage 5.0 (TID 456). 9089 bytes result sent to driver
[2025-07-19T20:31:02.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 92.0 in stage 5.0 (TID 464) (8b44f3d35cfa, executor driver, partition 92, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 92.0 in stage 5.0 (TID 464)
[2025-07-19T20:31:02.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 78.0 in stage 5.0 (TID 456) in 138 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:31:02.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.1.delta.eaf81961-b80b-47e1-88b4-1ed0b806b765.TID457.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta
[2025-07-19T20:31:02.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/79/1.delta
[2025-07-19T20:31:02.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 457, attempt 0, stage 5.0)
[2025-07-19T20:31:02.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29679e2e
[2025-07-19T20:31:02.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.1.delta.3791ee45-9ba8-488b-8694-469e0d6372fe.TID463.tmp
[2025-07-19T20:31:02.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.1.delta.b85307dc-2e4b-4692-9145-eab8de41bb45.TID458.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta
[2025-07-19T20:31:02.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/82/1.delta
[2025-07-19T20:31:02.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92] for update
[2025-07-19T20:31:02.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 458, attempt 0, stage 5.0)
[2025-07-19T20:31:02.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.1.delta.87513b8f-a55c-4286-8422-51f98f8c8967.TID459.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta
[2025-07-19T20:31:02.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/83/1.delta
[2025-07-19T20:31:02.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 459, attempt 0, stage 5.0)
[2025-07-19T20:31:02.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 79 (task 457, attempt 0, stage 5.0)
[2025-07-19T20:31:02.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 79.0 in stage 5.0 (TID 457). 9082 bytes result sent to driver
[2025-07-19T20:31:02.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 94.0 in stage 5.0 (TID 465) (8b44f3d35cfa, executor driver, partition 94, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 79.0 in stage 5.0 (TID 457) in 142 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:31:02.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 94.0 in stage 5.0 (TID 465)
[2025-07-19T20:31:02.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.1.delta.d01ed09a-f06c-4181-867a-8bd3966acbac.TID464.tmp
[2025-07-19T20:31:02.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:02.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.1.delta.33aeff5d-ba85-4880-a194-146ece7c3e17.TID460.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta
[2025-07-19T20:31:02.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/85/1.delta
[2025-07-19T20:31:02.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 82 (task 458, attempt 0, stage 5.0)
[2025-07-19T20:31:02.978+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 460, attempt 0, stage 5.0)
[2025-07-19T20:31:02.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 82.0 in stage 5.0 (TID 458). 9082 bytes result sent to driver
[2025-07-19T20:31:02.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 95.0 in stage 5.0 (TID 466) (8b44f3d35cfa, executor driver, partition 95, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:02.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 95.0 in stage 5.0 (TID 466)
[2025-07-19T20:31:02.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f7ceb1c
[2025-07-19T20:31:02.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 82.0 in stage 5.0 (TID 458) in 150 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:31:02.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:02.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94] for update
[2025-07-19T20:31:02.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:02.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:02.987+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.1.delta.03d8226c-aaaa-4b2e-853f-ba741f464dc8.TID461.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta
[2025-07-19T20:31:02.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/86/1.delta
[2025-07-19T20:31:02.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.1.delta.23670f34-1074-4f62-b8c6-a63a932f7dab.TID462.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta
[2025-07-19T20:31:02.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/87/1.delta
[2025-07-19T20:31:02.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Committed partition 83 (task 459, attempt 0, stage 5.0)
[2025-07-19T20:31:03.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 462, attempt 0, stage 5.0)
[2025-07-19T20:31:03.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Finished task 83.0 in stage 5.0 (TID 459). 9081 bytes result sent to driver
[2025-07-19T20:31:03.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Starting task 96.0 in stage 5.0 (TID 467) (8b44f3d35cfa, executor driver, partition 96, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 461, attempt 0, stage 5.0)
[2025-07-19T20:31:03.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO TaskSetManager: Finished task 83.0 in stage 5.0 (TID 459) in 157 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:31:03.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:02 INFO Executor: Running task 96.0 in stage 5.0 (TID 467)
[2025-07-19T20:31:03.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 87 (task 462, attempt 0, stage 5.0)
[2025-07-19T20:31:03.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 87.0 in stage 5.0 (TID 462). 9033 bytes result sent to driver
[2025-07-19T20:31:03.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2847621d
[2025-07-19T20:31:03.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 97.0 in stage 5.0 (TID 468) (8b44f3d35cfa, executor driver, partition 97, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.015+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.015+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95] for update
[2025-07-19T20:31:03.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 87.0 in stage 5.0 (TID 462) in 113 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:31:03.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 97.0 in stage 5.0 (TID 468)
[2025-07-19T20:31:03.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 85 (task 460, attempt 0, stage 5.0)
[2025-07-19T20:31:03.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.1.delta.6c55c081-b3f4-437a-8205-fb4fd133d67b.TID465.tmp
[2025-07-19T20:31:03.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.1.delta.3791ee45-9ba8-488b-8694-469e0d6372fe.TID463.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta
[2025-07-19T20:31:03.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/89/1.delta
[2025-07-19T20:31:03.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 85.0 in stage 5.0 (TID 460). 9134 bytes result sent to driver
[2025-07-19T20:31:03.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 86 (task 461, attempt 0, stage 5.0)
[2025-07-19T20:31:03.048+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 99.0 in stage 5.0 (TID 469) (8b44f3d35cfa, executor driver, partition 99, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.049+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 85.0 in stage 5.0 (TID 460) in 170 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:31:03.050+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 463, attempt 0, stage 5.0)
[2025-07-19T20:31:03.051+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 99.0 in stage 5.0 (TID 469)
[2025-07-19T20:31:03.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 86.0 in stage 5.0 (TID 461). 9094 bytes result sent to driver
[2025-07-19T20:31:03.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 100.0 in stage 5.0 (TID 470) (8b44f3d35cfa, executor driver, partition 100, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 100.0 in stage 5.0 (TID 470)
[2025-07-19T20:31:03.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 86.0 in stage 5.0 (TID 461) in 163 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:31:03.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.1.delta.d2d56503-07cd-4a06-b992-a8b86d949dd0.TID466.tmp
[2025-07-19T20:31:03.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f94d699
[2025-07-19T20:31:03.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97] for update
[2025-07-19T20:31:03.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2141de80
[2025-07-19T20:31:03.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100] for update
[2025-07-19T20:31:03.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.072+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31218369
[2025-07-19T20:31:03.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.1.delta.fe24e75f-c6ac-4c8b-9ca9-e2a64b51480c.TID468.tmp
[2025-07-19T20:31:03.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99] for update
[2025-07-19T20:31:03.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 89 (task 463, attempt 0, stage 5.0)
[2025-07-19T20:31:03.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 89.0 in stage 5.0 (TID 463). 9078 bytes result sent to driver
[2025-07-19T20:31:03.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 102.0 in stage 5.0 (TID 471) (8b44f3d35cfa, executor driver, partition 102, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 89.0 in stage 5.0 (TID 463) in 179 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:31:03.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.092+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31a0a9be
[2025-07-19T20:31:03.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96] for update
[2025-07-19T20:31:03.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.1.delta.d01ed09a-f06c-4181-867a-8bd3966acbac.TID464.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta
[2025-07-19T20:31:03.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/92/1.delta
[2025-07-19T20:31:03.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.1.delta.0c1e9a33-3c64-4d7e-b7c0-5d4d52824d97.TID470.tmp
[2025-07-19T20:31:03.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 464, attempt 0, stage 5.0)
[2025-07-19T20:31:03.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.1.delta.941a1def-83cd-4923-b82e-087cfe74c127.TID469.tmp
[2025-07-19T20:31:03.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 102.0 in stage 5.0 (TID 471)
[2025-07-19T20:31:03.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.1.delta.24d9d166-0efa-4c96-b13d-31cbb6c4f285.TID467.tmp
[2025-07-19T20:31:03.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44cd2024
[2025-07-19T20:31:03.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102] for update
[2025-07-19T20:31:03.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 92 (task 464, attempt 0, stage 5.0)
[2025-07-19T20:31:03.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 92.0 in stage 5.0 (TID 464). 9121 bytes result sent to driver
[2025-07-19T20:31:03.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 104.0 in stage 5.0 (TID 472) (8b44f3d35cfa, executor driver, partition 104, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 104.0 in stage 5.0 (TID 472)
[2025-07-19T20:31:03.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 92.0 in stage 5.0 (TID 464) in 197 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:31:03.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.1.delta.d2d56503-07cd-4a06-b992-a8b86d949dd0.TID466.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta
[2025-07-19T20:31:03.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/95/1.delta
[2025-07-19T20:31:03.142+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 466, attempt 0, stage 5.0)
[2025-07-19T20:31:03.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.1.delta.8ac49c65-8234-4b15-864e-c2c6e3aa512e.TID471.tmp
[2025-07-19T20:31:03.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2193eb59
[2025-07-19T20:31:03.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104] for update
[2025-07-19T20:31:03.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.1.delta.6c55c081-b3f4-437a-8205-fb4fd133d67b.TID465.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta
[2025-07-19T20:31:03.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/94/1.delta
[2025-07-19T20:31:03.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.1.delta.fe24e75f-c6ac-4c8b-9ca9-e2a64b51480c.TID468.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta
[2025-07-19T20:31:03.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/97/1.delta
[2025-07-19T20:31:03.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 468, attempt 0, stage 5.0)
[2025-07-19T20:31:03.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 465, attempt 0, stage 5.0)
[2025-07-19T20:31:03.156+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 95 (task 466, attempt 0, stage 5.0)
[2025-07-19T20:31:03.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 95.0 in stage 5.0 (TID 466). 9080 bytes result sent to driver
[2025-07-19T20:31:03.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 105.0 in stage 5.0 (TID 473) (8b44f3d35cfa, executor driver, partition 105, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 95.0 in stage 5.0 (TID 466) in 185 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:31:03.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 105.0 in stage 5.0 (TID 473)
[2025-07-19T20:31:03.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.1.delta.0c1e9a33-3c64-4d7e-b7c0-5d4d52824d97.TID470.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta
[2025-07-19T20:31:03.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/100/1.delta
[2025-07-19T20:31:03.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.1.delta.5965802a-d420-4865-988c-557076dfa374.TID472.tmp
[2025-07-19T20:31:03.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 470, attempt 0, stage 5.0)
[2025-07-19T20:31:03.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.1.delta.941a1def-83cd-4923-b82e-087cfe74c127.TID469.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta
[2025-07-19T20:31:03.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/99/1.delta
[2025-07-19T20:31:03.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 469, attempt 0, stage 5.0)
[2025-07-19T20:31:03.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.1.delta.24d9d166-0efa-4c96-b13d-31cbb6c4f285.TID467.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta
[2025-07-19T20:31:03.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/96/1.delta
[2025-07-19T20:31:03.179+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 467, attempt 0, stage 5.0)
[2025-07-19T20:31:03.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4aeeca45
[2025-07-19T20:31:03.181+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105] for update
[2025-07-19T20:31:03.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 94 (task 465, attempt 0, stage 5.0)
[2025-07-19T20:31:03.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 94.0 in stage 5.0 (TID 465). 9095 bytes result sent to driver
[2025-07-19T20:31:03.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 106.0 in stage 5.0 (TID 474) (8b44f3d35cfa, executor driver, partition 106, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.188+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 106.0 in stage 5.0 (TID 474)
[2025-07-19T20:31:03.189+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 94.0 in stage 5.0 (TID 465) in 223 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:31:03.189+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.1.delta.811a8a8b-fbbe-4945-9420-7d836841fd92.TID473.tmp
[2025-07-19T20:31:03.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e885c92
[2025-07-19T20:31:03.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106] for update
[2025-07-19T20:31:03.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.1.delta.8ac49c65-8234-4b15-864e-c2c6e3aa512e.TID471.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta
[2025-07-19T20:31:03.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/102/1.delta
[2025-07-19T20:31:03.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 471, attempt 0, stage 5.0)
[2025-07-19T20:31:03.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 96 (task 467, attempt 0, stage 5.0)
[2025-07-19T20:31:03.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 97 (task 468, attempt 0, stage 5.0)
[2025-07-19T20:31:03.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 96.0 in stage 5.0 (TID 467). 9075 bytes result sent to driver
[2025-07-19T20:31:03.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 97.0 in stage 5.0 (TID 468). 9080 bytes result sent to driver
[2025-07-19T20:31:03.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 107.0 in stage 5.0 (TID 475) (8b44f3d35cfa, executor driver, partition 107, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 107.0 in stage 5.0 (TID 475)
[2025-07-19T20:31:03.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 99 (task 469, attempt 0, stage 5.0)
[2025-07-19T20:31:03.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 99.0 in stage 5.0 (TID 469). 9037 bytes result sent to driver
[2025-07-19T20:31:03.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 110.0 in stage 5.0 (TID 476) (8b44f3d35cfa, executor driver, partition 110, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 96.0 in stage 5.0 (TID 467) in 215 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:31:03.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 97.0 in stage 5.0 (TID 468) in 195 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:31:03.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 111.0 in stage 5.0 (TID 477) (8b44f3d35cfa, executor driver, partition 111, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 99.0 in stage 5.0 (TID 469) in 160 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:31:03.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 110.0 in stage 5.0 (TID 476)
[2025-07-19T20:31:03.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 111.0 in stage 5.0 (TID 477)
[2025-07-19T20:31:03.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.1.delta.6329053e-8780-4509-bcf9-e369e700944c.TID474.tmp
[2025-07-19T20:31:03.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 100 (task 470, attempt 0, stage 5.0)
[2025-07-19T20:31:03.226+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.226+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 100.0 in stage 5.0 (TID 470). 9045 bytes result sent to driver
[2025-07-19T20:31:03.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 100.0 in stage 5.0 (TID 470) in 163 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:31:03.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 113.0 in stage 5.0 (TID 478) (8b44f3d35cfa, executor driver, partition 113, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 113.0 in stage 5.0 (TID 478)
[2025-07-19T20:31:03.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.1.delta.5965802a-d420-4865-988c-557076dfa374.TID472.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta
[2025-07-19T20:31:03.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/104/1.delta
[2025-07-19T20:31:03.232+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 472, attempt 0, stage 5.0)
[2025-07-19T20:31:03.234+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 102 (task 471, attempt 0, stage 5.0)
[2025-07-19T20:31:03.234+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 102.0 in stage 5.0 (TID 471). 9037 bytes result sent to driver
[2025-07-19T20:31:03.234+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4329affe
[2025-07-19T20:31:03.234+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 117.0 in stage 5.0 (TID 479) (8b44f3d35cfa, executor driver, partition 117, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 102.0 in stage 5.0 (TID 471) in 140 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:31:03.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 117.0 in stage 5.0 (TID 479)
[2025-07-19T20:31:03.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107] for update
[2025-07-19T20:31:03.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18bdf19a
[2025-07-19T20:31:03.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117] for update
[2025-07-19T20:31:03.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.1.delta.f5b167bb-a96c-4ea6-a51f-74d1f5c82522.TID475.tmp
[2025-07-19T20:31:03.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f04b30f
[2025-07-19T20:31:03.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113] for update
[2025-07-19T20:31:03.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 104 (task 472, attempt 0, stage 5.0)
[2025-07-19T20:31:03.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 104.0 in stage 5.0 (TID 472). 9084 bytes result sent to driver
[2025-07-19T20:31:03.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.247+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 118.0 in stage 5.0 (TID 480) (8b44f3d35cfa, executor driver, partition 118, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 118.0 in stage 5.0 (TID 480)
[2025-07-19T20:31:03.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 104.0 in stage 5.0 (TID 472) in 114 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:31:03.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.1.delta.811a8a8b-fbbe-4945-9420-7d836841fd92.TID473.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta
[2025-07-19T20:31:03.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/105/1.delta
[2025-07-19T20:31:03.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 473, attempt 0, stage 5.0)
[2025-07-19T20:31:03.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.1.delta.5aaf34c0-79fd-47df-a787-919fb6b408d7.TID479.tmp
[2025-07-19T20:31:03.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.1.delta.6329053e-8780-4509-bcf9-e369e700944c.TID474.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta
[2025-07-19T20:31:03.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/106/1.delta
[2025-07-19T20:31:03.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d9a0ee3
[2025-07-19T20:31:03.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 474, attempt 0, stage 5.0)
[2025-07-19T20:31:03.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 105 (task 473, attempt 0, stage 5.0)
[2025-07-19T20:31:03.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.1.delta.0c43a31d-161e-432d-b035-9102dcadeff1.TID478.tmp
[2025-07-19T20:31:03.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 105.0 in stage 5.0 (TID 473). 9086 bytes result sent to driver
[2025-07-19T20:31:03.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111] for update
[2025-07-19T20:31:03.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 119.0 in stage 5.0 (TID 481) (8b44f3d35cfa, executor driver, partition 119, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 105.0 in stage 5.0 (TID 473) in 109 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:31:03.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 119.0 in stage 5.0 (TID 481)
[2025-07-19T20:31:03.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74723299
[2025-07-19T20:31:03.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110] for update
[2025-07-19T20:31:03.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 106 (task 474, attempt 0, stage 5.0)
[2025-07-19T20:31:03.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.1.delta.625d7c46-3d7d-489e-ac90-64f95fa0751b.TID477.tmp
[2025-07-19T20:31:03.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 106.0 in stage 5.0 (TID 474). 9078 bytes result sent to driver
[2025-07-19T20:31:03.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 120.0 in stage 5.0 (TID 482) (8b44f3d35cfa, executor driver, partition 120, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 120.0 in stage 5.0 (TID 482)
[2025-07-19T20:31:03.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 106.0 in stage 5.0 (TID 474) in 100 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:31:03.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dced0e0
[2025-07-19T20:31:03.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119] for update
[2025-07-19T20:31:03.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.1.delta.c017a6d0-ddd0-4df9-aed0-4aa489f5b458.TID476.tmp
[2025-07-19T20:31:03.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1428d07e
[2025-07-19T20:31:03.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118] for update
[2025-07-19T20:31:03.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.1.delta.f5b167bb-a96c-4ea6-a51f-74d1f5c82522.TID475.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta
[2025-07-19T20:31:03.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/107/1.delta
[2025-07-19T20:31:03.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.1.delta.2136bf05-7be3-4ca5-b7e3-ed05644bf08d.TID481.tmp
[2025-07-19T20:31:03.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 475, attempt 0, stage 5.0)
[2025-07-19T20:31:03.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@790cfd7
[2025-07-19T20:31:03.365+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120] for update
[2025-07-19T20:31:03.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.1.delta.5aaf34c0-79fd-47df-a787-919fb6b408d7.TID479.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta
[2025-07-19T20:31:03.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/117/1.delta
[2025-07-19T20:31:03.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 479, attempt 0, stage 5.0)
[2025-07-19T20:31:03.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.1.delta.ef19dfce-1fb6-4c35-ae11-bf7243af8347.TID480.tmp
[2025-07-19T20:31:03.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.1.delta.0c43a31d-161e-432d-b035-9102dcadeff1.TID478.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta
[2025-07-19T20:31:03.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/113/1.delta
[2025-07-19T20:31:03.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 478, attempt 0, stage 5.0)
[2025-07-19T20:31:03.390+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.1.delta.f2ec6aa7-7e6d-48f6-b93c-61e11d22e642.TID482.tmp
[2025-07-19T20:31:03.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 107 (task 475, attempt 0, stage 5.0)
[2025-07-19T20:31:03.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 107.0 in stage 5.0 (TID 475). 9084 bytes result sent to driver
[2025-07-19T20:31:03.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 121.0 in stage 5.0 (TID 483) (8b44f3d35cfa, executor driver, partition 121, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 107.0 in stage 5.0 (TID 475) in 203 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:31:03.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 121.0 in stage 5.0 (TID 483)
[2025-07-19T20:31:03.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.414+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 117 (task 479, attempt 0, stage 5.0)
[2025-07-19T20:31:03.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.1.delta.625d7c46-3d7d-489e-ac90-64f95fa0751b.TID477.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta
[2025-07-19T20:31:03.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/111/1.delta
[2025-07-19T20:31:03.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 117.0 in stage 5.0 (TID 479). 9078 bytes result sent to driver
[2025-07-19T20:31:03.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 477, attempt 0, stage 5.0)
[2025-07-19T20:31:03.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 122.0 in stage 5.0 (TID 484) (8b44f3d35cfa, executor driver, partition 122, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 122.0 in stage 5.0 (TID 484)
[2025-07-19T20:31:03.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 117.0 in stage 5.0 (TID 479) in 201 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:31:03.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 113 (task 478, attempt 0, stage 5.0)
[2025-07-19T20:31:03.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 113.0 in stage 5.0 (TID 478). 9095 bytes result sent to driver
[2025-07-19T20:31:03.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 113.0 in stage 5.0 (TID 478) in 214 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:31:03.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 123.0 in stage 5.0 (TID 485) (8b44f3d35cfa, executor driver, partition 123, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 123.0 in stage 5.0 (TID 485)
[2025-07-19T20:31:03.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b293266
[2025-07-19T20:31:03.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.1.delta.c017a6d0-ddd0-4df9-aed0-4aa489f5b458.TID476.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta
[2025-07-19T20:31:03.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/110/1.delta
[2025-07-19T20:31:03.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 476, attempt 0, stage 5.0)
[2025-07-19T20:31:03.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121] for update
[2025-07-19T20:31:03.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6759cc3b
[2025-07-19T20:31:03.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122] for update
[2025-07-19T20:31:03.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.1.delta.2136bf05-7be3-4ca5-b7e3-ed05644bf08d.TID481.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta
[2025-07-19T20:31:03.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/119/1.delta
[2025-07-19T20:31:03.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.456+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 481, attempt 0, stage 5.0)
[2025-07-19T20:31:03.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 111 (task 477, attempt 0, stage 5.0)
[2025-07-19T20:31:03.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 111.0 in stage 5.0 (TID 477). 9094 bytes result sent to driver
[2025-07-19T20:31:03.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 127.0 in stage 5.0 (TID 486) (8b44f3d35cfa, executor driver, partition 127, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 111.0 in stage 5.0 (TID 477) in 246 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:31:03.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 110 (task 476, attempt 0, stage 5.0)
[2025-07-19T20:31:03.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 110.0 in stage 5.0 (TID 476). 9061 bytes result sent to driver
[2025-07-19T20:31:03.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 127.0 in stage 5.0 (TID 486)
[2025-07-19T20:31:03.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 128.0 in stage 5.0 (TID 487) (8b44f3d35cfa, executor driver, partition 128, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 128.0 in stage 5.0 (TID 487)
[2025-07-19T20:31:03.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@cf2b9f5
[2025-07-19T20:31:03.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123] for update
[2025-07-19T20:31:03.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 110.0 in stage 5.0 (TID 476) in 252 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:31:03.476+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:03.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.482+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.1.delta.bf4f80cd-994d-48f4-b7b3-cfe64e72ea8f.TID483.tmp
[2025-07-19T20:31:03.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@116f1367
[2025-07-19T20:31:03.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.486+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127] for update
[2025-07-19T20:31:03.486+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.1.delta.ef19dfce-1fb6-4c35-ae11-bf7243af8347.TID480.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta
[2025-07-19T20:31:03.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/118/1.delta
[2025-07-19T20:31:03.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 480, attempt 0, stage 5.0)
[2025-07-19T20:31:03.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.1.delta.5c83c852-fa83-4c88-a074-3936db494e8e.TID484.tmp
[2025-07-19T20:31:03.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.1.delta.643abb28-2a2d-4e07-b62c-ca750b4e4042.TID485.tmp
[2025-07-19T20:31:03.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@107d1c4e
[2025-07-19T20:31:03.504+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 119 (task 481, attempt 0, stage 5.0)
[2025-07-19T20:31:03.507+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128] for update
[2025-07-19T20:31:03.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 119.0 in stage 5.0 (TID 481). 9080 bytes result sent to driver
[2025-07-19T20:31:03.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 118 (task 480, attempt 0, stage 5.0)
[2025-07-19T20:31:03.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 129.0 in stage 5.0 (TID 488) (8b44f3d35cfa, executor driver, partition 129, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 129.0 in stage 5.0 (TID 488)
[2025-07-19T20:31:03.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 118.0 in stage 5.0 (TID 480). 9078 bytes result sent to driver
[2025-07-19T20:31:03.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.1.delta.f2ec6aa7-7e6d-48f6-b93c-61e11d22e642.TID482.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta
[2025-07-19T20:31:03.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/120/1.delta
[2025-07-19T20:31:03.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.1.delta.18cc8ab3-fef1-4e41-b0e9-35b48722ba23.TID486.tmp
[2025-07-19T20:31:03.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 119.0 in stage 5.0 (TID 481) in 246 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:31:03.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.524+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 130.0 in stage 5.0 (TID 489) (8b44f3d35cfa, executor driver, partition 130, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 130.0 in stage 5.0 (TID 489)
[2025-07-19T20:31:03.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 118.0 in stage 5.0 (TID 480) in 272 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:31:03.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 482, attempt 0, stage 5.0)
[2025-07-19T20:31:03.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@bb076df
[2025-07-19T20:31:03.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130] for update
[2025-07-19T20:31:03.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.1.delta.fcde9494-91dc-40cb-a528-b2878b8ebf8a.TID487.tmp
[2025-07-19T20:31:03.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 120 (task 482, attempt 0, stage 5.0)
[2025-07-19T20:31:03.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 120.0 in stage 5.0 (TID 482). 9121 bytes result sent to driver
[2025-07-19T20:31:03.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 131.0 in stage 5.0 (TID 490) (8b44f3d35cfa, executor driver, partition 131, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 131.0 in stage 5.0 (TID 490)
[2025-07-19T20:31:03.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 120.0 in stage 5.0 (TID 482) in 283 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:31:03.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20ad308f
[2025-07-19T20:31:03.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.1.delta.dd1485d4-2270-456c-9655-7dea6e0d445e.TID489.tmp
[2025-07-19T20:31:03.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129] for update
[2025-07-19T20:31:03.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.1.delta.bf4f80cd-994d-48f4-b7b3-cfe64e72ea8f.TID483.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta
[2025-07-19T20:31:03.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/121/1.delta
[2025-07-19T20:31:03.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 483, attempt 0, stage 5.0)
[2025-07-19T20:31:03.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@133e9376
[2025-07-19T20:31:03.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131] for update
[2025-07-19T20:31:03.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.1.delta.643abb28-2a2d-4e07-b62c-ca750b4e4042.TID485.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta
[2025-07-19T20:31:03.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/123/1.delta
[2025-07-19T20:31:03.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 485, attempt 0, stage 5.0)
[2025-07-19T20:31:03.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.1.delta.77b722fc-3b66-47bf-9984-dd5637531e8d.TID488.tmp
[2025-07-19T20:31:03.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.1.delta.5c83c852-fa83-4c88-a074-3936db494e8e.TID484.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta
[2025-07-19T20:31:03.617+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/122/1.delta
[2025-07-19T20:31:03.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 484, attempt 0, stage 5.0)
[2025-07-19T20:31:03.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.1.delta.7271603f-71df-4465-9603-54b72f528a9a.TID490.tmp
[2025-07-19T20:31:03.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 121 (task 483, attempt 0, stage 5.0)
[2025-07-19T20:31:03.639+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 121.0 in stage 5.0 (TID 483). 9078 bytes result sent to driver
[2025-07-19T20:31:03.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 133.0 in stage 5.0 (TID 491) (8b44f3d35cfa, executor driver, partition 133, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 133.0 in stage 5.0 (TID 491)
[2025-07-19T20:31:03.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 121.0 in stage 5.0 (TID 483) in 237 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:31:03.649+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:03.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 123 (task 485, attempt 0, stage 5.0)
[2025-07-19T20:31:03.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 123.0 in stage 5.0 (TID 485). 9072 bytes result sent to driver
[2025-07-19T20:31:03.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 122 (task 484, attempt 0, stage 5.0)
[2025-07-19T20:31:03.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 122.0 in stage 5.0 (TID 484). 9061 bytes result sent to driver
[2025-07-19T20:31:03.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 135.0 in stage 5.0 (TID 492) (8b44f3d35cfa, executor driver, partition 135, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 136.0 in stage 5.0 (TID 493) (8b44f3d35cfa, executor driver, partition 136, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 135.0 in stage 5.0 (TID 492)
[2025-07-19T20:31:03.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 136.0 in stage 5.0 (TID 493)
[2025-07-19T20:31:03.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 123.0 in stage 5.0 (TID 485) in 234 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:31:03.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 122.0 in stage 5.0 (TID 484) in 243 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:31:03.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49c60add
[2025-07-19T20:31:03.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133] for update
[2025-07-19T20:31:03.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.1.delta.fcde9494-91dc-40cb-a528-b2878b8ebf8a.TID487.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta
[2025-07-19T20:31:03.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/128/1.delta
[2025-07-19T20:31:03.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 487, attempt 0, stage 5.0)
[2025-07-19T20:31:03.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.1.delta.18cc8ab3-fef1-4e41-b0e9-35b48722ba23.TID486.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta
[2025-07-19T20:31:03.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/127/1.delta
[2025-07-19T20:31:03.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 486, attempt 0, stage 5.0)
[2025-07-19T20:31:03.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fea55c
[2025-07-19T20:31:03.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 128 (task 487, attempt 0, stage 5.0)
[2025-07-19T20:31:03.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 128.0 in stage 5.0 (TID 487). 9068 bytes result sent to driver
[2025-07-19T20:31:03.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 137.0 in stage 5.0 (TID 494) (8b44f3d35cfa, executor driver, partition 137, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 137.0 in stage 5.0 (TID 494)
[2025-07-19T20:31:03.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.708+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136] for update
[2025-07-19T20:31:03.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 128.0 in stage 5.0 (TID 487) in 241 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:31:03.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.1.delta.dd1485d4-2270-456c-9655-7dea6e0d445e.TID489.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta
[2025-07-19T20:31:03.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/130/1.delta
[2025-07-19T20:31:03.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.1.delta.77b722fc-3b66-47bf-9984-dd5637531e8d.TID488.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta
[2025-07-19T20:31:03.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/129/1.delta
[2025-07-19T20:31:03.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 488, attempt 0, stage 5.0)
[2025-07-19T20:31:03.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 489, attempt 0, stage 5.0)
[2025-07-19T20:31:03.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.1.delta.d537c958-7332-46b3-97a9-70330557132f.TID491.tmp
[2025-07-19T20:31:03.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2da4c242
[2025-07-19T20:31:03.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135] for update
[2025-07-19T20:31:03.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 127 (task 486, attempt 0, stage 5.0)
[2025-07-19T20:31:03.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.729+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 127.0 in stage 5.0 (TID 486). 9068 bytes result sent to driver
[2025-07-19T20:31:03.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 138.0 in stage 5.0 (TID 495) (8b44f3d35cfa, executor driver, partition 138, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 127.0 in stage 5.0 (TID 486) in 284 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:31:03.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 138.0 in stage 5.0 (TID 495)
[2025-07-19T20:31:03.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.1.delta.7271603f-71df-4465-9603-54b72f528a9a.TID490.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta
[2025-07-19T20:31:03.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/131/1.delta
[2025-07-19T20:31:03.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 130 (task 489, attempt 0, stage 5.0)
[2025-07-19T20:31:03.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 130.0 in stage 5.0 (TID 489). 9092 bytes result sent to driver
[2025-07-19T20:31:03.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 490, attempt 0, stage 5.0)
[2025-07-19T20:31:03.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.742+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a671af4
[2025-07-19T20:31:03.742+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 140.0 in stage 5.0 (TID 496) (8b44f3d35cfa, executor driver, partition 140, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 140.0 in stage 5.0 (TID 496)
[2025-07-19T20:31:03.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.1.delta.96271673-8634-46c5-afe7-b46d4731437e.TID493.tmp
[2025-07-19T20:31:03.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.759+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.1.delta.d38eaaf4-f445-40b4-89d4-1ff87264a77b.TID492.tmp
[2025-07-19T20:31:03.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 130.0 in stage 5.0 (TID 489) in 233 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:31:03.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.765+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137] for update
[2025-07-19T20:31:03.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 129 (task 488, attempt 0, stage 5.0)
[2025-07-19T20:31:03.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 129.0 in stage 5.0 (TID 488). 9087 bytes result sent to driver
[2025-07-19T20:31:03.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 144.0 in stage 5.0 (TID 497) (8b44f3d35cfa, executor driver, partition 144, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 129.0 in stage 5.0 (TID 488) in 244 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:31:03.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 144.0 in stage 5.0 (TID 497)
[2025-07-19T20:31:03.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a620a6c
[2025-07-19T20:31:03.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140] for update
[2025-07-19T20:31:03.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.1.delta.28706005-4445-41b5-8d07-d3b4bedee81e.TID494.tmp
[2025-07-19T20:31:03.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f4eb986
[2025-07-19T20:31:03.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138] for update
[2025-07-19T20:31:03.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 131 (task 490, attempt 0, stage 5.0)
[2025-07-19T20:31:03.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.1.delta.3b37f29a-9302-4a28-97d2-959ccecc7ceb.TID496.tmp
[2025-07-19T20:31:03.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 131.0 in stage 5.0 (TID 490). 9089 bytes result sent to driver
[2025-07-19T20:31:03.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 145.0 in stage 5.0 (TID 498) (8b44f3d35cfa, executor driver, partition 145, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 145.0 in stage 5.0 (TID 498)
[2025-07-19T20:31:03.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 131.0 in stage 5.0 (TID 490) in 226 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:31:03.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@523aa00
[2025-07-19T20:31:03.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.1.delta.5c46826f-eb30-46c0-b022-19d33c96703a.TID495.tmp
[2025-07-19T20:31:03.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.1.delta.d537c958-7332-46b3-97a9-70330557132f.TID491.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta
[2025-07-19T20:31:03.801+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/133/1.delta
[2025-07-19T20:31:03.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144] for update
[2025-07-19T20:31:03.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 491, attempt 0, stage 5.0)
[2025-07-19T20:31:03.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4970600
[2025-07-19T20:31:03.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145] for update
[2025-07-19T20:31:03.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.1.delta.d38eaaf4-f445-40b4-89d4-1ff87264a77b.TID492.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta
[2025-07-19T20:31:03.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/135/1.delta
[2025-07-19T20:31:03.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 492, attempt 0, stage 5.0)
[2025-07-19T20:31:03.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.1.delta.96271673-8634-46c5-afe7-b46d4731437e.TID493.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta
[2025-07-19T20:31:03.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/136/1.delta
[2025-07-19T20:31:03.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.1.delta.adad27f6-3057-41d5-b7b0-20dfff8e94ff.TID497.tmp
[2025-07-19T20:31:03.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 493, attempt 0, stage 5.0)
[2025-07-19T20:31:03.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.1.delta.28706005-4445-41b5-8d07-d3b4bedee81e.TID494.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta
[2025-07-19T20:31:03.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/137/1.delta
[2025-07-19T20:31:03.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.1.delta.a49c03a5-9289-4a5b-8796-d815ff624e88.TID498.tmp
[2025-07-19T20:31:03.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 494, attempt 0, stage 5.0)
[2025-07-19T20:31:03.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 133 (task 491, attempt 0, stage 5.0)
[2025-07-19T20:31:03.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 133.0 in stage 5.0 (TID 491). 9078 bytes result sent to driver
[2025-07-19T20:31:03.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 149.0 in stage 5.0 (TID 499) (8b44f3d35cfa, executor driver, partition 149, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 135 (task 492, attempt 0, stage 5.0)
[2025-07-19T20:31:03.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 133.0 in stage 5.0 (TID 491) in 203 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:31:03.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 149.0 in stage 5.0 (TID 499)
[2025-07-19T20:31:03.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 136 (task 493, attempt 0, stage 5.0)
[2025-07-19T20:31:03.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 135.0 in stage 5.0 (TID 492). 9123 bytes result sent to driver
[2025-07-19T20:31:03.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 136.0 in stage 5.0 (TID 493). 9121 bytes result sent to driver
[2025-07-19T20:31:03.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 150.0 in stage 5.0 (TID 500) (8b44f3d35cfa, executor driver, partition 150, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 153.0 in stage 5.0 (TID 501) (8b44f3d35cfa, executor driver, partition 153, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 153.0 in stage 5.0 (TID 501)
[2025-07-19T20:31:03.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 136.0 in stage 5.0 (TID 493) in 198 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:31:03.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 135.0 in stage 5.0 (TID 492) in 200 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:31:03.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 150.0 in stage 5.0 (TID 500)
[2025-07-19T20:31:03.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:03.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 137 (task 494, attempt 0, stage 5.0)
[2025-07-19T20:31:03.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 137.0 in stage 5.0 (TID 494). 9095 bytes result sent to driver
[2025-07-19T20:31:03.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 154.0 in stage 5.0 (TID 502) (8b44f3d35cfa, executor driver, partition 154, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 154.0 in stage 5.0 (TID 502)
[2025-07-19T20:31:03.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 137.0 in stage 5.0 (TID 494) in 172 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:31:03.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52e6289c
[2025-07-19T20:31:03.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149] for update
[2025-07-19T20:31:03.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.1.delta.3b37f29a-9302-4a28-97d2-959ccecc7ceb.TID496.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta
[2025-07-19T20:31:03.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/140/1.delta
[2025-07-19T20:31:03.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 496, attempt 0, stage 5.0)
[2025-07-19T20:31:03.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.1.delta.5c46826f-eb30-46c0-b022-19d33c96703a.TID495.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta
[2025-07-19T20:31:03.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/138/1.delta
[2025-07-19T20:31:03.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 495, attempt 0, stage 5.0)
[2025-07-19T20:31:03.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.1.delta.529cbe31-192a-4f76-a4cc-9efe547a5b27.TID499.tmp
[2025-07-19T20:31:03.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30dccf1c
[2025-07-19T20:31:03.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150] for update
[2025-07-19T20:31:03.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.1.delta.adad27f6-3057-41d5-b7b0-20dfff8e94ff.TID497.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta
[2025-07-19T20:31:03.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/144/1.delta
[2025-07-19T20:31:03.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 497, attempt 0, stage 5.0)
[2025-07-19T20:31:03.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 140 (task 496, attempt 0, stage 5.0)
[2025-07-19T20:31:03.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 140.0 in stage 5.0 (TID 496). 9082 bytes result sent to driver
[2025-07-19T20:31:03.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 155.0 in stage 5.0 (TID 503) (8b44f3d35cfa, executor driver, partition 155, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 140.0 in stage 5.0 (TID 496) in 147 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:31:03.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6d504595
[2025-07-19T20:31:03.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 155.0 in stage 5.0 (TID 503)
[2025-07-19T20:31:03.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.1.delta.c02ff3a7-341b-4ed1-8793-185046bc5ebd.TID500.tmp
[2025-07-19T20:31:03.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153] for update
[2025-07-19T20:31:03.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.1.delta.a49c03a5-9289-4a5b-8796-d815ff624e88.TID498.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta
[2025-07-19T20:31:03.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/145/1.delta
[2025-07-19T20:31:03.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 498, attempt 0, stage 5.0)
[2025-07-19T20:31:03.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 138 (task 495, attempt 0, stage 5.0)
[2025-07-19T20:31:03.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20e92bf5
[2025-07-19T20:31:03.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 138.0 in stage 5.0 (TID 495). 9087 bytes result sent to driver
[2025-07-19T20:31:03.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154] for update
[2025-07-19T20:31:03.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:03.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 158.0 in stage 5.0 (TID 504) (8b44f3d35cfa, executor driver, partition 158, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 138.0 in stage 5.0 (TID 495) in 170 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:31:03.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 158.0 in stage 5.0 (TID 504)
[2025-07-19T20:31:03.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.927+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@ef286a7
[2025-07-19T20:31:03.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155] for update
[2025-07-19T20:31:03.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.1.delta.9b02f953-f721-40ff-9173-d5c5b76a8df4.TID501.tmp
[2025-07-19T20:31:03.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.1.delta.3277207c-a383-4459-b7fc-e443ef776ff1.TID502.tmp
[2025-07-19T20:31:03.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 144 (task 497, attempt 0, stage 5.0)
[2025-07-19T20:31:03.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 144.0 in stage 5.0 (TID 497). 9074 bytes result sent to driver
[2025-07-19T20:31:03.932+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Committed partition 145 (task 498, attempt 0, stage 5.0)
[2025-07-19T20:31:03.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@fd6c8cf
[2025-07-19T20:31:03.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 159.0 in stage 5.0 (TID 505) (8b44f3d35cfa, executor driver, partition 159, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158] for update
[2025-07-19T20:31:03.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 159.0 in stage 5.0 (TID 505)
[2025-07-19T20:31:03.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 144.0 in stage 5.0 (TID 497) in 170 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:31:03.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Finished task 145.0 in stage 5.0 (TID 498). 9091 bytes result sent to driver
[2025-07-19T20:31:03.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Starting task 160.0 in stage 5.0 (TID 506) (8b44f3d35cfa, executor driver, partition 160, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:03.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO Executor: Running task 160.0 in stage 5.0 (TID 506)
[2025-07-19T20:31:03.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO TaskSetManager: Finished task 145.0 in stage 5.0 (TID 498) in 138 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:31:03.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:03.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:03.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.1.delta.fac4edba-5bb3-413c-b3f3-c20c2d48e707.TID504.tmp
[2025-07-19T20:31:03.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f4969f6
[2025-07-19T20:31:03.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159] for update
[2025-07-19T20:31:03.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.1.delta.d06bdd39-0994-4188-baa3-4624caa7496a.TID503.tmp
[2025-07-19T20:31:03.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.1.delta.529cbe31-192a-4f76-a4cc-9efe547a5b27.TID499.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta
[2025-07-19T20:31:03.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/149/1.delta
[2025-07-19T20:31:03.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 499, attempt 0, stage 5.0)
[2025-07-19T20:31:03.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.1.delta.c02ff3a7-341b-4ed1-8793-185046bc5ebd.TID500.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta
[2025-07-19T20:31:03.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/150/1.delta
[2025-07-19T20:31:03.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 500, attempt 0, stage 5.0)
[2025-07-19T20:31:03.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bc5bffd
[2025-07-19T20:31:03.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:03.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160] for update
[2025-07-19T20:31:03.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:03.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.1.delta.3e7b83c6-af05-4a79-9eef-e8e31ac1cc32.TID505.tmp
[2025-07-19T20:31:04.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.1.delta.3277207c-a383-4459-b7fc-e443ef776ff1.TID502.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta
[2025-07-19T20:31:04.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/154/1.delta
[2025-07-19T20:31:04.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.1.delta.dfd9f59b-25f5-49e8-b90e-f680b6333b98.TID506.tmp
[2025-07-19T20:31:04.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:03 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 502, attempt 0, stage 5.0)
[2025-07-19T20:31:04.046+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.1.delta.9b02f953-f721-40ff-9173-d5c5b76a8df4.TID501.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta
[2025-07-19T20:31:04.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.1.delta.fac4edba-5bb3-413c-b3f3-c20c2d48e707.TID504.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta
[2025-07-19T20:31:04.050+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/158/1.delta
[2025-07-19T20:31:04.052+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/153/1.delta
[2025-07-19T20:31:04.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 501, attempt 0, stage 5.0)
[2025-07-19T20:31:04.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 150 (task 500, attempt 0, stage 5.0)
[2025-07-19T20:31:04.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 504, attempt 0, stage 5.0)
[2025-07-19T20:31:04.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 150.0 in stage 5.0 (TID 500). 9083 bytes result sent to driver
[2025-07-19T20:31:04.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 149 (task 499, attempt 0, stage 5.0)
[2025-07-19T20:31:04.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 149.0 in stage 5.0 (TID 499). 9099 bytes result sent to driver
[2025-07-19T20:31:04.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 161.0 in stage 5.0 (TID 507) (8b44f3d35cfa, executor driver, partition 161, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 150.0 in stage 5.0 (TID 500) in 200 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:31:04.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 161.0 in stage 5.0 (TID 507)
[2025-07-19T20:31:04.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 162.0 in stage 5.0 (TID 508) (8b44f3d35cfa, executor driver, partition 162, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 149.0 in stage 5.0 (TID 499) in 219 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:31:04.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 162.0 in stage 5.0 (TID 508)
[2025-07-19T20:31:04.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:04.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 153 (task 501, attempt 0, stage 5.0)
[2025-07-19T20:31:04.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 154 (task 502, attempt 0, stage 5.0)
[2025-07-19T20:31:04.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 153.0 in stage 5.0 (TID 501). 9082 bytes result sent to driver
[2025-07-19T20:31:04.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 154.0 in stage 5.0 (TID 502). 9099 bytes result sent to driver
[2025-07-19T20:31:04.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 163.0 in stage 5.0 (TID 509) (8b44f3d35cfa, executor driver, partition 163, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 165.0 in stage 5.0 (TID 510) (8b44f3d35cfa, executor driver, partition 165, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.067+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 163.0 in stage 5.0 (TID 509)
[2025-07-19T20:31:04.067+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 165.0 in stage 5.0 (TID 510)
[2025-07-19T20:31:04.067+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.1.delta.d06bdd39-0994-4188-baa3-4624caa7496a.TID503.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta
[2025-07-19T20:31:04.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/155/1.delta
[2025-07-19T20:31:04.069+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:31:04.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (251.0 B) non-empty blocks including 1 (251.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 153.0 in stage 5.0 (TID 501) in 214 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:31:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 154.0 in stage 5.0 (TID 502) in 208 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:31:04.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 158 (task 504, attempt 0, stage 5.0)
[2025-07-19T20:31:04.072+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 503, attempt 0, stage 5.0)
[2025-07-19T20:31:04.072+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@132572fe
[2025-07-19T20:31:04.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 158.0 in stage 5.0 (TID 504). 9085 bytes result sent to driver
[2025-07-19T20:31:04.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 169.0 in stage 5.0 (TID 511) (8b44f3d35cfa, executor driver, partition 169, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161] for update
[2025-07-19T20:31:04.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 169.0 in stage 5.0 (TID 511)
[2025-07-19T20:31:04.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 158.0 in stage 5.0 (TID 504) in 180 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:31:04.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f98ced7
[2025-07-19T20:31:04.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162] for update
[2025-07-19T20:31:04.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 155 (task 503, attempt 0, stage 5.0)
[2025-07-19T20:31:04.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 155.0 in stage 5.0 (TID 503). 9093 bytes result sent to driver
[2025-07-19T20:31:04.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.1.delta.dfd9f59b-25f5-49e8-b90e-f680b6333b98.TID506.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta
[2025-07-19T20:31:04.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/160/1.delta
[2025-07-19T20:31:04.091+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 170.0 in stage 5.0 (TID 512) (8b44f3d35cfa, executor driver, partition 170, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 155.0 in stage 5.0 (TID 503) in 206 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:31:04.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 170.0 in stage 5.0 (TID 512)
[2025-07-19T20:31:04.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.1.delta.3e7b83c6-af05-4a79-9eef-e8e31ac1cc32.TID505.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta
[2025-07-19T20:31:04.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/159/1.delta
[2025-07-19T20:31:04.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.1.delta.9554daba-8b79-400e-b957-54e3b1d02c0f.TID507.tmp
[2025-07-19T20:31:04.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@422ffaeb
[2025-07-19T20:31:04.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165] for update
[2025-07-19T20:31:04.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 506, attempt 0, stage 5.0)
[2025-07-19T20:31:04.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 505, attempt 0, stage 5.0)
[2025-07-19T20:31:04.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.1.delta.a75d87ab-413f-4767-9637-5344d00cf327.TID508.tmp
[2025-07-19T20:31:04.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@66202ed4
[2025-07-19T20:31:04.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163] for update
[2025-07-19T20:31:04.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.1.delta.a90e55f0-a4b3-495b-bbca-2d422567819b.TID510.tmp
[2025-07-19T20:31:04.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 160 (task 506, attempt 0, stage 5.0)
[2025-07-19T20:31:04.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a43ba6
[2025-07-19T20:31:04.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 160.0 in stage 5.0 (TID 506). 9083 bytes result sent to driver
[2025-07-19T20:31:04.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.1.delta.4fe42dde-6473-4156-9218-03a945055680.TID509.tmp
[2025-07-19T20:31:04.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 159 (task 505, attempt 0, stage 5.0)
[2025-07-19T20:31:04.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 159.0 in stage 5.0 (TID 505). 9080 bytes result sent to driver
[2025-07-19T20:31:04.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170] for update
[2025-07-19T20:31:04.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 172.0 in stage 5.0 (TID 513) (8b44f3d35cfa, executor driver, partition 172, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 174.0 in stage 5.0 (TID 514) (8b44f3d35cfa, executor driver, partition 174, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 172.0 in stage 5.0 (TID 513)
[2025-07-19T20:31:04.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 160.0 in stage 5.0 (TID 506) in 208 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:31:04.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 159.0 in stage 5.0 (TID 505) in 212 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:31:04.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 174.0 in stage 5.0 (TID 514)
[2025-07-19T20:31:04.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5617e0f4
[2025-07-19T20:31:04.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169] for update
[2025-07-19T20:31:04.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.1.delta.b1ba0edf-f219-4f44-8dc6-e2c5501e18e0.TID512.tmp
[2025-07-19T20:31:04.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.1.delta.9554daba-8b79-400e-b957-54e3b1d02c0f.TID507.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta
[2025-07-19T20:31:04.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/161/1.delta
[2025-07-19T20:31:04.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 507, attempt 0, stage 5.0)
[2025-07-19T20:31:04.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.1.delta.38403cb1-8b3a-4f47-9f26-d4456df69c7d.TID511.tmp
[2025-07-19T20:31:04.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31e99c6f
[2025-07-19T20:31:04.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174] for update
[2025-07-19T20:31:04.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.1.delta.a75d87ab-413f-4767-9637-5344d00cf327.TID508.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta
[2025-07-19T20:31:04.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/162/1.delta
[2025-07-19T20:31:04.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 508, attempt 0, stage 5.0)
[2025-07-19T20:31:04.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.1.delta.a90e55f0-a4b3-495b-bbca-2d422567819b.TID510.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta
[2025-07-19T20:31:04.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/165/1.delta
[2025-07-19T20:31:04.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 510, attempt 0, stage 5.0)
[2025-07-19T20:31:04.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71ccdd8f
[2025-07-19T20:31:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172] for update
[2025-07-19T20:31:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.1.delta.2d79948a-e68d-4970-8d1c-698ca070c6c3.TID514.tmp
[2025-07-19T20:31:04.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.1.delta.4fe42dde-6473-4156-9218-03a945055680.TID509.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta
[2025-07-19T20:31:04.182+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/163/1.delta
[2025-07-19T20:31:04.182+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 509, attempt 0, stage 5.0)
[2025-07-19T20:31:04.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 162 (task 508, attempt 0, stage 5.0)
[2025-07-19T20:31:04.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 162.0 in stage 5.0 (TID 508). 9033 bytes result sent to driver
[2025-07-19T20:31:04.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 175.0 in stage 5.0 (TID 515) (8b44f3d35cfa, executor driver, partition 175, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 162.0 in stage 5.0 (TID 508) in 130 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:31:04.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 175.0 in stage 5.0 (TID 515)
[2025-07-19T20:31:04.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.1.delta.b1ba0edf-f219-4f44-8dc6-e2c5501e18e0.TID512.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta
[2025-07-19T20:31:04.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/170/1.delta
[2025-07-19T20:31:04.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 161 (task 507, attempt 0, stage 5.0)
[2025-07-19T20:31:04.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.1.delta.1ca1b0ba-8e79-43ac-a106-34bbd3ff1b30.TID513.tmp
[2025-07-19T20:31:04.191+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 161.0 in stage 5.0 (TID 507). 9035 bytes result sent to driver
[2025-07-19T20:31:04.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 177.0 in stage 5.0 (TID 516) (8b44f3d35cfa, executor driver, partition 177, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 177.0 in stage 5.0 (TID 516)
[2025-07-19T20:31:04.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 165 (task 510, attempt 0, stage 5.0)
[2025-07-19T20:31:04.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 512, attempt 0, stage 5.0)
[2025-07-19T20:31:04.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 165.0 in stage 5.0 (TID 510). 9073 bytes result sent to driver
[2025-07-19T20:31:04.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41991ba2
[2025-07-19T20:31:04.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175] for update
[2025-07-19T20:31:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 163 (task 509, attempt 0, stage 5.0)
[2025-07-19T20:31:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 178.0 in stage 5.0 (TID 517) (8b44f3d35cfa, executor driver, partition 178, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 163.0 in stage 5.0 (TID 509). 9050 bytes result sent to driver
[2025-07-19T20:31:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
[2025-07-19T20:31:04.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 179.0 in stage 5.0 (TID 518) (8b44f3d35cfa, executor driver, partition 179, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 178.0 in stage 5.0 (TID 517)
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 165.0 in stage 5.0 (TID 510) in 140 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 179.0 in stage 5.0 (TID 518)
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 163.0 in stage 5.0 (TID 509) in 145 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 161.0 in stage 5.0 (TID 507) in 157 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18bac409
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.1.delta.38403cb1-8b3a-4f47-9f26-d4456df69c7d.TID511.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta
[2025-07-19T20:31:04.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177] for update
[2025-07-19T20:31:04.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/169/1.delta
[2025-07-19T20:31:04.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 511, attempt 0, stage 5.0)
[2025-07-19T20:31:04.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.1.delta.0a69febe-6a48-4a27-8af1-bc4d9e713728.TID515.tmp
[2025-07-19T20:31:04.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54bf700
[2025-07-19T20:31:04.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178] for update
[2025-07-19T20:31:04.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 27 ms
[2025-07-19T20:31:04.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 170 (task 512, attempt 0, stage 5.0)
[2025-07-19T20:31:04.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 170.0 in stage 5.0 (TID 512). 9082 bytes result sent to driver
[2025-07-19T20:31:04.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 180.0 in stage 5.0 (TID 519) (8b44f3d35cfa, executor driver, partition 180, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 180.0 in stage 5.0 (TID 519)
[2025-07-19T20:31:04.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 170.0 in stage 5.0 (TID 512) in 155 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:31:04.247+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (304.0 B) non-empty blocks including 1 (304.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.1.delta.a01117e7-c8df-45ee-a35d-9c5d7639363a.TID516.tmp
[2025-07-19T20:31:04.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e3a7d4d
[2025-07-19T20:31:04.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179] for update
[2025-07-19T20:31:04.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.1.delta.1ca1b0ba-8e79-43ac-a106-34bbd3ff1b30.TID513.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta
[2025-07-19T20:31:04.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/172/1.delta
[2025-07-19T20:31:04.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.1.delta.2d79948a-e68d-4970-8d1c-698ca070c6c3.TID514.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta
[2025-07-19T20:31:04.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/174/1.delta
[2025-07-19T20:31:04.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 513, attempt 0, stage 5.0)
[2025-07-19T20:31:04.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 169 (task 511, attempt 0, stage 5.0)
[2025-07-19T20:31:04.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 169.0 in stage 5.0 (TID 511). 9053 bytes result sent to driver
[2025-07-19T20:31:04.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 181.0 in stage 5.0 (TID 520) (8b44f3d35cfa, executor driver, partition 181, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 514, attempt 0, stage 5.0)
[2025-07-19T20:31:04.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 181.0 in stage 5.0 (TID 520)
[2025-07-19T20:31:04.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 169.0 in stage 5.0 (TID 511) in 182 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:31:04.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.1.delta.aba61ab7-1482-431f-a785-ac3308de135d.TID517.tmp
[2025-07-19T20:31:04.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@559ec47a
[2025-07-19T20:31:04.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180] for update
[2025-07-19T20:31:04.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.1.delta.b704adfe-046d-4de2-b698-3434d08606b8.TID518.tmp
[2025-07-19T20:31:04.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 174 (task 514, attempt 0, stage 5.0)
[2025-07-19T20:31:04.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 174.0 in stage 5.0 (TID 514). 9072 bytes result sent to driver
[2025-07-19T20:31:04.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 182.0 in stage 5.0 (TID 521) (8b44f3d35cfa, executor driver, partition 182, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 182.0 in stage 5.0 (TID 521)
[2025-07-19T20:31:04.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 174.0 in stage 5.0 (TID 514) in 145 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:31:04.279+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1416e0a1
[2025-07-19T20:31:04.279+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181] for update
[2025-07-19T20:31:04.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 172 (task 513, attempt 0, stage 5.0)
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 172.0 in stage 5.0 (TID 513). 9086 bytes result sent to driver
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 183.0 in stage 5.0 (TID 522) (8b44f3d35cfa, executor driver, partition 183, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 183.0 in stage 5.0 (TID 522)
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 172.0 in stage 5.0 (TID 513) in 150 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.1.delta.e85bfdbe-ffb6-4f74-a3e0-cc801e7519f6.TID519.tmp
[2025-07-19T20:31:04.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e0a0f25
[2025-07-19T20:31:04.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183] for update
[2025-07-19T20:31:04.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.1.delta.30424ebd-b880-48b8-a7b1-86bad0abdc8b.TID520.tmp
[2025-07-19T20:31:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.1.delta.0a69febe-6a48-4a27-8af1-bc4d9e713728.TID515.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta
[2025-07-19T20:31:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@310191e2
[2025-07-19T20:31:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/175/1.delta
[2025-07-19T20:31:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 515, attempt 0, stage 5.0)
[2025-07-19T20:31:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182] for update
[2025-07-19T20:31:04.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.1.delta.5328ac16-4299-470c-8e4b-78abab6b5c8b.TID522.tmp
[2025-07-19T20:31:04.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.1.delta.aba61ab7-1482-431f-a785-ac3308de135d.TID517.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta
[2025-07-19T20:31:04.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/178/1.delta
[2025-07-19T20:31:04.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.1.delta.a01117e7-c8df-45ee-a35d-9c5d7639363a.TID516.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta
[2025-07-19T20:31:04.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/177/1.delta
[2025-07-19T20:31:04.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 517, attempt 0, stage 5.0)
[2025-07-19T20:31:04.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 516, attempt 0, stage 5.0)
[2025-07-19T20:31:04.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.1.delta.e0759a34-5b25-41c8-9145-87c13bf8b776.TID521.tmp
[2025-07-19T20:31:04.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.1.delta.b704adfe-046d-4de2-b698-3434d08606b8.TID518.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta
[2025-07-19T20:31:04.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/179/1.delta
[2025-07-19T20:31:04.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 518, attempt 0, stage 5.0)
[2025-07-19T20:31:04.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 177 (task 516, attempt 0, stage 5.0)
[2025-07-19T20:31:04.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 177.0 in stage 5.0 (TID 516). 9087 bytes result sent to driver
[2025-07-19T20:31:04.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 178 (task 517, attempt 0, stage 5.0)
[2025-07-19T20:31:04.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 185.0 in stage 5.0 (TID 523) (8b44f3d35cfa, executor driver, partition 185, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.329+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 185.0 in stage 5.0 (TID 523)
[2025-07-19T20:31:04.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 175 (task 515, attempt 0, stage 5.0)
[2025-07-19T20:31:04.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 175.0 in stage 5.0 (TID 515). 9070 bytes result sent to driver
[2025-07-19T20:31:04.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 177.0 in stage 5.0 (TID 516) in 136 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:31:04.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 186.0 in stage 5.0 (TID 524) (8b44f3d35cfa, executor driver, partition 186, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 186.0 in stage 5.0 (TID 524)
[2025-07-19T20:31:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 178.0 in stage 5.0 (TID 517). 9072 bytes result sent to driver
[2025-07-19T20:31:04.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 188.0 in stage 5.0 (TID 525) (8b44f3d35cfa, executor driver, partition 188, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 188.0 in stage 5.0 (TID 525)
[2025-07-19T20:31:04.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 179 (task 518, attempt 0, stage 5.0)
[2025-07-19T20:31:04.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (276.0 B) non-empty blocks including 1 (276.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 179.0 in stage 5.0 (TID 518). 9096 bytes result sent to driver
[2025-07-19T20:31:04.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 190.0 in stage 5.0 (TID 526) (8b44f3d35cfa, executor driver, partition 190, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 175.0 in stage 5.0 (TID 515) in 150 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:31:04.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 178.0 in stage 5.0 (TID 517) in 132 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:31:04.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 179.0 in stage 5.0 (TID 518) in 131 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:31:04.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 190.0 in stage 5.0 (TID 526)
[2025-07-19T20:31:04.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.1.delta.e85bfdbe-ffb6-4f74-a3e0-cc801e7519f6.TID519.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta
[2025-07-19T20:31:04.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/180/1.delta
[2025-07-19T20:31:04.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1941b8a2
[2025-07-19T20:31:04.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 519, attempt 0, stage 5.0)
[2025-07-19T20:31:04.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185] for update
[2025-07-19T20:31:04.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.1.delta.30424ebd-b880-48b8-a7b1-86bad0abdc8b.TID520.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta
[2025-07-19T20:31:04.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/181/1.delta
[2025-07-19T20:31:04.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 520, attempt 0, stage 5.0)
[2025-07-19T20:31:04.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@be91916
[2025-07-19T20:31:04.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190] for update
[2025-07-19T20:31:04.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.1.delta.5328ac16-4299-470c-8e4b-78abab6b5c8b.TID522.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta
[2025-07-19T20:31:04.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/183/1.delta
[2025-07-19T20:31:04.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 522, attempt 0, stage 5.0)
[2025-07-19T20:31:04.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.1.delta.02332de6-d087-49f7-8648-d7cc4f6695ee.TID523.tmp
[2025-07-19T20:31:04.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.353+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3860a398
[2025-07-19T20:31:04.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186] for update
[2025-07-19T20:31:04.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.1.delta.e0759a34-5b25-41c8-9145-87c13bf8b776.TID521.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta
[2025-07-19T20:31:04.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/182/1.delta
[2025-07-19T20:31:04.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 521, attempt 0, stage 5.0)
[2025-07-19T20:31:04.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.1.delta.b110c520-92eb-4aa2-80f7-5b356bb76878.TID526.tmp
[2025-07-19T20:31:04.365+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13392045
[2025-07-19T20:31:04.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188] for update
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 180 (task 519, attempt 0, stage 5.0)
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 181 (task 520, attempt 0, stage 5.0)
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 180.0 in stage 5.0 (TID 519). 9100 bytes result sent to driver
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 181.0 in stage 5.0 (TID 520). 9080 bytes result sent to driver
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 192.0 in stage 5.0 (TID 527) (8b44f3d35cfa, executor driver, partition 192, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 195.0 in stage 5.0 (TID 528) (8b44f3d35cfa, executor driver, partition 195, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.369+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 192.0 in stage 5.0 (TID 527)
[2025-07-19T20:31:04.369+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 180.0 in stage 5.0 (TID 519) in 125 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:31:04.369+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 181.0 in stage 5.0 (TID 520) in 115 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:31:04.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 195.0 in stage 5.0 (TID 528)
[2025-07-19T20:31:04.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 183 (task 522, attempt 0, stage 5.0)
[2025-07-19T20:31:04.373+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.373+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.374+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 183.0 in stage 5.0 (TID 522). 9092 bytes result sent to driver
[2025-07-19T20:31:04.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.1.delta.d2a98fd3-1626-4747-a7eb-42224360db3d.TID524.tmp
[2025-07-19T20:31:04.377+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 199.0 in stage 5.0 (TID 529) (8b44f3d35cfa, executor driver, partition 199, NODE_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 199.0 in stage 5.0 (TID 529)
[2025-07-19T20:31:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 183.0 in stage 5.0 (TID 522) in 98 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:31:04.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12ed5b85
[2025-07-19T20:31:04.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 182 (task 521, attempt 0, stage 5.0)
[2025-07-19T20:31:04.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192] for update
[2025-07-19T20:31:04.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 182.0 in stage 5.0 (TID 521). 9074 bytes result sent to driver
[2025-07-19T20:31:04.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 530) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 182.0 in stage 5.0 (TID 521) in 104 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:31:04.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 0.0 in stage 5.0 (TID 530)
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.1.delta.f0eae007-f786-4aa4-b13d-f966608e041c.TID525.tmp
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bbb7c28
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195] for update
[2025-07-19T20:31:04.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.1.delta.ad76e0cf-ca9d-4174-a7d9-e1f6d4e5aebf.TID527.tmp
[2025-07-19T20:31:04.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.1.delta.02332de6-d087-49f7-8648-d7cc4f6695ee.TID523.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta
[2025-07-19T20:31:04.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/185/1.delta
[2025-07-19T20:31:04.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 523, attempt 0, stage 5.0)
[2025-07-19T20:31:04.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.1.delta.844597e7-c337-454e-b0cf-317612ad7b17.TID528.tmp
[2025-07-19T20:31:04.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/schema using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/.schema.b0be3b95-3001-498f-bb8d-95a3a4d1f35e.TID530.tmp
[2025-07-19T20:31:04.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.1.delta.b110c520-92eb-4aa2-80f7-5b356bb76878.TID526.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta
[2025-07-19T20:31:04.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/190/1.delta
[2025-07-19T20:31:04.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 526, attempt 0, stage 5.0)
[2025-07-19T20:31:04.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.1.delta.d2a98fd3-1626-4747-a7eb-42224360db3d.TID524.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta
[2025-07-19T20:31:04.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/186/1.delta
[2025-07-19T20:31:04.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 185 (task 523, attempt 0, stage 5.0)
[2025-07-19T20:31:04.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 524, attempt 0, stage 5.0)
[2025-07-19T20:31:04.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 185.0 in stage 5.0 (TID 523). 9068 bytes result sent to driver
[2025-07-19T20:31:04.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 531) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 2.0 in stage 5.0 (TID 531)
[2025-07-19T20:31:04.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 185.0 in stage 5.0 (TID 523) in 84 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:31:04.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.1.delta.f0eae007-f786-4aa4-b13d-f966608e041c.TID525.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta
[2025-07-19T20:31:04.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/188/1.delta
[2025-07-19T20:31:04.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 525, attempt 0, stage 5.0)
[2025-07-19T20:31:04.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 190 (task 526, attempt 0, stage 5.0)
[2025-07-19T20:31:04.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 190.0 in stage 5.0 (TID 526). 9091 bytes result sent to driver
[2025-07-19T20:31:04.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 190.0 in stage 5.0 (TID 526) in 86 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:31:04.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 532) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 8.0 in stage 5.0 (TID 532)
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 186 (task 524, attempt 0, stage 5.0)
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 186.0 in stage 5.0 (TID 524). 9067 bytes result sent to driver
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 533) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 10.0 in stage 5.0 (TID 533)
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 186.0 in stage 5.0 (TID 524) in 95 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.1.delta.ad76e0cf-ca9d-4174-a7d9-e1f6d4e5aebf.TID527.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/192/1.delta
[2025-07-19T20:31:04.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 527, attempt 0, stage 5.0)
[2025-07-19T20:31:04.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.1.delta.844597e7-c337-454e-b0cf-317612ad7b17.TID528.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta
[2025-07-19T20:31:04.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/195/1.delta
[2025-07-19T20:31:04.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 528, attempt 0, stage 5.0)
[2025-07-19T20:31:04.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 188 (task 525, attempt 0, stage 5.0)
[2025-07-19T20:31:04.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 188.0 in stage 5.0 (TID 525). 9095 bytes result sent to driver
[2025-07-19T20:31:04.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 534) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 13.0 in stage 5.0 (TID 534)
[2025-07-19T20:31:04.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 188.0 in stage 5.0 (TID 525) in 105 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:31:04.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/.schema.b0be3b95-3001-498f-bb8d-95a3a4d1f35e.TID530.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/_metadata/schema
[2025-07-19T20:31:04.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@489e2cd8
[2025-07-19T20:31:04.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0] for update
[2025-07-19T20:31:04.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.438+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 192 (task 527, attempt 0, stage 5.0)
[2025-07-19T20:31:04.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 192.0 in stage 5.0 (TID 527). 9044 bytes result sent to driver
[2025-07-19T20:31:04.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 535) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 195 (task 528, attempt 0, stage 5.0)
[2025-07-19T20:31:04.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e8e2c0e
[2025-07-19T20:31:04.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 192.0 in stage 5.0 (TID 527) in 73 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:31:04.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 195.0 in stage 5.0 (TID 528). 9037 bytes result sent to driver
[2025-07-19T20:31:04.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 17.0 in stage 5.0 (TID 536) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 15.0 in stage 5.0 (TID 535)
[2025-07-19T20:31:04.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199] for update
[2025-07-19T20:31:04.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 195.0 in stage 5.0 (TID 528) in 75 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:31:04.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.445+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 17.0 in stage 5.0 (TID 536)
[2025-07-19T20:31:04.445+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.1.delta.88133068-53c6-4258-9323-ee3acf728a25.TID530.tmp
[2025-07-19T20:31:04.445+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20caaf8b
[2025-07-19T20:31:04.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13] for update
[2025-07-19T20:31:04.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.1.delta.c65b06ed-fdf1-4fb6-9eb0-0ed0f61b308c.TID529.tmp
[2025-07-19T20:31:04.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd8d2af
[2025-07-19T20:31:04.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10] for update
[2025-07-19T20:31:04.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b45d456
[2025-07-19T20:31:04.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8] for update
[2025-07-19T20:31:04.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.1.delta.94d0a7c1-0f3f-455f-86f8-781dc83271a4.TID534.tmp
[2025-07-19T20:31:04.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.1.delta.c47783c6-30f2-46e8-907d-7b03aec49266.TID533.tmp
[2025-07-19T20:31:04.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35576690
[2025-07-19T20:31:04.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2] for update
[2025-07-19T20:31:04.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.1.delta.87827ced-ec08-4a85-ad94-fb807bc3a044.TID532.tmp
[2025-07-19T20:31:04.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@23aee88c
[2025-07-19T20:31:04.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15] for update
[2025-07-19T20:31:04.482+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.1.delta.88133068-53c6-4258-9323-ee3acf728a25.TID530.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta
[2025-07-19T20:31:04.482+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/0/1.delta
[2025-07-19T20:31:04.486+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 530, attempt 0, stage 5.0)
[2025-07-19T20:31:04.486+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.1.delta.30ddec82-304c-4dce-ae50-57f78d46c2a4.TID531.tmp
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2303b052
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17] for update
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 0 (task 530, attempt 0, stage 5.0)
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 530). 6243 bytes result sent to driver
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 27.0 in stage 5.0 (TID 537) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 27.0 in stage 5.0 (TID 537)
[2025-07-19T20:31:04.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 530) in 113 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:31:04.492+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.500+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.1.delta.c65b06ed-fdf1-4fb6-9eb0-0ed0f61b308c.TID529.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta
[2025-07-19T20:31:04.500+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/199/1.delta
[2025-07-19T20:31:04.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47b4b32b
[2025-07-19T20:31:04.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 529, attempt 0, stage 5.0)
[2025-07-19T20:31:04.504+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.1.delta.0464c5de-6b39-40d4-9ce2-8fa81230528c.TID535.tmp
[2025-07-19T20:31:04.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.1.delta.0360c04b-f4c9-4fb5-902b-0b2e8c3ddac4.TID536.tmp
[2025-07-19T20:31:04.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27] for update
[2025-07-19T20:31:04.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.1.delta.94d0a7c1-0f3f-455f-86f8-781dc83271a4.TID534.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta
[2025-07-19T20:31:04.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/13/1.delta
[2025-07-19T20:31:04.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 534, attempt 0, stage 5.0)
[2025-07-19T20:31:04.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 13 (task 534, attempt 0, stage 5.0)
[2025-07-19T20:31:04.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 13.0 in stage 5.0 (TID 534). 6243 bytes result sent to driver
[2025-07-19T20:31:04.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 28.0 in stage 5.0 (TID 538) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 28.0 in stage 5.0 (TID 538)
[2025-07-19T20:31:04.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 199 (task 529, attempt 0, stage 5.0)
[2025-07-19T20:31:04.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 199.0 in stage 5.0 (TID 529). 9070 bytes result sent to driver
[2025-07-19T20:31:04.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 31.0 in stage 5.0 (TID 539) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 31.0 in stage 5.0 (TID 539)
[2025-07-19T20:31:04.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 534) in 83 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:31:04.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 199.0 in stage 5.0 (TID 529) in 142 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:31:04.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.1.delta.c47783c6-30f2-46e8-907d-7b03aec49266.TID533.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta
[2025-07-19T20:31:04.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/10/1.delta
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 533, attempt 0, stage 5.0)
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.1.delta.87827ced-ec08-4a85-ad94-fb807bc3a044.TID532.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/8/1.delta
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d8bcf5d
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 532, attempt 0, stage 5.0)
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 10 (task 533, attempt 0, stage 5.0)
[2025-07-19T20:31:04.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28] for update
[2025-07-19T20:31:04.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 10.0 in stage 5.0 (TID 533). 6243 bytes result sent to driver
[2025-07-19T20:31:04.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 33.0 in stage 5.0 (TID 540) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 533) in 103 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:31:04.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 33.0 in stage 5.0 (TID 540)
[2025-07-19T20:31:04.530+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.1.delta.162d687d-04c5-4515-95bc-c8f0c8849bc0.TID537.tmp
[2025-07-19T20:31:04.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 8 (task 532, attempt 0, stage 5.0)
[2025-07-19T20:31:04.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 8.0 in stage 5.0 (TID 532). 6243 bytes result sent to driver
[2025-07-19T20:31:04.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 532) in 112 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:31:04.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 34.0 in stage 5.0 (TID 541) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 34.0 in stage 5.0 (TID 541)
[2025-07-19T20:31:04.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@41ff7b15
[2025-07-19T20:31:04.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31] for update
[2025-07-19T20:31:04.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.543+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.1.delta.ccc655cd-75e1-4f63-a4f1-aaf6460ab116.TID538.tmp
[2025-07-19T20:31:04.544+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fc4d20a
[2025-07-19T20:31:04.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34] for update
[2025-07-19T20:31:04.550+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.1.delta.30ddec82-304c-4dce-ae50-57f78d46c2a4.TID531.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta
[2025-07-19T20:31:04.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/2/1.delta
[2025-07-19T20:31:04.552+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.1.delta.0464c5de-6b39-40d4-9ce2-8fa81230528c.TID535.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta
[2025-07-19T20:31:04.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/15/1.delta
[2025-07-19T20:31:04.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 531, attempt 0, stage 5.0)
[2025-07-19T20:31:04.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 535, attempt 0, stage 5.0)
[2025-07-19T20:31:04.557+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c3acf72
[2025-07-19T20:31:04.558+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.559+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33] for update
[2025-07-19T20:31:04.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 15 (task 535, attempt 0, stage 5.0)
[2025-07-19T20:31:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 2 (task 531, attempt 0, stage 5.0)
[2025-07-19T20:31:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 2.0 in stage 5.0 (TID 531). 6243 bytes result sent to driver
[2025-07-19T20:31:04.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.1.delta.0360c04b-f4c9-4fb5-902b-0b2e8c3ddac4.TID536.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta
[2025-07-19T20:31:04.562+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/17/1.delta
[2025-07-19T20:31:04.562+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 15.0 in stage 5.0 (TID 535). 6243 bytes result sent to driver
[2025-07-19T20:31:04.562+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 36.0 in stage 5.0 (TID 542) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.563+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 36.0 in stage 5.0 (TID 542)
[2025-07-19T20:31:04.563+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 536, attempt 0, stage 5.0)
[2025-07-19T20:31:04.564+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 40.0 in stage 5.0 (TID 543) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.564+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 531) in 147 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:31:04.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 535) in 116 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:31:04.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 40.0 in stage 5.0 (TID 543)
[2025-07-19T20:31:04.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 17 (task 536, attempt 0, stage 5.0)
[2025-07-19T20:31:04.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 17.0 in stage 5.0 (TID 536). 6243 bytes result sent to driver
[2025-07-19T20:31:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 42.0 in stage 5.0 (TID 544) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.1.delta.7c446a5c-d814-47c5-9cc4-7119a9f111c1.TID541.tmp
[2025-07-19T20:31:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 17.0 in stage 5.0 (TID 536) in 119 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:31:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 42.0 in stage 5.0 (TID 544)
[2025-07-19T20:31:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.568+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.568+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.568+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57f4dac9
[2025-07-19T20:31:04.568+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.1.delta.db06e7f1-6bec-421f-a155-eff031114cda.TID539.tmp
[2025-07-19T20:31:04.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36] for update
[2025-07-19T20:31:04.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.1.delta.6d524779-5db7-480f-9ca4-f2ef5175033b.TID540.tmp
[2025-07-19T20:31:04.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.1.delta.0e2f2f27-063e-4474-8ddf-a96e4c7ec7cf.TID542.tmp
[2025-07-19T20:31:04.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.1.delta.162d687d-04c5-4515-95bc-c8f0c8849bc0.TID537.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta
[2025-07-19T20:31:04.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/27/1.delta
[2025-07-19T20:31:04.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 537, attempt 0, stage 5.0)
[2025-07-19T20:31:04.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47e2f6d1
[2025-07-19T20:31:04.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42] for update
[2025-07-19T20:31:04.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 27 (task 537, attempt 0, stage 5.0)
[2025-07-19T20:31:04.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 27.0 in stage 5.0 (TID 537). 6243 bytes result sent to driver
[2025-07-19T20:31:04.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 44.0 in stage 5.0 (TID 545) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 44.0 in stage 5.0 (TID 545)
[2025-07-19T20:31:04.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 27.0 in stage 5.0 (TID 537) in 88 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:31:04.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a351fce
[2025-07-19T20:31:04.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40] for update
[2025-07-19T20:31:04.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.1.delta.171d8013-84c7-4a5b-9a8e-533e22864009.TID544.tmp
[2025-07-19T20:31:04.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@46b1cfee
[2025-07-19T20:31:04.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44] for update
[2025-07-19T20:31:04.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.1.delta.7c446a5c-d814-47c5-9cc4-7119a9f111c1.TID541.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta
[2025-07-19T20:31:04.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/34/1.delta
[2025-07-19T20:31:04.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.1.delta.ccc655cd-75e1-4f63-a4f1-aaf6460ab116.TID538.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta
[2025-07-19T20:31:04.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/28/1.delta
[2025-07-19T20:31:04.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 538, attempt 0, stage 5.0)
[2025-07-19T20:31:04.597+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 541, attempt 0, stage 5.0)
[2025-07-19T20:31:04.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 34 (task 541, attempt 0, stage 5.0)
[2025-07-19T20:31:04.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 34.0 in stage 5.0 (TID 541). 6243 bytes result sent to driver
[2025-07-19T20:31:04.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 28 (task 538, attempt 0, stage 5.0)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 28.0 in stage 5.0 (TID 538). 6243 bytes result sent to driver
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 49.0 in stage 5.0 (TID 546) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 50.0 in stage 5.0 (TID 547) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 28.0 in stage 5.0 (TID 538) in 90 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 34.0 in stage 5.0 (TID 541) in 72 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 49.0 in stage 5.0 (TID 546)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.1.delta.36f877e3-5d47-48c4-91b0-dbfec88f97ce.TID543.tmp
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 50.0 in stage 5.0 (TID 547)
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.1.delta.0e2f2f27-063e-4474-8ddf-a96e4c7ec7cf.TID542.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta
[2025-07-19T20:31:04.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/36/1.delta
[2025-07-19T20:31:04.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.1.delta.1509f4c1-8b41-41d8-ac90-621a45205e76.TID545.tmp
[2025-07-19T20:31:04.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.1.delta.db06e7f1-6bec-421f-a155-eff031114cda.TID539.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta
[2025-07-19T20:31:04.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/31/1.delta
[2025-07-19T20:31:04.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 542, attempt 0, stage 5.0)
[2025-07-19T20:31:04.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 539, attempt 0, stage 5.0)
[2025-07-19T20:31:04.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 36 (task 542, attempt 0, stage 5.0)
[2025-07-19T20:31:04.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 36.0 in stage 5.0 (TID 542). 6200 bytes result sent to driver
[2025-07-19T20:31:04.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 54.0 in stage 5.0 (TID 548) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 54.0 in stage 5.0 (TID 548)
[2025-07-19T20:31:04.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 36.0 in stage 5.0 (TID 542) in 66 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:31:04.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42feff5a
[2025-07-19T20:31:04.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.1.delta.6d524779-5db7-480f-9ca4-f2ef5175033b.TID540.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta
[2025-07-19T20:31:04.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49] for update
[2025-07-19T20:31:04.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 31 (task 539, attempt 0, stage 5.0)
[2025-07-19T20:31:04.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/33/1.delta
[2025-07-19T20:31:04.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 540, attempt 0, stage 5.0)
[2025-07-19T20:31:04.631+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 31.0 in stage 5.0 (TID 539). 6286 bytes result sent to driver
[2025-07-19T20:31:04.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 55.0 in stage 5.0 (TID 549) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.635+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 33 (task 540, attempt 0, stage 5.0)
[2025-07-19T20:31:04.635+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 55.0 in stage 5.0 (TID 549)
[2025-07-19T20:31:04.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 33.0 in stage 5.0 (TID 540). 6243 bytes result sent to driver
[2025-07-19T20:31:04.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 31.0 in stage 5.0 (TID 539) in 121 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:31:04.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 61.0 in stage 5.0 (TID 550) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 33.0 in stage 5.0 (TID 540) in 113 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:31:04.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 61.0 in stage 5.0 (TID 550)
[2025-07-19T20:31:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6561c227
[2025-07-19T20:31:04.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54] for update
[2025-07-19T20:31:04.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6511a4c1
[2025-07-19T20:31:04.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50] for update
[2025-07-19T20:31:04.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.1.delta.9fde1060-868d-4dd0-8f13-397a22f3f2ff.TID546.tmp
[2025-07-19T20:31:04.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.1.delta.171d8013-84c7-4a5b-9a8e-533e22864009.TID544.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/42/1.delta
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.1.delta.9c61f20e-ff95-4a3a-8cc3-96335f70947b.TID548.tmp
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 544, attempt 0, stage 5.0)
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32da7c46
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61] for update
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.1.delta.36f877e3-5d47-48c4-91b0-dbfec88f97ce.TID543.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta
[2025-07-19T20:31:04.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/40/1.delta
[2025-07-19T20:31:04.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 543, attempt 0, stage 5.0)
[2025-07-19T20:31:04.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.1.delta.0061af6d-d4a8-4b39-8de8-6ad567e12ed7.TID547.tmp
[2025-07-19T20:31:04.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 42 (task 544, attempt 0, stage 5.0)
[2025-07-19T20:31:04.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 42.0 in stage 5.0 (TID 544). 6243 bytes result sent to driver
[2025-07-19T20:31:04.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 67.0 in stage 5.0 (TID 551) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.663+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 40 (task 543, attempt 0, stage 5.0)
[2025-07-19T20:31:04.663+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 67.0 in stage 5.0 (TID 551)
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 42.0 in stage 5.0 (TID 544) in 103 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 40.0 in stage 5.0 (TID 543). 6243 bytes result sent to driver
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 70.0 in stage 5.0 (TID 552) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 70.0 in stage 5.0 (TID 552)
[2025-07-19T20:31:04.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 40.0 in stage 5.0 (TID 543) in 111 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:31:04.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c8e583d
[2025-07-19T20:31:04.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55] for update
[2025-07-19T20:31:04.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.1.delta.b120c71c-9d1f-4ebf-a4cb-29e9d72832cd.TID550.tmp
[2025-07-19T20:31:04.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c7a1f28
[2025-07-19T20:31:04.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70] for update
[2025-07-19T20:31:04.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.1.delta.1509f4c1-8b41-41d8-ac90-621a45205e76.TID545.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta
[2025-07-19T20:31:04.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/44/1.delta
[2025-07-19T20:31:04.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 545, attempt 0, stage 5.0)
[2025-07-19T20:31:04.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d13d399
[2025-07-19T20:31:04.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67] for update
[2025-07-19T20:31:04.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 44 (task 545, attempt 0, stage 5.0)
[2025-07-19T20:31:04.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 44.0 in stage 5.0 (TID 545). 6243 bytes result sent to driver
[2025-07-19T20:31:04.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.1.delta.45cd96b2-187a-414a-a5e2-5b1d11f692f2.TID552.tmp
[2025-07-19T20:31:04.695+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.1.delta.1222d35e-fb3a-4d66-af6c-de31a8fe7327.TID549.tmp
[2025-07-19T20:31:04.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 74.0 in stage 5.0 (TID 553) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.702+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 74.0 in stage 5.0 (TID 553)
[2025-07-19T20:31:04.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 44.0 in stage 5.0 (TID 545) in 119 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:31:04.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.1.delta.c7203399-d6a5-4543-8479-3c58aeedce56.TID551.tmp
[2025-07-19T20:31:04.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.708+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.1.delta.9c61f20e-ff95-4a3a-8cc3-96335f70947b.TID548.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta
[2025-07-19T20:31:04.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/54/1.delta
[2025-07-19T20:31:04.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 548, attempt 0, stage 5.0)
[2025-07-19T20:31:04.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.1.delta.9fde1060-868d-4dd0-8f13-397a22f3f2ff.TID546.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta
[2025-07-19T20:31:04.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/49/1.delta
[2025-07-19T20:31:04.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 546, attempt 0, stage 5.0)
[2025-07-19T20:31:04.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b5d1641
[2025-07-19T20:31:04.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 54 (task 548, attempt 0, stage 5.0)
[2025-07-19T20:31:04.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.1.delta.0061af6d-d4a8-4b39-8de8-6ad567e12ed7.TID547.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta
[2025-07-19T20:31:04.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/50/1.delta
[2025-07-19T20:31:04.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74] for update
[2025-07-19T20:31:04.759+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 547, attempt 0, stage 5.0)
[2025-07-19T20:31:04.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 54.0 in stage 5.0 (TID 548). 6243 bytes result sent to driver
[2025-07-19T20:31:04.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 49 (task 546, attempt 0, stage 5.0)
[2025-07-19T20:31:04.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 49.0 in stage 5.0 (TID 546). 6243 bytes result sent to driver
[2025-07-19T20:31:04.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 76.0 in stage 5.0 (TID 554) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 54.0 in stage 5.0 (TID 548) in 109 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:31:04.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 50 (task 547, attempt 0, stage 5.0)
[2025-07-19T20:31:04.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 80.0 in stage 5.0 (TID 555) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 80.0 in stage 5.0 (TID 555)
[2025-07-19T20:31:04.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 76.0 in stage 5.0 (TID 554)
[2025-07-19T20:31:04.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 49.0 in stage 5.0 (TID 546) in 130 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:31:04.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 50.0 in stage 5.0 (TID 547). 6200 bytes result sent to driver
[2025-07-19T20:31:04.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 81.0 in stage 5.0 (TID 556) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 50.0 in stage 5.0 (TID 547) in 135 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:31:04.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:04.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 81.0 in stage 5.0 (TID 556)
[2025-07-19T20:31:04.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:04.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.1.delta.b120c71c-9d1f-4ebf-a4cb-29e9d72832cd.TID550.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta
[2025-07-19T20:31:04.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/61/1.delta
[2025-07-19T20:31:04.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5dbd466b
[2025-07-19T20:31:04.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 550, attempt 0, stage 5.0)
[2025-07-19T20:31:04.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76] for update
[2025-07-19T20:31:04.783+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.1.delta.bcdf1792-070c-41e8-b8d4-6d729d4178a7.TID553.tmp
[2025-07-19T20:31:04.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2af58abb
[2025-07-19T20:31:04.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 61 (task 550, attempt 0, stage 5.0)
[2025-07-19T20:31:04.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 61.0 in stage 5.0 (TID 550). 6243 bytes result sent to driver
[2025-07-19T20:31:04.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80] for update
[2025-07-19T20:31:04.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 84.0 in stage 5.0 (TID 557) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 61.0 in stage 5.0 (TID 550) in 141 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:31:04.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 84.0 in stage 5.0 (TID 557)
[2025-07-19T20:31:04.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c06e461
[2025-07-19T20:31:04.798+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.1.delta.1222d35e-fb3a-4d66-af6c-de31a8fe7327.TID549.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta
[2025-07-19T20:31:04.801+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/55/1.delta
[2025-07-19T20:31:04.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81] for update
[2025-07-19T20:31:04.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 549, attempt 0, stage 5.0)
[2025-07-19T20:31:04.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.1.delta.45cd96b2-187a-414a-a5e2-5b1d11f692f2.TID552.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta
[2025-07-19T20:31:04.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/70/1.delta
[2025-07-19T20:31:04.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 552, attempt 0, stage 5.0)
[2025-07-19T20:31:04.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 55 (task 549, attempt 0, stage 5.0)
[2025-07-19T20:31:04.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 55.0 in stage 5.0 (TID 549). 6243 bytes result sent to driver
[2025-07-19T20:31:04.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.1.delta.ae4c8b35-1881-4293-ab8b-00ee5942d9b4.TID554.tmp
[2025-07-19T20:31:04.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 88.0 in stage 5.0 (TID 558) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.1.delta.c1cd9acb-fcaa-443d-9eb7-1e65ca75195b.TID555.tmp
[2025-07-19T20:31:04.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 55.0 in stage 5.0 (TID 549) in 162 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:31:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 88.0 in stage 5.0 (TID 558)
[2025-07-19T20:31:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@780f4f3e
[2025-07-19T20:31:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84] for update
[2025-07-19T20:31:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 70 (task 552, attempt 0, stage 5.0)
[2025-07-19T20:31:04.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 70.0 in stage 5.0 (TID 552). 6243 bytes result sent to driver
[2025-07-19T20:31:04.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.1.delta.c7203399-d6a5-4543-8479-3c58aeedce56.TID551.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta
[2025-07-19T20:31:04.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/67/1.delta
[2025-07-19T20:31:04.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 551, attempt 0, stage 5.0)
[2025-07-19T20:31:04.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.1.delta.cbdf4628-27ca-461b-914c-62a614d4690a.TID556.tmp
[2025-07-19T20:31:04.815+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 90.0 in stage 5.0 (TID 559) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 90.0 in stage 5.0 (TID 559)
[2025-07-19T20:31:04.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 70.0 in stage 5.0 (TID 552) in 142 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:31:04.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 67 (task 551, attempt 0, stage 5.0)
[2025-07-19T20:31:04.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 67.0 in stage 5.0 (TID 551). 6243 bytes result sent to driver
[2025-07-19T20:31:04.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 91.0 in stage 5.0 (TID 560) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 67.0 in stage 5.0 (TID 551) in 154 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:31:04.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 91.0 in stage 5.0 (TID 560)
[2025-07-19T20:31:04.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.1.delta.d98a5d9b-81b0-4660-b1ba-c0db587546a8.TID557.tmp
[2025-07-19T20:31:04.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54584d12
[2025-07-19T20:31:04.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.1.delta.bcdf1792-070c-41e8-b8d4-6d729d4178a7.TID553.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta
[2025-07-19T20:31:04.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/74/1.delta
[2025-07-19T20:31:04.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88] for update
[2025-07-19T20:31:04.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 553, attempt 0, stage 5.0)
[2025-07-19T20:31:04.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74a5d059
[2025-07-19T20:31:04.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91] for update
[2025-07-19T20:31:04.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 74 (task 553, attempt 0, stage 5.0)
[2025-07-19T20:31:04.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 74.0 in stage 5.0 (TID 553). 6243 bytes result sent to driver
[2025-07-19T20:31:04.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 93.0 in stage 5.0 (TID 561) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 74.0 in stage 5.0 (TID 553) in 126 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:31:04.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 93.0 in stage 5.0 (TID 561)
[2025-07-19T20:31:04.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b64fcb9
[2025-07-19T20:31:04.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90] for update
[2025-07-19T20:31:04.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.1.delta.1a1b08a5-f7b6-4ab9-8aaf-8e139cbabbf9.TID558.tmp
[2025-07-19T20:31:04.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55f3d0ec
[2025-07-19T20:31:04.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.1.delta.ed3995c5-fab6-4759-bbb5-1d2e5cb5a6d4.TID560.tmp
[2025-07-19T20:31:04.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93] for update
[2025-07-19T20:31:04.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.1.delta.ae4c8b35-1881-4293-ab8b-00ee5942d9b4.TID554.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta
[2025-07-19T20:31:04.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/76/1.delta
[2025-07-19T20:31:04.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 554, attempt 0, stage 5.0)
[2025-07-19T20:31:04.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.1.delta.c064e744-58df-4b96-b4a7-d5832ff8f519.TID559.tmp
[2025-07-19T20:31:04.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.1.delta.c1cd9acb-fcaa-443d-9eb7-1e65ca75195b.TID555.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta
[2025-07-19T20:31:04.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/80/1.delta
[2025-07-19T20:31:04.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 555, attempt 0, stage 5.0)
[2025-07-19T20:31:04.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 76 (task 554, attempt 0, stage 5.0)
[2025-07-19T20:31:04.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 76.0 in stage 5.0 (TID 554). 6243 bytes result sent to driver
[2025-07-19T20:31:04.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 80 (task 555, attempt 0, stage 5.0)
[2025-07-19T20:31:04.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 80.0 in stage 5.0 (TID 555). 6243 bytes result sent to driver
[2025-07-19T20:31:04.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 98.0 in stage 5.0 (TID 562) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 101.0 in stage 5.0 (TID 563) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 80.0 in stage 5.0 (TID 555) in 115 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:31:04.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 101.0 in stage 5.0 (TID 563)
[2025-07-19T20:31:04.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 98.0 in stage 5.0 (TID 562)
[2025-07-19T20:31:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 76.0 in stage 5.0 (TID 554) in 121 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:31:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.1.delta.cbdf4628-27ca-461b-914c-62a614d4690a.TID556.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta
[2025-07-19T20:31:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/81/1.delta
[2025-07-19T20:31:04.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 556, attempt 0, stage 5.0)
[2025-07-19T20:31:04.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:04.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 81 (task 556, attempt 0, stage 5.0)
[2025-07-19T20:31:04.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 81.0 in stage 5.0 (TID 556). 6243 bytes result sent to driver
[2025-07-19T20:31:04.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 103.0 in stage 5.0 (TID 564) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 103.0 in stage 5.0 (TID 564)
[2025-07-19T20:31:04.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 81.0 in stage 5.0 (TID 556) in 117 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:31:04.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.1.delta.2a882716-99bd-4969-bcc0-6c2daee2e77b.TID561.tmp
[2025-07-19T20:31:04.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6edd7da
[2025-07-19T20:31:04.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.1.delta.d98a5d9b-81b0-4660-b1ba-c0db587546a8.TID557.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta
[2025-07-19T20:31:04.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/84/1.delta
[2025-07-19T20:31:04.860+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101] for update
[2025-07-19T20:31:04.860+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 557, attempt 0, stage 5.0)
[2025-07-19T20:31:04.865+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f3dd33b
[2025-07-19T20:31:04.868+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103] for update
[2025-07-19T20:31:04.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.1.delta.1a1b08a5-f7b6-4ab9-8aaf-8e139cbabbf9.TID558.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta
[2025-07-19T20:31:04.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/88/1.delta
[2025-07-19T20:31:04.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 558, attempt 0, stage 5.0)
[2025-07-19T20:31:04.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 84 (task 557, attempt 0, stage 5.0)
[2025-07-19T20:31:04.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 84.0 in stage 5.0 (TID 557). 6200 bytes result sent to driver
[2025-07-19T20:31:04.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 108.0 in stage 5.0 (TID 565) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 108.0 in stage 5.0 (TID 565)
[2025-07-19T20:31:04.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.1.delta.faec60c9-a74c-4998-abfa-7226116c9875.TID563.tmp
[2025-07-19T20:31:04.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 88 (task 558, attempt 0, stage 5.0)
[2025-07-19T20:31:04.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.1.delta.ed3995c5-fab6-4759-bbb5-1d2e5cb5a6d4.TID560.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta
[2025-07-19T20:31:04.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/91/1.delta
[2025-07-19T20:31:04.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 84.0 in stage 5.0 (TID 557) in 95 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:31:04.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 560, attempt 0, stage 5.0)
[2025-07-19T20:31:04.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 88.0 in stage 5.0 (TID 558). 6200 bytes result sent to driver
[2025-07-19T20:31:04.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 109.0 in stage 5.0 (TID 566) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 109.0 in stage 5.0 (TID 566)
[2025-07-19T20:31:04.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 88.0 in stage 5.0 (TID 558) in 82 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:31:04.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 91 (task 560, attempt 0, stage 5.0)
[2025-07-19T20:31:04.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 91.0 in stage 5.0 (TID 560). 6200 bytes result sent to driver
[2025-07-19T20:31:04.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 112.0 in stage 5.0 (TID 567) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 112.0 in stage 5.0 (TID 567)
[2025-07-19T20:31:04.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3742785c
[2025-07-19T20:31:04.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 91.0 in stage 5.0 (TID 560) in 67 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:31:04.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98] for update
[2025-07-19T20:31:04.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.1.delta.26d711c5-7bc0-453c-8bd0-d6734f05abe0.TID564.tmp
[2025-07-19T20:31:04.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e3d78be
[2025-07-19T20:31:04.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108] for update
[2025-07-19T20:31:04.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.1.delta.c064e744-58df-4b96-b4a7-d5832ff8f519.TID559.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta
[2025-07-19T20:31:04.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/90/1.delta
[2025-07-19T20:31:04.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 559, attempt 0, stage 5.0)
[2025-07-19T20:31:04.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.1.delta.1d1be7b7-7311-41a1-9089-b42c12b57cf6.TID562.tmp
[2025-07-19T20:31:04.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67208d73
[2025-07-19T20:31:04.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109] for update
[2025-07-19T20:31:04.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 90 (task 559, attempt 0, stage 5.0)
[2025-07-19T20:31:04.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.1.delta.2a882716-99bd-4969-bcc0-6c2daee2e77b.TID561.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta
[2025-07-19T20:31:04.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/93/1.delta
[2025-07-19T20:31:04.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 90.0 in stage 5.0 (TID 559). 6200 bytes result sent to driver
[2025-07-19T20:31:04.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 561, attempt 0, stage 5.0)
[2025-07-19T20:31:04.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.1.delta.6d609a81-dcc9-423d-95c9-c09ff7a69939.TID565.tmp
[2025-07-19T20:31:04.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 114.0 in stage 5.0 (TID 568) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 114.0 in stage 5.0 (TID 568)
[2025-07-19T20:31:04.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@44c4dd88
[2025-07-19T20:31:04.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.909+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112] for update
[2025-07-19T20:31:04.910+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 90.0 in stage 5.0 (TID 559) in 100 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:31:04.911+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 93 (task 561, attempt 0, stage 5.0)
[2025-07-19T20:31:04.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 93.0 in stage 5.0 (TID 561). 6243 bytes result sent to driver
[2025-07-19T20:31:04.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 115.0 in stage 5.0 (TID 569) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 93.0 in stage 5.0 (TID 561) in 85 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:31:04.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 115.0 in stage 5.0 (TID 569)
[2025-07-19T20:31:04.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.1.delta.9f8b0cd2-d613-4d4f-995b-e370eebcee17.TID566.tmp
[2025-07-19T20:31:04.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d3de23e
[2025-07-19T20:31:04.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114] for update
[2025-07-19T20:31:04.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.924+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.1.delta.ee8ad8d2-17c2-4a40-a864-f609ebfa85fa.TID567.tmp
[2025-07-19T20:31:04.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d45f571
[2025-07-19T20:31:04.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.927+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115] for update
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.1.delta.15fef9de-3118-47df-82a4-7ffa70e43cf5.TID568.tmp
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.1.delta.faec60c9-a74c-4998-abfa-7226116c9875.TID563.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/101/1.delta
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 563, attempt 0, stage 5.0)
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.1.delta.26d711c5-7bc0-453c-8bd0-d6734f05abe0.TID564.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/103/1.delta
[2025-07-19T20:31:04.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 564, attempt 0, stage 5.0)
[2025-07-19T20:31:04.932+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.1.delta.1d1be7b7-7311-41a1-9089-b42c12b57cf6.TID562.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta
[2025-07-19T20:31:04.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/98/1.delta
[2025-07-19T20:31:04.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 103 (task 564, attempt 0, stage 5.0)
[2025-07-19T20:31:04.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 101 (task 563, attempt 0, stage 5.0)
[2025-07-19T20:31:04.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 103.0 in stage 5.0 (TID 564). 6243 bytes result sent to driver
[2025-07-19T20:31:04.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 101.0 in stage 5.0 (TID 563). 6243 bytes result sent to driver
[2025-07-19T20:31:04.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 116.0 in stage 5.0 (TID 570) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 124.0 in stage 5.0 (TID 571) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 116.0 in stage 5.0 (TID 570)
[2025-07-19T20:31:04.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 124.0 in stage 5.0 (TID 571)
[2025-07-19T20:31:04.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 101.0 in stage 5.0 (TID 563) in 91 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:31:04.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 103.0 in stage 5.0 (TID 564) in 82 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:31:04.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.1.delta.6d609a81-dcc9-423d-95c9-c09ff7a69939.TID565.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta
[2025-07-19T20:31:04.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/108/1.delta
[2025-07-19T20:31:04.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.1.delta.dc036583-0669-4cbd-a293-401a8d65dbf6.TID569.tmp
[2025-07-19T20:31:04.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 562, attempt 0, stage 5.0)
[2025-07-19T20:31:04.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 565, attempt 0, stage 5.0)
[2025-07-19T20:31:04.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 108 (task 565, attempt 0, stage 5.0)
[2025-07-19T20:31:04.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 108.0 in stage 5.0 (TID 565). 6243 bytes result sent to driver
[2025-07-19T20:31:04.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 98 (task 562, attempt 0, stage 5.0)
[2025-07-19T20:31:04.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ec7b836
[2025-07-19T20:31:04.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 108.0 in stage 5.0 (TID 565) in 71 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:31:04.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 125.0 in stage 5.0 (TID 572) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 98.0 in stage 5.0 (TID 562). 6243 bytes result sent to driver
[2025-07-19T20:31:04.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 125.0 in stage 5.0 (TID 572)
[2025-07-19T20:31:04.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 126.0 in stage 5.0 (TID 573) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:04.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124] for update
[2025-07-19T20:31:04.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 126.0 in stage 5.0 (TID 573)
[2025-07-19T20:31:04.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 98.0 in stage 5.0 (TID 562) in 102 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:31:04.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.991+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:04.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:04.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:04.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e664547
[2025-07-19T20:31:04.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:04.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116] for update
[2025-07-19T20:31:04.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.1.delta.ceaf2b7f-f001-4400-b328-bc10a4782596.TID571.tmp
[2025-07-19T20:31:04.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:04.999+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40ad9bd6
[2025-07-19T20:31:04.999+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.1.delta.9f8b0cd2-d613-4d4f-995b-e370eebcee17.TID566.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta
[2025-07-19T20:31:05.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/109/1.delta
[2025-07-19T20:31:05.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.1.delta.15fef9de-3118-47df-82a4-7ffa70e43cf5.TID568.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta
[2025-07-19T20:31:05.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/114/1.delta
[2025-07-19T20:31:05.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 568, attempt 0, stage 5.0)
[2025-07-19T20:31:05.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 566, attempt 0, stage 5.0)
[2025-07-19T20:31:05.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 109 (task 566, attempt 0, stage 5.0)
[2025-07-19T20:31:05.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 109.0 in stage 5.0 (TID 566). 6243 bytes result sent to driver
[2025-07-19T20:31:05.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Committed partition 114 (task 568, attempt 0, stage 5.0)
[2025-07-19T20:31:05.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Finished task 114.0 in stage 5.0 (TID 568). 6200 bytes result sent to driver
[2025-07-19T20:31:05.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 132.0 in stage 5.0 (TID 574) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Starting task 134.0 in stage 5.0 (TID 575) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 132.0 in stage 5.0 (TID 574)
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126] for update
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO Executor: Running task 134.0 in stage 5.0 (TID 575)
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 114.0 in stage 5.0 (TID 568) in 93 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO TaskSetManager: Finished task 109.0 in stage 5.0 (TID 566) in 120 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:31:05.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.1.delta.b157ebd8-ee81-4ba7-a8b7-6e31bedf7645.TID570.tmp
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.1.delta.ee8ad8d2-17c2-4a40-a864-f609ebfa85fa.TID567.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/112/1.delta
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:04 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 567, attempt 0, stage 5.0)
[2025-07-19T20:31:05.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 112 (task 567, attempt 0, stage 5.0)
[2025-07-19T20:31:05.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@52977424
[2025-07-19T20:31:05.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 112.0 in stage 5.0 (TID 567). 6243 bytes result sent to driver
[2025-07-19T20:31:05.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125] for update
[2025-07-19T20:31:05.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 139.0 in stage 5.0 (TID 576) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 112.0 in stage 5.0 (TID 567) in 126 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:31:05.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 139.0 in stage 5.0 (TID 576)
[2025-07-19T20:31:05.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.010+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.010+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.011+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.1.delta.dc036583-0669-4cbd-a293-401a8d65dbf6.TID569.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta
[2025-07-19T20:31:05.011+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/115/1.delta
[2025-07-19T20:31:05.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.1.delta.3ef0e225-7a61-45b0-875e-3904503cd6d1.TID573.tmp
[2025-07-19T20:31:05.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 569, attempt 0, stage 5.0)
[2025-07-19T20:31:05.013+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1fd8891a
[2025-07-19T20:31:05.013+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.013+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134] for update
[2025-07-19T20:31:05.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 115 (task 569, attempt 0, stage 5.0)
[2025-07-19T20:31:05.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.1.delta.b8d1a658-0379-48ca-80fe-00972263d191.TID572.tmp
[2025-07-19T20:31:05.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 115.0 in stage 5.0 (TID 569). 6200 bytes result sent to driver
[2025-07-19T20:31:05.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 141.0 in stage 5.0 (TID 577) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.018+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4645b71f
[2025-07-19T20:31:05.018+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132] for update
[2025-07-19T20:31:05.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 115.0 in stage 5.0 (TID 569) in 112 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:31:05.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 141.0 in stage 5.0 (TID 577)
[2025-07-19T20:31:05.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.1.delta.791f49cf-bc34-4a00-9bc4-a2fdd800d68b.TID575.tmp
[2025-07-19T20:31:05.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.1.delta.ceaf2b7f-f001-4400-b328-bc10a4782596.TID571.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta
[2025-07-19T20:31:05.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/124/1.delta
[2025-07-19T20:31:05.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 571, attempt 0, stage 5.0)
[2025-07-19T20:31:05.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.1.delta.b157ebd8-ee81-4ba7-a8b7-6e31bedf7645.TID570.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta
[2025-07-19T20:31:05.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/116/1.delta
[2025-07-19T20:31:05.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 570, attempt 0, stage 5.0)
[2025-07-19T20:31:05.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31b6182
[2025-07-19T20:31:05.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 116 (task 570, attempt 0, stage 5.0)
[2025-07-19T20:31:05.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 116.0 in stage 5.0 (TID 570). 6200 bytes result sent to driver
[2025-07-19T20:31:05.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139] for update
[2025-07-19T20:31:05.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 142.0 in stage 5.0 (TID 578) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 124 (task 571, attempt 0, stage 5.0)
[2025-07-19T20:31:05.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 116.0 in stage 5.0 (TID 570) in 101 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:31:05.039+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 124.0 in stage 5.0 (TID 571). 6286 bytes result sent to driver
[2025-07-19T20:31:05.039+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 143.0 in stage 5.0 (TID 579) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 142.0 in stage 5.0 (TID 578)
[2025-07-19T20:31:05.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 143.0 in stage 5.0 (TID 579)
[2025-07-19T20:31:05.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.1.delta.a74a8a17-0a61-4b5b-9160-7349125e380a.TID574.tmp
[2025-07-19T20:31:05.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 124.0 in stage 5.0 (TID 571) in 103 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:31:05.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1459e0a5
[2025-07-19T20:31:05.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141] for update
[2025-07-19T20:31:05.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.046+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.1.delta.c35e253e-5d91-4be1-bf2c-ccc77d60e8ed.TID576.tmp
[2025-07-19T20:31:05.050+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55189f57
[2025-07-19T20:31:05.052+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143] for update
[2025-07-19T20:31:05.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.1.delta.791f49cf-bc34-4a00-9bc4-a2fdd800d68b.TID575.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta
[2025-07-19T20:31:05.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/134/1.delta
[2025-07-19T20:31:05.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 575, attempt 0, stage 5.0)
[2025-07-19T20:31:05.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.1.delta.b8d1a658-0379-48ca-80fe-00972263d191.TID572.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta
[2025-07-19T20:31:05.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/125/1.delta
[2025-07-19T20:31:05.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.1.delta.dcc1ed80-3ce0-41fb-a7bd-6bc39cd198f4.TID579.tmp
[2025-07-19T20:31:05.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.1.delta.b4316313-9a94-43bb-9a89-7a562bc7794f.TID577.tmp
[2025-07-19T20:31:05.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f529873
[2025-07-19T20:31:05.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142] for update
[2025-07-19T20:31:05.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 572, attempt 0, stage 5.0)
[2025-07-19T20:31:05.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 134 (task 575, attempt 0, stage 5.0)
[2025-07-19T20:31:05.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 134.0 in stage 5.0 (TID 575). 6243 bytes result sent to driver
[2025-07-19T20:31:05.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 125 (task 572, attempt 0, stage 5.0)
[2025-07-19T20:31:05.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 146.0 in stage 5.0 (TID 580) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.069+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 146.0 in stage 5.0 (TID 580)
[2025-07-19T20:31:05.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 125.0 in stage 5.0 (TID 572). 6243 bytes result sent to driver
[2025-07-19T20:31:05.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 134.0 in stage 5.0 (TID 575) in 74 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:31:05.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 147.0 in stage 5.0 (TID 581) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.072+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 125.0 in stage 5.0 (TID 572) in 125 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:31:05.072+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 147.0 in stage 5.0 (TID 581)
[2025-07-19T20:31:05.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.1.delta.3ef0e225-7a61-45b0-875e-3904503cd6d1.TID573.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta
[2025-07-19T20:31:05.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/126/1.delta
[2025-07-19T20:31:05.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 573, attempt 0, stage 5.0)
[2025-07-19T20:31:05.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5b60242
[2025-07-19T20:31:05.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 126 (task 573, attempt 0, stage 5.0)
[2025-07-19T20:31:05.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.1.delta.880ee961-066b-4c03-9dd8-e49822319224.TID578.tmp
[2025-07-19T20:31:05.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146] for update
[2025-07-19T20:31:05.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 126.0 in stage 5.0 (TID 573). 6243 bytes result sent to driver
[2025-07-19T20:31:05.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 148.0 in stage 5.0 (TID 582) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 126.0 in stage 5.0 (TID 573) in 136 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:31:05.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 148.0 in stage 5.0 (TID 582)
[2025-07-19T20:31:05.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.1.delta.a74a8a17-0a61-4b5b-9160-7349125e380a.TID574.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta
[2025-07-19T20:31:05.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/132/1.delta
[2025-07-19T20:31:05.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 574, attempt 0, stage 5.0)
[2025-07-19T20:31:05.091+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31ec20c8
[2025-07-19T20:31:05.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147] for update
[2025-07-19T20:31:05.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 132 (task 574, attempt 0, stage 5.0)
[2025-07-19T20:31:05.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 132.0 in stage 5.0 (TID 574). 6243 bytes result sent to driver
[2025-07-19T20:31:05.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.1.delta.f9e98d9a-16ea-4ea9-a700-2396d37563ca.TID580.tmp
[2025-07-19T20:31:05.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 151.0 in stage 5.0 (TID 583) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.097+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 132.0 in stage 5.0 (TID 574) in 97 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:31:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 151.0 in stage 5.0 (TID 583)
[2025-07-19T20:31:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.1.delta.c35e253e-5d91-4be1-bf2c-ccc77d60e8ed.TID576.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta
[2025-07-19T20:31:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/139/1.delta
[2025-07-19T20:31:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 576, attempt 0, stage 5.0)
[2025-07-19T20:31:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69453310
[2025-07-19T20:31:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.1.delta.b4316313-9a94-43bb-9a89-7a562bc7794f.TID577.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta
[2025-07-19T20:31:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/141/1.delta
[2025-07-19T20:31:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148] for update
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 577, attempt 0, stage 5.0)
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 141 (task 577, attempt 0, stage 5.0)
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 141.0 in stage 5.0 (TID 577). 6243 bytes result sent to driver
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 139 (task 576, attempt 0, stage 5.0)
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 152.0 in stage 5.0 (TID 584) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 152.0 in stage 5.0 (TID 584)
[2025-07-19T20:31:05.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 141.0 in stage 5.0 (TID 577) in 85 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:31:05.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a66b115
[2025-07-19T20:31:05.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151] for update
[2025-07-19T20:31:05.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 139.0 in stage 5.0 (TID 576). 6243 bytes result sent to driver
[2025-07-19T20:31:05.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 156.0 in stage 5.0 (TID 585) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 139.0 in stage 5.0 (TID 576) in 102 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:31:05.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 156.0 in stage 5.0 (TID 585)
[2025-07-19T20:31:05.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.1.delta.dcc1ed80-3ce0-41fb-a7bd-6bc39cd198f4.TID579.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta
[2025-07-19T20:31:05.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/143/1.delta
[2025-07-19T20:31:05.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 579, attempt 0, stage 5.0)
[2025-07-19T20:31:05.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.1.delta.3be12f79-b2ac-4499-97a6-c267b5abc05f.TID581.tmp
[2025-07-19T20:31:05.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.1.delta.306e3153-b94b-46e8-9291-2535bb1c697e.TID582.tmp
[2025-07-19T20:31:05.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 143 (task 579, attempt 0, stage 5.0)
[2025-07-19T20:31:05.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 143.0 in stage 5.0 (TID 579). 6200 bytes result sent to driver
[2025-07-19T20:31:05.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 157.0 in stage 5.0 (TID 586) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 143.0 in stage 5.0 (TID 579) in 79 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:31:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 157.0 in stage 5.0 (TID 586)
[2025-07-19T20:31:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62ca889c
[2025-07-19T20:31:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152] for update
[2025-07-19T20:31:05.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.1.delta.3d03b1e6-ef6b-4dd4-8ff0-4e62f01c67b8.TID583.tmp
[2025-07-19T20:31:05.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.1.delta.880ee961-066b-4c03-9dd8-e49822319224.TID578.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta
[2025-07-19T20:31:05.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/142/1.delta
[2025-07-19T20:31:05.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 578, attempt 0, stage 5.0)
[2025-07-19T20:31:05.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a37e650
[2025-07-19T20:31:05.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157] for update
[2025-07-19T20:31:05.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 142 (task 578, attempt 0, stage 5.0)
[2025-07-19T20:31:05.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 142.0 in stage 5.0 (TID 578). 6286 bytes result sent to driver
[2025-07-19T20:31:05.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 164.0 in stage 5.0 (TID 587) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 142.0 in stage 5.0 (TID 578) in 102 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:31:05.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e968d9f
[2025-07-19T20:31:05.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 164.0 in stage 5.0 (TID 587)
[2025-07-19T20:31:05.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.1.delta.f9e98d9a-16ea-4ea9-a700-2396d37563ca.TID580.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta
[2025-07-19T20:31:05.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/146/1.delta
[2025-07-19T20:31:05.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 580, attempt 0, stage 5.0)
[2025-07-19T20:31:05.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156] for update
[2025-07-19T20:31:05.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.1.delta.d0131749-7ae4-4094-8a6d-e6baa5d41130.TID584.tmp
[2025-07-19T20:31:05.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.1.delta.c7037d64-77ab-4919-bff1-66b652a01078.TID586.tmp
[2025-07-19T20:31:05.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@222492aa
[2025-07-19T20:31:05.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164] for update
[2025-07-19T20:31:05.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 146 (task 580, attempt 0, stage 5.0)
[2025-07-19T20:31:05.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 146.0 in stage 5.0 (TID 580). 6243 bytes result sent to driver
[2025-07-19T20:31:05.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 166.0 in stage 5.0 (TID 588) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 146.0 in stage 5.0 (TID 580) in 88 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:31:05.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 166.0 in stage 5.0 (TID 588)
[2025-07-19T20:31:05.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.1.delta.c3057216-5bd9-438b-854a-b214adf12387.TID587.tmp
[2025-07-19T20:31:05.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.1.delta.306e3153-b94b-46e8-9291-2535bb1c697e.TID582.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta
[2025-07-19T20:31:05.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/148/1.delta
[2025-07-19T20:31:05.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 582, attempt 0, stage 5.0)
[2025-07-19T20:31:05.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.1.delta.144842af-fccc-43af-b526-869085993e49.TID585.tmp
[2025-07-19T20:31:05.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@463062e4
[2025-07-19T20:31:05.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166] for update
[2025-07-19T20:31:05.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 148 (task 582, attempt 0, stage 5.0)
[2025-07-19T20:31:05.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 148.0 in stage 5.0 (TID 582). 6243 bytes result sent to driver
[2025-07-19T20:31:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.1.delta.3be12f79-b2ac-4499-97a6-c267b5abc05f.TID581.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta
[2025-07-19T20:31:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/147/1.delta
[2025-07-19T20:31:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 167.0 in stage 5.0 (TID 589) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 167.0 in stage 5.0 (TID 589)
[2025-07-19T20:31:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 581, attempt 0, stage 5.0)
[2025-07-19T20:31:05.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 148.0 in stage 5.0 (TID 582) in 90 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:31:05.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 147 (task 581, attempt 0, stage 5.0)
[2025-07-19T20:31:05.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 147.0 in stage 5.0 (TID 581). 6243 bytes result sent to driver
[2025-07-19T20:31:05.179+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 168.0 in stage 5.0 (TID 590) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.182+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 147.0 in stage 5.0 (TID 581) in 111 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:31:05.182+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 168.0 in stage 5.0 (TID 590)
[2025-07-19T20:31:05.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.1.delta.c6cdb998-3f79-43af-8289-25adc3bf0a68.TID588.tmp
[2025-07-19T20:31:05.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:05.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.1.delta.3d03b1e6-ef6b-4dd4-8ff0-4e62f01c67b8.TID583.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta
[2025-07-19T20:31:05.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/151/1.delta
[2025-07-19T20:31:05.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 583, attempt 0, stage 5.0)
[2025-07-19T20:31:05.203+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e9bacd5
[2025-07-19T20:31:05.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167] for update
[2025-07-19T20:31:05.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 151 (task 583, attempt 0, stage 5.0)
[2025-07-19T20:31:05.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 151.0 in stage 5.0 (TID 583). 6243 bytes result sent to driver
[2025-07-19T20:31:05.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 171.0 in stage 5.0 (TID 591) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 171.0 in stage 5.0 (TID 591)
[2025-07-19T20:31:05.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 151.0 in stage 5.0 (TID 583) in 114 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:31:05.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.1.delta.d0131749-7ae4-4094-8a6d-e6baa5d41130.TID584.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta
[2025-07-19T20:31:05.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/152/1.delta
[2025-07-19T20:31:05.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.1.delta.c7037d64-77ab-4919-bff1-66b652a01078.TID586.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta
[2025-07-19T20:31:05.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/157/1.delta
[2025-07-19T20:31:05.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 584, attempt 0, stage 5.0)
[2025-07-19T20:31:05.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 586, attempt 0, stage 5.0)
[2025-07-19T20:31:05.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@212d9aee
[2025-07-19T20:31:05.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168] for update
[2025-07-19T20:31:05.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 152 (task 584, attempt 0, stage 5.0)
[2025-07-19T20:31:05.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 157 (task 586, attempt 0, stage 5.0)
[2025-07-19T20:31:05.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 152.0 in stage 5.0 (TID 584). 6243 bytes result sent to driver
[2025-07-19T20:31:05.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 157.0 in stage 5.0 (TID 586). 6243 bytes result sent to driver
[2025-07-19T20:31:05.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 173.0 in stage 5.0 (TID 592) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 173.0 in stage 5.0 (TID 592)
[2025-07-19T20:31:05.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.1.delta.4d335c10-32b7-4b08-9f51-8bbe10f44c80.TID589.tmp
[2025-07-19T20:31:05.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 176.0 in stage 5.0 (TID 593) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 152.0 in stage 5.0 (TID 584) in 119 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 157.0 in stage 5.0 (TID 586) in 105 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 176.0 in stage 5.0 (TID 593)
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.1.delta.144842af-fccc-43af-b526-869085993e49.TID585.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta
[2025-07-19T20:31:05.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/156/1.delta
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 585, attempt 0, stage 5.0)
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.1.delta.c3057216-5bd9-438b-854a-b214adf12387.TID587.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/164/1.delta
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 587, attempt 0, stage 5.0)
[2025-07-19T20:31:05.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4dcf4aff
[2025-07-19T20:31:05.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171] for update
[2025-07-19T20:31:05.225+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.226+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 164 (task 587, attempt 0, stage 5.0)
[2025-07-19T20:31:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 164.0 in stage 5.0 (TID 587). 6200 bytes result sent to driver
[2025-07-19T20:31:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 184.0 in stage 5.0 (TID 594) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 184.0 in stage 5.0 (TID 594)
[2025-07-19T20:31:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 156 (task 585, attempt 0, stage 5.0)
[2025-07-19T20:31:05.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 156.0 in stage 5.0 (TID 585). 6243 bytes result sent to driver
[2025-07-19T20:31:05.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 164.0 in stage 5.0 (TID 587) in 97 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:31:05.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 187.0 in stage 5.0 (TID 595) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 156.0 in stage 5.0 (TID 585) in 131 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:31:05.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:05.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16fd04ab
[2025-07-19T20:31:05.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176] for update
[2025-07-19T20:31:05.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 187.0 in stage 5.0 (TID 595)
[2025-07-19T20:31:05.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.1.delta.24644499-c849-46f4-b6b2-e0200ba59107.TID591.tmp
[2025-07-19T20:31:05.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.1.delta.b098e894-0db9-4b1d-80ee-0a6cb54d9cf1.TID590.tmp
[2025-07-19T20:31:05.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bcaf3ef
[2025-07-19T20:31:05.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173] for update
[2025-07-19T20:31:05.247+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.1.delta.c6cdb998-3f79-43af-8289-25adc3bf0a68.TID588.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta
[2025-07-19T20:31:05.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/166/1.delta
[2025-07-19T20:31:05.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.1.delta.9cdfa180-b23c-4ce2-87e3-40b60161b091.TID593.tmp
[2025-07-19T20:31:05.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 588, attempt 0, stage 5.0)
[2025-07-19T20:31:05.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f762564
[2025-07-19T20:31:05.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187] for update
[2025-07-19T20:31:05.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 166 (task 588, attempt 0, stage 5.0)
[2025-07-19T20:31:05.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 166.0 in stage 5.0 (TID 588). 6286 bytes result sent to driver
[2025-07-19T20:31:05.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 189.0 in stage 5.0 (TID 596) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 189.0 in stage 5.0 (TID 596)
[2025-07-19T20:31:05.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 166.0 in stage 5.0 (TID 588) in 115 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:31:05.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.1.delta.f5527557-5d6b-40b0-8751-97cc16b7eebb.TID592.tmp
[2025-07-19T20:31:05.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b406b18
[2025-07-19T20:31:05.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184] for update
[2025-07-19T20:31:05.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.1.delta.4d335c10-32b7-4b08-9f51-8bbe10f44c80.TID589.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta
[2025-07-19T20:31:05.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/167/1.delta
[2025-07-19T20:31:05.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 589, attempt 0, stage 5.0)
[2025-07-19T20:31:05.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d4684c8
[2025-07-19T20:31:05.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.276+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189] for update
[2025-07-19T20:31:05.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 167 (task 589, attempt 0, stage 5.0)
[2025-07-19T20:31:05.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 167.0 in stage 5.0 (TID 589). 6243 bytes result sent to driver
[2025-07-19T20:31:05.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.1.delta.22c60a03-a3a1-439b-a156-94d3f9eb89ba.TID595.tmp
[2025-07-19T20:31:05.279+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 191.0 in stage 5.0 (TID 597) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 167.0 in stage 5.0 (TID 589) in 112 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:31:05.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 191.0 in stage 5.0 (TID 597)
[2025-07-19T20:31:05.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.1.delta.24644499-c849-46f4-b6b2-e0200ba59107.TID591.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta
[2025-07-19T20:31:05.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/171/1.delta
[2025-07-19T20:31:05.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.1.delta.36383b20-83c2-4c35-8d02-ab8e2236fd63.TID594.tmp
[2025-07-19T20:31:05.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 591, attempt 0, stage 5.0)
[2025-07-19T20:31:05.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.1.delta.70829aa3-5cea-4d84-a87e-ddf5d2b3c623.TID596.tmp
[2025-07-19T20:31:05.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.1.delta.9cdfa180-b23c-4ce2-87e3-40b60161b091.TID593.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta
[2025-07-19T20:31:05.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/176/1.delta
[2025-07-19T20:31:05.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17e94b36
[2025-07-19T20:31:05.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 171 (task 591, attempt 0, stage 5.0)
[2025-07-19T20:31:05.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191] for update
[2025-07-19T20:31:05.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 171.0 in stage 5.0 (TID 591). 6243 bytes result sent to driver
[2025-07-19T20:31:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 171.0 in stage 5.0 (TID 591) in 92 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:31:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 193.0 in stage 5.0 (TID 598) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 193.0 in stage 5.0 (TID 598)
[2025-07-19T20:31:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.1.delta.b098e894-0db9-4b1d-80ee-0a6cb54d9cf1.TID590.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta
[2025-07-19T20:31:05.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 593, attempt 0, stage 5.0)
[2025-07-19T20:31:05.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/168/1.delta
[2025-07-19T20:31:05.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 590, attempt 0, stage 5.0)
[2025-07-19T20:31:05.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 168 (task 590, attempt 0, stage 5.0)
[2025-07-19T20:31:05.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 168.0 in stage 5.0 (TID 590). 6243 bytes result sent to driver
[2025-07-19T20:31:05.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 176 (task 593, attempt 0, stage 5.0)
[2025-07-19T20:31:05.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 176.0 in stage 5.0 (TID 593). 6243 bytes result sent to driver
[2025-07-19T20:31:05.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 194.0 in stage 5.0 (TID 599) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 194.0 in stage 5.0 (TID 599)
[2025-07-19T20:31:05.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 196.0 in stage 5.0 (TID 600) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 196.0 in stage 5.0 (TID 600)
[2025-07-19T20:31:05.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 168.0 in stage 5.0 (TID 590) in 131 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:31:05.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 176.0 in stage 5.0 (TID 593) in 89 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:31:05.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.1.delta.b094b835-1aeb-4268-b87c-1953ffed4de4.TID597.tmp
[2025-07-19T20:31:05.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55f25bd8
[2025-07-19T20:31:05.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193] for update
[2025-07-19T20:31:05.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.1.delta.f5527557-5d6b-40b0-8751-97cc16b7eebb.TID592.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta
[2025-07-19T20:31:05.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/173/1.delta
[2025-07-19T20:31:05.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 592, attempt 0, stage 5.0)
[2025-07-19T20:31:05.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1061eb59
[2025-07-19T20:31:05.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196] for update
[2025-07-19T20:31:05.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 173 (task 592, attempt 0, stage 5.0)
[2025-07-19T20:31:05.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 173.0 in stage 5.0 (TID 592). 6243 bytes result sent to driver
[2025-07-19T20:31:05.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 197.0 in stage 5.0 (TID 601) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 173.0 in stage 5.0 (TID 592) in 105 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:31:05.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 197.0 in stage 5.0 (TID 601)
[2025-07-19T20:31:05.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.1.delta.22c60a03-a3a1-439b-a156-94d3f9eb89ba.TID595.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta
[2025-07-19T20:31:05.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/187/1.delta
[2025-07-19T20:31:05.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 595, attempt 0, stage 5.0)
[2025-07-19T20:31:05.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.1.delta.20d68351-9c85-4106-86c8-3d3bb954717f.TID598.tmp
[2025-07-19T20:31:05.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fde86a5
[2025-07-19T20:31:05.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 187 (task 595, attempt 0, stage 5.0)
[2025-07-19T20:31:05.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.329+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 187.0 in stage 5.0 (TID 595). 6243 bytes result sent to driver
[2025-07-19T20:31:05.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194] for update
[2025-07-19T20:31:05.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 198.0 in stage 5.0 (TID 602) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 187.0 in stage 5.0 (TID 595) in 99 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:31:05.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.1.delta.95edf789-f2a7-4fd3-b588-7627b67e8ebb.TID600.tmp
[2025-07-19T20:31:05.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.1.delta.36383b20-83c2-4c35-8d02-ab8e2236fd63.TID594.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta
[2025-07-19T20:31:05.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/184/1.delta
[2025-07-19T20:31:05.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 198.0 in stage 5.0 (TID 602)
[2025-07-19T20:31:05.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 594, attempt 0, stage 5.0)
[2025-07-19T20:31:05.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c98cfee
[2025-07-19T20:31:05.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197] for update
[2025-07-19T20:31:05.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 184 (task 594, attempt 0, stage 5.0)
[2025-07-19T20:31:05.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 184.0 in stage 5.0 (TID 594). 6243 bytes result sent to driver
[2025-07-19T20:31:05.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.1.delta.70829aa3-5cea-4d84-a87e-ddf5d2b3c623.TID596.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta
[2025-07-19T20:31:05.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/189/1.delta
[2025-07-19T20:31:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 596, attempt 0, stage 5.0)
[2025-07-19T20:31:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 603) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 184.0 in stage 5.0 (TID 594) in 113 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:31:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 0.0 in stage 7.0 (TID 603)
[2025-07-19T20:31:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d6b5b7d
[2025-07-19T20:31:05.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],1022e83e-36d1-4afb-8314-3ff56fa50ef9) is active
[2025-07-19T20:31:05.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 0 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198] for update
[2025-07-19T20:31:05.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e422386
[2025-07-19T20:31:05.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0] for update
[2025-07-19T20:31:05.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 189 (task 596, attempt 0, stage 5.0)
[2025-07-19T20:31:05.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.1.delta.2efbc101-d69c-4f69-bea4-f936952e21e0.TID599.tmp
[2025-07-19T20:31:05.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 189.0 in stage 5.0 (TID 596). 6286 bytes result sent to driver
[2025-07-19T20:31:05.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 604) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 1.0 in stage 7.0 (TID 604)
[2025-07-19T20:31:05.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 189.0 in stage 5.0 (TID 596) in 90 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:31:05.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@84e60b5
[2025-07-19T20:31:05.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1] for update
[2025-07-19T20:31:05.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.1.delta.9e798e7c-6671-4b47-bba4-98de1de5612f.TID601.tmp
[2025-07-19T20:31:05.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.1.delta.eec57dc8-d486-4c6d-b8b3-1158ae6444a1.TID602.tmp
[2025-07-19T20:31:05.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodeGenerator: Code generated in 6.579667 ms
[2025-07-19T20:31:05.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.1.delta.b094b835-1aeb-4268-b87c-1953ffed4de4.TID597.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta
[2025-07-19T20:31:05.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/191/1.delta
[2025-07-19T20:31:05.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 597, attempt 0, stage 5.0)
[2025-07-19T20:31:05.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 191 (task 597, attempt 0, stage 5.0)
[2025-07-19T20:31:05.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 191.0 in stage 5.0 (TID 597). 6243 bytes result sent to driver
[2025-07-19T20:31:05.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 605) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.376+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 2.0 in stage 7.0 (TID 605)
[2025-07-19T20:31:05.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.2.delta.6760fd15-f01f-4ee9-b318-9fc9ce647987.TID603.tmp
[2025-07-19T20:31:05.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 191.0 in stage 5.0 (TID 597) in 99 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:31:05.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.2.delta.c8b80dc8-63b9-4e15-b57a-4fd83e480c6a.TID604.tmp
[2025-07-19T20:31:05.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54758917
[2025-07-19T20:31:05.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2] for update
[2025-07-19T20:31:05.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.1.delta.20d68351-9c85-4106-86c8-3d3bb954717f.TID598.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta
[2025-07-19T20:31:05.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/193/1.delta
[2025-07-19T20:31:05.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 598, attempt 0, stage 5.0)
[2025-07-19T20:31:05.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 193 (task 598, attempt 0, stage 5.0)
[2025-07-19T20:31:05.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 193.0 in stage 5.0 (TID 598). 6243 bytes result sent to driver
[2025-07-19T20:31:05.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 606) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 193.0 in stage 5.0 (TID 598) in 99 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:31:05.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 3.0 in stage 7.0 (TID 606)
[2025-07-19T20:31:05.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@786d566d
[2025-07-19T20:31:05.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3] for update
[2025-07-19T20:31:05.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.2.delta.f2d15c70-3c3a-4b00-bb93-8da4029e1fed.TID605.tmp
[2025-07-19T20:31:05.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.1.delta.9e798e7c-6671-4b47-bba4-98de1de5612f.TID601.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta
[2025-07-19T20:31:05.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/197/1.delta
[2025-07-19T20:31:05.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.1.delta.2efbc101-d69c-4f69-bea4-f936952e21e0.TID599.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta
[2025-07-19T20:31:05.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/194/1.delta
[2025-07-19T20:31:05.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 601, attempt 0, stage 5.0)
[2025-07-19T20:31:05.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 599, attempt 0, stage 5.0)
[2025-07-19T20:31:05.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 197 (task 601, attempt 0, stage 5.0)
[2025-07-19T20:31:05.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 197.0 in stage 5.0 (TID 601). 6243 bytes result sent to driver
[2025-07-19T20:31:05.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 607) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 4.0 in stage 7.0 (TID 607)
[2025-07-19T20:31:05.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 197.0 in stage 5.0 (TID 601) in 88 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:31:05.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.1.delta.95edf789-f2a7-4fd3-b588-7627b67e8ebb.TID600.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta
[2025-07-19T20:31:05.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/196/1.delta
[2025-07-19T20:31:05.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 600, attempt 0, stage 5.0)
[2025-07-19T20:31:05.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 194 (task 599, attempt 0, stage 5.0)
[2025-07-19T20:31:05.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1623e42c
[2025-07-19T20:31:05.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4] for update
[2025-07-19T20:31:05.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 194.0 in stage 5.0 (TID 599). 6243 bytes result sent to driver
[2025-07-19T20:31:05.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 608) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 194.0 in stage 5.0 (TID 599) in 114 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:31:05.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.1.delta.eec57dc8-d486-4c6d-b8b3-1158ae6444a1.TID602.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta
[2025-07-19T20:31:05.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/state/0/198/1.delta
[2025-07-19T20:31:05.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 602, attempt 0, stage 5.0)
[2025-07-19T20:31:05.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 198 (task 602, attempt 0, stage 5.0)
[2025-07-19T20:31:05.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 198.0 in stage 5.0 (TID 602). 6243 bytes result sent to driver
[2025-07-19T20:31:05.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.2.delta.50796ee6-230b-4cd7-ae85-df3e626aaf9c.TID606.tmp
[2025-07-19T20:31:05.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.2.delta.57628fc8-56d9-4d49-bf8f-e77cfc053334.TID607.tmp
[2025-07-19T20:31:05.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 609) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 6.0 in stage 7.0 (TID 609)
[2025-07-19T20:31:05.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 198.0 in stage 5.0 (TID 602) in 104 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:31:05.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1db59115
[2025-07-19T20:31:05.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6] for update
[2025-07-19T20:31:05.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 196 (task 600, attempt 0, stage 5.0)
[2025-07-19T20:31:05.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.2.delta.6760fd15-f01f-4ee9-b318-9fc9ce647987.TID603.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/2.delta
[2025-07-19T20:31:05.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 196.0 in stage 5.0 (TID 600). 6243 bytes result sent to driver
[2025-07-19T20:31:05.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/0/2.delta
[2025-07-19T20:31:05.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 610) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 196.0 in stage 5.0 (TID 600) in 132 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:31:05.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-07-19T20:31:05.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T20:31:05.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 7.0 in stage 7.0 (TID 610)
[2025-07-19T20:31:05.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DAGScheduler: ResultStage 5 (start at <unknown>:0) finished in 12.475 s
[2025-07-19T20:31:05.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DAGScheduler: Job 2 finished: start at <unknown>:0, took 14.240067 s
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a684160
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 5.0 in stage 7.0 (TID 608)
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] is committing.
[2025-07-19T20:31:05.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO SparkWrite: Committing epoch 0 for query 3de98e67-50a3-4b36-b6f0-c27ff416e371 in append mode
[2025-07-19T20:31:05.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7] for update
[2025-07-19T20:31:05.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 0 (task 603, attempt 0, stage 7.0)
[2025-07-19T20:31:05.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 0.0 in stage 7.0 (TID 603). 5872 bytes result sent to driver
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 611) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 603) in 110 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16a65498
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5] for update
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.2.delta.c9e0c3af-7fc1-4163-b32a-b25d2923d74d.TID609.tmp
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 8.0 in stage 7.0 (TID 611)
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.2.delta.c8b80dc8-63b9-4e15-b57a-4fd83e480c6a.TID604.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/2.delta
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/1/2.delta
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76b4e723
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8] for update
[2025-07-19T20:31:05.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO SparkWrite: Committing streaming append with 127 new data files to table my_catalog.bronze.Reservations_raw
[2025-07-19T20:31:05.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 1 (task 604, attempt 0, stage 7.0)
[2025-07-19T20:31:05.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.2.delta.38f196c1-4371-4d0d-924c-8e3801f4ea73.TID610.tmp
[2025-07-19T20:31:05.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.2.delta.f2d15c70-3c3a-4b00-bb93-8da4029e1fed.TID605.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/2.delta
[2025-07-19T20:31:05.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/2/2.delta
[2025-07-19T20:31:05.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T20:31:05.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.2.delta.50e4b1d6-a5d0-43e9-aa35-ec3b2707a87f.TID608.tmp
[2025-07-19T20:31:05.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 2 (task 605, attempt 0, stage 7.0)
[2025-07-19T20:31:05.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 1.0 in stage 7.0 (TID 604). 5829 bytes result sent to driver
[2025-07-19T20:31:05.500+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 2.0 in stage 7.0 (TID 605). 5915 bytes result sent to driver
[2025-07-19T20:31:05.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 612) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 613) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 604) in 140 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:31:05.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 605) in 118 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:31:05.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 10.0 in stage 7.0 (TID 613)
[2025-07-19T20:31:05.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 9.0 in stage 7.0 (TID 612)
[2025-07-19T20:31:05.505+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.2.delta.1f6f9bf9-5044-4326-886e-79d186f64517.TID611.tmp
[2025-07-19T20:31:05.505+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f53f9ff
[2025-07-19T20:31:05.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9] for update
[2025-07-19T20:31:05.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2366fff9
[2025-07-19T20:31:05.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10] for update
[2025-07-19T20:31:05.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.2.delta.57628fc8-56d9-4d49-bf8f-e77cfc053334.TID607.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/2.delta
[2025-07-19T20:31:05.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/4/2.delta
[2025-07-19T20:31:05.523+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T20:31:05.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 4 (task 607, attempt 0, stage 7.0)
[2025-07-19T20:31:05.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 4.0 in stage 7.0 (TID 607). 5872 bytes result sent to driver
[2025-07-19T20:31:05.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 614) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 607) in 126 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:31:05.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 11.0 in stage 7.0 (TID 614)
[2025-07-19T20:31:05.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f5eda96
[2025-07-19T20:31:05.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11] for update
[2025-07-19T20:31:05.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.2.delta.49db68ab-397b-442e-9c27-ead72ee2656e.TID612.tmp
[2025-07-19T20:31:05.538+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.540+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.2.delta.50796ee6-230b-4cd7-ae85-df3e626aaf9c.TID606.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/2.delta
[2025-07-19T20:31:05.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/3/2.delta
[2025-07-19T20:31:05.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T20:31:05.544+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.2.delta.3c0c2799-62c5-4635-b015-3cf4cd3804c0.TID613.tmp
[2025-07-19T20:31:05.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 3 (task 606, attempt 0, stage 7.0)
[2025-07-19T20:31:05.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 3.0 in stage 7.0 (TID 606). 5872 bytes result sent to driver
[2025-07-19T20:31:05.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 12.0 in stage 7.0 (TID 615) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 12.0 in stage 7.0 (TID 615)
[2025-07-19T20:31:05.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 606) in 156 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:31:05.550+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73261376
[2025-07-19T20:31:05.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.554+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12] for update
[2025-07-19T20:31:05.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.2.delta.c9e0c3af-7fc1-4163-b32a-b25d2923d74d.TID609.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/2.delta
[2025-07-19T20:31:05.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/6/2.delta
[2025-07-19T20:31:05.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T20:31:05.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.2.delta.dd189694-4283-4fce-aee1-66b08fe6fab7.TID614.tmp
[2025-07-19T20:31:05.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 6 (task 609, attempt 0, stage 7.0)
[2025-07-19T20:31:05.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.2.delta.38f196c1-4371-4d0d-924c-8e3801f4ea73.TID610.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/2.delta
[2025-07-19T20:31:05.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/7/2.delta
[2025-07-19T20:31:05.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T20:31:05.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 6.0 in stage 7.0 (TID 609). 5872 bytes result sent to driver
[2025-07-19T20:31:05.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 13.0 in stage 7.0 (TID 616) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 13.0 in stage 7.0 (TID 616)
[2025-07-19T20:31:05.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@51fd7b0d
[2025-07-19T20:31:05.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 609) in 140 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:31:05.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13] for update
[2025-07-19T20:31:05.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.2.delta.50e4b1d6-a5d0-43e9-aa35-ec3b2707a87f.TID608.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/2.delta
[2025-07-19T20:31:05.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/5/2.delta
[2025-07-19T20:31:05.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T20:31:05.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.2.delta.1b2fb7f1-8548-4a3c-9b25-38be76f57147.TID615.tmp
[2025-07-19T20:31:05.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 7 (task 610, attempt 0, stage 7.0)
[2025-07-19T20:31:05.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 7.0 in stage 7.0 (TID 610). 5872 bytes result sent to driver
[2025-07-19T20:31:05.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 5 (task 608, attempt 0, stage 7.0)
[2025-07-19T20:31:05.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 5.0 in stage 7.0 (TID 608). 5872 bytes result sent to driver
[2025-07-19T20:31:05.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.2.delta.1f6f9bf9-5044-4326-886e-79d186f64517.TID611.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/2.delta
[2025-07-19T20:31:05.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/8/2.delta
[2025-07-19T20:31:05.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T20:31:05.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 14.0 in stage 7.0 (TID 617) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 14.0 in stage 7.0 (TID 617)
[2025-07-19T20:31:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 15.0 in stage 7.0 (TID 618) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 610) in 143 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:31:05.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 608) in 162 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:31:05.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 15.0 in stage 7.0 (TID 618)
[2025-07-19T20:31:05.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.2.delta.49db68ab-397b-442e-9c27-ead72ee2656e.TID612.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/2.delta
[2025-07-19T20:31:05.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/9/2.delta
[2025-07-19T20:31:05.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 8 (task 611, attempt 0, stage 7.0)
[2025-07-19T20:31:05.591+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 8.0 in stage 7.0 (TID 611). 5872 bytes result sent to driver
[2025-07-19T20:31:05.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53a1b624
[2025-07-19T20:31:05.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T20:31:05.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 611) in 136 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:31:05.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 16.0 in stage 7.0 (TID 619) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14] for update
[2025-07-19T20:31:05.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 16.0 in stage 7.0 (TID 619)
[2025-07-19T20:31:05.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e820b79
[2025-07-19T20:31:05.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.2.delta.1c0708e3-e3f1-4441-b9fe-f3bf1f11b9c1.TID616.tmp
[2025-07-19T20:31:05.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15] for update
[2025-07-19T20:31:05.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 9 (task 612, attempt 0, stage 7.0)
[2025-07-19T20:31:05.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 9.0 in stage 7.0 (TID 612). 5829 bytes result sent to driver
[2025-07-19T20:31:05.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c5162bc
[2025-07-19T20:31:05.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 17.0 in stage 7.0 (TID 620) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16] for update
[2025-07-19T20:31:05.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 17.0 in stage 7.0 (TID 620)
[2025-07-19T20:31:05.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 612) in 116 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:31:05.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3dbac72c
[2025-07-19T20:31:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17] for update
[2025-07-19T20:31:05.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.2.delta.b59913c8-3905-469e-baf0-51ddd1f81f7f.TID617.tmp
[2025-07-19T20:31:05.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.2.delta.3c0c2799-62c5-4635-b015-3cf4cd3804c0.TID613.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/2.delta
[2025-07-19T20:31:05.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/10/2.delta
[2025-07-19T20:31:05.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T20:31:05.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.2.delta.dd189694-4283-4fce-aee1-66b08fe6fab7.TID614.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/2.delta
[2025-07-19T20:31:05.617+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/11/2.delta
[2025-07-19T20:31:05.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T20:31:05.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.2.delta.4472bed2-5e24-4753-b297-7f5595544d9d.TID618.tmp
[2025-07-19T20:31:05.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 10 (task 613, attempt 0, stage 7.0)
[2025-07-19T20:31:05.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 10.0 in stage 7.0 (TID 613). 5872 bytes result sent to driver
[2025-07-19T20:31:05.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 18.0 in stage 7.0 (TID 621) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 613) in 123 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:31:05.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 11 (task 614, attempt 0, stage 7.0)
[2025-07-19T20:31:05.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 18.0 in stage 7.0 (TID 621)
[2025-07-19T20:31:05.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 11.0 in stage 7.0 (TID 614). 5872 bytes result sent to driver
[2025-07-19T20:31:05.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 19.0 in stage 7.0 (TID 622) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 614) in 86 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:31:05.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 19.0 in stage 7.0 (TID 622)
[2025-07-19T20:31:05.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8d1c330
[2025-07-19T20:31:05.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18] for update
[2025-07-19T20:31:05.630+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.2.delta.c2dd97f2-90a5-4bb2-a7f2-8298dbdaa42f.TID619.tmp
[2025-07-19T20:31:05.631+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@770e3baa
[2025-07-19T20:31:05.631+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.2.delta.ee111a8a-e376-4a44-966f-06e4c0410a57.TID620.tmp
[2025-07-19T20:31:05.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.633+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19] for update
[2025-07-19T20:31:05.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.2.delta.1b2fb7f1-8548-4a3c-9b25-38be76f57147.TID615.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/2.delta
[2025-07-19T20:31:05.637+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/12/2.delta
[2025-07-19T20:31:05.637+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T20:31:05.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.2.delta.3f276ce2-7711-43bd-aa4c-b2827ee78ee2.TID621.tmp
[2025-07-19T20:31:05.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 12 (task 615, attempt 0, stage 7.0)
[2025-07-19T20:31:05.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 12.0 in stage 7.0 (TID 615). 5872 bytes result sent to driver
[2025-07-19T20:31:05.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 20.0 in stage 7.0 (TID 623) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 12.0 in stage 7.0 (TID 615) in 94 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:31:05.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 20.0 in stage 7.0 (TID 623)
[2025-07-19T20:31:05.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7373a22
[2025-07-19T20:31:05.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.2.delta.9fa4c7b7-bf0e-476a-87f4-0bbeb78fe7a2.TID622.tmp
[2025-07-19T20:31:05.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20] for update
[2025-07-19T20:31:05.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.2.delta.1c0708e3-e3f1-4441-b9fe-f3bf1f11b9c1.TID616.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/2.delta
[2025-07-19T20:31:05.649+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/13/2.delta
[2025-07-19T20:31:05.650+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T20:31:05.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 13 (task 616, attempt 0, stage 7.0)
[2025-07-19T20:31:05.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.2.delta.b59913c8-3905-469e-baf0-51ddd1f81f7f.TID617.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/2.delta
[2025-07-19T20:31:05.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/14/2.delta
[2025-07-19T20:31:05.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T20:31:05.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 13.0 in stage 7.0 (TID 616). 5872 bytes result sent to driver
[2025-07-19T20:31:05.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 13.0 in stage 7.0 (TID 616) in 97 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:31:05.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 21.0 in stage 7.0 (TID 624) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 14 (task 617, attempt 0, stage 7.0)
[2025-07-19T20:31:05.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 21.0 in stage 7.0 (TID 624)
[2025-07-19T20:31:05.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 14.0 in stage 7.0 (TID 617). 5872 bytes result sent to driver
[2025-07-19T20:31:05.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 22.0 in stage 7.0 (TID 625) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1c04f30d
[2025-07-19T20:31:05.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21] for update
[2025-07-19T20:31:05.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 14.0 in stage 7.0 (TID 617) in 87 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:31:05.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 22.0 in stage 7.0 (TID 625)
[2025-07-19T20:31:05.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.2.delta.5b17fce1-acc7-425e-bbc9-b7c08cc2e39c.TID623.tmp
[2025-07-19T20:31:05.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.2.delta.c2dd97f2-90a5-4bb2-a7f2-8298dbdaa42f.TID619.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/2.delta
[2025-07-19T20:31:05.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/16/2.delta
[2025-07-19T20:31:05.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f387b1f
[2025-07-19T20:31:05.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T20:31:05.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22] for update
[2025-07-19T20:31:05.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 16 (task 619, attempt 0, stage 7.0)
[2025-07-19T20:31:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Reservations_raw/metadata/v56.metadata.json
[2025-07-19T20:31:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 16.0 in stage 7.0 (TID 619). 5872 bytes result sent to driver
[2025-07-19T20:31:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 23.0 in stage 7.0 (TID 626) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 23.0 in stage 7.0 (TID 626)
[2025-07-19T20:31:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 16.0 in stage 7.0 (TID 619) in 95 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:31:05.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.2.delta.4472bed2-5e24-4753-b297-7f5595544d9d.TID618.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/2.delta
[2025-07-19T20:31:05.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/15/2.delta
[2025-07-19T20:31:05.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T20:31:05.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.2.delta.ee111a8a-e376-4a44-966f-06e4c0410a57.TID620.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/2.delta
[2025-07-19T20:31:05.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/17/2.delta
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6c2134b8
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23] for update
[2025-07-19T20:31:05.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.2.delta.fae3886f-81e1-45ad-98d1-785b7260e565.TID625.tmp
[2025-07-19T20:31:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 15 (task 618, attempt 0, stage 7.0)
[2025-07-19T20:31:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 15.0 in stage 7.0 (TID 618). 5872 bytes result sent to driver
[2025-07-19T20:31:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 24.0 in stage 7.0 (TID 627) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 17 (task 620, attempt 0, stage 7.0)
[2025-07-19T20:31:05.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 15.0 in stage 7.0 (TID 618) in 112 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:31:05.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 17.0 in stage 7.0 (TID 620). 5872 bytes result sent to driver
[2025-07-19T20:31:05.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 25.0 in stage 7.0 (TID 628) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 24.0 in stage 7.0 (TID 627)
[2025-07-19T20:31:05.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 17.0 in stage 7.0 (TID 620) in 98 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:31:05.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 25.0 in stage 7.0 (TID 628)
[2025-07-19T20:31:05.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.2.delta.8f17903b-ee30-44d4-8b7b-9a63989d3604.TID624.tmp
[2025-07-19T20:31:05.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.2.delta.3f276ce2-7711-43bd-aa4c-b2827ee78ee2.TID621.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/2.delta
[2025-07-19T20:31:05.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/18/2.delta
[2025-07-19T20:31:05.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@443b57e2
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25] for update
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71203586
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24] for update
[2025-07-19T20:31:05.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.2.delta.9fa4c7b7-bf0e-476a-87f4-0bbeb78fe7a2.TID622.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/2.delta
[2025-07-19T20:31:05.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/19/2.delta
[2025-07-19T20:31:05.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T20:31:05.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 18 (task 621, attempt 0, stage 7.0)
[2025-07-19T20:31:05.711+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 18.0 in stage 7.0 (TID 621). 5872 bytes result sent to driver
[2025-07-19T20:31:05.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 18.0 in stage 7.0 (TID 621) in 92 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:31:05.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 26.0 in stage 7.0 (TID 629) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 26.0 in stage 7.0 (TID 629)
[2025-07-19T20:31:05.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 19 (task 622, attempt 0, stage 7.0)
[2025-07-19T20:31:05.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 19.0 in stage 7.0 (TID 622). 5829 bytes result sent to driver
[2025-07-19T20:31:05.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.2.delta.ab881fdd-abec-40bf-bf3b-2377e277ad07.TID628.tmp
[2025-07-19T20:31:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 27.0 in stage 7.0 (TID 630) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.2.delta.94b51f61-b6fd-43d1-9d49-4630ae66fec0.TID626.tmp
[2025-07-19T20:31:05.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 19.0 in stage 7.0 (TID 622) in 98 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:31:05.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 27.0 in stage 7.0 (TID 630)
[2025-07-19T20:31:05.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60be6ada
[2025-07-19T20:31:05.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27] for update
[2025-07-19T20:31:05.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.728+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.729+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5cc631b9
[2025-07-19T20:31:05.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.731+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26] for update
[2025-07-19T20:31:05.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.2.delta.53d2241c-7a8b-41fd-b494-9a8744d5bce5.TID627.tmp
[2025-07-19T20:31:05.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.2.delta.3b1ba41e-f3c2-4019-ac34-c30256541475.TID630.tmp
[2025-07-19T20:31:05.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO SnapshotProducer: Committed snapshot 5446313518187781837 (FastAppend)
[2025-07-19T20:31:05.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.2.delta.5b17fce1-acc7-425e-bbc9-b7c08cc2e39c.TID623.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/2.delta
[2025-07-19T20:31:05.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/20/2.delta
[2025-07-19T20:31:05.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.2.delta.70b0fc2d-0b31-4eaa-a05a-8794f0623966.TID629.tmp
[2025-07-19T20:31:05.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T20:31:05.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.2.delta.fae3886f-81e1-45ad-98d1-785b7260e565.TID625.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/2.delta
[2025-07-19T20:31:05.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/22/2.delta
[2025-07-19T20:31:05.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 20 (task 623, attempt 0, stage 7.0)
[2025-07-19T20:31:05.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T20:31:05.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 20.0 in stage 7.0 (TID 623). 5872 bytes result sent to driver
[2025-07-19T20:31:05.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 28.0 in stage 7.0 (TID 631) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 20.0 in stage 7.0 (TID 623) in 118 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:31:05.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 28.0 in stage 7.0 (TID 631)
[2025-07-19T20:31:05.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 22 (task 625, attempt 0, stage 7.0)
[2025-07-19T20:31:05.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 22.0 in stage 7.0 (TID 625). 5872 bytes result sent to driver
[2025-07-19T20:31:05.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1752043c
[2025-07-19T20:31:05.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 29.0 in stage 7.0 (TID 632) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 22.0 in stage 7.0 (TID 625) in 112 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:31:05.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 29.0 in stage 7.0 (TID 632)
[2025-07-19T20:31:05.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28] for update
[2025-07-19T20:31:05.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40329010
[2025-07-19T20:31:05.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29] for update
[2025-07-19T20:31:05.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.2.delta.8f17903b-ee30-44d4-8b7b-9a63989d3604.TID624.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/2.delta
[2025-07-19T20:31:05.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/21/2.delta
[2025-07-19T20:31:05.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T20:31:05.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 21 (task 624, attempt 0, stage 7.0)
[2025-07-19T20:31:05.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 21.0 in stage 7.0 (TID 624). 5872 bytes result sent to driver
[2025-07-19T20:31:05.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 30.0 in stage 7.0 (TID 633) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.810+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 30.0 in stage 7.0 (TID 633)
[2025-07-19T20:31:05.810+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 21.0 in stage 7.0 (TID 624) in 142 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:31:05.810+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5da5545
[2025-07-19T20:31:05.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30] for update
[2025-07-19T20:31:05.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.2.delta.5fd38611-86d5-4031-86c6-eedf47d3dc03.TID631.tmp
[2025-07-19T20:31:05.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Reservations_raw, snapshotId=5446313518187781837, sequenceNumber=55, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.354305334S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=127}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=4984}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=200}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=6774}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=379622}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=14844176}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752957046551, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:31:05.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO SparkWrite: Committed in 354 ms
[2025-07-19T20:31:05.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: IcebergStreamingWrite(table=my_catalog.bronze.Reservations_raw, format=PARQUET)] committed.
[2025-07-19T20:31:05.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.2.delta.ab881fdd-abec-40bf-bf3b-2377e277ad07.TID628.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/2.delta
[2025-07-19T20:31:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/25/2.delta
[2025-07-19T20:31:05.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T20:31:05.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.2.delta.efe55625-f8bc-4ae8-8a8e-1454e280ca8c.TID633.tmp
[2025-07-19T20:31:05.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.2.delta.71be0472-8809-4ca1-8a82-27153a9b6b99.TID632.tmp
[2025-07-19T20:31:05.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.2.delta.3b1ba41e-f3c2-4019-ac34-c30256541475.TID630.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/2.delta
[2025-07-19T20:31:05.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/27/2.delta
[2025-07-19T20:31:05.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T20:31:05.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.2.delta.94b51f61-b6fd-43d1-9d49-4630ae66fec0.TID626.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/2.delta
[2025-07-19T20:31:05.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/23/2.delta
[2025-07-19T20:31:05.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T20:31:05.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 27 (task 630, attempt 0, stage 7.0)
[2025-07-19T20:31:05.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 27.0 in stage 7.0 (TID 630). 5829 bytes result sent to driver
[2025-07-19T20:31:05.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 31.0 in stage 7.0 (TID 634) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 31.0 in stage 7.0 (TID 634)
[2025-07-19T20:31:05.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 27.0 in stage 7.0 (TID 630) in 125 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:31:05.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.2.delta.53d2241c-7a8b-41fd-b494-9a8744d5bce5.TID627.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/2.delta
[2025-07-19T20:31:05.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/24/2.delta
[2025-07-19T20:31:05.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/commits/0 using temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/commits/.0.2e90a8e8-947f-4335-8df8-361194398777.tmp
[2025-07-19T20:31:05.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 23 (task 626, attempt 0, stage 7.0)
[2025-07-19T20:31:05.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 25 (task 628, attempt 0, stage 7.0)
[2025-07-19T20:31:05.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 25.0 in stage 7.0 (TID 628). 5829 bytes result sent to driver
[2025-07-19T20:31:05.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T20:31:05.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 32.0 in stage 7.0 (TID 635) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 23.0 in stage 7.0 (TID 626). 5872 bytes result sent to driver
[2025-07-19T20:31:05.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13c37bec
[2025-07-19T20:31:05.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31] for update
[2025-07-19T20:31:05.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 33.0 in stage 7.0 (TID 636) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 32.0 in stage 7.0 (TID 635)
[2025-07-19T20:31:05.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 24 (task 627, attempt 0, stage 7.0)
[2025-07-19T20:31:05.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 25.0 in stage 7.0 (TID 628) in 164 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:31:05.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 24.0 in stage 7.0 (TID 627). 5872 bytes result sent to driver
[2025-07-19T20:31:05.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 34.0 in stage 7.0 (TID 637) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 23.0 in stage 7.0 (TID 626) in 178 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:31:05.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 34.0 in stage 7.0 (TID 637)
[2025-07-19T20:31:05.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 33.0 in stage 7.0 (TID 636)
[2025-07-19T20:31:05.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.864+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 24.0 in stage 7.0 (TID 627) in 168 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:31:05.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2d335995
[2025-07-19T20:31:05.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.868+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:05.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32] for update
[2025-07-19T20:31:05.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@226fd185
[2025-07-19T20:31:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.2.delta.70b0fc2d-0b31-4eaa-a05a-8794f0623966.TID629.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/2.delta
[2025-07-19T20:31:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/26/2.delta
[2025-07-19T20:31:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T20:31:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33] for update
[2025-07-19T20:31:05.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67057c11
[2025-07-19T20:31:05.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 26 (task 629, attempt 0, stage 7.0)
[2025-07-19T20:31:05.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34] for update
[2025-07-19T20:31:05.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 26.0 in stage 7.0 (TID 629). 5915 bytes result sent to driver
[2025-07-19T20:31:05.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 35.0 in stage 7.0 (TID 638) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.910+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 35.0 in stage 7.0 (TID 638)
[2025-07-19T20:31:05.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 26.0 in stage 7.0 (TID 629) in 197 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:31:05.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.2.delta.63ee68f6-d554-4241-9bca-6f51bce8afc1.TID634.tmp
[2025-07-19T20:31:05.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@edf6fed
[2025-07-19T20:31:05.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35] for update
[2025-07-19T20:31:05.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.2.delta.6ee4fccc-29bb-4b8e-a021-ca4c88fe9fca.TID635.tmp
[2025-07-19T20:31:05.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.2.delta.5fd38611-86d5-4031-86c6-eedf47d3dc03.TID631.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/2.delta
[2025-07-19T20:31:05.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/28/2.delta
[2025-07-19T20:31:05.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T20:31:05.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.2.delta.0831fdbc-0bfa-406f-86fd-d1b83de0e844.TID636.tmp
[2025-07-19T20:31:05.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.2.delta.166aea69-c423-4c43-a330-ec04c25926b9.TID637.tmp
[2025-07-19T20:31:05.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 28 (task 631, attempt 0, stage 7.0)
[2025-07-19T20:31:05.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.2.delta.2591d58b-eed3-4c9f-b905-1a63de6746df.TID638.tmp
[2025-07-19T20:31:05.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 28.0 in stage 7.0 (TID 631). 5872 bytes result sent to driver
[2025-07-19T20:31:05.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.2.delta.efe55625-f8bc-4ae8-8a8e-1454e280ca8c.TID633.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/2.delta
[2025-07-19T20:31:05.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/30/2.delta
[2025-07-19T20:31:05.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 36.0 in stage 7.0 (TID 639) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 28.0 in stage 7.0 (TID 631) in 186 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:31:05.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 36.0 in stage 7.0 (TID 639)
[2025-07-19T20:31:05.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T20:31:05.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 30 (task 633, attempt 0, stage 7.0)
[2025-07-19T20:31:05.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:05.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 30.0 in stage 7.0 (TID 633). 5872 bytes result sent to driver
[2025-07-19T20:31:05.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 37.0 in stage 7.0 (TID 640) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 37.0 in stage 7.0 (TID 640)
[2025-07-19T20:31:05.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 30.0 in stage 7.0 (TID 633) in 149 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:31:05.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@260a8629
[2025-07-19T20:31:05.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.2.delta.71be0472-8809-4ca1-8a82-27153a9b6b99.TID632.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/2.delta
[2025-07-19T20:31:05.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/29/2.delta
[2025-07-19T20:31:05.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36] for update
[2025-07-19T20:31:05.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T20:31:05.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:05.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:05.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 29 (task 632, attempt 0, stage 7.0)
[2025-07-19T20:31:05.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:05.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 29.0 in stage 7.0 (TID 632). 5872 bytes result sent to driver
[2025-07-19T20:31:05.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/commits/.0.2e90a8e8-947f-4335-8df8-361194398777.tmp to file:/tmp/checkpoints/reservations/scheduled__2025-07-19T20:28:00+00:00/commits/0
[2025-07-19T20:31:05.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 38.0 in stage 7.0 (TID 641) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:05.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 38.0 in stage 7.0 (TID 641)
[2025-07-19T20:31:05.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d2af7cc
[2025-07-19T20:31:05.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 29.0 in stage 7.0 (TID 632) in 184 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:31:05.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:05.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37] for update
[2025-07-19T20:31:05.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:31:05.980+0000] {subprocess.py:93} INFO -   "id" : "3de98e67-50a3-4b36-b6f0-c27ff416e371",
[2025-07-19T20:31:05.981+0000] {subprocess.py:93} INFO -   "runId" : "1022e83e-36d1-4afb-8314-3ff56fa50ef9",
[2025-07-19T20:31:05.981+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:31:05.982+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:30:49.079Z",
[2025-07-19T20:31:05.983+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-07-19T20:31:05.983+0000] {subprocess.py:93} INFO -   "numInputRows" : 207,
[2025-07-19T20:31:05.984+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:05.985+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 12.265939796160227,
[2025-07-19T20:31:05.985+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:31:05.986+0000] {subprocess.py:93} INFO -     "addBatch" : 15498,
[2025-07-19T20:31:05.986+0000] {subprocess.py:93} INFO -     "commitOffsets" : 131,
[2025-07-19T20:31:05.987+0000] {subprocess.py:93} INFO -     "getBatch" : 9,
[2025-07-19T20:31:05.988+0000] {subprocess.py:93} INFO -     "latestOffset" : 596,
[2025-07-19T20:31:05.989+0000] {subprocess.py:93} INFO -     "queryPlanning" : 564,
[2025-07-19T20:31:05.991+0000] {subprocess.py:93} INFO -     "triggerExecution" : 16876,
[2025-07-19T20:31:05.992+0000] {subprocess.py:93} INFO -     "walCommit" : 56
[2025-07-19T20:31:05.992+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:05.992+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:31:05.993+0000] {subprocess.py:93} INFO -     "avg" : "1970-01-01T00:00:00.000Z",
[2025-07-19T20:31:05.994+0000] {subprocess.py:93} INFO -     "max" : "1970-01-01T00:00:00.000Z",
[2025-07-19T20:31:05.996+0000] {subprocess.py:93} INFO -     "min" : "1970-01-01T00:00:00.000Z",
[2025-07-19T20:31:05.997+0000] {subprocess.py:93} INFO -     "watermark" : "1970-01-01T00:00:00.000Z"
[2025-07-19T20:31:06.002+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:06.002+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:31:06.003+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:31:06.003+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 200,
[2025-07-19T20:31:06.003+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 200,
[2025-07-19T20:31:06.004+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 2767,
[2025-07-19T20:31:06.004+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:31:06.006+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 123,
[2025-07-19T20:31:06.006+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 13496,
[2025-07-19T20:31:06.007+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 94960,
[2025-07-19T20:31:06.009+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:31:06.010+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:31:06.010+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:31:06.011+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:31:06.011+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 0,
[2025-07-19T20:31:06.012+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:31:06.012+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 7,
[2025-07-19T20:31:06.014+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 66160
[2025-07-19T20:31:06.014+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:06.015+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:06.017+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:31:06.019+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[reservations]]",
[2025-07-19T20:31:06.019+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-07-19T20:31:06.020+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:31:06.020+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T20:31:06.021+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:06.022+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:06.022+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:06.023+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:31:06.023+0000] {subprocess.py:93} INFO -       "reservations" : {
[2025-07-19T20:31:06.023+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:06.024+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:06.024+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:06.024+0000] {subprocess.py:93} INFO -     "numInputRows" : 207,
[2025-07-19T20:31:06.024+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:06.025+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 12.265939796160227,
[2025-07-19T20:31:06.026+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:31:06.027+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:31:06.027+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:31:06.028+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:31:06.029+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:06.029+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:06.030+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:31:06.031+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Reservations_raw",
[2025-07-19T20:31:06.034+0000] {subprocess.py:93} INFO -     "numOutputRows" : 200
[2025-07-19T20:31:06.034+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:31:06.035+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:31:06.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@24827f28
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38] for update
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.2.delta.63ee68f6-d554-4241-9bca-6f51bce8afc1.TID634.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/2.delta
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/31/2.delta
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 31 (task 634, attempt 0, stage 7.0)
[2025-07-19T20:31:06.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 31.0 in stage 7.0 (TID 634). 5872 bytes result sent to driver
[2025-07-19T20:31:06.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 39.0 in stage 7.0 (TID 642) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 39.0 in stage 7.0 (TID 642)
[2025-07-19T20:31:06.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 31.0 in stage 7.0 (TID 634) in 141 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:31:06.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.2.delta.105e878d-ce42-4d74-a6e7-3b94b99aec7b.TID640.tmp
[2025-07-19T20:31:06.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.046+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.048+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bbc116
[2025-07-19T20:31:06.049+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.2.delta.e043f85d-6957-4269-ba6c-c2974f388034.TID639.tmp
[2025-07-19T20:31:06.051+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.2.delta.36839360-9589-455e-a5ad-35639aac04be.TID641.tmp
[2025-07-19T20:31:06.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.2.delta.6ee4fccc-29bb-4b8e-a021-ca4c88fe9fca.TID635.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/2.delta
[2025-07-19T20:31:06.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/32/2.delta
[2025-07-19T20:31:06.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T20:31:06.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.2.delta.0831fdbc-0bfa-406f-86fd-d1b83de0e844.TID636.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/2.delta
[2025-07-19T20:31:06.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/33/2.delta
[2025-07-19T20:31:06.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T20:31:06.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.2.delta.166aea69-c423-4c43-a330-ec04c25926b9.TID637.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/2.delta
[2025-07-19T20:31:06.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/34/2.delta
[2025-07-19T20:31:06.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T20:31:06.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 32 (task 635, attempt 0, stage 7.0)
[2025-07-19T20:31:06.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39] for update
[2025-07-19T20:31:06.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 32.0 in stage 7.0 (TID 635). 5872 bytes result sent to driver
[2025-07-19T20:31:06.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 34 (task 637, attempt 0, stage 7.0)
[2025-07-19T20:31:06.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO DataWritingSparkTask: Committed partition 33 (task 636, attempt 0, stage 7.0)
[2025-07-19T20:31:06.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 33.0 in stage 7.0 (TID 636). 5872 bytes result sent to driver
[2025-07-19T20:31:06.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 40.0 in stage 7.0 (TID 643) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 41.0 in stage 7.0 (TID 644) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 33.0 in stage 7.0 (TID 636) in 148 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:31:06.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 40.0 in stage 7.0 (TID 643)
[2025-07-19T20:31:06.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 41.0 in stage 7.0 (TID 644)
[2025-07-19T20:31:06.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Finished task 34.0 in stage 7.0 (TID 637). 5872 bytes result sent to driver
[2025-07-19T20:31:06.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Finished task 32.0 in stage 7.0 (TID 635) in 154 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:31:06.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO TaskSetManager: Starting task 42.0 in stage 7.0 (TID 645) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.092+0000] {subprocess.py:93} INFO - 25/07/19 20:31:05 INFO Executor: Running task 42.0 in stage 7.0 (TID 645)
[2025-07-19T20:31:06.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.2.delta.2591d58b-eed3-4c9f-b905-1a63de6746df.TID638.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/2.delta
[2025-07-19T20:31:06.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/35/2.delta
[2025-07-19T20:31:06.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 34.0 in stage 7.0 (TID 637) in 148 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:31:06.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T20:31:06.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 35 (task 638, attempt 0, stage 7.0)
[2025-07-19T20:31:06.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 35.0 in stage 7.0 (TID 638). 5829 bytes result sent to driver
[2025-07-19T20:31:06.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.097+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 43.0 in stage 7.0 (TID 646) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 35.0 in stage 7.0 (TID 638) in 104 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:31:06.110+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 43.0 in stage 7.0 (TID 646)
[2025-07-19T20:31:06.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e8398d0
[2025-07-19T20:31:06.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40] for update
[2025-07-19T20:31:06.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b336ff4
[2025-07-19T20:31:06.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43] for update
[2025-07-19T20:31:06.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@689cf073
[2025-07-19T20:31:06.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41] for update
[2025-07-19T20:31:06.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.117+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2bc0551f
[2025-07-19T20:31:06.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42] for update
[2025-07-19T20:31:06.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.2.delta.c0e335f8-40cd-4d6e-826a-15fd9498eb3b.TID644.tmp
[2025-07-19T20:31:06.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.2.delta.0c1ee53e-7952-4936-81e2-7ba0f399b3b9.TID643.tmp
[2025-07-19T20:31:06.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.2.delta.b72b413e-f247-44e6-b021-218ddfc9fd4b.TID646.tmp
[2025-07-19T20:31:06.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.2.delta.c0aa4b74-0915-47c0-8672-9c4c1c1a86f1.TID645.tmp
[2025-07-19T20:31:06.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.2.delta.d2819958-dc71-443f-8a59-f15b42a4f67c.TID642.tmp
[2025-07-19T20:31:06.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.2.delta.e043f85d-6957-4269-ba6c-c2974f388034.TID639.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/2.delta
[2025-07-19T20:31:06.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/36/2.delta
[2025-07-19T20:31:06.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T20:31:06.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 36 (task 639, attempt 0, stage 7.0)
[2025-07-19T20:31:06.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 36.0 in stage 7.0 (TID 639). 5872 bytes result sent to driver
[2025-07-19T20:31:06.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 44.0 in stage 7.0 (TID 647) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 44.0 in stage 7.0 (TID 647)
[2025-07-19T20:31:06.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 36.0 in stage 7.0 (TID 639) in 111 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:31:06.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19e70bd2
[2025-07-19T20:31:06.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44] for update
[2025-07-19T20:31:06.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.2.delta.105e878d-ce42-4d74-a6e7-3b94b99aec7b.TID640.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/2.delta
[2025-07-19T20:31:06.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/37/2.delta
[2025-07-19T20:31:06.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T20:31:06.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 37 (task 640, attempt 0, stage 7.0)
[2025-07-19T20:31:06.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.2.delta.36839360-9589-455e-a5ad-35639aac04be.TID641.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/2.delta
[2025-07-19T20:31:06.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.2.delta.56463840-decb-485a-aec4-aa7942393e6c.TID647.tmp
[2025-07-19T20:31:06.142+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/38/2.delta
[2025-07-19T20:31:06.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 37.0 in stage 7.0 (TID 640). 5872 bytes result sent to driver
[2025-07-19T20:31:06.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T20:31:06.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 45.0 in stage 7.0 (TID 648) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 45.0 in stage 7.0 (TID 648)
[2025-07-19T20:31:06.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 37.0 in stage 7.0 (TID 640) in 159 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:31:06.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3526c92c
[2025-07-19T20:31:06.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 38 (task 641, attempt 0, stage 7.0)
[2025-07-19T20:31:06.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45] for update
[2025-07-19T20:31:06.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 38.0 in stage 7.0 (TID 641). 5872 bytes result sent to driver
[2025-07-19T20:31:06.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 46.0 in stage 7.0 (TID 649) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 46.0 in stage 7.0 (TID 649)
[2025-07-19T20:31:06.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 38.0 in stage 7.0 (TID 641) in 160 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:31:06.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@69bdd6d2
[2025-07-19T20:31:06.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46] for update
[2025-07-19T20:31:06.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.2.delta.091762bd-61a9-42fc-ad36-953c3b877d7a.TID648.tmp
[2025-07-19T20:31:06.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.2.delta.c0e335f8-40cd-4d6e-826a-15fd9498eb3b.TID644.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/2.delta
[2025-07-19T20:31:06.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/41/2.delta
[2025-07-19T20:31:06.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T20:31:06.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 41 (task 644, attempt 0, stage 7.0)
[2025-07-19T20:31:06.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 41.0 in stage 7.0 (TID 644). 5872 bytes result sent to driver
[2025-07-19T20:31:06.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 47.0 in stage 7.0 (TID 650) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 47.0 in stage 7.0 (TID 650)
[2025-07-19T20:31:06.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.2.delta.d2819958-dc71-443f-8a59-f15b42a4f67c.TID642.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/2.delta
[2025-07-19T20:31:06.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 41.0 in stage 7.0 (TID 644) in 137 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:31:06.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/39/2.delta
[2025-07-19T20:31:06.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T20:31:06.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.2.delta.0c1ee53e-7952-4936-81e2-7ba0f399b3b9.TID643.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/2.delta
[2025-07-19T20:31:06.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/40/2.delta
[2025-07-19T20:31:06.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.2.delta.b72b413e-f247-44e6-b021-218ddfc9fd4b.TID646.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/2.delta
[2025-07-19T20:31:06.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/43/2.delta
[2025-07-19T20:31:06.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:06.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T20:31:06.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T20:31:06.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 39 (task 642, attempt 0, stage 7.0)
[2025-07-19T20:31:06.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.2.delta.565cab52-12e2-4880-b6e6-c542fef1a26e.TID649.tmp
[2025-07-19T20:31:06.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 39.0 in stage 7.0 (TID 642). 5872 bytes result sent to driver
[2025-07-19T20:31:06.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.2.delta.c0aa4b74-0915-47c0-8672-9c4c1c1a86f1.TID645.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/2.delta
[2025-07-19T20:31:06.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/42/2.delta
[2025-07-19T20:31:06.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 48.0 in stage 7.0 (TID 651) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 39.0 in stage 7.0 (TID 642) in 168 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 48.0 in stage 7.0 (TID 651)
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@420aabde
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 40 (task 643, attempt 0, stage 7.0)
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 40.0 in stage 7.0 (TID 643). 5872 bytes result sent to driver
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 49.0 in stage 7.0 (TID 652) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47] for update
[2025-07-19T20:31:06.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 40.0 in stage 7.0 (TID 643) in 151 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:31:06.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 43 (task 646, attempt 0, stage 7.0)
[2025-07-19T20:31:06.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 43.0 in stage 7.0 (TID 646). 5872 bytes result sent to driver
[2025-07-19T20:31:06.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 49.0 in stage 7.0 (TID 652)
[2025-07-19T20:31:06.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d0a55ed
[2025-07-19T20:31:06.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T20:31:06.188+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 50.0 in stage 7.0 (TID 653) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.188+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48] for update
[2025-07-19T20:31:06.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 50.0 in stage 7.0 (TID 653)
[2025-07-19T20:31:06.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:06.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 43.0 in stage 7.0 (TID 646) in 150 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:31:06.191+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.2.delta.56463840-decb-485a-aec4-aa7942393e6c.TID647.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/2.delta
[2025-07-19T20:31:06.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/44/2.delta
[2025-07-19T20:31:06.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T20:31:06.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3df64e58
[2025-07-19T20:31:06.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49] for update
[2025-07-19T20:31:06.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bfca516
[2025-07-19T20:31:06.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 42 (task 645, attempt 0, stage 7.0)
[2025-07-19T20:31:06.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 42.0 in stage 7.0 (TID 645). 5872 bytes result sent to driver
[2025-07-19T20:31:06.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50] for update
[2025-07-19T20:31:06.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 51.0 in stage 7.0 (TID 654) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 42.0 in stage 7.0 (TID 645) in 169 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:31:06.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 51.0 in stage 7.0 (TID 654)
[2025-07-19T20:31:06.200+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 44 (task 647, attempt 0, stage 7.0)
[2025-07-19T20:31:06.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 44.0 in stage 7.0 (TID 647). 5829 bytes result sent to driver
[2025-07-19T20:31:06.202+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 52.0 in stage 7.0 (TID 655) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.203+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 44.0 in stage 7.0 (TID 647) in 121 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:31:06.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 52.0 in stage 7.0 (TID 655)
[2025-07-19T20:31:06.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7339a211
[2025-07-19T20:31:06.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51] for update
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b4f9d85
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52] for update
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.2.delta.296db28d-7a78-4eec-9668-c158645ffd5f.TID650.tmp
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.2.delta.8e10a01e-0e47-4b79-88f9-ea0c194f9dc5.TID652.tmp
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.2.delta.bdb22541-1ac5-47c6-a608-835578f850fa.TID651.tmp
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.2.delta.02826fc7-0141-4c45-a11b-7e77ef605601.TID655.tmp
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.2.delta.ee96dbed-1fdd-44ad-8a0c-29c7053db83b.TID654.tmp
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.2.delta.7655b9cb-ed2a-4705-85bf-80e805014e98.TID653.tmp
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.2.delta.091762bd-61a9-42fc-ad36-953c3b877d7a.TID648.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/2.delta
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/45/2.delta
[2025-07-19T20:31:06.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T20:31:06.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.2.delta.565cab52-12e2-4880-b6e6-c542fef1a26e.TID649.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/2.delta
[2025-07-19T20:31:06.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/46/2.delta
[2025-07-19T20:31:06.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T20:31:06.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 45 (task 648, attempt 0, stage 7.0)
[2025-07-19T20:31:06.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 45.0 in stage 7.0 (TID 648). 5872 bytes result sent to driver
[2025-07-19T20:31:06.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 53.0 in stage 7.0 (TID 656) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 45.0 in stage 7.0 (TID 648) in 105 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:31:06.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 46 (task 649, attempt 0, stage 7.0)
[2025-07-19T20:31:06.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 46.0 in stage 7.0 (TID 649). 5872 bytes result sent to driver
[2025-07-19T20:31:06.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 53.0 in stage 7.0 (TID 656)
[2025-07-19T20:31:06.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 54.0 in stage 7.0 (TID 657) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 46.0 in stage 7.0 (TID 649) in 98 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:31:06.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 54.0 in stage 7.0 (TID 657)
[2025-07-19T20:31:06.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@340a0039
[2025-07-19T20:31:06.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53] for update
[2025-07-19T20:31:06.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67d7b8f2
[2025-07-19T20:31:06.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54] for update
[2025-07-19T20:31:06.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.2.delta.f6a940d2-853e-4286-86d1-ae4b2c319090.TID656.tmp
[2025-07-19T20:31:06.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.2.delta.8e10a01e-0e47-4b79-88f9-ea0c194f9dc5.TID652.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/2.delta
[2025-07-19T20:31:06.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/49/2.delta
[2025-07-19T20:31:06.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.2.delta.05dc1fe3-521c-4abf-8f5f-1ee215a1e54c.TID657.tmp
[2025-07-19T20:31:06.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T20:31:06.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.2.delta.296db28d-7a78-4eec-9668-c158645ffd5f.TID650.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/2.delta
[2025-07-19T20:31:06.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/47/2.delta
[2025-07-19T20:31:06.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 49 (task 652, attempt 0, stage 7.0)
[2025-07-19T20:31:06.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T20:31:06.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 49.0 in stage 7.0 (TID 652). 5872 bytes result sent to driver
[2025-07-19T20:31:06.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 55.0 in stage 7.0 (TID 658) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 55.0 in stage 7.0 (TID 658)
[2025-07-19T20:31:06.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 49.0 in stage 7.0 (TID 652) in 89 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:31:06.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 47 (task 650, attempt 0, stage 7.0)
[2025-07-19T20:31:06.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.2.delta.bdb22541-1ac5-47c6-a608-835578f850fa.TID651.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/2.delta
[2025-07-19T20:31:06.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/48/2.delta
[2025-07-19T20:31:06.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 47.0 in stage 7.0 (TID 650). 5872 bytes result sent to driver
[2025-07-19T20:31:06.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.2.delta.7655b9cb-ed2a-4705-85bf-80e805014e98.TID653.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/2.delta
[2025-07-19T20:31:06.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/50/2.delta
[2025-07-19T20:31:06.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 56.0 in stage 7.0 (TID 659) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T20:31:06.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T20:31:06.247+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 47.0 in stage 7.0 (TID 650) in 107 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:31:06.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 56.0 in stage 7.0 (TID 659)
[2025-07-19T20:31:06.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bd667e9
[2025-07-19T20:31:06.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55] for update
[2025-07-19T20:31:06.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.2.delta.02826fc7-0141-4c45-a11b-7e77ef605601.TID655.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/2.delta
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/52/2.delta
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 48 (task 651, attempt 0, stage 7.0)
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 50 (task 653, attempt 0, stage 7.0)
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 48.0 in stage 7.0 (TID 651). 5872 bytes result sent to driver
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 50.0 in stage 7.0 (TID 653). 5872 bytes result sent to driver
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14abbaee
[2025-07-19T20:31:06.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 48.0 in stage 7.0 (TID 651) in 101 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:31:06.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56] for update
[2025-07-19T20:31:06.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 57.0 in stage 7.0 (TID 660) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 58.0 in stage 7.0 (TID 661) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 58.0 in stage 7.0 (TID 661)
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 57.0 in stage 7.0 (TID 660)
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 50.0 in stage 7.0 (TID 653) in 94 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.2.delta.ee96dbed-1fdd-44ad-8a0c-29c7053db83b.TID654.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/2.delta
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/51/2.delta
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54e8e51b
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 52 (task 655, attempt 0, stage 7.0)
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 52.0 in stage 7.0 (TID 655). 5872 bytes result sent to driver
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 59.0 in stage 7.0 (TID 662) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57] for update
[2025-07-19T20:31:06.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 52.0 in stage 7.0 (TID 655) in 84 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 59.0 in stage 7.0 (TID 662)
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b0aae2e
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58] for update
[2025-07-19T20:31:06.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 51 (task 654, attempt 0, stage 7.0)
[2025-07-19T20:31:06.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 51.0 in stage 7.0 (TID 654). 5872 bytes result sent to driver
[2025-07-19T20:31:06.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 60.0 in stage 7.0 (TID 663) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 60.0 in stage 7.0 (TID 663)
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 51.0 in stage 7.0 (TID 654) in 92 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7c33b356
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60] for update
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.2.delta.2d1e69e6-cf4f-49ac-8e3e-b9a6b8ae7861.TID659.tmp
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@501db397
[2025-07-19T20:31:06.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59] for update
[2025-07-19T20:31:06.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.2.delta.116a9ba8-7364-42cb-b70e-c2dec2904a77.TID660.tmp
[2025-07-19T20:31:06.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.2.delta.5d2c9093-0936-4e80-baf8-e1b1fafa5d7b.TID658.tmp
[2025-07-19T20:31:06.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.2.delta.abfa768d-6c03-4c0d-acd1-05e64b9a2fc5.TID661.tmp
[2025-07-19T20:31:06.279+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.2.delta.e9d0fdc6-0ac4-4f50-b7f7-7f899cfe9bd3.TID663.tmp
[2025-07-19T20:31:06.279+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.2.delta.ed4b411d-67ad-4055-a6f9-6b21d028b724.TID662.tmp
[2025-07-19T20:31:06.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.2.delta.f6a940d2-853e-4286-86d1-ae4b2c319090.TID656.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/2.delta
[2025-07-19T20:31:06.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/53/2.delta
[2025-07-19T20:31:06.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T20:31:06.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.2.delta.05dc1fe3-521c-4abf-8f5f-1ee215a1e54c.TID657.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/2.delta
[2025-07-19T20:31:06.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/54/2.delta
[2025-07-19T20:31:06.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T20:31:06.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 53 (task 656, attempt 0, stage 7.0)
[2025-07-19T20:31:06.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 53.0 in stage 7.0 (TID 656). 5872 bytes result sent to driver
[2025-07-19T20:31:06.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 54 (task 657, attempt 0, stage 7.0)
[2025-07-19T20:31:06.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 54.0 in stage 7.0 (TID 657). 5872 bytes result sent to driver
[2025-07-19T20:31:06.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 61.0 in stage 7.0 (TID 664) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 62.0 in stage 7.0 (TID 665) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 53.0 in stage 7.0 (TID 656) in 83 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:31:06.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 54.0 in stage 7.0 (TID 657) in 77 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:31:06.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 61.0 in stage 7.0 (TID 664)
[2025-07-19T20:31:06.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 62.0 in stage 7.0 (TID 665)
[2025-07-19T20:31:06.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2395e90f
[2025-07-19T20:31:06.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6150334c
[2025-07-19T20:31:06.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61] for update
[2025-07-19T20:31:06.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62] for update
[2025-07-19T20:31:06.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.2.delta.2d1e69e6-cf4f-49ac-8e3e-b9a6b8ae7861.TID659.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/2.delta
[2025-07-19T20:31:06.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/56/2.delta
[2025-07-19T20:31:06.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T20:31:06.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.2.delta.5d2c9093-0936-4e80-baf8-e1b1fafa5d7b.TID658.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/2.delta
[2025-07-19T20:31:06.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/55/2.delta
[2025-07-19T20:31:06.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T20:31:06.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.2.delta.40f76834-86da-482a-8136-c6a964b76a24.TID665.tmp
[2025-07-19T20:31:06.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 56 (task 659, attempt 0, stage 7.0)
[2025-07-19T20:31:06.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 56.0 in stage 7.0 (TID 659). 5872 bytes result sent to driver
[2025-07-19T20:31:06.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.2.delta.b9f0e974-13e4-4195-a358-f31d5deed5ef.TID664.tmp
[2025-07-19T20:31:06.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 63.0 in stage 7.0 (TID 666) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 63.0 in stage 7.0 (TID 666)
[2025-07-19T20:31:06.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 55 (task 658, attempt 0, stage 7.0)
[2025-07-19T20:31:06.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 55.0 in stage 7.0 (TID 658). 5872 bytes result sent to driver
[2025-07-19T20:31:06.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 56.0 in stage 7.0 (TID 659) in 76 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:31:06.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 64.0 in stage 7.0 (TID 667) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 55.0 in stage 7.0 (TID 658) in 84 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:31:06.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 64.0 in stage 7.0 (TID 667)
[2025-07-19T20:31:06.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.329+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.329+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40a24e9b
[2025-07-19T20:31:06.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.2.delta.116a9ba8-7364-42cb-b70e-c2dec2904a77.TID660.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/2.delta
[2025-07-19T20:31:06.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/57/2.delta
[2025-07-19T20:31:06.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T20:31:06.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64] for update
[2025-07-19T20:31:06.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67dd4ae7
[2025-07-19T20:31:06.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 57 (task 660, attempt 0, stage 7.0)
[2025-07-19T20:31:06.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 57.0 in stage 7.0 (TID 660). 5872 bytes result sent to driver
[2025-07-19T20:31:06.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.2.delta.abfa768d-6c03-4c0d-acd1-05e64b9a2fc5.TID661.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/2.delta
[2025-07-19T20:31:06.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/58/2.delta
[2025-07-19T20:31:06.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63] for update
[2025-07-19T20:31:06.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.2.delta.ed4b411d-67ad-4055-a6f9-6b21d028b724.TID662.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/2.delta
[2025-07-19T20:31:06.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/59/2.delta
[2025-07-19T20:31:06.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T20:31:06.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T20:31:06.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.2.delta.52ba8bf2-c556-4a07-89b8-e1aba376d079.TID667.tmp
[2025-07-19T20:31:06.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 65.0 in stage 7.0 (TID 668) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 57.0 in stage 7.0 (TID 660) in 93 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:31:06.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.2.delta.e9d0fdc6-0ac4-4f50-b7f7-7f899cfe9bd3.TID663.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/2.delta
[2025-07-19T20:31:06.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/60/2.delta
[2025-07-19T20:31:06.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T20:31:06.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 65.0 in stage 7.0 (TID 668)
[2025-07-19T20:31:06.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 58 (task 661, attempt 0, stage 7.0)
[2025-07-19T20:31:06.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 58.0 in stage 7.0 (TID 661). 5872 bytes result sent to driver
[2025-07-19T20:31:06.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 66.0 in stage 7.0 (TID 669) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 59 (task 662, attempt 0, stage 7.0)
[2025-07-19T20:31:06.353+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 59.0 in stage 7.0 (TID 662). 5872 bytes result sent to driver
[2025-07-19T20:31:06.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 58.0 in stage 7.0 (TID 661) in 106 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:31:06.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.2.delta.b24f64d6-b563-4db6-b69c-ff3210478b11.TID666.tmp
[2025-07-19T20:31:06.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 60 (task 663, attempt 0, stage 7.0)
[2025-07-19T20:31:06.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 60.0 in stage 7.0 (TID 663). 5872 bytes result sent to driver
[2025-07-19T20:31:06.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 67.0 in stage 7.0 (TID 670) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 68.0 in stage 7.0 (TID 671) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 66.0 in stage 7.0 (TID 669)
[2025-07-19T20:31:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 68.0 in stage 7.0 (TID 671)
[2025-07-19T20:31:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 59.0 in stage 7.0 (TID 662) in 108 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:31:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 60.0 in stage 7.0 (TID 663) in 103 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:31:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 67.0 in stage 7.0 (TID 670)
[2025-07-19T20:31:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.2.delta.b9f0e974-13e4-4195-a358-f31d5deed5ef.TID664.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/2.delta
[2025-07-19T20:31:06.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/61/2.delta
[2025-07-19T20:31:06.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
[2025-07-19T20:31:06.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.2.delta.40f76834-86da-482a-8136-c6a964b76a24.TID665.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/2.delta
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/62/2.delta
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ccfa3a2
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.2.delta.52ba8bf2-c556-4a07-89b8-e1aba376d079.TID667.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/2.delta
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/64/2.delta
[2025-07-19T20:31:06.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T20:31:06.374+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 62 (task 665, attempt 0, stage 7.0)
[2025-07-19T20:31:06.377+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 62.0 in stage 7.0 (TID 665). 5829 bytes result sent to driver
[2025-07-19T20:31:06.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65] for update
[2025-07-19T20:31:06.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:06.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 61 (task 664, attempt 0, stage 7.0)
[2025-07-19T20:31:06.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 61.0 in stage 7.0 (TID 664). 5829 bytes result sent to driver
[2025-07-19T20:31:06.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e289b8f
[2025-07-19T20:31:06.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 64 (task 667, attempt 0, stage 7.0)
[2025-07-19T20:31:06.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 64.0 in stage 7.0 (TID 667). 5829 bytes result sent to driver
[2025-07-19T20:31:06.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 69.0 in stage 7.0 (TID 672) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 61.0 in stage 7.0 (TID 664) in 93 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66] for update
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 69.0 in stage 7.0 (TID 672)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 70.0 in stage 7.0 (TID 673) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 71.0 in stage 7.0 (TID 674) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 62.0 in stage 7.0 (TID 665) in 91 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 71.0 in stage 7.0 (TID 674)
[2025-07-19T20:31:06.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 64.0 in stage 7.0 (TID 667) in 62 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:31:06.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10fa7c09
[2025-07-19T20:31:06.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69] for update
[2025-07-19T20:31:06.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 70.0 in stage 7.0 (TID 673)
[2025-07-19T20:31:06.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ca201e1
[2025-07-19T20:31:06.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68] for update
[2025-07-19T20:31:06.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33bf6006
[2025-07-19T20:31:06.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67] for update
[2025-07-19T20:31:06.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a6a2cd1
[2025-07-19T20:31:06.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70] for update
[2025-07-19T20:31:06.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7447dbdc
[2025-07-19T20:31:06.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.2.delta.f449d719-8b23-4b0c-bf71-c17ddd9d78c9.TID669.tmp
[2025-07-19T20:31:06.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.2.delta.1dd26cfd-f6b7-4ecc-ae4f-49642d32a9a7.TID672.tmp
[2025-07-19T20:31:06.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.2.delta.e544d641-976b-43e9-9e3d-bc4865deaa01.TID668.tmp
[2025-07-19T20:31:06.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.2.delta.625b6295-ff4d-4e76-9a53-6439c3c6d7eb.TID671.tmp
[2025-07-19T20:31:06.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71] for update
[2025-07-19T20:31:06.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.2.delta.77d9e77d-02bb-4cbf-9dd6-a10a98f79301.TID670.tmp
[2025-07-19T20:31:06.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.2.delta.7f32c6e9-6ae5-4b31-aa95-ef97d9033fac.TID674.tmp
[2025-07-19T20:31:06.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.2.delta.b24f64d6-b563-4db6-b69c-ff3210478b11.TID666.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/2.delta
[2025-07-19T20:31:06.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/63/2.delta
[2025-07-19T20:31:06.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T20:31:06.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.2.delta.63864532-c9d9-42fb-bd6f-613405303cbe.TID673.tmp
[2025-07-19T20:31:06.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 63 (task 666, attempt 0, stage 7.0)
[2025-07-19T20:31:06.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 63.0 in stage 7.0 (TID 666). 5872 bytes result sent to driver
[2025-07-19T20:31:06.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 72.0 in stage 7.0 (TID 675) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 72.0 in stage 7.0 (TID 675)
[2025-07-19T20:31:06.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 63.0 in stage 7.0 (TID 666) in 122 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:31:06.438+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b5a75cc
[2025-07-19T20:31:06.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72] for update
[2025-07-19T20:31:06.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.2.delta.cb82d782-c89f-4364-87d6-3d3af0a86ece.TID675.tmp
[2025-07-19T20:31:06.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.2.delta.1dd26cfd-f6b7-4ecc-ae4f-49642d32a9a7.TID672.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/2.delta
[2025-07-19T20:31:06.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/69/2.delta
[2025-07-19T20:31:06.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.2.delta.f449d719-8b23-4b0c-bf71-c17ddd9d78c9.TID669.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/2.delta
[2025-07-19T20:31:06.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/66/2.delta
[2025-07-19T20:31:06.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.2.delta.e544d641-976b-43e9-9e3d-bc4865deaa01.TID668.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/2.delta
[2025-07-19T20:31:06.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/65/2.delta
[2025-07-19T20:31:06.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T20:31:06.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T20:31:06.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T20:31:06.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.2.delta.625b6295-ff4d-4e76-9a53-6439c3c6d7eb.TID671.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/2.delta
[2025-07-19T20:31:06.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/68/2.delta
[2025-07-19T20:31:06.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T20:31:06.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.2.delta.77d9e77d-02bb-4cbf-9dd6-a10a98f79301.TID670.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/2.delta
[2025-07-19T20:31:06.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/67/2.delta
[2025-07-19T20:31:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T20:31:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 69 (task 672, attempt 0, stage 7.0)
[2025-07-19T20:31:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 68 (task 671, attempt 0, stage 7.0)
[2025-07-19T20:31:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 68.0 in stage 7.0 (TID 671). 5872 bytes result sent to driver
[2025-07-19T20:31:06.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 73.0 in stage 7.0 (TID 676) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 69.0 in stage 7.0 (TID 672). 5872 bytes result sent to driver
[2025-07-19T20:31:06.476+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 68.0 in stage 7.0 (TID 671) in 104 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:31:06.476+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 66 (task 669, attempt 0, stage 7.0)
[2025-07-19T20:31:06.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 73.0 in stage 7.0 (TID 676)
[2025-07-19T20:31:06.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 66.0 in stage 7.0 (TID 669). 5872 bytes result sent to driver
[2025-07-19T20:31:06.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 74.0 in stage 7.0 (TID 677) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 65 (task 668, attempt 0, stage 7.0)
[2025-07-19T20:31:06.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 75.0 in stage 7.0 (TID 678) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 69.0 in stage 7.0 (TID 672) in 90 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:31:06.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 66.0 in stage 7.0 (TID 669) in 119 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:31:06.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 75.0 in stage 7.0 (TID 678)
[2025-07-19T20:31:06.482+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 65.0 in stage 7.0 (TID 668). 5872 bytes result sent to driver
[2025-07-19T20:31:06.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 74.0 in stage 7.0 (TID 677)
[2025-07-19T20:31:06.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 76.0 in stage 7.0 (TID 679) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 65.0 in stage 7.0 (TID 668) in 130 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:31:06.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 76.0 in stage 7.0 (TID 679)
[2025-07-19T20:31:06.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:06.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 67 (task 670, attempt 0, stage 7.0)
[2025-07-19T20:31:06.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@745b9e6d
[2025-07-19T20:31:06.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 67.0 in stage 7.0 (TID 670). 5872 bytes result sent to driver
[2025-07-19T20:31:06.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 77.0 in stage 7.0 (TID 680) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 77.0 in stage 7.0 (TID 680)
[2025-07-19T20:31:06.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 67.0 in stage 7.0 (TID 670) in 114 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:31:06.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73] for update
[2025-07-19T20:31:06.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14f7a526
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76] for update
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.2.delta.7f32c6e9-6ae5-4b31-aa95-ef97d9033fac.TID674.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/2.delta
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/71/2.delta
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3022765
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75] for update
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2e9310
[2025-07-19T20:31:06.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74] for update
[2025-07-19T20:31:06.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f800ae2
[2025-07-19T20:31:06.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77] for update
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.2.delta.63864532-c9d9-42fb-bd6f-613405303cbe.TID673.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/2.delta
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/70/2.delta
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.2.delta.d38f2b5d-2105-44ec-ab9e-8096b6651a38.TID676.tmp
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 71 (task 674, attempt 0, stage 7.0)
[2025-07-19T20:31:06.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 71.0 in stage 7.0 (TID 674). 5872 bytes result sent to driver
[2025-07-19T20:31:06.498+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 78.0 in stage 7.0 (TID 681) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.500+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 78.0 in stage 7.0 (TID 681)
[2025-07-19T20:31:06.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 71.0 in stage 7.0 (TID 674) in 116 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.2.delta.a69835f3-f360-4629-9915-0178380a5fb8.TID677.tmp
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.2.delta.53bad4d9-fbd8-47bd-9f2a-81cc8698c73b.TID679.tmp
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 70 (task 673, attempt 0, stage 7.0)
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 70.0 in stage 7.0 (TID 673). 5829 bytes result sent to driver
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 79.0 in stage 7.0 (TID 682) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.2.delta.3eb74feb-00c4-4dad-b087-dc4efe8e01c0.TID678.tmp
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 79.0 in stage 7.0 (TID 682)
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 70.0 in stage 7.0 (TID 673) in 120 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3cb7ea94
[2025-07-19T20:31:06.502+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78] for update
[2025-07-19T20:31:06.504+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.2.delta.ca0b4a98-a2c6-482b-a259-d868c0862105.TID680.tmp
[2025-07-19T20:31:06.505+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9a7e976
[2025-07-19T20:31:06.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.511+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79] for update
[2025-07-19T20:31:06.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.2.delta.cb82d782-c89f-4364-87d6-3d3af0a86ece.TID675.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/2.delta
[2025-07-19T20:31:06.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/72/2.delta
[2025-07-19T20:31:06.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T20:31:06.524+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 72 (task 675, attempt 0, stage 7.0)
[2025-07-19T20:31:06.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 72.0 in stage 7.0 (TID 675). 5872 bytes result sent to driver
[2025-07-19T20:31:06.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 80.0 in stage 7.0 (TID 683) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 72.0 in stage 7.0 (TID 675) in 93 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:31:06.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.2.delta.f94fe3e2-ad44-4580-a2f5-109cc31b912d.TID681.tmp
[2025-07-19T20:31:06.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 80.0 in stage 7.0 (TID 683)
[2025-07-19T20:31:06.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.530+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13e9c61c
[2025-07-19T20:31:06.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80] for update
[2025-07-19T20:31:06.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.2.delta.dca58fa5-6f1e-4f15-8c38-3f29555589bb.TID682.tmp
[2025-07-19T20:31:06.545+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.2.delta.d38f2b5d-2105-44ec-ab9e-8096b6651a38.TID676.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/2.delta
[2025-07-19T20:31:06.546+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/73/2.delta
[2025-07-19T20:31:06.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T20:31:06.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.2.delta.15204996-a752-4cc3-a6e4-e2dcb8dfeffd.TID683.tmp
[2025-07-19T20:31:06.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.2.delta.a69835f3-f360-4629-9915-0178380a5fb8.TID677.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/2.delta
[2025-07-19T20:31:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/74/2.delta
[2025-07-19T20:31:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 73 (task 676, attempt 0, stage 7.0)
[2025-07-19T20:31:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 73.0 in stage 7.0 (TID 676). 5872 bytes result sent to driver
[2025-07-19T20:31:06.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 81.0 in stage 7.0 (TID 684) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 73.0 in stage 7.0 (TID 676) in 86 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:31:06.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T20:31:06.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 81.0 in stage 7.0 (TID 684)
[2025-07-19T20:31:06.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.554+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.2.delta.53bad4d9-fbd8-47bd-9f2a-81cc8698c73b.TID679.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/2.delta
[2025-07-19T20:31:06.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/76/2.delta
[2025-07-19T20:31:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T20:31:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@513aba7e
[2025-07-19T20:31:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.2.delta.ca0b4a98-a2c6-482b-a259-d868c0862105.TID680.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/2.delta
[2025-07-19T20:31:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/77/2.delta
[2025-07-19T20:31:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 74 (task 677, attempt 0, stage 7.0)
[2025-07-19T20:31:06.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 74.0 in stage 7.0 (TID 677). 5872 bytes result sent to driver
[2025-07-19T20:31:06.562+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T20:31:06.563+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81] for update
[2025-07-19T20:31:06.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 82.0 in stage 7.0 (TID 685) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 82.0 in stage 7.0 (TID 685)
[2025-07-19T20:31:06.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 74.0 in stage 7.0 (TID 677) in 94 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:31:06.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.568+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 76 (task 679, attempt 0, stage 7.0)
[2025-07-19T20:31:06.568+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6b8c7e51
[2025-07-19T20:31:06.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82] for update
[2025-07-19T20:31:06.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 77 (task 680, attempt 0, stage 7.0)
[2025-07-19T20:31:06.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 77.0 in stage 7.0 (TID 680). 5872 bytes result sent to driver
[2025-07-19T20:31:06.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 76.0 in stage 7.0 (TID 679). 5915 bytes result sent to driver
[2025-07-19T20:31:06.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 83.0 in stage 7.0 (TID 686) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 84.0 in stage 7.0 (TID 687) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 84.0 in stage 7.0 (TID 687)
[2025-07-19T20:31:06.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 77.0 in stage 7.0 (TID 680) in 91 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:31:06.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 76.0 in stage 7.0 (TID 679) in 96 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:31:06.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 83.0 in stage 7.0 (TID 686)
[2025-07-19T20:31:06.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.2.delta.3eb74feb-00c4-4dad-b087-dc4efe8e01c0.TID678.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/2.delta
[2025-07-19T20:31:06.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/75/2.delta
[2025-07-19T20:31:06.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@559811aa
[2025-07-19T20:31:06.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T20:31:06.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84] for update
[2025-07-19T20:31:06.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@551bf302
[2025-07-19T20:31:06.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.2.delta.f94fe3e2-ad44-4580-a2f5-109cc31b912d.TID681.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/2.delta
[2025-07-19T20:31:06.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/78/2.delta
[2025-07-19T20:31:06.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83] for update
[2025-07-19T20:31:06.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 75 (task 678, attempt 0, stage 7.0)
[2025-07-19T20:31:06.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 75.0 in stage 7.0 (TID 678). 5872 bytes result sent to driver
[2025-07-19T20:31:06.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T20:31:06.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 85.0 in stage 7.0 (TID 688) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 85.0 in stage 7.0 (TID 688)
[2025-07-19T20:31:06.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 75.0 in stage 7.0 (TID 678) in 106 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:31:06.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.2.delta.8686b303-968e-4eb7-94e9-aecf5eae91f4.TID684.tmp
[2025-07-19T20:31:06.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 78 (task 681, attempt 0, stage 7.0)
[2025-07-19T20:31:06.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 78.0 in stage 7.0 (TID 681). 5872 bytes result sent to driver
[2025-07-19T20:31:06.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 86.0 in stage 7.0 (TID 689) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 86.0 in stage 7.0 (TID 689)
[2025-07-19T20:31:06.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 78.0 in stage 7.0 (TID 681) in 81 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:31:06.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.2.delta.26f498aa-a987-454b-b54e-f8a7513bacd9.TID685.tmp
[2025-07-19T20:31:06.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:06.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8b7c843
[2025-07-19T20:31:06.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86] for update
[2025-07-19T20:31:06.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a8f0057
[2025-07-19T20:31:06.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85] for update
[2025-07-19T20:31:06.597+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.2.delta.1062c66c-b492-4ae7-93cd-81e54fd75dd3.TID687.tmp
[2025-07-19T20:31:06.597+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.2.delta.dca58fa5-6f1e-4f15-8c38-3f29555589bb.TID682.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/2.delta
[2025-07-19T20:31:06.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/79/2.delta
[2025-07-19T20:31:06.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T20:31:06.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.2.delta.15204996-a752-4cc3-a6e4-e2dcb8dfeffd.TID683.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/2.delta
[2025-07-19T20:31:06.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/80/2.delta
[2025-07-19T20:31:06.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.2.delta.6c5a15da-19aa-457d-8d1b-c9220a7d7443.TID686.tmp
[2025-07-19T20:31:06.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T20:31:06.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 79 (task 682, attempt 0, stage 7.0)
[2025-07-19T20:31:06.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 80 (task 683, attempt 0, stage 7.0)
[2025-07-19T20:31:06.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 79.0 in stage 7.0 (TID 682). 5915 bytes result sent to driver
[2025-07-19T20:31:06.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 80.0 in stage 7.0 (TID 683). 5915 bytes result sent to driver
[2025-07-19T20:31:06.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 87.0 in stage 7.0 (TID 690) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 88.0 in stage 7.0 (TID 691) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 79.0 in stage 7.0 (TID 682) in 105 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:31:06.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.2.delta.e6565d2a-ba93-41ae-819c-061286d2ab65.TID689.tmp
[2025-07-19T20:31:06.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 88.0 in stage 7.0 (TID 691)
[2025-07-19T20:31:06.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 87.0 in stage 7.0 (TID 690)
[2025-07-19T20:31:06.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 80.0 in stage 7.0 (TID 683) in 82 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:31:06.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e61f52
[2025-07-19T20:31:06.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:06.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.617+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87] for update
[2025-07-19T20:31:06.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2c9571e6
[2025-07-19T20:31:06.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88] for update
[2025-07-19T20:31:06.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.2.delta.076f0c42-20b0-4b20-b0b0-d43ec4225d7c.TID688.tmp
[2025-07-19T20:31:06.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.2.delta.58819fa7-6759-4bc0-94da-ff842a91ebb0.TID691.tmp
[2025-07-19T20:31:06.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.2.delta.7c5b0114-a0dd-4143-93c9-e189e2d01341.TID690.tmp
[2025-07-19T20:31:06.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.2.delta.8686b303-968e-4eb7-94e9-aecf5eae91f4.TID684.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/2.delta
[2025-07-19T20:31:06.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/81/2.delta
[2025-07-19T20:31:06.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.2.delta.26f498aa-a987-454b-b54e-f8a7513bacd9.TID685.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/2.delta
[2025-07-19T20:31:06.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/82/2.delta
[2025-07-19T20:31:06.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T20:31:06.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T20:31:06.649+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 82 (task 685, attempt 0, stage 7.0)
[2025-07-19T20:31:06.649+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 81 (task 684, attempt 0, stage 7.0)
[2025-07-19T20:31:06.650+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.2.delta.6c5a15da-19aa-457d-8d1b-c9220a7d7443.TID686.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/2.delta
[2025-07-19T20:31:06.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 82.0 in stage 7.0 (TID 685). 5872 bytes result sent to driver
[2025-07-19T20:31:06.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/83/2.delta
[2025-07-19T20:31:06.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 81.0 in stage 7.0 (TID 684). 5872 bytes result sent to driver
[2025-07-19T20:31:06.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 89.0 in stage 7.0 (TID 692) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T20:31:06.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 90.0 in stage 7.0 (TID 693) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 89.0 in stage 7.0 (TID 692)
[2025-07-19T20:31:06.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 81.0 in stage 7.0 (TID 684) in 103 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:31:06.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 82.0 in stage 7.0 (TID 685) in 94 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:31:06.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.2.delta.1062c66c-b492-4ae7-93cd-81e54fd75dd3.TID687.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/2.delta
[2025-07-19T20:31:06.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/84/2.delta
[2025-07-19T20:31:06.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 90.0 in stage 7.0 (TID 693)
[2025-07-19T20:31:06.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T20:31:06.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@64e67728
[2025-07-19T20:31:06.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 83 (task 686, attempt 0, stage 7.0)
[2025-07-19T20:31:06.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90] for update
[2025-07-19T20:31:06.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 83.0 in stage 7.0 (TID 686). 5872 bytes result sent to driver
[2025-07-19T20:31:06.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20955265
[2025-07-19T20:31:06.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 91.0 in stage 7.0 (TID 694) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89] for update
[2025-07-19T20:31:06.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 83.0 in stage 7.0 (TID 686) in 99 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:31:06.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 84 (task 687, attempt 0, stage 7.0)
[2025-07-19T20:31:06.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 84.0 in stage 7.0 (TID 687). 5872 bytes result sent to driver
[2025-07-19T20:31:06.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 91.0 in stage 7.0 (TID 694)
[2025-07-19T20:31:06.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 92.0 in stage 7.0 (TID 695) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 92.0 in stage 7.0 (TID 695)
[2025-07-19T20:31:06.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 84.0 in stage 7.0 (TID 687) in 100 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:31:06.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.2.delta.e6565d2a-ba93-41ae-819c-061286d2ab65.TID689.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/2.delta
[2025-07-19T20:31:06.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/86/2.delta
[2025-07-19T20:31:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T20:31:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1e765e70
[2025-07-19T20:31:06.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91] for update
[2025-07-19T20:31:06.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1650264c
[2025-07-19T20:31:06.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92] for update
[2025-07-19T20:31:06.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 86 (task 689, attempt 0, stage 7.0)
[2025-07-19T20:31:06.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 86.0 in stage 7.0 (TID 689). 5872 bytes result sent to driver
[2025-07-19T20:31:06.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 93.0 in stage 7.0 (TID 696) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 86.0 in stage 7.0 (TID 689) in 99 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:31:06.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.2.delta.bbb7d436-5bd7-43ed-8c6e-f2d4571eb0c4.TID693.tmp
[2025-07-19T20:31:06.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 93.0 in stage 7.0 (TID 696)
[2025-07-19T20:31:06.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@771ed6f9
[2025-07-19T20:31:06.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93] for update
[2025-07-19T20:31:06.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.2.delta.58819fa7-6759-4bc0-94da-ff842a91ebb0.TID691.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/2.delta
[2025-07-19T20:31:06.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/88/2.delta
[2025-07-19T20:31:06.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.2.delta.076f0c42-20b0-4b20-b0b0-d43ec4225d7c.TID688.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/2.delta
[2025-07-19T20:31:06.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/85/2.delta
[2025-07-19T20:31:06.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.2.delta.795d943e-c15b-47ed-beb3-9773ca638f6d.TID692.tmp
[2025-07-19T20:31:06.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T20:31:06.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T20:31:06.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 85 (task 688, attempt 0, stage 7.0)
[2025-07-19T20:31:06.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 88 (task 691, attempt 0, stage 7.0)
[2025-07-19T20:31:06.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 85.0 in stage 7.0 (TID 688). 5872 bytes result sent to driver
[2025-07-19T20:31:06.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 88.0 in stage 7.0 (TID 691). 5829 bytes result sent to driver
[2025-07-19T20:31:06.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 94.0 in stage 7.0 (TID 697) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 95.0 in stage 7.0 (TID 698) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 95.0 in stage 7.0 (TID 698)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 85.0 in stage 7.0 (TID 688) in 113 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 88.0 in stage 7.0 (TID 691) in 82 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 94.0 in stage 7.0 (TID 697)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.2.delta.7c5b0114-a0dd-4143-93c9-e189e2d01341.TID690.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/2.delta
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/87/2.delta
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T20:31:06.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 87 (task 690, attempt 0, stage 7.0)
[2025-07-19T20:31:06.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:06.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.2.delta.b6b901d2-e1b0-4ee3-bc1e-40f18582c5c1.TID695.tmp
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.2.delta.b6461a59-f328-4925-975b-d90310004c53.TID696.tmp
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ae23549
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 87.0 in stage 7.0 (TID 690). 5915 bytes result sent to driver
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.2.delta.8e12d6ae-bffd-4779-b58d-0ea3d00ee778.TID694.tmp
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95] for update
[2025-07-19T20:31:06.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 96.0 in stage 7.0 (TID 699) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 87.0 in stage 7.0 (TID 690) in 95 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:31:06.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 96.0 in stage 7.0 (TID 699)
[2025-07-19T20:31:06.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d5df31e
[2025-07-19T20:31:06.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94] for update
[2025-07-19T20:31:06.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.702+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6fb0f1f8
[2025-07-19T20:31:06.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.707+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96] for update
[2025-07-19T20:31:06.707+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.2.delta.843a8da8-122a-4c9b-90fc-35b57d9ca5f0.TID698.tmp
[2025-07-19T20:31:06.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.2.delta.6639653a-51e3-424a-a821-966ef95a90b7.TID697.tmp
[2025-07-19T20:31:06.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.2.delta.bbb7d436-5bd7-43ed-8c6e-f2d4571eb0c4.TID693.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/2.delta
[2025-07-19T20:31:06.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/90/2.delta
[2025-07-19T20:31:06.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T20:31:06.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.2.delta.fbdb702d-e30b-4421-b3ed-966781efbd95.TID699.tmp
[2025-07-19T20:31:06.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 90 (task 693, attempt 0, stage 7.0)
[2025-07-19T20:31:06.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 90.0 in stage 7.0 (TID 693). 5872 bytes result sent to driver
[2025-07-19T20:31:06.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 97.0 in stage 7.0 (TID 700) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 97.0 in stage 7.0 (TID 700)
[2025-07-19T20:31:06.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 90.0 in stage 7.0 (TID 693) in 72 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:31:06.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.2.delta.795d943e-c15b-47ed-beb3-9773ca638f6d.TID692.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/2.delta
[2025-07-19T20:31:06.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/89/2.delta
[2025-07-19T20:31:06.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T20:31:06.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.729+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@556db2f
[2025-07-19T20:31:06.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.731+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97] for update
[2025-07-19T20:31:06.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 89 (task 692, attempt 0, stage 7.0)
[2025-07-19T20:31:06.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 89.0 in stage 7.0 (TID 692). 5872 bytes result sent to driver
[2025-07-19T20:31:06.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 98.0 in stage 7.0 (TID 701) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 98.0 in stage 7.0 (TID 701)
[2025-07-19T20:31:06.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 89.0 in stage 7.0 (TID 692) in 82 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:31:06.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53ec8661
[2025-07-19T20:31:06.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98] for update
[2025-07-19T20:31:06.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.2.delta.facd619b-1328-40d7-a80e-ea7fd44fba31.TID700.tmp
[2025-07-19T20:31:06.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.2.delta.b6b901d2-e1b0-4ee3-bc1e-40f18582c5c1.TID695.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/2.delta
[2025-07-19T20:31:06.744+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/92/2.delta
[2025-07-19T20:31:06.744+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.2.delta.b6461a59-f328-4925-975b-d90310004c53.TID696.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/2.delta
[2025-07-19T20:31:06.744+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/93/2.delta
[2025-07-19T20:31:06.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T20:31:06.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.2.delta.8e12d6ae-bffd-4779-b58d-0ea3d00ee778.TID694.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/2.delta
[2025-07-19T20:31:06.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/91/2.delta
[2025-07-19T20:31:06.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T20:31:06.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T20:31:06.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 92 (task 695, attempt 0, stage 7.0)
[2025-07-19T20:31:06.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 92.0 in stage 7.0 (TID 695). 5872 bytes result sent to driver
[2025-07-19T20:31:06.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 91 (task 694, attempt 0, stage 7.0)
[2025-07-19T20:31:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 92.0 in stage 7.0 (TID 695) in 87 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:31:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 91.0 in stage 7.0 (TID 694). 5872 bytes result sent to driver
[2025-07-19T20:31:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 99.0 in stage 7.0 (TID 702) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 100.0 in stage 7.0 (TID 703) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 91.0 in stage 7.0 (TID 694) in 90 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:31:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.2.delta.d55915ba-90c0-49f5-8374-2a6bd1288716.TID701.tmp
[2025-07-19T20:31:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 93 (task 696, attempt 0, stage 7.0)
[2025-07-19T20:31:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 93.0 in stage 7.0 (TID 696). 5872 bytes result sent to driver
[2025-07-19T20:31:06.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 99.0 in stage 7.0 (TID 702)
[2025-07-19T20:31:06.753+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.2.delta.843a8da8-122a-4c9b-90fc-35b57d9ca5f0.TID698.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/2.delta
[2025-07-19T20:31:06.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/95/2.delta
[2025-07-19T20:31:06.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 101.0 in stage 7.0 (TID 704) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T20:31:06.758+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@342cab28
[2025-07-19T20:31:06.758+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 101.0 in stage 7.0 (TID 704)
[2025-07-19T20:31:06.759+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 93.0 in stage 7.0 (TID 696) in 80 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:31:06.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.2.delta.6639653a-51e3-424a-a821-966ef95a90b7.TID697.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/2.delta
[2025-07-19T20:31:06.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/94/2.delta
[2025-07-19T20:31:06.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T20:31:06.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 100.0 in stage 7.0 (TID 703)
[2025-07-19T20:31:06.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99] for update
[2025-07-19T20:31:06.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12a39ce6
[2025-07-19T20:31:06.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101] for update
[2025-07-19T20:31:06.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 94 (task 697, attempt 0, stage 7.0)
[2025-07-19T20:31:06.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 95 (task 698, attempt 0, stage 7.0)
[2025-07-19T20:31:06.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 95.0 in stage 7.0 (TID 698). 5872 bytes result sent to driver
[2025-07-19T20:31:06.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 94.0 in stage 7.0 (TID 697). 5872 bytes result sent to driver
[2025-07-19T20:31:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.2.delta.fbdb702d-e30b-4421-b3ed-966781efbd95.TID699.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/2.delta
[2025-07-19T20:31:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/96/2.delta
[2025-07-19T20:31:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@228f2330
[2025-07-19T20:31:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T20:31:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 102.0 in stage 7.0 (TID 705) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 103.0 in stage 7.0 (TID 706) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100] for update
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 102.0 in stage 7.0 (TID 705)
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 95.0 in stage 7.0 (TID 698) in 76 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 94.0 in stage 7.0 (TID 697) in 77 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 103.0 in stage 7.0 (TID 706)
[2025-07-19T20:31:06.776+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 96 (task 699, attempt 0, stage 7.0)
[2025-07-19T20:31:06.776+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@11dc924e
[2025-07-19T20:31:06.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 96.0 in stage 7.0 (TID 699). 5829 bytes result sent to driver
[2025-07-19T20:31:06.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.2.delta.3ee1b1f7-528f-4288-9c2e-2d167acafc8e.TID702.tmp
[2025-07-19T20:31:06.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102] for update
[2025-07-19T20:31:06.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 104.0 in stage 7.0 (TID 707) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 96.0 in stage 7.0 (TID 699) in 69 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 104.0 in stage 7.0 (TID 707)
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f5be910
[2025-07-19T20:31:06.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.2.delta.ed9c6a57-f224-458e-99ca-83d0cdb07e6d.TID704.tmp
[2025-07-19T20:31:06.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104] for update
[2025-07-19T20:31:06.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6182f9f
[2025-07-19T20:31:06.783+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.783+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103] for update
[2025-07-19T20:31:06.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.2.delta.dfa38a21-7676-44d2-b566-71b147de6d3a.TID705.tmp
[2025-07-19T20:31:06.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.2.delta.a4c32363-eb42-4778-b83c-7835c3e14666.TID703.tmp
[2025-07-19T20:31:06.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.2.delta.b93e5b87-c5de-4b54-b265-0885765bf129.TID707.tmp
[2025-07-19T20:31:06.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.2.delta.d55915ba-90c0-49f5-8374-2a6bd1288716.TID701.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/2.delta
[2025-07-19T20:31:06.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/98/2.delta
[2025-07-19T20:31:06.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T20:31:06.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.2.delta.824195f1-70ea-47fd-9f1c-ccbbd98d9ab6.TID706.tmp
[2025-07-19T20:31:06.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.2.delta.facd619b-1328-40d7-a80e-ea7fd44fba31.TID700.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/2.delta
[2025-07-19T20:31:06.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/97/2.delta
[2025-07-19T20:31:06.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T20:31:06.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 97 (task 700, attempt 0, stage 7.0)
[2025-07-19T20:31:06.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 97.0 in stage 7.0 (TID 700). 5872 bytes result sent to driver
[2025-07-19T20:31:06.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 98 (task 701, attempt 0, stage 7.0)
[2025-07-19T20:31:06.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 98.0 in stage 7.0 (TID 701). 5872 bytes result sent to driver
[2025-07-19T20:31:06.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 105.0 in stage 7.0 (TID 708) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 106.0 in stage 7.0 (TID 709) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 97.0 in stage 7.0 (TID 700) in 83 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:31:06.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 105.0 in stage 7.0 (TID 708)
[2025-07-19T20:31:06.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 98.0 in stage 7.0 (TID 701) in 74 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:31:06.810+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 106.0 in stage 7.0 (TID 709)
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@79e4a813
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105] for update
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a9c64cd
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106] for update
[2025-07-19T20:31:06.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.2.delta.3ee1b1f7-528f-4288-9c2e-2d167acafc8e.TID702.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/2.delta
[2025-07-19T20:31:06.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/99/2.delta
[2025-07-19T20:31:06.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T20:31:06.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.2.delta.ed9c6a57-f224-458e-99ca-83d0cdb07e6d.TID704.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/2.delta
[2025-07-19T20:31:06.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/101/2.delta
[2025-07-19T20:31:06.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T20:31:06.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.2.delta.6f08e507-7544-478f-bcad-3c413fa46027.TID708.tmp
[2025-07-19T20:31:06.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 101 (task 704, attempt 0, stage 7.0)
[2025-07-19T20:31:06.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 101.0 in stage 7.0 (TID 704). 5872 bytes result sent to driver
[2025-07-19T20:31:06.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 107.0 in stage 7.0 (TID 710) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 99 (task 702, attempt 0, stage 7.0)
[2025-07-19T20:31:06.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 101.0 in stage 7.0 (TID 704) in 70 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:31:06.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 107.0 in stage 7.0 (TID 710)
[2025-07-19T20:31:06.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 99.0 in stage 7.0 (TID 702). 5872 bytes result sent to driver
[2025-07-19T20:31:06.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 108.0 in stage 7.0 (TID 711) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 99.0 in stage 7.0 (TID 702) in 75 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:31:06.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 108.0 in stage 7.0 (TID 711)
[2025-07-19T20:31:06.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e6c65ab
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.2.delta.bc03100f-b3ca-4063-b904-9f680e810a30.TID709.tmp
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107] for update
[2025-07-19T20:31:06.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.2.delta.a4c32363-eb42-4778-b83c-7835c3e14666.TID703.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/2.delta
[2025-07-19T20:31:06.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/100/2.delta
[2025-07-19T20:31:06.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T20:31:06.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@55728e4d
[2025-07-19T20:31:06.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.2.delta.b93e5b87-c5de-4b54-b265-0885765bf129.TID707.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/2.delta
[2025-07-19T20:31:06.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/104/2.delta
[2025-07-19T20:31:06.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T20:31:06.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108] for update
[2025-07-19T20:31:06.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.2.delta.dfa38a21-7676-44d2-b566-71b147de6d3a.TID705.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/2.delta
[2025-07-19T20:31:06.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/102/2.delta
[2025-07-19T20:31:06.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.2.delta.824195f1-70ea-47fd-9f1c-ccbbd98d9ab6.TID706.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/2.delta
[2025-07-19T20:31:06.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/103/2.delta
[2025-07-19T20:31:06.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T20:31:06.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T20:31:06.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 103 (task 706, attempt 0, stage 7.0)
[2025-07-19T20:31:06.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 100 (task 703, attempt 0, stage 7.0)
[2025-07-19T20:31:06.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 103.0 in stage 7.0 (TID 706). 5872 bytes result sent to driver
[2025-07-19T20:31:06.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 100.0 in stage 7.0 (TID 703). 5872 bytes result sent to driver
[2025-07-19T20:31:06.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 109.0 in stage 7.0 (TID 712) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 110.0 in stage 7.0 (TID 713) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 102 (task 705, attempt 0, stage 7.0)
[2025-07-19T20:31:06.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.2.delta.a40a8466-1990-454d-8453-7b4a353ac72d.TID710.tmp
[2025-07-19T20:31:06.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 100.0 in stage 7.0 (TID 703) in 97 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:31:06.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 103.0 in stage 7.0 (TID 706) in 87 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:31:06.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 110.0 in stage 7.0 (TID 713)
[2025-07-19T20:31:06.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 102.0 in stage 7.0 (TID 705). 5872 bytes result sent to driver
[2025-07-19T20:31:06.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 109.0 in stage 7.0 (TID 712)
[2025-07-19T20:31:06.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 104 (task 707, attempt 0, stage 7.0)
[2025-07-19T20:31:06.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:06.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 104.0 in stage 7.0 (TID 707). 5872 bytes result sent to driver
[2025-07-19T20:31:06.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 111.0 in stage 7.0 (TID 714) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 112.0 in stage 7.0 (TID 715) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 111.0 in stage 7.0 (TID 714)
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 104.0 in stage 7.0 (TID 707) in 87 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6102b314
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 102.0 in stage 7.0 (TID 705) in 93 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 112.0 in stage 7.0 (TID 715)
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109] for update
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1b3e2f22
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.2.delta.2b0df580-4427-46cb-a483-b30e1ef42754.TID711.tmp
[2025-07-19T20:31:06.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.865+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110] for update
[2025-07-19T20:31:06.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@114c7d7f
[2025-07-19T20:31:06.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111] for update
[2025-07-19T20:31:06.868+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fe3ffeb
[2025-07-19T20:31:06.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.870+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112] for update
[2025-07-19T20:31:06.870+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.2.delta.6f08e507-7544-478f-bcad-3c413fa46027.TID708.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/2.delta
[2025-07-19T20:31:06.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/105/2.delta
[2025-07-19T20:31:06.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T20:31:06.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.2.delta.b4d003b2-a5ac-4c48-bb7c-d53045530236.TID712.tmp
[2025-07-19T20:31:06.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.2.delta.ea55e064-5899-49e0-8db2-39fe57a204c6.TID713.tmp
[2025-07-19T20:31:06.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 105 (task 708, attempt 0, stage 7.0)
[2025-07-19T20:31:06.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 105.0 in stage 7.0 (TID 708). 5872 bytes result sent to driver
[2025-07-19T20:31:06.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.2.delta.bc03100f-b3ca-4063-b904-9f680e810a30.TID709.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/2.delta
[2025-07-19T20:31:06.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/106/2.delta
[2025-07-19T20:31:06.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T20:31:06.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 113.0 in stage 7.0 (TID 716) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 113.0 in stage 7.0 (TID 716)
[2025-07-19T20:31:06.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 105.0 in stage 7.0 (TID 708) in 81 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:31:06.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.2.delta.a145b80b-a81a-4925-84ee-9b37b33989c4.TID715.tmp
[2025-07-19T20:31:06.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.2.delta.e177c94f-a926-42f7-a062-11509de3f7a1.TID714.tmp
[2025-07-19T20:31:06.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5452cb1
[2025-07-19T20:31:06.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113] for update
[2025-07-19T20:31:06.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 106 (task 709, attempt 0, stage 7.0)
[2025-07-19T20:31:06.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 106.0 in stage 7.0 (TID 709). 5872 bytes result sent to driver
[2025-07-19T20:31:06.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 114.0 in stage 7.0 (TID 717) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 106.0 in stage 7.0 (TID 709) in 88 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:31:06.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 114.0 in stage 7.0 (TID 717)
[2025-07-19T20:31:06.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a9277a8
[2025-07-19T20:31:06.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114] for update
[2025-07-19T20:31:06.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.2.delta.483e7270-b80b-4311-b408-41deadfc32e5.TID716.tmp
[2025-07-19T20:31:06.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.2.delta.870c0d7c-efb9-4087-bc1a-49ace94424c6.TID717.tmp
[2025-07-19T20:31:06.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.2.delta.2b0df580-4427-46cb-a483-b30e1ef42754.TID711.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/2.delta
[2025-07-19T20:31:06.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/108/2.delta
[2025-07-19T20:31:06.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T20:31:06.923+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.2.delta.a40a8466-1990-454d-8453-7b4a353ac72d.TID710.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/2.delta
[2025-07-19T20:31:06.923+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/107/2.delta
[2025-07-19T20:31:06.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 108 (task 711, attempt 0, stage 7.0)
[2025-07-19T20:31:06.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 108.0 in stage 7.0 (TID 711). 5872 bytes result sent to driver
[2025-07-19T20:31:06.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T20:31:06.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 115.0 in stage 7.0 (TID 718) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.932+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 108.0 in stage 7.0 (TID 711) in 108 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:31:06.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 115.0 in stage 7.0 (TID 718)
[2025-07-19T20:31:06.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 107 (task 710, attempt 0, stage 7.0)
[2025-07-19T20:31:06.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 107.0 in stage 7.0 (TID 710). 5872 bytes result sent to driver
[2025-07-19T20:31:06.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 116.0 in stage 7.0 (TID 719) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:06.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 107.0 in stage 7.0 (TID 710) in 115 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:31:06.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.2.delta.b4d003b2-a5ac-4c48-bb7c-d53045530236.TID712.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/2.delta
[2025-07-19T20:31:06.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/109/2.delta
[2025-07-19T20:31:06.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.2.delta.e177c94f-a926-42f7-a062-11509de3f7a1.TID714.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/2.delta
[2025-07-19T20:31:06.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T20:31:06.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/111/2.delta
[2025-07-19T20:31:06.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T20:31:06.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@472b3e7d
[2025-07-19T20:31:06.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 116.0 in stage 7.0 (TID 719)
[2025-07-19T20:31:06.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115] for update
[2025-07-19T20:31:06.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 109 (task 712, attempt 0, stage 7.0)
[2025-07-19T20:31:06.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 109.0 in stage 7.0 (TID 712). 5872 bytes result sent to driver
[2025-07-19T20:31:06.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 117.0 in stage 7.0 (TID 720) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 109.0 in stage 7.0 (TID 712) in 101 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:31:06.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 117.0 in stage 7.0 (TID 720)
[2025-07-19T20:31:06.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 111 (task 714, attempt 0, stage 7.0)
[2025-07-19T20:31:06.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68b3afc4
[2025-07-19T20:31:06.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116] for update
[2025-07-19T20:31:06.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 111.0 in stage 7.0 (TID 714). 5872 bytes result sent to driver
[2025-07-19T20:31:06.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 118.0 in stage 7.0 (TID 721) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 111.0 in stage 7.0 (TID 714) in 97 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:31:06.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 118.0 in stage 7.0 (TID 721)
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3179aba6
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.2.delta.ea55e064-5899-49e0-8db2-39fe57a204c6.TID713.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/2.delta
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/110/2.delta
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T20:31:06.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.2.delta.a145b80b-a81a-4925-84ee-9b37b33989c4.TID715.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/2.delta
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/112/2.delta
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117] for update
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@429b9943
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118] for update
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 110 (task 713, attempt 0, stage 7.0)
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.2.delta.ba2bd0f5-5cdc-431c-8dbf-85ddf8104437.TID719.tmp
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 110.0 in stage 7.0 (TID 713). 5872 bytes result sent to driver
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 119.0 in stage 7.0 (TID 722) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 110.0 in stage 7.0 (TID 713) in 118 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 119.0 in stage 7.0 (TID 722)
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 112 (task 715, attempt 0, stage 7.0)
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 112.0 in stage 7.0 (TID 715). 5829 bytes result sent to driver
[2025-07-19T20:31:06.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 120.0 in stage 7.0 (TID 723) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 112.0 in stage 7.0 (TID 715) in 112 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:31:06.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 120.0 in stage 7.0 (TID 723)
[2025-07-19T20:31:06.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.2.delta.870c0d7c-efb9-4087-bc1a-49ace94424c6.TID717.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/2.delta
[2025-07-19T20:31:06.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/114/2.delta
[2025-07-19T20:31:06.978+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T20:31:06.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a668ac5
[2025-07-19T20:31:06.980+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119] for update
[2025-07-19T20:31:06.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.2.delta.483e7270-b80b-4311-b408-41deadfc32e5.TID716.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/2.delta
[2025-07-19T20:31:06.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29a9c2f8
[2025-07-19T20:31:06.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/113/2.delta
[2025-07-19T20:31:06.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120] for update
[2025-07-19T20:31:06.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T20:31:06.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.2.delta.31a7ee4e-957f-48df-a8cb-990a8fede3b6.TID718.tmp
[2025-07-19T20:31:06.987+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 114 (task 717, attempt 0, stage 7.0)
[2025-07-19T20:31:06.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 114.0 in stage 7.0 (TID 717). 5872 bytes result sent to driver
[2025-07-19T20:31:06.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 121.0 in stage 7.0 (TID 724) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 114.0 in stage 7.0 (TID 717) in 87 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:31:06.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 121.0 in stage 7.0 (TID 724)
[2025-07-19T20:31:06.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.2.delta.2aafa2fb-f5cd-420f-8d52-55361d4a0887.TID721.tmp
[2025-07-19T20:31:06.991+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO DataWritingSparkTask: Committed partition 113 (task 716, attempt 0, stage 7.0)
[2025-07-19T20:31:06.991+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Finished task 113.0 in stage 7.0 (TID 716). 5872 bytes result sent to driver
[2025-07-19T20:31:06.992+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Starting task 122.0 in stage 7.0 (TID 725) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:06.992+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.2.delta.9f6c5147-ee5b-4bfa-bdc1-6a7a29c4152b.TID720.tmp
[2025-07-19T20:31:06.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO TaskSetManager: Finished task 113.0 in stage 7.0 (TID 716) in 102 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:31:06.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO Executor: Running task 122.0 in stage 7.0 (TID 725)
[2025-07-19T20:31:06.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1280c293
[2025-07-19T20:31:06.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121] for update
[2025-07-19T20:31:06.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:06.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:06.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.2.delta.1b2a5997-b3d7-4c2a-a605-906380ead352.TID722.tmp
[2025-07-19T20:31:06.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@448e5e81
[2025-07-19T20:31:06.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:06.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122] for update
[2025-07-19T20:31:06.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:06.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.2.delta.274f9c04-db7e-4f02-817a-a5e2d281e3c4.TID723.tmp
[2025-07-19T20:31:06.999+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.2.delta.7b0b0830-ef3e-40a5-b5be-97b60495818a.TID725.tmp
[2025-07-19T20:31:07.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.2.delta.4a9f67fc-19cc-42d1-9cca-38df9cf659e4.TID724.tmp
[2025-07-19T20:31:07.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.2.delta.ba2bd0f5-5cdc-431c-8dbf-85ddf8104437.TID719.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/2.delta
[2025-07-19T20:31:07.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/116/2.delta
[2025-07-19T20:31:07.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T20:31:07.013+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 116 (task 719, attempt 0, stage 7.0)
[2025-07-19T20:31:07.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 116.0 in stage 7.0 (TID 719). 5872 bytes result sent to driver
[2025-07-19T20:31:07.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 123.0 in stage 7.0 (TID 726) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 116.0 in stage 7.0 (TID 719) in 76 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:31:07.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 123.0 in stage 7.0 (TID 726)
[2025-07-19T20:31:07.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42001571
[2025-07-19T20:31:07.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123] for update
[2025-07-19T20:31:07.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.2.delta.9f6c5147-ee5b-4bfa-bdc1-6a7a29c4152b.TID720.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/2.delta
[2025-07-19T20:31:07.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/117/2.delta
[2025-07-19T20:31:07.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T20:31:07.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.2.delta.31a7ee4e-957f-48df-a8cb-990a8fede3b6.TID718.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/2.delta
[2025-07-19T20:31:07.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/115/2.delta
[2025-07-19T20:31:07.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T20:31:07.038+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.2.delta.2aafa2fb-f5cd-420f-8d52-55361d4a0887.TID721.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/2.delta
[2025-07-19T20:31:07.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/118/2.delta
[2025-07-19T20:31:07.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T20:31:07.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 117 (task 720, attempt 0, stage 7.0)
[2025-07-19T20:31:07.050+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 115 (task 718, attempt 0, stage 7.0)
[2025-07-19T20:31:07.051+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 115.0 in stage 7.0 (TID 718). 5872 bytes result sent to driver
[2025-07-19T20:31:07.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 117.0 in stage 7.0 (TID 720). 5872 bytes result sent to driver
[2025-07-19T20:31:07.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 124.0 in stage 7.0 (TID 727) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.2.delta.1b2a5997-b3d7-4c2a-a605-906380ead352.TID722.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/2.delta
[2025-07-19T20:31:07.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 124.0 in stage 7.0 (TID 727)
[2025-07-19T20:31:07.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 118 (task 721, attempt 0, stage 7.0)
[2025-07-19T20:31:07.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/119/2.delta
[2025-07-19T20:31:07.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 118.0 in stage 7.0 (TID 721). 5872 bytes result sent to driver
[2025-07-19T20:31:07.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 125.0 in stage 7.0 (TID 728) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 125.0 in stage 7.0 (TID 728)
[2025-07-19T20:31:07.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 126.0 in stage 7.0 (TID 729) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T20:31:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 117.0 in stage 7.0 (TID 720) in 87 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:31:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 118.0 in stage 7.0 (TID 721) in 82 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:31:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 126.0 in stage 7.0 (TID 729)
[2025-07-19T20:31:07.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 115.0 in stage 7.0 (TID 718) in 103 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:31:07.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@201a66e4
[2025-07-19T20:31:07.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125] for update
[2025-07-19T20:31:07.067+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.067+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fee90a0
[2025-07-19T20:31:07.067+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126] for update
[2025-07-19T20:31:07.071+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1f02d91b
[2025-07-19T20:31:07.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.2.delta.885acaec-c075-4414-9362-7b5a49899ef1.TID726.tmp
[2025-07-19T20:31:07.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124] for update
[2025-07-19T20:31:07.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 119 (task 722, attempt 0, stage 7.0)
[2025-07-19T20:31:07.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 119.0 in stage 7.0 (TID 722). 5915 bytes result sent to driver
[2025-07-19T20:31:07.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 127.0 in stage 7.0 (TID 730) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 127.0 in stage 7.0 (TID 730)
[2025-07-19T20:31:07.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 119.0 in stage 7.0 (TID 722) in 87 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.2.delta.7b0b0830-ef3e-40a5-b5be-97b60495818a.TID725.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/2.delta
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/122/2.delta
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f9d59ab
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.2.delta.274f9c04-db7e-4f02-817a-a5e2d281e3c4.TID723.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/2.delta
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/120/2.delta
[2025-07-19T20:31:07.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127] for update
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.2.delta.6ff969f6-ed61-4148-8990-90994bfa7c62.TID728.tmp
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.2.delta.3a13d6d7-acee-477c-a24c-cab94f7613ec.TID729.tmp
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 122 (task 725, attempt 0, stage 7.0)
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 122.0 in stage 7.0 (TID 725). 5829 bytes result sent to driver
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 128.0 in stage 7.0 (TID 731) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 122.0 in stage 7.0 (TID 725) in 74 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 128.0 in stage 7.0 (TID 731)
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 120 (task 723, attempt 0, stage 7.0)
[2025-07-19T20:31:07.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 120.0 in stage 7.0 (TID 723). 5915 bytes result sent to driver
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 120.0 in stage 7.0 (TID 723) in 105 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.2.delta.4a9f67fc-19cc-42d1-9cca-38df9cf659e4.TID724.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/2.delta
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 129.0 in stage 7.0 (TID 732) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/121/2.delta
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 129.0 in stage 7.0 (TID 732)
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6f717697
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128] for update
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 121 (task 724, attempt 0, stage 7.0)
[2025-07-19T20:31:07.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 121.0 in stage 7.0 (TID 724). 5872 bytes result sent to driver
[2025-07-19T20:31:07.091+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 121.0 in stage 7.0 (TID 724) in 98 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:31:07.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 130.0 in stage 7.0 (TID 733) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 130.0 in stage 7.0 (TID 733)
[2025-07-19T20:31:07.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@701f8a61
[2025-07-19T20:31:07.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129] for update
[2025-07-19T20:31:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.2.delta.3feda07e-306a-465e-be8f-08a8047615e3.TID730.tmp
[2025-07-19T20:31:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.2.delta.0af22407-b368-4164-8be7-033ae4e1b22e.TID727.tmp
[2025-07-19T20:31:07.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56a88a88
[2025-07-19T20:31:07.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130] for update
[2025-07-19T20:31:07.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.2.delta.1b53e588-6cc8-4354-b378-09fa7dc833b7.TID731.tmp
[2025-07-19T20:31:07.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.2.delta.a0e96960-8a28-4ebd-84f8-41772ff58402.TID732.tmp
[2025-07-19T20:31:07.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.2.delta.6f949958-7148-4a72-afc4-d7d7dca1332a.TID733.tmp
[2025-07-19T20:31:07.112+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.2.delta.885acaec-c075-4414-9362-7b5a49899ef1.TID726.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/2.delta
[2025-07-19T20:31:07.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/123/2.delta
[2025-07-19T20:31:07.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T20:31:07.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 123 (task 726, attempt 0, stage 7.0)
[2025-07-19T20:31:07.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 123.0 in stage 7.0 (TID 726). 5872 bytes result sent to driver
[2025-07-19T20:31:07.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 131.0 in stage 7.0 (TID 734) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 123.0 in stage 7.0 (TID 726) in 113 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:31:07.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 131.0 in stage 7.0 (TID 734)
[2025-07-19T20:31:07.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.2.delta.3a13d6d7-acee-477c-a24c-cab94f7613ec.TID729.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/2.delta
[2025-07-19T20:31:07.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/126/2.delta
[2025-07-19T20:31:07.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T20:31:07.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.2.delta.6ff969f6-ed61-4148-8990-90994bfa7c62.TID728.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/2.delta
[2025-07-19T20:31:07.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/125/2.delta
[2025-07-19T20:31:07.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T20:31:07.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@325df1ee
[2025-07-19T20:31:07.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 125 (task 728, attempt 0, stage 7.0)
[2025-07-19T20:31:07.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131] for update
[2025-07-19T20:31:07.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 125.0 in stage 7.0 (TID 728). 5872 bytes result sent to driver
[2025-07-19T20:31:07.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.2.delta.0af22407-b368-4164-8be7-033ae4e1b22e.TID727.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/2.delta
[2025-07-19T20:31:07.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/124/2.delta
[2025-07-19T20:31:07.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 132.0 in stage 7.0 (TID 735) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.142+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 125.0 in stage 7.0 (TID 728) in 110 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:31:07.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T20:31:07.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 132.0 in stage 7.0 (TID 735)
[2025-07-19T20:31:07.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 126 (task 729, attempt 0, stage 7.0)
[2025-07-19T20:31:07.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.2.delta.3feda07e-306a-465e-be8f-08a8047615e3.TID730.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/2.delta
[2025-07-19T20:31:07.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/127/2.delta
[2025-07-19T20:31:07.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 126.0 in stage 7.0 (TID 729). 5872 bytes result sent to driver
[2025-07-19T20:31:07.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 126.0 in stage 7.0 (TID 729) in 112 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:31:07.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T20:31:07.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@565ee07e
[2025-07-19T20:31:07.152+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132] for update
[2025-07-19T20:31:07.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 133.0 in stage 7.0 (TID 736) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 124 (task 727, attempt 0, stage 7.0)
[2025-07-19T20:31:07.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 124.0 in stage 7.0 (TID 727). 5872 bytes result sent to driver
[2025-07-19T20:31:07.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 133.0 in stage 7.0 (TID 736)
[2025-07-19T20:31:07.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 134.0 in stage 7.0 (TID 737) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.156+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 134.0 in stage 7.0 (TID 737)
[2025-07-19T20:31:07.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 124.0 in stage 7.0 (TID 727) in 120 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:31:07.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6df4025a
[2025-07-19T20:31:07.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 127 (task 730, attempt 0, stage 7.0)
[2025-07-19T20:31:07.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 127.0 in stage 7.0 (TID 730). 5872 bytes result sent to driver
[2025-07-19T20:31:07.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b53eab0
[2025-07-19T20:31:07.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134] for update
[2025-07-19T20:31:07.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133] for update
[2025-07-19T20:31:07.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 135.0 in stage 7.0 (TID 738) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 135.0 in stage 7.0 (TID 738)
[2025-07-19T20:31:07.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 127.0 in stage 7.0 (TID 730) in 108 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:31:07.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16c01787
[2025-07-19T20:31:07.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135] for update
[2025-07-19T20:31:07.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.2.delta.1b53e588-6cc8-4354-b378-09fa7dc833b7.TID731.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/2.delta
[2025-07-19T20:31:07.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/128/2.delta
[2025-07-19T20:31:07.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T20:31:07.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.2.delta.a0e96960-8a28-4ebd-84f8-41772ff58402.TID732.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/2.delta
[2025-07-19T20:31:07.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/129/2.delta
[2025-07-19T20:31:07.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T20:31:07.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.2.delta.4a55cad5-db26-48e7-ab51-a8cc64b7e7b2.TID734.tmp
[2025-07-19T20:31:07.188+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 129 (task 732, attempt 0, stage 7.0)
[2025-07-19T20:31:07.189+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 129.0 in stage 7.0 (TID 732). 5829 bytes result sent to driver
[2025-07-19T20:31:07.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 136.0 in stage 7.0 (TID 739) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 136.0 in stage 7.0 (TID 739)
[2025-07-19T20:31:07.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 129.0 in stage 7.0 (TID 732) in 104 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:31:07.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 128 (task 731, attempt 0, stage 7.0)
[2025-07-19T20:31:07.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 128.0 in stage 7.0 (TID 731). 5872 bytes result sent to driver
[2025-07-19T20:31:07.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 137.0 in stage 7.0 (TID 740) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 128.0 in stage 7.0 (TID 731) in 118 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:31:07.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.2.delta.03b8b025-c601-43c7-8f80-2f260967bb01.TID735.tmp
[2025-07-19T20:31:07.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.2.delta.c14342a1-9ee0-4c49-ae6e-2c29fd06b671.TID736.tmp
[2025-07-19T20:31:07.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 137.0 in stage 7.0 (TID 740)
[2025-07-19T20:31:07.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@8b0687f
[2025-07-19T20:31:07.200+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.2.delta.10081434-3ffb-4717-bd49-0afbb0ba25c2.TID737.tmp
[2025-07-19T20:31:07.202+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.2.delta.6f949958-7148-4a72-afc4-d7d7dca1332a.TID733.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/2.delta
[2025-07-19T20:31:07.202+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/130/2.delta
[2025-07-19T20:31:07.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T20:31:07.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136] for update
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.2.delta.d166e96f-a6cd-4b32-bb08-722aa9340685.TID738.tmp
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 130 (task 733, attempt 0, stage 7.0)
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7854e6de
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 130.0 in stage 7.0 (TID 733). 5829 bytes result sent to driver
[2025-07-19T20:31:07.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 138.0 in stage 7.0 (TID 741) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 138.0 in stage 7.0 (TID 741)
[2025-07-19T20:31:07.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137] for update
[2025-07-19T20:31:07.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 130.0 in stage 7.0 (TID 733) in 124 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:31:07.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61c5a3af
[2025-07-19T20:31:07.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138] for update
[2025-07-19T20:31:07.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.2.delta.5642d300-1270-403a-8c14-7eb9bd5b7822.TID739.tmp
[2025-07-19T20:31:07.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.2.delta.6be7aa54-2919-42ae-923c-2c38ef4489a5.TID740.tmp
[2025-07-19T20:31:07.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.2.delta.f57497f6-c3c0-4362-879c-67a030a8907b.TID741.tmp
[2025-07-19T20:31:07.232+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.2.delta.4a55cad5-db26-48e7-ab51-a8cc64b7e7b2.TID734.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/2.delta
[2025-07-19T20:31:07.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/131/2.delta
[2025-07-19T20:31:07.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T20:31:07.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 131 (task 734, attempt 0, stage 7.0)
[2025-07-19T20:31:07.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 131.0 in stage 7.0 (TID 734). 5872 bytes result sent to driver
[2025-07-19T20:31:07.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 139.0 in stage 7.0 (TID 742) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 131.0 in stage 7.0 (TID 734) in 113 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:31:07.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 139.0 in stage 7.0 (TID 742)
[2025-07-19T20:31:07.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.2.delta.03b8b025-c601-43c7-8f80-2f260967bb01.TID735.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/2.delta
[2025-07-19T20:31:07.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/132/2.delta
[2025-07-19T20:31:07.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T20:31:07.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@71f412a3
[2025-07-19T20:31:07.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139] for update
[2025-07-19T20:31:07.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.2.delta.c14342a1-9ee0-4c49-ae6e-2c29fd06b671.TID736.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/2.delta
[2025-07-19T20:31:07.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/133/2.delta
[2025-07-19T20:31:07.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T20:31:07.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 132 (task 735, attempt 0, stage 7.0)
[2025-07-19T20:31:07.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 132.0 in stage 7.0 (TID 735). 5872 bytes result sent to driver
[2025-07-19T20:31:07.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 140.0 in stage 7.0 (TID 743) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 133 (task 736, attempt 0, stage 7.0)
[2025-07-19T20:31:07.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 140.0 in stage 7.0 (TID 743)
[2025-07-19T20:31:07.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 132.0 in stage 7.0 (TID 735) in 112 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:31:07.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 133.0 in stage 7.0 (TID 736). 5872 bytes result sent to driver
[2025-07-19T20:31:07.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 141.0 in stage 7.0 (TID 744) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 141.0 in stage 7.0 (TID 744)
[2025-07-19T20:31:07.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 133.0 in stage 7.0 (TID 736) in 107 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:31:07.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ae419c
[2025-07-19T20:31:07.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141] for update
[2025-07-19T20:31:07.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.2.delta.10081434-3ffb-4717-bd49-0afbb0ba25c2.TID737.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/2.delta
[2025-07-19T20:31:07.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/134/2.delta
[2025-07-19T20:31:07.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3018077f
[2025-07-19T20:31:07.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140] for update
[2025-07-19T20:31:07.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.2.delta.d166e96f-a6cd-4b32-bb08-722aa9340685.TID738.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/2.delta
[2025-07-19T20:31:07.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/135/2.delta
[2025-07-19T20:31:07.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T20:31:07.294+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T20:31:07.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 134 (task 737, attempt 0, stage 7.0)
[2025-07-19T20:31:07.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 134.0 in stage 7.0 (TID 737). 5872 bytes result sent to driver
[2025-07-19T20:31:07.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 142.0 in stage 7.0 (TID 745) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 142.0 in stage 7.0 (TID 745)
[2025-07-19T20:31:07.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.2.delta.ef44e6f5-5b84-4615-a9e6-449cee0cf485.TID742.tmp
[2025-07-19T20:31:07.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 134.0 in stage 7.0 (TID 737) in 120 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:31:07.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 135 (task 738, attempt 0, stage 7.0)
[2025-07-19T20:31:07.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 135.0 in stage 7.0 (TID 738). 5872 bytes result sent to driver
[2025-07-19T20:31:07.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 143.0 in stage 7.0 (TID 746) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 143.0 in stage 7.0 (TID 746)
[2025-07-19T20:31:07.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 135.0 in stage 7.0 (TID 738) in 118 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:31:07.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32c41bef
[2025-07-19T20:31:07.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142] for update
[2025-07-19T20:31:07.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.310+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ee4a089
[2025-07-19T20:31:07.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143] for update
[2025-07-19T20:31:07.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.2.delta.f4d04463-90f1-44a4-a6f5-70b3fac497fd.TID744.tmp
[2025-07-19T20:31:07.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.2.delta.a79bdafc-3b8a-48f3-856e-649a636333e9.TID743.tmp
[2025-07-19T20:31:07.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.2.delta.6be7aa54-2919-42ae-923c-2c38ef4489a5.TID740.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/2.delta
[2025-07-19T20:31:07.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/137/2.delta
[2025-07-19T20:31:07.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T20:31:07.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.2.delta.5642d300-1270-403a-8c14-7eb9bd5b7822.TID739.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/2.delta
[2025-07-19T20:31:07.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/136/2.delta
[2025-07-19T20:31:07.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T20:31:07.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 137 (task 740, attempt 0, stage 7.0)
[2025-07-19T20:31:07.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 137.0 in stage 7.0 (TID 740). 5872 bytes result sent to driver
[2025-07-19T20:31:07.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.2.delta.f57497f6-c3c0-4362-879c-67a030a8907b.TID741.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/2.delta
[2025-07-19T20:31:07.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/138/2.delta
[2025-07-19T20:31:07.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.2.delta.0ddfed4e-5745-45b3-bc21-7e40362d0884.TID746.tmp
[2025-07-19T20:31:07.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 144.0 in stage 7.0 (TID 747) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 137.0 in stage 7.0 (TID 740) in 118 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:31:07.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 144.0 in stage 7.0 (TID 747)
[2025-07-19T20:31:07.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 136 (task 739, attempt 0, stage 7.0)
[2025-07-19T20:31:07.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T20:31:07.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.2.delta.95231a9b-342a-4153-905b-5e219fe6eeaa.TID745.tmp
[2025-07-19T20:31:07.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 136.0 in stage 7.0 (TID 739). 5872 bytes result sent to driver
[2025-07-19T20:31:07.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 145.0 in stage 7.0 (TID 748) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37c8ecf6
[2025-07-19T20:31:07.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144] for update
[2025-07-19T20:31:07.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 145.0 in stage 7.0 (TID 748)
[2025-07-19T20:31:07.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 136.0 in stage 7.0 (TID 739) in 124 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:31:07.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 138 (task 741, attempt 0, stage 7.0)
[2025-07-19T20:31:07.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 138.0 in stage 7.0 (TID 741). 5829 bytes result sent to driver
[2025-07-19T20:31:07.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 146.0 in stage 7.0 (TID 749) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 138.0 in stage 7.0 (TID 741) in 102 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:31:07.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 146.0 in stage 7.0 (TID 749)
[2025-07-19T20:31:07.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d3eba81
[2025-07-19T20:31:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145] for update
[2025-07-19T20:31:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e9e86cc
[2025-07-19T20:31:07.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146] for update
[2025-07-19T20:31:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.2.delta.98c0a103-2944-4c95-8d0e-9cec35ef0d15.TID747.tmp
[2025-07-19T20:31:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.2.delta.13160a5e-3a84-491c-91f9-0318ab9c028c.TID749.tmp
[2025-07-19T20:31:07.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.2.delta.ef44e6f5-5b84-4615-a9e6-449cee0cf485.TID742.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/2.delta
[2025-07-19T20:31:07.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/139/2.delta
[2025-07-19T20:31:07.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.2.delta.009716e9-991c-41c7-a8c0-dde7025fa57e.TID748.tmp
[2025-07-19T20:31:07.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T20:31:07.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.2.delta.a79bdafc-3b8a-48f3-856e-649a636333e9.TID743.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/2.delta
[2025-07-19T20:31:07.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/140/2.delta
[2025-07-19T20:31:07.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.2.delta.f4d04463-90f1-44a4-a6f5-70b3fac497fd.TID744.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/2.delta
[2025-07-19T20:31:07.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/141/2.delta
[2025-07-19T20:31:07.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T20:31:07.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 139 (task 742, attempt 0, stage 7.0)
[2025-07-19T20:31:07.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T20:31:07.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 139.0 in stage 7.0 (TID 742). 5915 bytes result sent to driver
[2025-07-19T20:31:07.369+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 139.0 in stage 7.0 (TID 742) in 116 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:31:07.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 147.0 in stage 7.0 (TID 750) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 147.0 in stage 7.0 (TID 750)
[2025-07-19T20:31:07.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65e6db1c
[2025-07-19T20:31:07.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 140 (task 743, attempt 0, stage 7.0)
[2025-07-19T20:31:07.390+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147] for update
[2025-07-19T20:31:07.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 141 (task 744, attempt 0, stage 7.0)
[2025-07-19T20:31:07.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 141.0 in stage 7.0 (TID 744). 5872 bytes result sent to driver
[2025-07-19T20:31:07.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 140.0 in stage 7.0 (TID 743). 5872 bytes result sent to driver
[2025-07-19T20:31:07.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 148.0 in stage 7.0 (TID 751) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 149.0 in stage 7.0 (TID 752) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 141.0 in stage 7.0 (TID 744) in 114 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:31:07.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 140.0 in stage 7.0 (TID 743) in 116 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:31:07.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 148.0 in stage 7.0 (TID 751)
[2025-07-19T20:31:07.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 149.0 in stage 7.0 (TID 752)
[2025-07-19T20:31:07.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3e4e8833
[2025-07-19T20:31:07.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149] for update
[2025-07-19T20:31:07.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f28a32c
[2025-07-19T20:31:07.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.2.delta.0ddfed4e-5745-45b3-bc21-7e40362d0884.TID746.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/2.delta
[2025-07-19T20:31:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.2.delta.95231a9b-342a-4153-905b-5e219fe6eeaa.TID745.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/2.delta
[2025-07-19T20:31:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/143/2.delta
[2025-07-19T20:31:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/142/2.delta
[2025-07-19T20:31:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T20:31:07.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T20:31:07.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148] for update
[2025-07-19T20:31:07.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 143 (task 746, attempt 0, stage 7.0)
[2025-07-19T20:31:07.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 142 (task 745, attempt 0, stage 7.0)
[2025-07-19T20:31:07.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 142.0 in stage 7.0 (TID 745). 5872 bytes result sent to driver
[2025-07-19T20:31:07.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 150.0 in stage 7.0 (TID 753) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 143.0 in stage 7.0 (TID 746). 5872 bytes result sent to driver
[2025-07-19T20:31:07.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 151.0 in stage 7.0 (TID 754) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 143.0 in stage 7.0 (TID 746) in 114 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:31:07.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.2.delta.730bd61c-2f82-4103-b4cd-c5f9ddab12ad.TID750.tmp
[2025-07-19T20:31:07.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 142.0 in stage 7.0 (TID 745) in 120 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:31:07.438+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 150.0 in stage 7.0 (TID 753)
[2025-07-19T20:31:07.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 151.0 in stage 7.0 (TID 754)
[2025-07-19T20:31:07.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.2.delta.98c0a103-2944-4c95-8d0e-9cec35ef0d15.TID747.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/2.delta
[2025-07-19T20:31:07.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/144/2.delta
[2025-07-19T20:31:07.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.448+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T20:31:07.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 144 (task 747, attempt 0, stage 7.0)
[2025-07-19T20:31:07.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 144.0 in stage 7.0 (TID 747). 5872 bytes result sent to driver
[2025-07-19T20:31:07.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a01af55
[2025-07-19T20:31:07.455+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 152.0 in stage 7.0 (TID 755) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 144.0 in stage 7.0 (TID 747) in 102 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:31:07.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151] for update
[2025-07-19T20:31:07.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 152.0 in stage 7.0 (TID 755)
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@35e79759
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.2.delta.644b673b-4cc8-4579-b4d6-3b3d12d26c59.TID751.tmp
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150] for update
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:07.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3664fbb0
[2025-07-19T20:31:07.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152] for update
[2025-07-19T20:31:07.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.2.delta.f93fbadd-3fa6-4d93-a557-3e68461115df.TID752.tmp
[2025-07-19T20:31:07.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.2.delta.13160a5e-3a84-491c-91f9-0318ab9c028c.TID749.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/2.delta
[2025-07-19T20:31:07.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/146/2.delta
[2025-07-19T20:31:07.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T20:31:07.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 146 (task 749, attempt 0, stage 7.0)
[2025-07-19T20:31:07.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.2.delta.009716e9-991c-41c7-a8c0-dde7025fa57e.TID748.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/2.delta
[2025-07-19T20:31:07.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/145/2.delta
[2025-07-19T20:31:07.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T20:31:07.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 146.0 in stage 7.0 (TID 749). 5872 bytes result sent to driver
[2025-07-19T20:31:07.476+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 153.0 in stage 7.0 (TID 756) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 146.0 in stage 7.0 (TID 749) in 129 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:31:07.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 153.0 in stage 7.0 (TID 756)
[2025-07-19T20:31:07.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.2.delta.982901a0-1dc0-4797-a9b8-cfc27e7976a9.TID754.tmp
[2025-07-19T20:31:07.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.2.delta.abac68d1-c4a5-4164-917d-6b2bda064a47.TID753.tmp
[2025-07-19T20:31:07.482+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:07.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 145 (task 748, attempt 0, stage 7.0)
[2025-07-19T20:31:07.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 145.0 in stage 7.0 (TID 748). 5872 bytes result sent to driver
[2025-07-19T20:31:07.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 154.0 in stage 7.0 (TID 757) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@582114da
[2025-07-19T20:31:07.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 154.0 in stage 7.0 (TID 757)
[2025-07-19T20:31:07.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 145.0 in stage 7.0 (TID 748) in 146 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:31:07.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153] for update
[2025-07-19T20:31:07.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.492+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.492+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5adab8bc
[2025-07-19T20:31:07.492+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.2.delta.87b1e720-0c62-4640-8cea-7678e8315b23.TID755.tmp
[2025-07-19T20:31:07.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154] for update
[2025-07-19T20:31:07.498+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.2.delta.730bd61c-2f82-4103-b4cd-c5f9ddab12ad.TID750.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/2.delta
[2025-07-19T20:31:07.498+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/147/2.delta
[2025-07-19T20:31:07.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T20:31:07.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.506+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 147 (task 750, attempt 0, stage 7.0)
[2025-07-19T20:31:07.507+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 147.0 in stage 7.0 (TID 750). 5829 bytes result sent to driver
[2025-07-19T20:31:07.508+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 155.0 in stage 7.0 (TID 758) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.508+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 147.0 in stage 7.0 (TID 750) in 109 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:31:07.510+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 155.0 in stage 7.0 (TID 758)
[2025-07-19T20:31:07.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4753a763
[2025-07-19T20:31:07.515+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.516+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155] for update
[2025-07-19T20:31:07.516+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.517+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.2.delta.45896bb3-7ea4-4bbc-b77f-199d612472ba.TID757.tmp
[2025-07-19T20:31:07.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.2.delta.df3060d3-130c-4f4f-ae23-2d6753a988fa.TID756.tmp
[2025-07-19T20:31:07.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.2.delta.644b673b-4cc8-4579-b4d6-3b3d12d26c59.TID751.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/2.delta
[2025-07-19T20:31:07.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/148/2.delta
[2025-07-19T20:31:07.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T20:31:07.520+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 148 (task 751, attempt 0, stage 7.0)
[2025-07-19T20:31:07.521+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 148.0 in stage 7.0 (TID 751). 5872 bytes result sent to driver
[2025-07-19T20:31:07.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 156.0 in stage 7.0 (TID 759) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 156.0 in stage 7.0 (TID 759)
[2025-07-19T20:31:07.524+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 148.0 in stage 7.0 (TID 751) in 132 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:31:07.526+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.527+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.2.delta.2fdc0d0c-ef69-4321-90f5-da69ff9ef1cc.TID758.tmp
[2025-07-19T20:31:07.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@536e804c
[2025-07-19T20:31:07.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156] for update
[2025-07-19T20:31:07.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.2.delta.f93fbadd-3fa6-4d93-a557-3e68461115df.TID752.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/2.delta
[2025-07-19T20:31:07.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/149/2.delta
[2025-07-19T20:31:07.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T20:31:07.529+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.2.delta.87b1e720-0c62-4640-8cea-7678e8315b23.TID755.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/2.delta
[2025-07-19T20:31:07.530+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 149 (task 752, attempt 0, stage 7.0)
[2025-07-19T20:31:07.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/152/2.delta
[2025-07-19T20:31:07.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T20:31:07.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 149.0 in stage 7.0 (TID 752). 5872 bytes result sent to driver
[2025-07-19T20:31:07.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 157.0 in stage 7.0 (TID 760) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 149.0 in stage 7.0 (TID 752) in 155 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:31:07.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 157.0 in stage 7.0 (TID 760)
[2025-07-19T20:31:07.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.2.delta.da3bc344-f582-462d-9012-991a1334c912.TID759.tmp
[2025-07-19T20:31:07.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.2.delta.982901a0-1dc0-4797-a9b8-cfc27e7976a9.TID754.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/2.delta
[2025-07-19T20:31:07.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/151/2.delta
[2025-07-19T20:31:07.540+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T20:31:07.540+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 152 (task 755, attempt 0, stage 7.0)
[2025-07-19T20:31:07.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.542+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 152.0 in stage 7.0 (TID 755). 5872 bytes result sent to driver
[2025-07-19T20:31:07.543+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 158.0 in stage 7.0 (TID 761) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.546+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 152.0 in stage 7.0 (TID 755) in 132 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:31:07.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 158.0 in stage 7.0 (TID 761)
[2025-07-19T20:31:07.547+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75cbbcfb
[2025-07-19T20:31:07.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.548+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157] for update
[2025-07-19T20:31:07.549+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 151 (task 754, attempt 0, stage 7.0)
[2025-07-19T20:31:07.550+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 151.0 in stage 7.0 (TID 754). 5872 bytes result sent to driver
[2025-07-19T20:31:07.550+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 159.0 in stage 7.0 (TID 762) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.551+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 151.0 in stage 7.0 (TID 754) in 148 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:31:07.552+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 159.0 in stage 7.0 (TID 762)
[2025-07-19T20:31:07.552+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.2.delta.abac68d1-c4a5-4164-917d-6b2bda064a47.TID753.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/2.delta
[2025-07-19T20:31:07.552+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/150/2.delta
[2025-07-19T20:31:07.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T20:31:07.553+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.554+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.554+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:07.555+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@27544fd2
[2025-07-19T20:31:07.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.556+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.558+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158] for update
[2025-07-19T20:31:07.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@c0644cc
[2025-07-19T20:31:07.564+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159] for update
[2025-07-19T20:31:07.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 150 (task 753, attempt 0, stage 7.0)
[2025-07-19T20:31:07.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 150.0 in stage 7.0 (TID 753). 5872 bytes result sent to driver
[2025-07-19T20:31:07.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 160.0 in stage 7.0 (TID 763) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 150.0 in stage 7.0 (TID 753) in 162 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:31:07.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 160.0 in stage 7.0 (TID 763)
[2025-07-19T20:31:07.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.2.delta.45896bb3-7ea4-4bbc-b77f-199d612472ba.TID757.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/2.delta
[2025-07-19T20:31:07.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/154/2.delta
[2025-07-19T20:31:07.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T20:31:07.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 154 (task 757, attempt 0, stage 7.0)
[2025-07-19T20:31:07.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2cbe10b2
[2025-07-19T20:31:07.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 154.0 in stage 7.0 (TID 757). 5872 bytes result sent to driver
[2025-07-19T20:31:07.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160] for update
[2025-07-19T20:31:07.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 161.0 in stage 7.0 (TID 764) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 154.0 in stage 7.0 (TID 757) in 113 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:31:07.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 161.0 in stage 7.0 (TID 764)
[2025-07-19T20:31:07.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@693fae52
[2025-07-19T20:31:07.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.2.delta.284c40f9-6466-4acf-876f-05eeb0a37abe.TID760.tmp
[2025-07-19T20:31:07.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.597+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161] for update
[2025-07-19T20:31:07.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.2.delta.df3060d3-130c-4f4f-ae23-2d6753a988fa.TID756.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/2.delta
[2025-07-19T20:31:07.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/153/2.delta
[2025-07-19T20:31:07.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T20:31:07.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.2.delta.35f951d2-31e3-43a3-a159-2f9d5b897a6d.TID761.tmp
[2025-07-19T20:31:07.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.2.delta.388c2cbf-84b3-4da5-a9d9-5f62cb0cba32.TID762.tmp
[2025-07-19T20:31:07.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 153 (task 756, attempt 0, stage 7.0)
[2025-07-19T20:31:07.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 153.0 in stage 7.0 (TID 756). 5872 bytes result sent to driver
[2025-07-19T20:31:07.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 162.0 in stage 7.0 (TID 765) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 153.0 in stage 7.0 (TID 756) in 133 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 162.0 in stage 7.0 (TID 765)
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dae5e06
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.2.delta.2fdc0d0c-ef69-4321-90f5-da69ff9ef1cc.TID758.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/2.delta
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/155/2.delta
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162] for update
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.2.delta.b4483d4e-38ff-4be4-aa69-170ff6f13301.TID763.tmp
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.2.delta.83009eef-01d0-46be-b850-9cce6433b550.TID764.tmp
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.2.delta.da3bc344-f582-462d-9012-991a1334c912.TID759.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/2.delta
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/156/2.delta
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 155 (task 758, attempt 0, stage 7.0)
[2025-07-19T20:31:07.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 155.0 in stage 7.0 (TID 758). 5872 bytes result sent to driver
[2025-07-19T20:31:07.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 163.0 in stage 7.0 (TID 766) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 163.0 in stage 7.0 (TID 766)
[2025-07-19T20:31:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 155.0 in stage 7.0 (TID 758) in 122 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:31:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 156 (task 759, attempt 0, stage 7.0)
[2025-07-19T20:31:07.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 156.0 in stage 7.0 (TID 759). 5829 bytes result sent to driver
[2025-07-19T20:31:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.2.delta.786f483b-3bf1-4cbd-ad52-5a4d2506ee27.TID765.tmp
[2025-07-19T20:31:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 164.0 in stage 7.0 (TID 767) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 156.0 in stage 7.0 (TID 759) in 97 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:31:07.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 164.0 in stage 7.0 (TID 767)
[2025-07-19T20:31:07.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@20367a3f
[2025-07-19T20:31:07.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163] for update
[2025-07-19T20:31:07.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f519821
[2025-07-19T20:31:07.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.614+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164] for update
[2025-07-19T20:31:07.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.2.delta.d98b703a-8f6d-42c0-97d0-db6c8c86dfb4.TID766.tmp
[2025-07-19T20:31:07.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.2.delta.388c2cbf-84b3-4da5-a9d9-5f62cb0cba32.TID762.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/2.delta
[2025-07-19T20:31:07.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/159/2.delta
[2025-07-19T20:31:07.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T20:31:07.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.2.delta.35f951d2-31e3-43a3-a159-2f9d5b897a6d.TID761.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/2.delta
[2025-07-19T20:31:07.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/158/2.delta
[2025-07-19T20:31:07.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T20:31:07.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.2.delta.284c40f9-6466-4acf-876f-05eeb0a37abe.TID760.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/2.delta
[2025-07-19T20:31:07.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/157/2.delta
[2025-07-19T20:31:07.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.2.delta.7c1ee4db-a80e-48de-84d0-caf3436c3cb3.TID767.tmp
[2025-07-19T20:31:07.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T20:31:07.650+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 158 (task 761, attempt 0, stage 7.0)
[2025-07-19T20:31:07.650+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 158.0 in stage 7.0 (TID 761). 5872 bytes result sent to driver
[2025-07-19T20:31:07.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 165.0 in stage 7.0 (TID 768) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 158.0 in stage 7.0 (TID 761) in 130 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:31:07.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.2.delta.b4483d4e-38ff-4be4-aa69-170ff6f13301.TID763.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/2.delta
[2025-07-19T20:31:07.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/160/2.delta
[2025-07-19T20:31:07.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T20:31:07.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.2.delta.83009eef-01d0-46be-b850-9cce6433b550.TID764.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/2.delta
[2025-07-19T20:31:07.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/161/2.delta
[2025-07-19T20:31:07.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T20:31:07.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 159 (task 762, attempt 0, stage 7.0)
[2025-07-19T20:31:07.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 159.0 in stage 7.0 (TID 762). 5872 bytes result sent to driver
[2025-07-19T20:31:07.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 165.0 in stage 7.0 (TID 768)
[2025-07-19T20:31:07.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 166.0 in stage 7.0 (TID 769) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 166.0 in stage 7.0 (TID 769)
[2025-07-19T20:31:07.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 157 (task 760, attempt 0, stage 7.0)
[2025-07-19T20:31:07.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@167c9517
[2025-07-19T20:31:07.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 161 (task 764, attempt 0, stage 7.0)
[2025-07-19T20:31:07.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 159.0 in stage 7.0 (TID 762) in 132 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:31:07.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 157.0 in stage 7.0 (TID 760). 5872 bytes result sent to driver
[2025-07-19T20:31:07.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165] for update
[2025-07-19T20:31:07.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 161.0 in stage 7.0 (TID 764). 5872 bytes result sent to driver
[2025-07-19T20:31:07.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 167.0 in stage 7.0 (TID 770) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 160 (task 763, attempt 0, stage 7.0)
[2025-07-19T20:31:07.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 157.0 in stage 7.0 (TID 760) in 147 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:31:07.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 167.0 in stage 7.0 (TID 770)
[2025-07-19T20:31:07.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 161.0 in stage 7.0 (TID 764) in 115 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:31:07.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.2.delta.786f483b-3bf1-4cbd-ad52-5a4d2506ee27.TID765.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/2.delta
[2025-07-19T20:31:07.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/162/2.delta
[2025-07-19T20:31:07.673+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 160.0 in stage 7.0 (TID 763). 5872 bytes result sent to driver
[2025-07-19T20:31:07.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 168.0 in stage 7.0 (TID 771) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.677+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T20:31:07.678+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 169.0 in stage 7.0 (TID 772) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 160.0 in stage 7.0 (TID 763) in 122 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:31:07.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 169.0 in stage 7.0 (TID 772)
[2025-07-19T20:31:07.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 168.0 in stage 7.0 (TID 771)
[2025-07-19T20:31:07.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@763403dc
[2025-07-19T20:31:07.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166] for update
[2025-07-19T20:31:07.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17bd5cc6
[2025-07-19T20:31:07.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167] for update
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@18a9daae
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 162 (task 765, attempt 0, stage 7.0)
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 162.0 in stage 7.0 (TID 765). 5872 bytes result sent to driver
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@356ae41e
[2025-07-19T20:31:07.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169] for update
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168] for update
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 170.0 in stage 7.0 (TID 773) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 162.0 in stage 7.0 (TID 765) in 117 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 170.0 in stage 7.0 (TID 773)
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.695+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.695+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@62fe54c0
[2025-07-19T20:31:07.695+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.2.delta.bb70e8a4-9985-45d5-afaa-a779866ad290.TID769.tmp
[2025-07-19T20:31:07.695+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.696+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170] for update
[2025-07-19T20:31:07.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.2.delta.123e4925-5487-413e-932c-e32a6af972a9.TID768.tmp
[2025-07-19T20:31:07.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.2.delta.d5350c33-80a2-4581-90a8-c62f8937731d.TID770.tmp
[2025-07-19T20:31:07.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.2.delta.ce52bab3-74a9-456b-af72-96a60348eb02.TID772.tmp
[2025-07-19T20:31:07.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.2.delta.d98b703a-8f6d-42c0-97d0-db6c8c86dfb4.TID766.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/2.delta
[2025-07-19T20:31:07.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/163/2.delta
[2025-07-19T20:31:07.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T20:31:07.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.2.delta.a251a9cc-c200-4293-8843-3e47d063a15f.TID771.tmp
[2025-07-19T20:31:07.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.2.delta.11371a9e-b5a0-4820-85e4-62210fb6844c.TID773.tmp
[2025-07-19T20:31:07.702+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 163 (task 766, attempt 0, stage 7.0)
[2025-07-19T20:31:07.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 163.0 in stage 7.0 (TID 766). 5872 bytes result sent to driver
[2025-07-19T20:31:07.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 171.0 in stage 7.0 (TID 774) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 171.0 in stage 7.0 (TID 774)
[2025-07-19T20:31:07.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 163.0 in stage 7.0 (TID 766) in 122 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:31:07.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.708+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34be556c
[2025-07-19T20:31:07.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171] for update
[2025-07-19T20:31:07.711+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.2.delta.7c1ee4db-a80e-48de-84d0-caf3436c3cb3.TID767.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/2.delta
[2025-07-19T20:31:07.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/164/2.delta
[2025-07-19T20:31:07.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T20:31:07.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 164 (task 767, attempt 0, stage 7.0)
[2025-07-19T20:31:07.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 164.0 in stage 7.0 (TID 767). 5872 bytes result sent to driver
[2025-07-19T20:31:07.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 172.0 in stage 7.0 (TID 775) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 164.0 in stage 7.0 (TID 767) in 128 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:31:07.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 172.0 in stage 7.0 (TID 775)
[2025-07-19T20:31:07.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.2.delta.588d852a-408b-48f2-bab1-65ce87e6660c.TID774.tmp
[2025-07-19T20:31:07.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@34c1e774
[2025-07-19T20:31:07.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172] for update
[2025-07-19T20:31:07.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.2.delta.123e4925-5487-413e-932c-e32a6af972a9.TID768.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/2.delta
[2025-07-19T20:31:07.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/165/2.delta
[2025-07-19T20:31:07.731+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T20:31:07.731+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.2.delta.bb70e8a4-9985-45d5-afaa-a779866ad290.TID769.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/2.delta
[2025-07-19T20:31:07.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/166/2.delta
[2025-07-19T20:31:07.733+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T20:31:07.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.2.delta.d5350c33-80a2-4581-90a8-c62f8937731d.TID770.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/2.delta
[2025-07-19T20:31:07.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/167/2.delta
[2025-07-19T20:31:07.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 165 (task 768, attempt 0, stage 7.0)
[2025-07-19T20:31:07.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T20:31:07.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.2.delta.ce52bab3-74a9-456b-af72-96a60348eb02.TID772.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/2.delta
[2025-07-19T20:31:07.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.2.delta.dfec07f8-2ad3-456c-8f36-848f4cecd2e7.TID775.tmp
[2025-07-19T20:31:07.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 165.0 in stage 7.0 (TID 768). 5915 bytes result sent to driver
[2025-07-19T20:31:07.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 173.0 in stage 7.0 (TID 776) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 166 (task 769, attempt 0, stage 7.0)
[2025-07-19T20:31:07.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/169/2.delta
[2025-07-19T20:31:07.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 173.0 in stage 7.0 (TID 776)
[2025-07-19T20:31:07.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T20:31:07.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 166.0 in stage 7.0 (TID 769). 5915 bytes result sent to driver
[2025-07-19T20:31:07.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 167 (task 770, attempt 0, stage 7.0)
[2025-07-19T20:31:07.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 167.0 in stage 7.0 (TID 770). 5872 bytes result sent to driver
[2025-07-19T20:31:07.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 174.0 in stage 7.0 (TID 777) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 175.0 in stage 7.0 (TID 778) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 175.0 in stage 7.0 (TID 778)
[2025-07-19T20:31:07.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 169 (task 772, attempt 0, stage 7.0)
[2025-07-19T20:31:07.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 169.0 in stage 7.0 (TID 772). 5872 bytes result sent to driver
[2025-07-19T20:31:07.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 174.0 in stage 7.0 (TID 777)
[2025-07-19T20:31:07.753+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.753+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.753+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 176.0 in stage 7.0 (TID 779) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 165.0 in stage 7.0 (TID 768) in 98 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:31:07.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:07.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 166.0 in stage 7.0 (TID 769) in 89 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:31:07.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 167.0 in stage 7.0 (TID 770) in 84 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:31:07.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 169.0 in stage 7.0 (TID 772) in 83 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:31:07.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 176.0 in stage 7.0 (TID 779)
[2025-07-19T20:31:07.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f6ac185
[2025-07-19T20:31:07.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b42256b
[2025-07-19T20:31:07.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175] for update
[2025-07-19T20:31:07.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.757+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173] for update
[2025-07-19T20:31:07.757+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.759+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.2.delta.a251a9cc-c200-4293-8843-3e47d063a15f.TID771.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/2.delta
[2025-07-19T20:31:07.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/168/2.delta
[2025-07-19T20:31:07.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.761+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T20:31:07.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d15346f
[2025-07-19T20:31:07.762+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174] for update
[2025-07-19T20:31:07.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ce3cbe5
[2025-07-19T20:31:07.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 168 (task 771, attempt 0, stage 7.0)
[2025-07-19T20:31:07.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176] for update
[2025-07-19T20:31:07.765+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.765+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.2.delta.588d852a-408b-48f2-bab1-65ce87e6660c.TID774.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/2.delta
[2025-07-19T20:31:07.765+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/171/2.delta
[2025-07-19T20:31:07.765+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.2.delta.11371a9e-b5a0-4820-85e4-62210fb6844c.TID773.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/2.delta
[2025-07-19T20:31:07.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/170/2.delta
[2025-07-19T20:31:07.766+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 168.0 in stage 7.0 (TID 771). 5872 bytes result sent to driver
[2025-07-19T20:31:07.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T20:31:07.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T20:31:07.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 177.0 in stage 7.0 (TID 780) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 168.0 in stage 7.0 (TID 771) in 97 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:31:07.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.2.delta.35bc37c7-f66d-4186-b413-64917da76cc8.TID778.tmp
[2025-07-19T20:31:07.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 171 (task 774, attempt 0, stage 7.0)
[2025-07-19T20:31:07.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 177.0 in stage 7.0 (TID 780)
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 171.0 in stage 7.0 (TID 774). 5872 bytes result sent to driver
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 178.0 in stage 7.0 (TID 781) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 170 (task 773, attempt 0, stage 7.0)
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 171.0 in stage 7.0 (TID 774) in 62 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 170.0 in stage 7.0 (TID 773). 5872 bytes result sent to driver
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 178.0 in stage 7.0 (TID 781)
[2025-07-19T20:31:07.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.2.delta.815e9e22-1497-4de2-a19b-e6d754a74338.TID776.tmp
[2025-07-19T20:31:07.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 179.0 in stage 7.0 (TID 782) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e82419c
[2025-07-19T20:31:07.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 170.0 in stage 7.0 (TID 773) in 90 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:31:07.776+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 179.0 in stage 7.0 (TID 782)
[2025-07-19T20:31:07.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177] for update
[2025-07-19T20:31:07.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.2.delta.e2b1f8ec-e663-4c47-a7d0-9b486ee4dec5.TID779.tmp
[2025-07-19T20:31:07.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.2.delta.dab5a00a-3c5a-4b2b-9a8b-7cd31dc17527.TID777.tmp
[2025-07-19T20:31:07.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5ec8ca88
[2025-07-19T20:31:07.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179] for update
[2025-07-19T20:31:07.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4435bb97
[2025-07-19T20:31:07.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178] for update
[2025-07-19T20:31:07.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.2.delta.cdb01196-cbfb-4a70-98c8-fe47299ee46b.TID780.tmp
[2025-07-19T20:31:07.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.2.delta.dfec07f8-2ad3-456c-8f36-848f4cecd2e7.TID775.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/2.delta
[2025-07-19T20:31:07.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/172/2.delta
[2025-07-19T20:31:07.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T20:31:07.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.2.delta.4bca8b2b-78f9-4b1a-8612-db4e581ea758.TID781.tmp
[2025-07-19T20:31:07.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.2.delta.fd12c17e-4f8e-4358-9451-4fc007ca1f3e.TID782.tmp
[2025-07-19T20:31:07.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 172 (task 775, attempt 0, stage 7.0)
[2025-07-19T20:31:07.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 172.0 in stage 7.0 (TID 775). 5872 bytes result sent to driver
[2025-07-19T20:31:07.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 180.0 in stage 7.0 (TID 783) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 172.0 in stage 7.0 (TID 775) in 79 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:31:07.810+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 180.0 in stage 7.0 (TID 783)
[2025-07-19T20:31:07.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@729b0563
[2025-07-19T20:31:07.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.2.delta.35bc37c7-f66d-4186-b413-64917da76cc8.TID778.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/2.delta
[2025-07-19T20:31:07.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/175/2.delta
[2025-07-19T20:31:07.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T20:31:07.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180] for update
[2025-07-19T20:31:07.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 175 (task 778, attempt 0, stage 7.0)
[2025-07-19T20:31:07.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 175.0 in stage 7.0 (TID 778). 5829 bytes result sent to driver
[2025-07-19T20:31:07.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 181.0 in stage 7.0 (TID 784) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.819+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 181.0 in stage 7.0 (TID 784)
[2025-07-19T20:31:07.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 175.0 in stage 7.0 (TID 778) in 73 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:31:07.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.2.delta.e2b1f8ec-e663-4c47-a7d0-9b486ee4dec5.TID779.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/2.delta
[2025-07-19T20:31:07.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/176/2.delta
[2025-07-19T20:31:07.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fc2b237
[2025-07-19T20:31:07.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181] for update
[2025-07-19T20:31:07.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T20:31:07.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.2.delta.815e9e22-1497-4de2-a19b-e6d754a74338.TID776.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/2.delta
[2025-07-19T20:31:07.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/173/2.delta
[2025-07-19T20:31:07.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T20:31:07.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.2.delta.dab5a00a-3c5a-4b2b-9a8b-7cd31dc17527.TID777.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/2.delta
[2025-07-19T20:31:07.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/174/2.delta
[2025-07-19T20:31:07.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T20:31:07.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 176 (task 779, attempt 0, stage 7.0)
[2025-07-19T20:31:07.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 176.0 in stage 7.0 (TID 779). 5872 bytes result sent to driver
[2025-07-19T20:31:07.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 182.0 in stage 7.0 (TID 785) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 182.0 in stage 7.0 (TID 785)
[2025-07-19T20:31:07.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 176.0 in stage 7.0 (TID 779) in 84 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:31:07.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 173 (task 776, attempt 0, stage 7.0)
[2025-07-19T20:31:07.840+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 173.0 in stage 7.0 (TID 776). 5872 bytes result sent to driver
[2025-07-19T20:31:07.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 183.0 in stage 7.0 (TID 786) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 173.0 in stage 7.0 (TID 776) in 93 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:31:07.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 183.0 in stage 7.0 (TID 786)
[2025-07-19T20:31:07.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21fbee43
[2025-07-19T20:31:07.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.2.delta.42cfc0c2-811a-487a-9264-54a38a8261f4.TID783.tmp
[2025-07-19T20:31:07.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:07.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 174 (task 777, attempt 0, stage 7.0)
[2025-07-19T20:31:07.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 174.0 in stage 7.0 (TID 777). 5829 bytes result sent to driver
[2025-07-19T20:31:07.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 184.0 in stage 7.0 (TID 787) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182] for update
[2025-07-19T20:31:07.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 184.0 in stage 7.0 (TID 787)
[2025-07-19T20:31:07.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 174.0 in stage 7.0 (TID 777) in 97 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:31:07.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.2.delta.cdb01196-cbfb-4a70-98c8-fe47299ee46b.TID780.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/2.delta
[2025-07-19T20:31:07.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/177/2.delta
[2025-07-19T20:31:07.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4348a515
[2025-07-19T20:31:07.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.2.delta.fd12c17e-4f8e-4358-9451-4fc007ca1f3e.TID782.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/2.delta
[2025-07-19T20:31:07.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/179/2.delta
[2025-07-19T20:31:07.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183] for update
[2025-07-19T20:31:07.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T20:31:07.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T20:31:07.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@60e5acc8
[2025-07-19T20:31:07.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 177 (task 780, attempt 0, stage 7.0)
[2025-07-19T20:31:07.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 179 (task 782, attempt 0, stage 7.0)
[2025-07-19T20:31:07.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 179.0 in stage 7.0 (TID 782). 5872 bytes result sent to driver
[2025-07-19T20:31:07.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 185.0 in stage 7.0 (TID 788) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 179.0 in stage 7.0 (TID 782) in 85 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:31:07.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 185.0 in stage 7.0 (TID 788)
[2025-07-19T20:31:07.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.860+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184] for update
[2025-07-19T20:31:07.860+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.2.delta.1cbe2b91-cc89-4744-9720-e7b5e27bdc43.TID784.tmp
[2025-07-19T20:31:07.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 177.0 in stage 7.0 (TID 780). 5872 bytes result sent to driver
[2025-07-19T20:31:07.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 186.0 in stage 7.0 (TID 789) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 186.0 in stage 7.0 (TID 789)
[2025-07-19T20:31:07.863+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@76e38f86
[2025-07-19T20:31:07.864+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.864+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.864+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.2.delta.a96a8464-6f27-4793-bd9b-6e05114d5b39.TID786.tmp
[2025-07-19T20:31:07.865+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.2.delta.b5ed6149-3717-4422-bca6-b884c364ff20.TID785.tmp
[2025-07-19T20:31:07.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.2.delta.4bca8b2b-78f9-4b1a-8612-db4e581ea758.TID781.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/2.delta
[2025-07-19T20:31:07.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/178/2.delta
[2025-07-19T20:31:07.866+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 177.0 in stage 7.0 (TID 780) in 102 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:31:07.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185] for update
[2025-07-19T20:31:07.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T20:31:07.868+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.868+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.2.delta.65ca511f-f18a-466f-ab2f-f6569d3fb359.TID787.tmp
[2025-07-19T20:31:07.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 178 (task 781, attempt 0, stage 7.0)
[2025-07-19T20:31:07.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 178.0 in stage 7.0 (TID 781). 5872 bytes result sent to driver
[2025-07-19T20:31:07.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 187.0 in stage 7.0 (TID 790) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 178.0 in stage 7.0 (TID 781) in 108 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:31:07.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29715f48
[2025-07-19T20:31:07.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186] for update
[2025-07-19T20:31:07.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 187.0 in stage 7.0 (TID 790)
[2025-07-19T20:31:07.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.2.delta.7bc3e3c5-4393-47c9-a3e9-02940721bcde.TID788.tmp
[2025-07-19T20:31:07.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f7475a7
[2025-07-19T20:31:07.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187] for update
[2025-07-19T20:31:07.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.2.delta.31779e45-cd60-4531-8899-9bbf06c2c160.TID789.tmp
[2025-07-19T20:31:07.901+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.2.delta.236099b2-5e6b-4c10-9455-d4aaedbb1e89.TID790.tmp
[2025-07-19T20:31:07.904+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.2.delta.42cfc0c2-811a-487a-9264-54a38a8261f4.TID783.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/2.delta
[2025-07-19T20:31:07.905+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/180/2.delta
[2025-07-19T20:31:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.2.delta.b5ed6149-3717-4422-bca6-b884c364ff20.TID785.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/2.delta
[2025-07-19T20:31:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/182/2.delta
[2025-07-19T20:31:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.2.delta.1cbe2b91-cc89-4744-9720-e7b5e27bdc43.TID784.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/2.delta
[2025-07-19T20:31:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/181/2.delta
[2025-07-19T20:31:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T20:31:07.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T20:31:07.908+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T20:31:07.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.2.delta.a96a8464-6f27-4793-bd9b-6e05114d5b39.TID786.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/2.delta
[2025-07-19T20:31:07.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/183/2.delta
[2025-07-19T20:31:07.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 182 (task 785, attempt 0, stage 7.0)
[2025-07-19T20:31:07.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 182.0 in stage 7.0 (TID 785). 5829 bytes result sent to driver
[2025-07-19T20:31:07.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T20:31:07.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 180 (task 783, attempt 0, stage 7.0)
[2025-07-19T20:31:07.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 181 (task 784, attempt 0, stage 7.0)
[2025-07-19T20:31:07.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 180.0 in stage 7.0 (TID 783). 5872 bytes result sent to driver
[2025-07-19T20:31:07.924+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 188.0 in stage 7.0 (TID 791) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.924+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 189.0 in stage 7.0 (TID 792) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 182.0 in stage 7.0 (TID 785) in 87 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:31:07.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 180.0 in stage 7.0 (TID 783) in 121 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:31:07.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 189.0 in stage 7.0 (TID 792)
[2025-07-19T20:31:07.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 188.0 in stage 7.0 (TID 791)
[2025-07-19T20:31:07.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.927+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 181.0 in stage 7.0 (TID 784). 5915 bytes result sent to driver
[2025-07-19T20:31:07.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f5a5bfb
[2025-07-19T20:31:07.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 181.0 in stage 7.0 (TID 784) in 104 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:31:07.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 190.0 in stage 7.0 (TID 793) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189] for update
[2025-07-19T20:31:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 190.0 in stage 7.0 (TID 793)
[2025-07-19T20:31:07.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7104e6a7
[2025-07-19T20:31:07.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 183 (task 786, attempt 0, stage 7.0)
[2025-07-19T20:31:07.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.2.delta.65ca511f-f18a-466f-ab2f-f6569d3fb359.TID787.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/2.delta
[2025-07-19T20:31:07.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/184/2.delta
[2025-07-19T20:31:07.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188] for update
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 183.0 in stage 7.0 (TID 786). 5872 bytes result sent to driver
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 184 (task 787, attempt 0, stage 7.0)
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 191.0 in stage 7.0 (TID 794) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 184.0 in stage 7.0 (TID 787). 5829 bytes result sent to driver
[2025-07-19T20:31:07.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ae191da
[2025-07-19T20:31:07.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 191.0 in stage 7.0 (TID 794)
[2025-07-19T20:31:07.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 192.0 in stage 7.0 (TID 795) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 192.0 in stage 7.0 (TID 795)
[2025-07-19T20:31:07.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190] for update
[2025-07-19T20:31:07.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a13afa9
[2025-07-19T20:31:07.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 184.0 in stage 7.0 (TID 787) in 96 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:31:07.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 183.0 in stage 7.0 (TID 786) in 101 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:31:07.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191] for update
[2025-07-19T20:31:07.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.2.delta.7bc3e3c5-4393-47c9-a3e9-02940721bcde.TID788.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/2.delta
[2025-07-19T20:31:07.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/185/2.delta
[2025-07-19T20:31:07.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@410f7582
[2025-07-19T20:31:07.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T20:31:07.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192] for update
[2025-07-19T20:31:07.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 185 (task 788, attempt 0, stage 7.0)
[2025-07-19T20:31:07.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 185.0 in stage 7.0 (TID 788). 5872 bytes result sent to driver
[2025-07-19T20:31:07.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 193.0 in stage 7.0 (TID 796) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.2.delta.e9f7fe7b-6a59-4d53-8cd3-cdc469d277c0.TID792.tmp
[2025-07-19T20:31:07.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 185.0 in stage 7.0 (TID 788) in 96 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:31:07.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 193.0 in stage 7.0 (TID 796)
[2025-07-19T20:31:07.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@747a2271
[2025-07-19T20:31:07.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193] for update
[2025-07-19T20:31:07.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.2.delta.5142d687-6be2-4698-ba02-3fab12fae4b0.TID793.tmp
[2025-07-19T20:31:07.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.2.delta.eea9d751-4d5d-4d30-aa87-142a3418e001.TID791.tmp
[2025-07-19T20:31:07.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.2.delta.31779e45-cd60-4531-8899-9bbf06c2c160.TID789.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/2.delta
[2025-07-19T20:31:07.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/186/2.delta
[2025-07-19T20:31:07.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T20:31:07.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.2.delta.a657f88f-ce0b-4e1f-b8bc-445a9ba95f7d.TID794.tmp
[2025-07-19T20:31:07.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.2.delta.ba881bed-1dd6-4380-958a-9d9932605404.TID795.tmp
[2025-07-19T20:31:07.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.2.delta.236099b2-5e6b-4c10-9455-d4aaedbb1e89.TID790.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/2.delta
[2025-07-19T20:31:07.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/187/2.delta
[2025-07-19T20:31:07.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 186 (task 789, attempt 0, stage 7.0)
[2025-07-19T20:31:07.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T20:31:07.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 186.0 in stage 7.0 (TID 789). 5872 bytes result sent to driver
[2025-07-19T20:31:07.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 186.0 in stage 7.0 (TID 789) in 106 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:31:07.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 194.0 in stage 7.0 (TID 797) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.2.delta.f070bef1-d409-40b0-b883-ac4badc209d3.TID796.tmp
[2025-07-19T20:31:07.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 194.0 in stage 7.0 (TID 797)
[2025-07-19T20:31:07.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 187 (task 790, attempt 0, stage 7.0)
[2025-07-19T20:31:07.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@783c0f53
[2025-07-19T20:31:07.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194] for update
[2025-07-19T20:31:07.969+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 187.0 in stage 7.0 (TID 790). 5872 bytes result sent to driver
[2025-07-19T20:31:07.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 195.0 in stage 7.0 (TID 798) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:07.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 195.0 in stage 7.0 (TID 798)
[2025-07-19T20:31:07.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:07.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:07.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 187.0 in stage 7.0 (TID 790) in 97 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:31:07.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21d80dd
[2025-07-19T20:31:07.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:07.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195] for update
[2025-07-19T20:31:07.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:07.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.2.delta.20ce8fa4-3481-4053-b2a8-f9aa2d837b95.TID797.tmp
[2025-07-19T20:31:07.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.2.delta.5d2b55f8-825f-4937-83ce-3080695e6861.TID798.tmp
[2025-07-19T20:31:07.987+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.2.delta.e9f7fe7b-6a59-4d53-8cd3-cdc469d277c0.TID792.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/2.delta
[2025-07-19T20:31:07.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/189/2.delta
[2025-07-19T20:31:07.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T20:31:07.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.2.delta.eea9d751-4d5d-4d30-aa87-142a3418e001.TID791.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/2.delta
[2025-07-19T20:31:07.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/188/2.delta
[2025-07-19T20:31:07.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T20:31:07.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.2.delta.5142d687-6be2-4698-ba02-3fab12fae4b0.TID793.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/2.delta
[2025-07-19T20:31:07.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/190/2.delta
[2025-07-19T20:31:08.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T20:31:08.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 189 (task 792, attempt 0, stage 7.0)
[2025-07-19T20:31:08.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 189.0 in stage 7.0 (TID 792). 5872 bytes result sent to driver
[2025-07-19T20:31:08.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 188 (task 791, attempt 0, stage 7.0)
[2025-07-19T20:31:08.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Finished task 188.0 in stage 7.0 (TID 791). 5829 bytes result sent to driver
[2025-07-19T20:31:08.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 196.0 in stage 7.0 (TID 799) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Finished task 189.0 in stage 7.0 (TID 792) in 80 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:31:08.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO TaskSetManager: Starting task 197.0 in stage 7.0 (TID 800) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO Executor: Running task 197.0 in stage 7.0 (TID 800)
[2025-07-19T20:31:08.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:07 INFO DataWritingSparkTask: Committed partition 190 (task 793, attempt 0, stage 7.0)
[2025-07-19T20:31:08.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 190.0 in stage 7.0 (TID 793). 5872 bytes result sent to driver
[2025-07-19T20:31:08.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 198.0 in stage 7.0 (TID 801) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 198.0 in stage 7.0 (TID 801)
[2025-07-19T20:31:08.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4879d4af
[2025-07-19T20:31:08.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 190.0 in stage 7.0 (TID 793) in 84 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:31:08.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 188.0 in stage 7.0 (TID 791) in 89 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:31:08.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 196.0 in stage 7.0 (TID 799)
[2025-07-19T20:31:08.011+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.2.delta.ba881bed-1dd6-4380-958a-9d9932605404.TID795.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/2.delta
[2025-07-19T20:31:08.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/192/2.delta
[2025-07-19T20:31:08.012+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.2.delta.f070bef1-d409-40b0-b883-ac4badc209d3.TID796.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/2.delta
[2025-07-19T20:31:08.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/193/2.delta
[2025-07-19T20:31:08.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T20:31:08.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T20:31:08.018+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:08.019+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197] for update
[2025-07-19T20:31:08.019+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.019+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@614c8a41
[2025-07-19T20:31:08.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:08.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196] for update
[2025-07-19T20:31:08.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 192 (task 795, attempt 0, stage 7.0)
[2025-07-19T20:31:08.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 192.0 in stage 7.0 (TID 795). 5829 bytes result sent to driver
[2025-07-19T20:31:08.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 199.0 in stage 7.0 (TID 802) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.2.delta.a657f88f-ce0b-4e1f-b8bc-445a9ba95f7d.TID794.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/2.delta
[2025-07-19T20:31:08.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 192.0 in stage 7.0 (TID 795) in 87 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:31:08.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/191/2.delta
[2025-07-19T20:31:08.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T20:31:08.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.2.delta.fd919c5c-6b71-4c55-8960-b036a209bafe.TID800.tmp
[2025-07-19T20:31:08.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.2.delta.5d2b55f8-825f-4937-83ce-3080695e6861.TID798.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/2.delta
[2025-07-19T20:31:08.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/195/2.delta
[2025-07-19T20:31:08.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T20:31:08.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.2.delta.20ce8fa4-3481-4053-b2a8-f9aa2d837b95.TID797.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/2.delta
[2025-07-19T20:31:08.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/194/2.delta
[2025-07-19T20:31:08.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 193 (task 796, attempt 0, stage 7.0)
[2025-07-19T20:31:08.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 193.0 in stage 7.0 (TID 796). 5829 bytes result sent to driver
[2025-07-19T20:31:08.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 803) (8b44f3d35cfa, executor driver, partition 0, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 193.0 in stage 7.0 (TID 796) in 79 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:31:08.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@462ef9a
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 0.0 in stage 9.0 (TID 803)
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 191 (task 794, attempt 0, stage 7.0)
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198] for update
[2025-07-19T20:31:08.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 191.0 in stage 7.0 (TID 794). 5872 bytes result sent to driver
[2025-07-19T20:31:08.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 195 (task 798, attempt 0, stage 7.0)
[2025-07-19T20:31:08.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 194 (task 797, attempt 0, stage 7.0)
[2025-07-19T20:31:08.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 195.0 in stage 7.0 (TID 798). 5829 bytes result sent to driver
[2025-07-19T20:31:08.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 194.0 in stage 7.0 (TID 797). 5829 bytes result sent to driver
[2025-07-19T20:31:08.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 199.0 in stage 7.0 (TID 802)
[2025-07-19T20:31:08.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.2.delta.5f9375a9-bd60-425c-a9eb-db431148ffa4.TID801.tmp
[2025-07-19T20:31:08.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 804) (8b44f3d35cfa, executor driver, partition 1, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 805) (8b44f3d35cfa, executor driver, partition 2, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 806) (8b44f3d35cfa, executor driver, partition 3, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 2.0 in stage 9.0 (TID 805)
[2025-07-19T20:31:08.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 195.0 in stage 7.0 (TID 798) in 68 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:31:08.038+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 3.0 in stage 9.0 (TID 806)
[2025-07-19T20:31:08.038+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 191.0 in stage 7.0 (TID 794) in 104 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:31:08.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 194.0 in stage 7.0 (TID 797) in 74 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:31:08.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 1.0 in stage 9.0 (TID 804)
[2025-07-19T20:31:08.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17beb533
[2025-07-19T20:31:08.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.045+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],0211514f-45c6-4006-a76e-be2d80eeafa5) is active
[2025-07-19T20:31:08.046+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199] for update
[2025-07-19T20:31:08.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@509b4ab8
[2025-07-19T20:31:08.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=0, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.2.delta.1a85e130-89f9-4ec2-8433-6c268a9b6987.TID799.tmp
[2025-07-19T20:31:08.047+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0] for update
[2025-07-19T20:31:08.048+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2063bd44
[2025-07-19T20:31:08.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=1, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=1),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1] for update
[2025-07-19T20:31:08.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.2.delta.fd919c5c-6b71-4c55-8960-b036a209bafe.TID800.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/2.delta
[2025-07-19T20:31:08.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/197/2.delta
[2025-07-19T20:31:08.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T20:31:08.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fe2ceab
[2025-07-19T20:31:08.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=3, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=3),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3] for update
[2025-07-19T20:31:08.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 197 (task 800, attempt 0, stage 7.0)
[2025-07-19T20:31:08.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 197.0 in stage 7.0 (TID 800). 5872 bytes result sent to driver
[2025-07-19T20:31:08.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodeGenerator: Code generated in 7.78425 ms
[2025-07-19T20:31:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 807) (8b44f3d35cfa, executor driver, partition 4, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 197.0 in stage 7.0 (TID 800) in 62 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:31:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 4.0 in stage 9.0 (TID 807)
[2025-07-19T20:31:08.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.2.delta.31fa070e-bbc6-4d38-b9d9-502fc79cbc1f.TID802.tmp
[2025-07-19T20:31:08.066+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:08.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f072741
[2025-07-19T20:31:08.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=2, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=2),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2] for update
[2025-07-19T20:31:08.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17ec3269
[2025-07-19T20:31:08.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=4, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=4),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4] for update
[2025-07-19T20:31:08.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.2.delta.5f9375a9-bd60-425c-a9eb-db431148ffa4.TID801.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/2.delta
[2025-07-19T20:31:08.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/198/2.delta
[2025-07-19T20:31:08.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.2.delta.39143ea5-9572-4fe5-99f7-d8fb7a287887.TID806.tmp
[2025-07-19T20:31:08.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T20:31:08.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.2.delta.f1e0ad21-a2b9-4ff7-a8b6-6bb1a906223d.TID804.tmp
[2025-07-19T20:31:08.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.2.delta.42632ebf-f32d-45dc-8635-b7578ab39ffd.TID803.tmp
[2025-07-19T20:31:08.091+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 198 (task 801, attempt 0, stage 7.0)
[2025-07-19T20:31:08.092+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 198.0 in stage 7.0 (TID 801). 5872 bytes result sent to driver
[2025-07-19T20:31:08.092+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 808) (8b44f3d35cfa, executor driver, partition 5, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 5.0 in stage 9.0 (TID 808)
[2025-07-19T20:31:08.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 198.0 in stage 7.0 (TID 801) in 86 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:31:08.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.2.delta.66ba6f05-78ea-4f8a-8083-b02055c49beb.TID807.tmp
[2025-07-19T20:31:08.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.2.delta.2efb8a70-26bf-4f40-8064-7a9bc54cb002.TID805.tmp
[2025-07-19T20:31:08.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@363c0c9
[2025-07-19T20:31:08.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=5, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=5),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5] for update
[2025-07-19T20:31:08.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.112+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.2.delta.1a85e130-89f9-4ec2-8433-6c268a9b6987.TID799.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/2.delta
[2025-07-19T20:31:08.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/196/2.delta
[2025-07-19T20:31:08.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T20:31:08.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.2.delta.d806d8f7-ebd8-4c6e-8198-32f1b41a31df.TID808.tmp
[2025-07-19T20:31:08.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 196 (task 799, attempt 0, stage 7.0)
[2025-07-19T20:31:08.118+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 196.0 in stage 7.0 (TID 799). 5872 bytes result sent to driver
[2025-07-19T20:31:08.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 809) (8b44f3d35cfa, executor driver, partition 6, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 6.0 in stage 9.0 (TID 809)
[2025-07-19T20:31:08.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 196.0 in stage 7.0 (TID 799) in 121 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:31:08.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.2.delta.31fa070e-bbc6-4d38-b9d9-502fc79cbc1f.TID802.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/2.delta
[2025-07-19T20:31:08.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/state/0/199/2.delta
[2025-07-19T20:31:08.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T20:31:08.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/.2.delta.39143ea5-9572-4fe5-99f7-d8fb7a287887.TID806.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/2.delta
[2025-07-19T20:31:08.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/3/2.delta
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61882883
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=6, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=6),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6] for update
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 3 (task 806, attempt 0, stage 9.0)
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 3.0 in stage 9.0 (TID 806). 5872 bytes result sent to driver
[2025-07-19T20:31:08.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 199 (task 802, attempt 0, stage 7.0)
[2025-07-19T20:31:08.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 810) (8b44f3d35cfa, executor driver, partition 7, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 806) in 94 ms on 8b44f3d35cfa (executor driver) (1/200)
[2025-07-19T20:31:08.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/.2.delta.42632ebf-f32d-45dc-8635-b7578ab39ffd.TID803.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/2.delta
[2025-07-19T20:31:08.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/0/2.delta
[2025-07-19T20:31:08.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 199.0 in stage 7.0 (TID 802). 5872 bytes result sent to driver
[2025-07-19T20:31:08.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 7.0 in stage 9.0 (TID 810)
[2025-07-19T20:31:08.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 199.0 in stage 7.0 (TID 802) in 113 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:31:08.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-07-19T20:31:08.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DAGScheduler: ResultStage 7 (start at <unknown>:0) finished in 7.892 s
[2025-07-19T20:31:08.142+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 8.0 in stage 9.0 (TID 811) (8b44f3d35cfa, executor driver, partition 8, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:31:08.145+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-07-19T20:31:08.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 8.0 in stage 9.0 (TID 811)
[2025-07-19T20:31:08.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T20:31:08.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32413321
[2025-07-19T20:31:08.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=7, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.150+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=7),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7] for update
[2025-07-19T20:31:08.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DAGScheduler: Job 3 finished: start at <unknown>:0, took 7.979689 s
[2025-07-19T20:31:08.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] is committing.
[2025-07-19T20:31:08.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO SparkWrite: Committing epoch 1 for query 1436cd49-bf2f-4720-8c9f-d251355ec5cf in append mode
[2025-07-19T20:31:08.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.152+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:08.152+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47e3e99c
[2025-07-19T20:31:08.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=8, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=8),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8] for update
[2025-07-19T20:31:08.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 0 (task 803, attempt 0, stage 9.0)
[2025-07-19T20:31:08.156+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/.2.delta.2efb8a70-26bf-4f40-8064-7a9bc54cb002.TID805.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/2.delta
[2025-07-19T20:31:08.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/2/2.delta
[2025-07-19T20:31:08.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 0.0 in stage 9.0 (TID 803). 5872 bytes result sent to driver
[2025-07-19T20:31:08.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 9.0 in stage 9.0 (TID 812) (8b44f3d35cfa, executor driver, partition 9, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T20:31:08.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/.2.delta.66ba6f05-78ea-4f8a-8083-b02055c49beb.TID807.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/2.delta
[2025-07-19T20:31:08.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/4/2.delta
[2025-07-19T20:31:08.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/.2.delta.f1e0ad21-a2b9-4ff7-a8b6-6bb1a906223d.TID804.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/2.delta
[2025-07-19T20:31:08.159+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/1/2.delta
[2025-07-19T20:31:08.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T20:31:08.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T20:31:08.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.2.delta.8441a111-4fa5-4fdc-8dbe-adcadaefaf0c.TID809.tmp
[2025-07-19T20:31:08.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 803) in 120 ms on 8b44f3d35cfa (executor driver) (2/200)
[2025-07-19T20:31:08.161+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 9.0 in stage 9.0 (TID 812)
[2025-07-19T20:31:08.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 4 (task 807, attempt 0, stage 9.0)
[2025-07-19T20:31:08.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 4.0 in stage 9.0 (TID 807). 5829 bytes result sent to driver
[2025-07-19T20:31:08.162+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 10.0 in stage 9.0 (TID 813) (8b44f3d35cfa, executor driver, partition 10, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 10.0 in stage 9.0 (TID 813)
[2025-07-19T20:31:08.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.2.delta.532f2822-0053-456b-8cd9-05eb113568a7.TID811.tmp
[2025-07-19T20:31:08.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 2 (task 805, attempt 0, stage 9.0)
[2025-07-19T20:31:08.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 807) in 90 ms on 8b44f3d35cfa (executor driver) (3/200)
[2025-07-19T20:31:08.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.2.delta.8baa59a3-39cb-419a-8cd1-1107f5543c2b.TID810.tmp
[2025-07-19T20:31:08.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 1 (task 804, attempt 0, stage 9.0)
[2025-07-19T20:31:08.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 2.0 in stage 9.0 (TID 805). 5872 bytes result sent to driver
[2025-07-19T20:31:08.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 1.0 in stage 9.0 (TID 804). 5872 bytes result sent to driver
[2025-07-19T20:31:08.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2b1979d5
[2025-07-19T20:31:08.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:08.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 11.0 in stage 9.0 (TID 814) (8b44f3d35cfa, executor driver, partition 11, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 11.0 in stage 9.0 (TID 814)
[2025-07-19T20:31:08.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 805) in 121 ms on 8b44f3d35cfa (executor driver) (4/200)
[2025-07-19T20:31:08.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 804) in 122 ms on 8b44f3d35cfa (executor driver) (5/200)
[2025-07-19T20:31:08.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 12.0 in stage 9.0 (TID 815) (8b44f3d35cfa, executor driver, partition 12, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 12.0 in stage 9.0 (TID 815)
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=10, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=10),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10] for update
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4f897d85
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Checkins_raw
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/.2.delta.d806d8f7-ebd8-4c6e-8198-32f1b41a31df.TID808.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/2.delta
[2025-07-19T20:31:08.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/5/2.delta
[2025-07-19T20:31:08.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T20:31:08.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=11, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:08.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=11),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11] for update
[2025-07-19T20:31:08.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c6939a9
[2025-07-19T20:31:08.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=12, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=12),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12] for update
[2025-07-19T20:31:08.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2178cdce
[2025-07-19T20:31:08.175+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 5 (task 808, attempt 0, stage 9.0)
[2025-07-19T20:31:08.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 5.0 in stage 9.0 (TID 808). 5829 bytes result sent to driver
[2025-07-19T20:31:08.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=9, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=9),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9] for update
[2025-07-19T20:31:08.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 13.0 in stage 9.0 (TID 816) (8b44f3d35cfa, executor driver, partition 13, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 13.0 in stage 9.0 (TID 816)
[2025-07-19T20:31:08.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 808) in 87 ms on 8b44f3d35cfa (executor driver) (6/200)
[2025-07-19T20:31:08.181+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.182+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.2.delta.bee747a4-8dec-4556-a43e-ae8259c33ccc.TID813.tmp
[2025-07-19T20:31:08.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32b6a140
[2025-07-19T20:31:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=13, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=13),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13] for update
[2025-07-19T20:31:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/.2.delta.8441a111-4fa5-4fdc-8dbe-adcadaefaf0c.TID809.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/2.delta
[2025-07-19T20:31:08.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/6/2.delta
[2025-07-19T20:31:08.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T20:31:08.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.2.delta.83f529fb-9055-46cd-9197-d4bae2f34d8a.TID814.tmp
[2025-07-19T20:31:08.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.2.delta.f5de322d-9d2b-441c-b512-9679210f0345.TID815.tmp
[2025-07-19T20:31:08.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.2.delta.68bc1847-26d6-403e-a31f-9690013ade1b.TID816.tmp
[2025-07-19T20:31:08.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/.2.delta.532f2822-0053-456b-8cd9-05eb113568a7.TID811.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/2.delta
[2025-07-19T20:31:08.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/8/2.delta
[2025-07-19T20:31:08.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T20:31:08.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.2.delta.85f12bcf-fc23-4c63-8259-ad66e54385b7.TID812.tmp
[2025-07-19T20:31:08.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 6 (task 809, attempt 0, stage 9.0)
[2025-07-19T20:31:08.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 6.0 in stage 9.0 (TID 809). 5872 bytes result sent to driver
[2025-07-19T20:31:08.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 14.0 in stage 9.0 (TID 817) (8b44f3d35cfa, executor driver, partition 14, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 809) in 92 ms on 8b44f3d35cfa (executor driver) (7/200)
[2025-07-19T20:31:08.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 14.0 in stage 9.0 (TID 817)
[2025-07-19T20:31:08.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 8 (task 811, attempt 0, stage 9.0)
[2025-07-19T20:31:08.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 8.0 in stage 9.0 (TID 811). 5872 bytes result sent to driver
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 15.0 in stage 9.0 (TID 818) (8b44f3d35cfa, executor driver, partition 15, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 15.0 in stage 9.0 (TID 818)
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 8.0 in stage 9.0 (TID 811) in 86 ms on 8b44f3d35cfa (executor driver) (8/200)
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@198ad3bf
[2025-07-19T20:31:08.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=14, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=14),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14] for update
[2025-07-19T20:31:08.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2235512f
[2025-07-19T20:31:08.223+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=15, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=15),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15] for update
[2025-07-19T20:31:08.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/.2.delta.8baa59a3-39cb-419a-8cd1-1107f5543c2b.TID810.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/2.delta
[2025-07-19T20:31:08.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/7/2.delta
[2025-07-19T20:31:08.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T20:31:08.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.2.delta.36fd34ca-02fd-4fa8-926e-2a1b8db98092.TID818.tmp
[2025-07-19T20:31:08.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 7 (task 810, attempt 0, stage 9.0)
[2025-07-19T20:31:08.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.2.delta.3b1043c2-15b3-4424-85c4-899866c62871.TID817.tmp
[2025-07-19T20:31:08.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 7.0 in stage 9.0 (TID 810). 5872 bytes result sent to driver
[2025-07-19T20:31:08.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 810) in 128 ms on 8b44f3d35cfa (executor driver) (9/200)
[2025-07-19T20:31:08.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 16.0 in stage 9.0 (TID 819) (8b44f3d35cfa, executor driver, partition 16, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 16.0 in stage 9.0 (TID 819)
[2025-07-19T20:31:08.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@14cc4da2
[2025-07-19T20:31:08.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=16, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=16),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16] for update
[2025-07-19T20:31:08.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/.2.delta.83f529fb-9055-46cd-9197-d4bae2f34d8a.TID814.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/2.delta
[2025-07-19T20:31:08.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/11/2.delta
[2025-07-19T20:31:08.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T20:31:08.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 11 (task 814, attempt 0, stage 9.0)
[2025-07-19T20:31:08.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 11.0 in stage 9.0 (TID 814). 5872 bytes result sent to driver
[2025-07-19T20:31:08.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 17.0 in stage 9.0 (TID 820) (8b44f3d35cfa, executor driver, partition 17, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 11.0 in stage 9.0 (TID 814) in 126 ms on 8b44f3d35cfa (executor driver) (10/200)
[2025-07-19T20:31:08.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/.2.delta.f5de322d-9d2b-441c-b512-9679210f0345.TID815.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/2.delta
[2025-07-19T20:31:08.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/12/2.delta
[2025-07-19T20:31:08.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 17.0 in stage 9.0 (TID 820)
[2025-07-19T20:31:08.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T20:31:08.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/.2.delta.bee747a4-8dec-4556-a43e-ae8259c33ccc.TID813.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/2.delta
[2025-07-19T20:31:08.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/10/2.delta
[2025-07-19T20:31:08.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T20:31:08.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5a1d90eb
[2025-07-19T20:31:08.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=17, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=17),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17] for update
[2025-07-19T20:31:08.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 12 (task 815, attempt 0, stage 9.0)
[2025-07-19T20:31:08.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 12.0 in stage 9.0 (TID 815). 5872 bytes result sent to driver
[2025-07-19T20:31:08.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 18.0 in stage 9.0 (TID 821) (8b44f3d35cfa, executor driver, partition 18, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 12.0 in stage 9.0 (TID 815) in 144 ms on 8b44f3d35cfa (executor driver) (11/200)
[2025-07-19T20:31:08.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.2.delta.e3751ba3-87c2-4e1b-979d-eb764360f41b.TID819.tmp
[2025-07-19T20:31:08.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 8b44f3d35cfa:36593 in memory (size: 19.7 KiB, free: 434.1 MiB)
[2025-07-19T20:31:08.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 18.0 in stage 9.0 (TID 821)
[2025-07-19T20:31:08.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/.2.delta.68bc1847-26d6-403e-a31f-9690013ade1b.TID816.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/2.delta
[2025-07-19T20:31:08.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 10 (task 813, attempt 0, stage 9.0)
[2025-07-19T20:31:08.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/13/2.delta
[2025-07-19T20:31:08.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T20:31:08.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 10.0 in stage 9.0 (TID 813). 5872 bytes result sent to driver
[2025-07-19T20:31:08.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 19.0 in stage 9.0 (TID 822) (8b44f3d35cfa, executor driver, partition 19, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 10.0 in stage 9.0 (TID 813) in 162 ms on 8b44f3d35cfa (executor driver) (12/200)
[2025-07-19T20:31:08.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 19.0 in stage 9.0 (TID 822)
[2025-07-19T20:31:08.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Checkins_raw/metadata/v111.metadata.json
[2025-07-19T20:31:08.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@9d6988e
[2025-07-19T20:31:08.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 13 (task 816, attempt 0, stage 9.0)
[2025-07-19T20:31:08.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=19, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=19),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19] for update
[2025-07-19T20:31:08.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 13.0 in stage 9.0 (TID 816). 5872 bytes result sent to driver
[2025-07-19T20:31:08.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:08.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 20.0 in stage 9.0 (TID 823) (8b44f3d35cfa, executor driver, partition 20, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 13.0 in stage 9.0 (TID 816) in 149 ms on 8b44f3d35cfa (executor driver) (13/200)
[2025-07-19T20:31:08.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 20.0 in stage 9.0 (TID 823)
[2025-07-19T20:31:08.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5f59738e
[2025-07-19T20:31:08.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=18, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=18),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18] for update
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/.2.delta.85f12bcf-fc23-4c63-8259-ad66e54385b7.TID812.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/2.delta
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/9/2.delta
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47738f8
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=20, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=20),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20] for update
[2025-07-19T20:31:08.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T20:31:08.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 8b44f3d35cfa:36593 in memory (size: 29.5 KiB, free: 434.1 MiB)
[2025-07-19T20:31:08.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 9 (task 812, attempt 0, stage 9.0)
[2025-07-19T20:31:08.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/.2.delta.36fd34ca-02fd-4fa8-926e-2a1b8db98092.TID818.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/2.delta
[2025-07-19T20:31:08.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/15/2.delta
[2025-07-19T20:31:08.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T20:31:08.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.2.delta.5ff49a71-6408-4b55-a950-33f85c7ff38a.TID820.tmp
[2025-07-19T20:31:08.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 9.0 in stage 9.0 (TID 812). 5872 bytes result sent to driver
[2025-07-19T20:31:08.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 21.0 in stage 9.0 (TID 824) (8b44f3d35cfa, executor driver, partition 21, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 21.0 in stage 9.0 (TID 824)
[2025-07-19T20:31:08.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 15 (task 818, attempt 0, stage 9.0)
[2025-07-19T20:31:08.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 15.0 in stage 9.0 (TID 818). 5829 bytes result sent to driver
[2025-07-19T20:31:08.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 9.0 in stage 9.0 (TID 812) in 200 ms on 8b44f3d35cfa (executor driver) (14/200)
[2025-07-19T20:31:08.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 22.0 in stage 9.0 (TID 825) (8b44f3d35cfa, executor driver, partition 22, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.2.delta.227d4b72-7c93-41d4-86d0-979be7044d31.TID823.tmp
[2025-07-19T20:31:08.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 15.0 in stage 9.0 (TID 818) in 128 ms on 8b44f3d35cfa (executor driver) (15/200)
[2025-07-19T20:31:08.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 22.0 in stage 9.0 (TID 825)
[2025-07-19T20:31:08.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.2.delta.2a2e8404-1f37-47e7-b5f4-fd8f9692ec1c.TID821.tmp
[2025-07-19T20:31:08.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.2.delta.9a1c33cc-ac72-44d6-b222-1dcef5721a4c.TID822.tmp
[2025-07-19T20:31:08.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.353+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@587227ef
[2025-07-19T20:31:08.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=21, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=21),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21] for update
[2025-07-19T20:31:08.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40ba12ea
[2025-07-19T20:31:08.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=22, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=22),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22] for update
[2025-07-19T20:31:08.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/.2.delta.3b1043c2-15b3-4424-85c4-899866c62871.TID817.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/2.delta
[2025-07-19T20:31:08.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/14/2.delta
[2025-07-19T20:31:08.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T20:31:08.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8b44f3d35cfa:36593 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T20:31:08.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 14 (task 817, attempt 0, stage 9.0)
[2025-07-19T20:31:08.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 14.0 in stage 9.0 (TID 817). 5829 bytes result sent to driver
[2025-07-19T20:31:08.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 23.0 in stage 9.0 (TID 826) (8b44f3d35cfa, executor driver, partition 23, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 23.0 in stage 9.0 (TID 826)
[2025-07-19T20:31:08.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 14.0 in stage 9.0 (TID 817) in 160 ms on 8b44f3d35cfa (executor driver) (16/200)
[2025-07-19T20:31:08.373+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.374+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ef427c5
[2025-07-19T20:31:08.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=23, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=23),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23] for update
[2025-07-19T20:31:08.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.377+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8b44f3d35cfa:36593 in memory (size: 35.4 KiB, free: 434.2 MiB)
[2025-07-19T20:31:08.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.2.delta.21c1df46-3982-48e8-9fb9-ac2247b61ebc.TID825.tmp
[2025-07-19T20:31:08.378+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO SnapshotProducer: Committed snapshot 239488118117226385 (FastAppend)
[2025-07-19T20:31:08.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.2.delta.c3c72dbf-617c-43b9-9c86-99c1166ec526.TID824.tmp
[2025-07-19T20:31:08.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/.2.delta.e3751ba3-87c2-4e1b-979d-eb764360f41b.TID819.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/2.delta
[2025-07-19T20:31:08.389+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/16/2.delta
[2025-07-19T20:31:08.389+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T20:31:08.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 8b44f3d35cfa:36593 in memory (size: 19.3 KiB, free: 434.2 MiB)
[2025-07-19T20:31:08.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.2.delta.a31811c1-2827-4b0b-8ae2-2a67810b10a9.TID826.tmp
[2025-07-19T20:31:08.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 16 (task 819, attempt 0, stage 9.0)
[2025-07-19T20:31:08.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 16.0 in stage 9.0 (TID 819). 5829 bytes result sent to driver
[2025-07-19T20:31:08.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 24.0 in stage 9.0 (TID 827) (8b44f3d35cfa, executor driver, partition 24, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 24.0 in stage 9.0 (TID 827)
[2025-07-19T20:31:08.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 16.0 in stage 9.0 (TID 819) in 140 ms on 8b44f3d35cfa (executor driver) (17/200)
[2025-07-19T20:31:08.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@507fb116
[2025-07-19T20:31:08.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=24, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=24),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24] for update
[2025-07-19T20:31:08.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 8b44f3d35cfa:36593 in memory (size: 29.5 KiB, free: 434.2 MiB)
[2025-07-19T20:31:08.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/.2.delta.5ff49a71-6408-4b55-a950-33f85c7ff38a.TID820.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/2.delta
[2025-07-19T20:31:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/17/2.delta
[2025-07-19T20:31:08.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T20:31:08.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 17 (task 820, attempt 0, stage 9.0)
[2025-07-19T20:31:08.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 17.0 in stage 9.0 (TID 820). 5829 bytes result sent to driver
[2025-07-19T20:31:08.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/.2.delta.2a2e8404-1f37-47e7-b5f4-fd8f9692ec1c.TID821.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/2.delta
[2025-07-19T20:31:08.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/18/2.delta
[2025-07-19T20:31:08.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T20:31:08.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 25.0 in stage 9.0 (TID 828) (8b44f3d35cfa, executor driver, partition 25, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 25.0 in stage 9.0 (TID 828)
[2025-07-19T20:31:08.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 17.0 in stage 9.0 (TID 820) in 136 ms on 8b44f3d35cfa (executor driver) (18/200)
[2025-07-19T20:31:08.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/.2.delta.9a1c33cc-ac72-44d6-b222-1dcef5721a4c.TID822.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/2.delta
[2025-07-19T20:31:08.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/19/2.delta
[2025-07-19T20:31:08.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/.2.delta.227d4b72-7c93-41d4-86d0-979be7044d31.TID823.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/2.delta
[2025-07-19T20:31:08.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/20/2.delta
[2025-07-19T20:31:08.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T20:31:08.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T20:31:08.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.2.delta.422764b7-b733-419c-a4ea-f9dcde6cd0b2.TID827.tmp
[2025-07-19T20:31:08.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 8b44f3d35cfa:36593 in memory (size: 15.9 KiB, free: 434.3 MiB)
[2025-07-19T20:31:08.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 19 (task 822, attempt 0, stage 9.0)
[2025-07-19T20:31:08.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 20 (task 823, attempt 0, stage 9.0)
[2025-07-19T20:31:08.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 19.0 in stage 9.0 (TID 822). 5829 bytes result sent to driver
[2025-07-19T20:31:08.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 20.0 in stage 9.0 (TID 823). 5829 bytes result sent to driver
[2025-07-19T20:31:08.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 26.0 in stage 9.0 (TID 829) (8b44f3d35cfa, executor driver, partition 26, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 27.0 in stage 9.0 (TID 830) (8b44f3d35cfa, executor driver, partition 27, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Checkins_raw, snapshotId=239488118117226385, sequenceNumber=110, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.261853625S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5047}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=6930}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=16331514}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752957046551, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:31:08.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO SparkWrite: Committed in 262 ms
[2025-07-19T20:31:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Checkins_raw, format=PARQUET)] committed.
[2025-07-19T20:31:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 27.0 in stage 9.0 (TID 830)
[2025-07-19T20:31:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 20.0 in stage 9.0 (TID 823) in 108 ms on 8b44f3d35cfa (executor driver) (19/200)
[2025-07-19T20:31:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 18 (task 821, attempt 0, stage 9.0)
[2025-07-19T20:31:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 19.0 in stage 9.0 (TID 822) in 114 ms on 8b44f3d35cfa (executor driver) (20/200)
[2025-07-19T20:31:08.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 18.0 in stage 9.0 (TID 821). 5829 bytes result sent to driver
[2025-07-19T20:31:08.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 26.0 in stage 9.0 (TID 829)
[2025-07-19T20:31:08.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 28.0 in stage 9.0 (TID 831) (8b44f3d35cfa, executor driver, partition 28, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@57351348
[2025-07-19T20:31:08.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 28.0 in stage 9.0 (TID 831)
[2025-07-19T20:31:08.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 18.0 in stage 9.0 (TID 821) in 138 ms on 8b44f3d35cfa (executor driver) (21/200)
[2025-07-19T20:31:08.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=25, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=25),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25] for update
[2025-07-19T20:31:08.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:08.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42ed17b0
[2025-07-19T20:31:08.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=28, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=28),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28] for update
[2025-07-19T20:31:08.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/.2.delta.c3c72dbf-617c-43b9-9c86-99c1166ec526.TID824.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/2.delta
[2025-07-19T20:31:08.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/21/2.delta
[2025-07-19T20:31:08.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.437+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/1 using temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/.1.91b231ce-899f-4a54-9c39-ddce4a4c3cdf.tmp
[2025-07-19T20:31:08.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T20:31:08.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@768da7b8
[2025-07-19T20:31:08.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=26, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=26),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26] for update
[2025-07-19T20:31:08.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.445+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 21 (task 824, attempt 0, stage 9.0)
[2025-07-19T20:31:08.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53fa6f86
[2025-07-19T20:31:08.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=27, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=27),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27] for update
[2025-07-19T20:31:08.448+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 21.0 in stage 9.0 (TID 824). 5829 bytes result sent to driver
[2025-07-19T20:31:08.448+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/.2.delta.21c1df46-3982-48e8-9fb9-ac2247b61ebc.TID825.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/2.delta
[2025-07-19T20:31:08.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/22/2.delta
[2025-07-19T20:31:08.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 29.0 in stage 9.0 (TID 832) (8b44f3d35cfa, executor driver, partition 29, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T20:31:08.451+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 21.0 in stage 9.0 (TID 824) in 110 ms on 8b44f3d35cfa (executor driver) (22/200)
[2025-07-19T20:31:08.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/.2.delta.a31811c1-2827-4b0b-8ae2-2a67810b10a9.TID826.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/2.delta
[2025-07-19T20:31:08.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/23/2.delta
[2025-07-19T20:31:08.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 29.0 in stage 9.0 (TID 832)
[2025-07-19T20:31:08.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 22 (task 825, attempt 0, stage 9.0)
[2025-07-19T20:31:08.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 22.0 in stage 9.0 (TID 825). 5829 bytes result sent to driver
[2025-07-19T20:31:08.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 30.0 in stage 9.0 (TID 833) (8b44f3d35cfa, executor driver, partition 30, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T20:31:08.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 30.0 in stage 9.0 (TID 833)
[2025-07-19T20:31:08.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 22.0 in stage 9.0 (TID 825) in 109 ms on 8b44f3d35cfa (executor driver) (23/200)
[2025-07-19T20:31:08.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.462+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 23 (task 826, attempt 0, stage 9.0)
[2025-07-19T20:31:08.463+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65ea9798
[2025-07-19T20:31:08.464+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 23.0 in stage 9.0 (TID 826). 5829 bytes result sent to driver
[2025-07-19T20:31:08.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=30, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=30),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30] for update
[2025-07-19T20:31:08.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 31.0 in stage 9.0 (TID 834) (8b44f3d35cfa, executor driver, partition 31, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.467+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 23.0 in stage 9.0 (TID 826) in 88 ms on 8b44f3d35cfa (executor driver) (24/200)
[2025-07-19T20:31:08.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:08.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 31.0 in stage 9.0 (TID 834)
[2025-07-19T20:31:08.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@187c3722
[2025-07-19T20:31:08.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=29, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=29),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29] for update
[2025-07-19T20:31:08.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@444aae02
[2025-07-19T20:31:08.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.2.delta.cbbcb99e-d4d9-47f0-9fd0-5dee0771c640.TID828.tmp
[2025-07-19T20:31:08.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=31, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=31),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31] for update
[2025-07-19T20:31:08.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.2.delta.68466ab4-1bb2-4783-a720-30b2199fc3c3.TID831.tmp
[2025-07-19T20:31:08.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.2.delta.647b8c21-850a-4797-b2d7-a2dd2bcdbe94.TID829.tmp
[2025-07-19T20:31:08.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.2.delta.883e74c2-40db-49ae-9117-7b55eb9bd13c.TID830.tmp
[2025-07-19T20:31:08.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.2.delta.779453c9-0d28-471b-ad00-fa0dbe475d44.TID833.tmp
[2025-07-19T20:31:08.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.2.delta.9fd5f48b-2ba7-4009-9964-9662f889ee78.TID832.tmp
[2025-07-19T20:31:08.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/.1.91b231ce-899f-4a54-9c39-ddce4a4c3cdf.tmp to file:/tmp/checkpoints/checkins/scheduled__2025-07-19T20:28:00+00:00/commits/1
[2025-07-19T20:31:08.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.2.delta.1e6d9f02-c282-4f69-bd17-45371233d17b.TID834.tmp
[2025-07-19T20:31:08.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:31:08.485+0000] {subprocess.py:93} INFO -   "id" : "1436cd49-bf2f-4720-8c9f-d251355ec5cf",
[2025-07-19T20:31:08.485+0000] {subprocess.py:93} INFO -   "runId" : "0211514f-45c6-4006-a76e-be2d80eeafa5",
[2025-07-19T20:31:08.486+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:31:08.486+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:30:59.703Z",
[2025-07-19T20:31:08.486+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T20:31:08.487+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T20:31:08.488+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:08.490+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T20:31:08.491+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:31:08.491+0000] {subprocess.py:93} INFO -     "addBatch" : 8453,
[2025-07-19T20:31:08.492+0000] {subprocess.py:93} INFO -     "commitOffsets" : 57,
[2025-07-19T20:31:08.492+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T20:31:08.494+0000] {subprocess.py:93} INFO -     "latestOffset" : 21,
[2025-07-19T20:31:08.494+0000] {subprocess.py:93} INFO -     "queryPlanning" : 130,
[2025-07-19T20:31:08.495+0000] {subprocess.py:93} INFO -     "triggerExecution" : 8777,
[2025-07-19T20:31:08.495+0000] {subprocess.py:93} INFO -     "walCommit" : 90
[2025-07-19T20:31:08.496+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:08.498+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:31:08.499+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T20:11:00.000Z"
[2025-07-19T20:31:08.500+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:08.500+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:31:08.500+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:31:08.501+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 207,
[2025-07-19T20:31:08.501+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T20:31:08.502+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 318,
[2025-07-19T20:31:08.504+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:31:08.506+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 83,
[2025-07-19T20:31:08.507+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 16059,
[2025-07-19T20:31:08.509+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 141800,
[2025-07-19T20:31:08.509+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:31:08.509+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:31:08.510+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:31:08.510+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:31:08.510+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T20:31:08.511+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:31:08.512+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:31:08.513+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 63976
[2025-07-19T20:31:08.513+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:08.513+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:08.514+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:31:08.514+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[checkins]]",
[2025-07-19T20:31:08.518+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T20:31:08.520+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:31:08.522+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:08.522+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:08.525+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:08.528+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:31:08.530+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:31:08.532+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:08.532+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:08.533+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:08.533+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:31:08.534+0000] {subprocess.py:93} INFO -       "checkins" : {
[2025-07-19T20:31:08.534+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:08.535+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:08.537+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:08.539+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T20:31:08.542+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:08.543+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T20:31:08.549+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:31:08.550+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:31:08.552+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:31:08.554+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:31:08.554+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:08.556+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:08.557+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:31:08.558+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Checkins_raw",
[2025-07-19T20:31:08.560+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T20:31:08.560+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:31:08.561+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:31:08.565+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/.2.delta.422764b7-b733-419c-a4ea-f9dcde6cd0b2.TID827.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/2.delta
[2025-07-19T20:31:08.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/24/2.delta
[2025-07-19T20:31:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T20:31:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 24 (task 827, attempt 0, stage 9.0)
[2025-07-19T20:31:08.570+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 24.0 in stage 9.0 (TID 827). 5829 bytes result sent to driver
[2025-07-19T20:31:08.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 32.0 in stage 9.0 (TID 835) (8b44f3d35cfa, executor driver, partition 32, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 24.0 in stage 9.0 (TID 827) in 99 ms on 8b44f3d35cfa (executor driver) (25/200)
[2025-07-19T20:31:08.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 32.0 in stage 9.0 (TID 835)
[2025-07-19T20:31:08.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.573+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:08.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6dafe81f
[2025-07-19T20:31:08.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=32, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=32),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32] for update
[2025-07-19T20:31:08.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.577+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/.2.delta.cbbcb99e-d4d9-47f0-9fd0-5dee0771c640.TID828.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/2.delta
[2025-07-19T20:31:08.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/25/2.delta
[2025-07-19T20:31:08.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T20:31:08.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 25 (task 828, attempt 0, stage 9.0)
[2025-07-19T20:31:08.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 25.0 in stage 9.0 (TID 828). 5829 bytes result sent to driver
[2025-07-19T20:31:08.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 33.0 in stage 9.0 (TID 836) (8b44f3d35cfa, executor driver, partition 33, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 25.0 in stage 9.0 (TID 828) in 114 ms on 8b44f3d35cfa (executor driver) (26/200)
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 33.0 in stage 9.0 (TID 836)
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c6b94d2
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=33, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.579+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=33),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33] for update
[2025-07-19T20:31:08.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.2.delta.3becc665-33ae-48a5-a1b6-1da0aaaa75a6.TID835.tmp
[2025-07-19T20:31:08.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/.2.delta.68466ab4-1bb2-4783-a720-30b2199fc3c3.TID831.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/2.delta
[2025-07-19T20:31:08.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/28/2.delta
[2025-07-19T20:31:08.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T20:31:08.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/.2.delta.647b8c21-850a-4797-b2d7-a2dd2bcdbe94.TID829.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/2.delta
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 28 (task 831, attempt 0, stage 9.0)
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/26/2.delta
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 28.0 in stage 9.0 (TID 831). 5786 bytes result sent to driver
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 34.0 in stage 9.0 (TID 837) (8b44f3d35cfa, executor driver, partition 34, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 34.0 in stage 9.0 (TID 837)
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 28.0 in stage 9.0 (TID 831) in 129 ms on 8b44f3d35cfa (executor driver) (27/200)
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 26 (task 829, attempt 0, stage 9.0)
[2025-07-19T20:31:08.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 26.0 in stage 9.0 (TID 829). 5829 bytes result sent to driver
[2025-07-19T20:31:08.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.2.delta.6adb82b6-9394-4ed7-9c79-be780bfb4ce5.TID836.tmp
[2025-07-19T20:31:08.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/.2.delta.883e74c2-40db-49ae-9117-7b55eb9bd13c.TID830.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/2.delta
[2025-07-19T20:31:08.584+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/27/2.delta
[2025-07-19T20:31:08.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 35.0 in stage 9.0 (TID 838) (8b44f3d35cfa, executor driver, partition 35, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@65f9d927
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 35.0 in stage 9.0 (TID 838)
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 26.0 in stage 9.0 (TID 829) in 141 ms on 8b44f3d35cfa (executor driver) (28/200)
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=34, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=34),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34] for update
[2025-07-19T20:31:08.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16eef5f3
[2025-07-19T20:31:08.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 27 (task 830, attempt 0, stage 9.0)
[2025-07-19T20:31:08.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=35, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=35),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35] for update
[2025-07-19T20:31:08.589+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 27.0 in stage 9.0 (TID 830). 5829 bytes result sent to driver
[2025-07-19T20:31:08.590+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 36.0 in stage 9.0 (TID 839) (8b44f3d35cfa, executor driver, partition 36, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.591+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.591+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 36.0 in stage 9.0 (TID 839)
[2025-07-19T20:31:08.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/.2.delta.779453c9-0d28-471b-ad00-fa0dbe475d44.TID833.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/2.delta
[2025-07-19T20:31:08.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/30/2.delta
[2025-07-19T20:31:08.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 27.0 in stage 9.0 (TID 830) in 152 ms on 8b44f3d35cfa (executor driver) (29/200)
[2025-07-19T20:31:08.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T20:31:08.595+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@797c0acf
[2025-07-19T20:31:08.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 30 (task 833, attempt 0, stage 9.0)
[2025-07-19T20:31:08.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=36, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=36),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36] for update
[2025-07-19T20:31:08.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 30.0 in stage 9.0 (TID 833). 5829 bytes result sent to driver
[2025-07-19T20:31:08.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 37.0 in stage 9.0 (TID 840) (8b44f3d35cfa, executor driver, partition 37, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/.2.delta.9fd5f48b-2ba7-4009-9964-9662f889ee78.TID832.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/2.delta
[2025-07-19T20:31:08.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/29/2.delta
[2025-07-19T20:31:08.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 37.0 in stage 9.0 (TID 840)
[2025-07-19T20:31:08.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T20:31:08.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/.2.delta.1e6d9f02-c282-4f69-bd17-45371233d17b.TID834.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/2.delta
[2025-07-19T20:31:08.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/31/2.delta
[2025-07-19T20:31:08.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T20:31:08.608+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 30.0 in stage 9.0 (TID 833) in 136 ms on 8b44f3d35cfa (executor driver) (30/200)
[2025-07-19T20:31:08.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4fbce785
[2025-07-19T20:31:08.609+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=37, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=37),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37] for update
[2025-07-19T20:31:08.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 29 (task 832, attempt 0, stage 9.0)
[2025-07-19T20:31:08.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 31 (task 834, attempt 0, stage 9.0)
[2025-07-19T20:31:08.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 29.0 in stage 9.0 (TID 832). 5829 bytes result sent to driver
[2025-07-19T20:31:08.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 31.0 in stage 9.0 (TID 834). 5829 bytes result sent to driver
[2025-07-19T20:31:08.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.2.delta.dd7a4a89-3b7a-41df-b219-faa2010651ac.TID837.tmp
[2025-07-19T20:31:08.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 38.0 in stage 9.0 (TID 841) (8b44f3d35cfa, executor driver, partition 38, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.2.delta.5bcb2b47-5d5e-496c-8b50-4d25f7769014.TID839.tmp
[2025-07-19T20:31:08.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 39.0 in stage 9.0 (TID 842) (8b44f3d35cfa, executor driver, partition 39, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 38.0 in stage 9.0 (TID 841)
[2025-07-19T20:31:08.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 29.0 in stage 9.0 (TID 832) in 148 ms on 8b44f3d35cfa (executor driver) (31/200)
[2025-07-19T20:31:08.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 31.0 in stage 9.0 (TID 834) in 139 ms on 8b44f3d35cfa (executor driver) (32/200)
[2025-07-19T20:31:08.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.2.delta.d630afb7-6ebf-472c-bfc2-5bca611c1be1.TID838.tmp
[2025-07-19T20:31:08.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 39.0 in stage 9.0 (TID 842)
[2025-07-19T20:31:08.622+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@235ea33c
[2025-07-19T20:31:08.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=38, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=38),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38] for update
[2025-07-19T20:31:08.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.2.delta.0fa1cf1f-28ee-466e-98e0-4c11d3f18252.TID840.tmp
[2025-07-19T20:31:08.626+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63a81be0
[2025-07-19T20:31:08.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=39, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.628+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=39),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39] for update
[2025-07-19T20:31:08.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.630+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/.2.delta.3becc665-33ae-48a5-a1b6-1da0aaaa75a6.TID835.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/2.delta
[2025-07-19T20:31:08.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/32/2.delta
[2025-07-19T20:31:08.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T20:31:08.633+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.2.delta.d8c7b042-a0bd-42dc-ab7a-3a303711319b.TID841.tmp
[2025-07-19T20:31:08.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 32 (task 835, attempt 0, stage 9.0)
[2025-07-19T20:31:08.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.2.delta.a15b80e9-6f87-4630-b3ba-560282da2a73.TID842.tmp
[2025-07-19T20:31:08.635+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 32.0 in stage 9.0 (TID 835). 5829 bytes result sent to driver
[2025-07-19T20:31:08.636+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 40.0 in stage 9.0 (TID 843) (8b44f3d35cfa, executor driver, partition 40, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.637+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 40.0 in stage 9.0 (TID 843)
[2025-07-19T20:31:08.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 32.0 in stage 9.0 (TID 835) in 133 ms on 8b44f3d35cfa (executor driver) (33/200)
[2025-07-19T20:31:08.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/.2.delta.6adb82b6-9394-4ed7-9c79-be780bfb4ce5.TID836.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/2.delta
[2025-07-19T20:31:08.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/33/2.delta
[2025-07-19T20:31:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T20:31:08.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@45df8762
[2025-07-19T20:31:08.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=40, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=40),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40] for update
[2025-07-19T20:31:08.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 33 (task 836, attempt 0, stage 9.0)
[2025-07-19T20:31:08.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 33.0 in stage 9.0 (TID 836). 5829 bytes result sent to driver
[2025-07-19T20:31:08.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 41.0 in stage 9.0 (TID 844) (8b44f3d35cfa, executor driver, partition 41, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 41.0 in stage 9.0 (TID 844)
[2025-07-19T20:31:08.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/.2.delta.dd7a4a89-3b7a-41df-b219-faa2010651ac.TID837.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/2.delta
[2025-07-19T20:31:08.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/34/2.delta
[2025-07-19T20:31:08.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T20:31:08.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 33.0 in stage 9.0 (TID 836) in 115 ms on 8b44f3d35cfa (executor driver) (34/200)
[2025-07-19T20:31:08.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@49ae5604
[2025-07-19T20:31:08.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.2.delta.1c315b1c-492b-40bf-9251-7c81b74a7225.TID843.tmp
[2025-07-19T20:31:08.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=41, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=41),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41] for update
[2025-07-19T20:31:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 34 (task 837, attempt 0, stage 9.0)
[2025-07-19T20:31:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 34.0 in stage 9.0 (TID 837). 5829 bytes result sent to driver
[2025-07-19T20:31:08.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 42.0 in stage 9.0 (TID 845) (8b44f3d35cfa, executor driver, partition 42, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 42.0 in stage 9.0 (TID 845)
[2025-07-19T20:31:08.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/.2.delta.5bcb2b47-5d5e-496c-8b50-4d25f7769014.TID839.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/2.delta
[2025-07-19T20:31:08.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/36/2.delta
[2025-07-19T20:31:08.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ae686a0
[2025-07-19T20:31:08.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T20:31:08.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=42, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 34.0 in stage 9.0 (TID 837) in 106 ms on 8b44f3d35cfa (executor driver) (35/200)
[2025-07-19T20:31:08.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=42),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42] for update
[2025-07-19T20:31:08.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/.2.delta.d630afb7-6ebf-472c-bfc2-5bca611c1be1.TID838.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/2.delta
[2025-07-19T20:31:08.664+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/35/2.delta
[2025-07-19T20:31:08.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 36 (task 839, attempt 0, stage 9.0)
[2025-07-19T20:31:08.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 36.0 in stage 9.0 (TID 839). 5829 bytes result sent to driver
[2025-07-19T20:31:08.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T20:31:08.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 43.0 in stage 9.0 (TID 846) (8b44f3d35cfa, executor driver, partition 43, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 43.0 in stage 9.0 (TID 846)
[2025-07-19T20:31:08.672+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 36.0 in stage 9.0 (TID 839) in 89 ms on 8b44f3d35cfa (executor driver) (36/200)
[2025-07-19T20:31:08.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.675+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5365aa82
[2025-07-19T20:31:08.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=43, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=43),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43] for update
[2025-07-19T20:31:08.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 35 (task 838, attempt 0, stage 9.0)
[2025-07-19T20:31:08.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.2.delta.4f8e9a0d-7adf-458f-a7f7-b3537ad490e3.TID844.tmp
[2025-07-19T20:31:08.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 35.0 in stage 9.0 (TID 838). 5829 bytes result sent to driver
[2025-07-19T20:31:08.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/.2.delta.0fa1cf1f-28ee-466e-98e0-4c11d3f18252.TID840.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/2.delta
[2025-07-19T20:31:08.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/37/2.delta
[2025-07-19T20:31:08.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 44.0 in stage 9.0 (TID 847) (8b44f3d35cfa, executor driver, partition 44, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 44.0 in stage 9.0 (TID 847)
[2025-07-19T20:31:08.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 35.0 in stage 9.0 (TID 838) in 107 ms on 8b44f3d35cfa (executor driver) (37/200)
[2025-07-19T20:31:08.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T20:31:08.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@370ddb5a
[2025-07-19T20:31:08.687+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=44, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.688+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=44),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44] for update
[2025-07-19T20:31:08.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 37 (task 840, attempt 0, stage 9.0)
[2025-07-19T20:31:08.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/.2.delta.d8c7b042-a0bd-42dc-ab7a-3a303711319b.TID841.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/2.delta
[2025-07-19T20:31:08.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/38/2.delta
[2025-07-19T20:31:08.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 37.0 in stage 9.0 (TID 840). 5829 bytes result sent to driver
[2025-07-19T20:31:08.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.2.delta.be11951b-c919-4dd7-8c34-bbbd2f109ba2.TID845.tmp
[2025-07-19T20:31:08.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 45.0 in stage 9.0 (TID 848) (8b44f3d35cfa, executor driver, partition 45, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 37.0 in stage 9.0 (TID 840) in 96 ms on 8b44f3d35cfa (executor driver) (38/200)
[2025-07-19T20:31:08.690+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T20:31:08.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 45.0 in stage 9.0 (TID 848)
[2025-07-19T20:31:08.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.2.delta.a615cdfb-6144-4700-ac73-96fa563e5996.TID846.tmp
[2025-07-19T20:31:08.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/.2.delta.a15b80e9-6f87-4630-b3ba-560282da2a73.TID842.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/2.delta
[2025-07-19T20:31:08.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/39/2.delta
[2025-07-19T20:31:08.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:08.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T20:31:08.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fde3fcd
[2025-07-19T20:31:08.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=45, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=45),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45] for update
[2025-07-19T20:31:08.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 38 (task 841, attempt 0, stage 9.0)
[2025-07-19T20:31:08.702+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 39 (task 842, attempt 0, stage 9.0)
[2025-07-19T20:31:08.702+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 39.0 in stage 9.0 (TID 842). 5829 bytes result sent to driver
[2025-07-19T20:31:08.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 46.0 in stage 9.0 (TID 849) (8b44f3d35cfa, executor driver, partition 46, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 46.0 in stage 9.0 (TID 849)
[2025-07-19T20:31:08.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 39.0 in stage 9.0 (TID 842) in 105 ms on 8b44f3d35cfa (executor driver) (39/200)
[2025-07-19T20:31:08.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 38.0 in stage 9.0 (TID 841). 5872 bytes result sent to driver
[2025-07-19T20:31:08.705+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 47.0 in stage 9.0 (TID 850) (8b44f3d35cfa, executor driver, partition 47, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 38.0 in stage 9.0 (TID 841) in 107 ms on 8b44f3d35cfa (executor driver) (40/200)
[2025-07-19T20:31:08.707+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.708+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 47.0 in stage 9.0 (TID 850)
[2025-07-19T20:31:08.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.2.delta.aeb0e51a-1b53-4744-afb4-0f3678911b6c.TID847.tmp
[2025-07-19T20:31:08.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74301574
[2025-07-19T20:31:08.711+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.2.delta.d75bf196-ace9-4de4-9e88-c4580f00f8e4.TID848.tmp
[2025-07-19T20:31:08.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/.2.delta.1c315b1c-492b-40bf-9251-7c81b74a7225.TID843.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/2.delta
[2025-07-19T20:31:08.712+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/40/2.delta
[2025-07-19T20:31:08.714+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T20:31:08.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=46, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=46),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46] for update
[2025-07-19T20:31:08.717+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@68f4538f
[2025-07-19T20:31:08.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=47, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=47),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47] for update
[2025-07-19T20:31:08.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.719+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 40 (task 843, attempt 0, stage 9.0)
[2025-07-19T20:31:08.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 40.0 in stage 9.0 (TID 843). 5829 bytes result sent to driver
[2025-07-19T20:31:08.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 48.0 in stage 9.0 (TID 851) (8b44f3d35cfa, executor driver, partition 48, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 48.0 in stage 9.0 (TID 851)
[2025-07-19T20:31:08.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 40.0 in stage 9.0 (TID 843) in 96 ms on 8b44f3d35cfa (executor driver) (41/200)
[2025-07-19T20:31:08.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.730+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.2.delta.668434fa-ca1a-4c67-b7b7-b2aa52e8f829.TID849.tmp
[2025-07-19T20:31:08.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/.2.delta.4f8e9a0d-7adf-458f-a7f7-b3537ad490e3.TID844.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/2.delta
[2025-07-19T20:31:08.735+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ac5e1bd
[2025-07-19T20:31:08.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.2.delta.8c648349-ac4d-4a3a-a3fb-c780f0abca1b.TID850.tmp
[2025-07-19T20:31:08.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/41/2.delta
[2025-07-19T20:31:08.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T20:31:08.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=48, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=48),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48] for update
[2025-07-19T20:31:08.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.742+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/.2.delta.a615cdfb-6144-4700-ac73-96fa563e5996.TID846.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/2.delta
[2025-07-19T20:31:08.742+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/43/2.delta
[2025-07-19T20:31:08.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T20:31:08.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 41 (task 844, attempt 0, stage 9.0)
[2025-07-19T20:31:08.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 41.0 in stage 9.0 (TID 844). 5829 bytes result sent to driver
[2025-07-19T20:31:08.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 49.0 in stage 9.0 (TID 852) (8b44f3d35cfa, executor driver, partition 49, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 41.0 in stage 9.0 (TID 844) in 109 ms on 8b44f3d35cfa (executor driver) (42/200)
[2025-07-19T20:31:08.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 49.0 in stage 9.0 (TID 852)
[2025-07-19T20:31:08.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 43 (task 846, attempt 0, stage 9.0)
[2025-07-19T20:31:08.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 43.0 in stage 9.0 (TID 846). 5829 bytes result sent to driver
[2025-07-19T20:31:08.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:08.767+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 43.0 in stage 9.0 (TID 846) in 96 ms on 8b44f3d35cfa (executor driver) (43/200)
[2025-07-19T20:31:08.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 50.0 in stage 9.0 (TID 853) (8b44f3d35cfa, executor driver, partition 50, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e0628e8
[2025-07-19T20:31:08.770+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 50.0 in stage 9.0 (TID 853)
[2025-07-19T20:31:08.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=49, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=49),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49] for update
[2025-07-19T20:31:08.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@238b3946
[2025-07-19T20:31:08.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.2.delta.fd2ce0f6-d092-45f5-8bab-1f396f192c85.TID851.tmp
[2025-07-19T20:31:08.776+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=50, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.776+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=50),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50] for update
[2025-07-19T20:31:08.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/.2.delta.be11951b-c919-4dd7-8c34-bbbd2f109ba2.TID845.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/2.delta
[2025-07-19T20:31:08.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/42/2.delta
[2025-07-19T20:31:08.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T20:31:08.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 42 (task 845, attempt 0, stage 9.0)
[2025-07-19T20:31:08.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 42.0 in stage 9.0 (TID 845). 5872 bytes result sent to driver
[2025-07-19T20:31:08.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 42.0 in stage 9.0 (TID 845) in 135 ms on 8b44f3d35cfa (executor driver) (44/200)
[2025-07-19T20:31:08.788+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 51.0 in stage 9.0 (TID 854) (8b44f3d35cfa, executor driver, partition 51, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 51.0 in stage 9.0 (TID 854)
[2025-07-19T20:31:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/.2.delta.d75bf196-ace9-4de4-9e88-c4580f00f8e4.TID848.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/2.delta
[2025-07-19T20:31:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/45/2.delta
[2025-07-19T20:31:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T20:31:08.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.2.delta.d9f010b2-f06d-4ad3-8545-a72aa32e6916.TID852.tmp
[2025-07-19T20:31:08.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.2.delta.a7332bb8-8e4b-481e-9665-ab1c2dc4ad45.TID853.tmp
[2025-07-19T20:31:08.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7fa389f
[2025-07-19T20:31:08.795+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=51, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=51),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51] for update
[2025-07-19T20:31:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 45 (task 848, attempt 0, stage 9.0)
[2025-07-19T20:31:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 45.0 in stage 9.0 (TID 848). 5829 bytes result sent to driver
[2025-07-19T20:31:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 52.0 in stage 9.0 (TID 855) (8b44f3d35cfa, executor driver, partition 52, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 45.0 in stage 9.0 (TID 848) in 119 ms on 8b44f3d35cfa (executor driver) (45/200)
[2025-07-19T20:31:08.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 52.0 in stage 9.0 (TID 855)
[2025-07-19T20:31:08.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/.2.delta.aeb0e51a-1b53-4744-afb4-0f3678911b6c.TID847.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/2.delta
[2025-07-19T20:31:08.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/44/2.delta
[2025-07-19T20:31:08.803+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:08.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T20:31:08.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4e9c58c3
[2025-07-19T20:31:08.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=52, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=52),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52] for update
[2025-07-19T20:31:08.805+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.807+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 44 (task 847, attempt 0, stage 9.0)
[2025-07-19T20:31:08.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 44.0 in stage 9.0 (TID 847). 5829 bytes result sent to driver
[2025-07-19T20:31:08.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 53.0 in stage 9.0 (TID 856) (8b44f3d35cfa, executor driver, partition 53, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 44.0 in stage 9.0 (TID 847) in 140 ms on 8b44f3d35cfa (executor driver) (46/200)
[2025-07-19T20:31:08.810+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 53.0 in stage 9.0 (TID 856)
[2025-07-19T20:31:08.812+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/.2.delta.8c648349-ac4d-4a3a-a3fb-c780f0abca1b.TID850.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/2.delta
[2025-07-19T20:31:08.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/47/2.delta
[2025-07-19T20:31:08.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T20:31:08.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.813+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@58b8498
[2025-07-19T20:31:08.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=53, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=53),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53] for update
[2025-07-19T20:31:08.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 47 (task 850, attempt 0, stage 9.0)
[2025-07-19T20:31:08.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 47.0 in stage 9.0 (TID 850). 5872 bytes result sent to driver
[2025-07-19T20:31:08.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.2.delta.7779fd4c-a9c5-4bbb-80da-e239ce226dce.TID854.tmp
[2025-07-19T20:31:08.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 54.0 in stage 9.0 (TID 857) (8b44f3d35cfa, executor driver, partition 54, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 47.0 in stage 9.0 (TID 850) in 130 ms on 8b44f3d35cfa (executor driver) (47/200)
[2025-07-19T20:31:08.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 54.0 in stage 9.0 (TID 857)
[2025-07-19T20:31:08.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/.2.delta.668434fa-ca1a-4c67-b7b7-b2aa52e8f829.TID849.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/2.delta
[2025-07-19T20:31:08.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/46/2.delta
[2025-07-19T20:31:08.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.836+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T20:31:08.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.2.delta.f339b401-9331-4bdf-bc99-a44f2949dc87.TID855.tmp
[2025-07-19T20:31:08.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@410caaa6
[2025-07-19T20:31:08.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=54, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=54),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54] for update
[2025-07-19T20:31:08.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.2.delta.ceba1d67-63d3-4fe8-ae4f-c19a7b37d6f4.TID856.tmp
[2025-07-19T20:31:08.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 46 (task 849, attempt 0, stage 9.0)
[2025-07-19T20:31:08.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 46.0 in stage 9.0 (TID 849). 5872 bytes result sent to driver
[2025-07-19T20:31:08.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 55.0 in stage 9.0 (TID 858) (8b44f3d35cfa, executor driver, partition 55, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 55.0 in stage 9.0 (TID 858)
[2025-07-19T20:31:08.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 46.0 in stage 9.0 (TID 849) in 146 ms on 8b44f3d35cfa (executor driver) (48/200)
[2025-07-19T20:31:08.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@32e0597d
[2025-07-19T20:31:08.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=55, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=55),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55] for update
[2025-07-19T20:31:08.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/.2.delta.fd2ce0f6-d092-45f5-8bab-1f396f192c85.TID851.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/2.delta
[2025-07-19T20:31:08.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/48/2.delta
[2025-07-19T20:31:08.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T20:31:08.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 48 (task 851, attempt 0, stage 9.0)
[2025-07-19T20:31:08.860+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 48.0 in stage 9.0 (TID 851). 5872 bytes result sent to driver
[2025-07-19T20:31:08.860+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 56.0 in stage 9.0 (TID 859) (8b44f3d35cfa, executor driver, partition 56, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 48.0 in stage 9.0 (TID 851) in 139 ms on 8b44f3d35cfa (executor driver) (49/200)
[2025-07-19T20:31:08.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 56.0 in stage 9.0 (TID 859)
[2025-07-19T20:31:08.869+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.2.delta.be2cbd55-46d5-4a2b-a053-c2e5e6d69794.TID857.tmp
[2025-07-19T20:31:08.870+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e19d13b
[2025-07-19T20:31:08.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=56, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=56),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56] for update
[2025-07-19T20:31:08.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.2.delta.8af42624-d2a1-4f85-bef8-97b8a6d6267e.TID858.tmp
[2025-07-19T20:31:08.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/.2.delta.a7332bb8-8e4b-481e-9665-ab1c2dc4ad45.TID853.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/2.delta
[2025-07-19T20:31:08.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/50/2.delta
[2025-07-19T20:31:08.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T20:31:08.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/.2.delta.d9f010b2-f06d-4ad3-8545-a72aa32e6916.TID852.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/2.delta
[2025-07-19T20:31:08.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/49/2.delta
[2025-07-19T20:31:08.880+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T20:31:08.881+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 50 (task 853, attempt 0, stage 9.0)
[2025-07-19T20:31:08.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 50.0 in stage 9.0 (TID 853). 5872 bytes result sent to driver
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 57.0 in stage 9.0 (TID 860) (8b44f3d35cfa, executor driver, partition 57, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 57.0 in stage 9.0 (TID 860)
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 50.0 in stage 9.0 (TID 853) in 118 ms on 8b44f3d35cfa (executor driver) (50/200)
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 49 (task 852, attempt 0, stage 9.0)
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 49.0 in stage 9.0 (TID 852). 5872 bytes result sent to driver
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 58.0 in stage 9.0 (TID 861) (8b44f3d35cfa, executor driver, partition 58, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 49.0 in stage 9.0 (TID 852) in 133 ms on 8b44f3d35cfa (executor driver) (51/200)
[2025-07-19T20:31:08.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 58.0 in stage 9.0 (TID 861)
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@676b9282
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=58, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=58),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58] for update
[2025-07-19T20:31:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.2.delta.e0fbf32b-c7b4-4ef1-8002-62921c7f786d.TID859.tmp
[2025-07-19T20:31:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6043f6e3
[2025-07-19T20:31:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=57, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=57),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57] for update
[2025-07-19T20:31:08.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/.2.delta.7779fd4c-a9c5-4bbb-80da-e239ce226dce.TID854.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/2.delta
[2025-07-19T20:31:08.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/51/2.delta
[2025-07-19T20:31:08.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T20:31:08.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/.2.delta.f339b401-9331-4bdf-bc99-a44f2949dc87.TID855.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/2.delta
[2025-07-19T20:31:08.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/52/2.delta
[2025-07-19T20:31:08.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T20:31:08.897+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.2.delta.9fcef87d-a0ac-4395-9d9a-635640c53b2a.TID860.tmp
[2025-07-19T20:31:08.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.2.delta.ebc6b9cb-c05d-4283-8964-20b548473304.TID861.tmp
[2025-07-19T20:31:08.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 51 (task 854, attempt 0, stage 9.0)
[2025-07-19T20:31:08.899+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 51.0 in stage 9.0 (TID 854). 5872 bytes result sent to driver
[2025-07-19T20:31:08.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 59.0 in stage 9.0 (TID 862) (8b44f3d35cfa, executor driver, partition 59, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.901+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 51.0 in stage 9.0 (TID 854) in 109 ms on 8b44f3d35cfa (executor driver) (52/200)
[2025-07-19T20:31:08.902+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/.2.delta.ceba1d67-63d3-4fe8-ae4f-c19a7b37d6f4.TID856.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/2.delta
[2025-07-19T20:31:08.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/53/2.delta
[2025-07-19T20:31:08.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 52 (task 855, attempt 0, stage 9.0)
[2025-07-19T20:31:08.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T20:31:08.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 59.0 in stage 9.0 (TID 862)
[2025-07-19T20:31:08.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 52.0 in stage 9.0 (TID 855). 5872 bytes result sent to driver
[2025-07-19T20:31:08.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 60.0 in stage 9.0 (TID 863) (8b44f3d35cfa, executor driver, partition 60, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.904+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 52.0 in stage 9.0 (TID 855) in 102 ms on 8b44f3d35cfa (executor driver) (53/200)
[2025-07-19T20:31:08.904+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.906+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 60.0 in stage 9.0 (TID 863)
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e5f07a7
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=59, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=59),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59] for update
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.907+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 53 (task 856, attempt 0, stage 9.0)
[2025-07-19T20:31:08.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bbea27f
[2025-07-19T20:31:08.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 53.0 in stage 9.0 (TID 856). 5872 bytes result sent to driver
[2025-07-19T20:31:08.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 61.0 in stage 9.0 (TID 864) (8b44f3d35cfa, executor driver, partition 61, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 53.0 in stage 9.0 (TID 856) in 104 ms on 8b44f3d35cfa (executor driver) (54/200)
[2025-07-19T20:31:08.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 61.0 in stage 9.0 (TID 864)
[2025-07-19T20:31:08.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=60, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=60),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60] for update
[2025-07-19T20:31:08.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/.2.delta.be2cbd55-46d5-4a2b-a053-c2e5e6d69794.TID857.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/2.delta
[2025-07-19T20:31:08.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/54/2.delta
[2025-07-19T20:31:08.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T20:31:08.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/.2.delta.8af42624-d2a1-4f85-bef8-97b8a6d6267e.TID858.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/2.delta
[2025-07-19T20:31:08.920+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/55/2.delta
[2025-07-19T20:31:08.921+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.923+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13667998
[2025-07-19T20:31:08.923+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T20:31:08.924+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=61, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=61),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61] for update
[2025-07-19T20:31:08.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 54 (task 857, attempt 0, stage 9.0)
[2025-07-19T20:31:08.927+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 54.0 in stage 9.0 (TID 857). 5872 bytes result sent to driver
[2025-07-19T20:31:08.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.2.delta.c3db0bc9-53ae-4d6c-9818-bacc17538f7f.TID862.tmp
[2025-07-19T20:31:08.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 55 (task 858, attempt 0, stage 9.0)
[2025-07-19T20:31:08.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 62.0 in stage 9.0 (TID 865) (8b44f3d35cfa, executor driver, partition 62, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 55.0 in stage 9.0 (TID 858). 5872 bytes result sent to driver
[2025-07-19T20:31:08.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 63.0 in stage 9.0 (TID 866) (8b44f3d35cfa, executor driver, partition 63, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 54.0 in stage 9.0 (TID 857) in 95 ms on 8b44f3d35cfa (executor driver) (55/200)
[2025-07-19T20:31:08.934+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 62.0 in stage 9.0 (TID 865)
[2025-07-19T20:31:08.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 55.0 in stage 9.0 (TID 858) in 83 ms on 8b44f3d35cfa (executor driver) (56/200)
[2025-07-19T20:31:08.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 63.0 in stage 9.0 (TID 866)
[2025-07-19T20:31:08.935+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/.2.delta.e0fbf32b-c7b4-4ef1-8002-62921c7f786d.TID859.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/2.delta
[2025-07-19T20:31:08.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/56/2.delta
[2025-07-19T20:31:08.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@387bfaf6
[2025-07-19T20:31:08.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T20:31:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=63, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=63),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63] for update
[2025-07-19T20:31:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.2.delta.a183d222-1574-4f00-9da2-cdbd9cde356e.TID863.tmp
[2025-07-19T20:31:08.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 56 (task 859, attempt 0, stage 9.0)
[2025-07-19T20:31:08.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 56.0 in stage 9.0 (TID 859). 5872 bytes result sent to driver
[2025-07-19T20:31:08.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 64.0 in stage 9.0 (TID 867) (8b44f3d35cfa, executor driver, partition 64, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:08.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 56.0 in stage 9.0 (TID 859) in 75 ms on 8b44f3d35cfa (executor driver) (57/200)
[2025-07-19T20:31:08.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 64.0 in stage 9.0 (TID 867)
[2025-07-19T20:31:08.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@632b3ab1
[2025-07-19T20:31:08.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=62, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=62),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62] for update
[2025-07-19T20:31:08.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.2.delta.33736739-a0a3-455f-887f-b63b7bf0d17b.TID864.tmp
[2025-07-19T20:31:08.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.951+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e91135c
[2025-07-19T20:31:08.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=64, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=64),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64] for update
[2025-07-19T20:31:08.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.2.delta.942b8099-48a1-4c6b-ba48-b5c06e034dac.TID866.tmp
[2025-07-19T20:31:08.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/.2.delta.9fcef87d-a0ac-4395-9d9a-635640c53b2a.TID860.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/2.delta
[2025-07-19T20:31:08.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/57/2.delta
[2025-07-19T20:31:08.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T20:31:08.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/.2.delta.ebc6b9cb-c05d-4283-8964-20b548473304.TID861.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/2.delta
[2025-07-19T20:31:08.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/58/2.delta
[2025-07-19T20:31:08.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T20:31:08.960+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.2.delta.ac1cf1d8-7c54-4af0-b1ae-c9f144a48a75.TID865.tmp
[2025-07-19T20:31:08.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 57 (task 860, attempt 0, stage 9.0)
[2025-07-19T20:31:08.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 57.0 in stage 9.0 (TID 860). 5872 bytes result sent to driver
[2025-07-19T20:31:08.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 65.0 in stage 9.0 (TID 868) (8b44f3d35cfa, executor driver, partition 65, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 58 (task 861, attempt 0, stage 9.0)
[2025-07-19T20:31:08.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 57.0 in stage 9.0 (TID 860) in 80 ms on 8b44f3d35cfa (executor driver) (58/200)
[2025-07-19T20:31:08.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 58.0 in stage 9.0 (TID 861). 5872 bytes result sent to driver
[2025-07-19T20:31:08.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.2.delta.f1f40f0e-d9ee-4867-9ba9-7e8db2a84b58.TID867.tmp
[2025-07-19T20:31:08.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 66.0 in stage 9.0 (TID 869) (8b44f3d35cfa, executor driver, partition 66, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 65.0 in stage 9.0 (TID 868)
[2025-07-19T20:31:08.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 66.0 in stage 9.0 (TID 869)
[2025-07-19T20:31:08.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 58.0 in stage 9.0 (TID 861) in 77 ms on 8b44f3d35cfa (executor driver) (59/200)
[2025-07-19T20:31:08.965+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.966+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4465ae0f
[2025-07-19T20:31:08.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=66, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=66),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66] for update
[2025-07-19T20:31:08.968+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.969+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53cc2f9b
[2025-07-19T20:31:08.969+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=65, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=65),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65] for update
[2025-07-19T20:31:08.971+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/.2.delta.c3db0bc9-53ae-4d6c-9818-bacc17538f7f.TID862.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/2.delta
[2025-07-19T20:31:08.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/59/2.delta
[2025-07-19T20:31:08.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T20:31:08.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.2.delta.b41f91a1-bcd6-4329-8fe7-785a09bfeed3.TID869.tmp
[2025-07-19T20:31:08.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.2.delta.671c3ad1-f8e7-466b-bb86-32cf0ee4c68a.TID868.tmp
[2025-07-19T20:31:08.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/.2.delta.a183d222-1574-4f00-9da2-cdbd9cde356e.TID863.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/2.delta
[2025-07-19T20:31:08.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/60/2.delta
[2025-07-19T20:31:08.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T20:31:08.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 59 (task 862, attempt 0, stage 9.0)
[2025-07-19T20:31:08.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 59.0 in stage 9.0 (TID 862). 5872 bytes result sent to driver
[2025-07-19T20:31:08.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 67.0 in stage 9.0 (TID 870) (8b44f3d35cfa, executor driver, partition 67, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.978+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 59.0 in stage 9.0 (TID 862) in 82 ms on 8b44f3d35cfa (executor driver) (60/200)
[2025-07-19T20:31:08.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 67.0 in stage 9.0 (TID 870)
[2025-07-19T20:31:08.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6cfb0ff4
[2025-07-19T20:31:08.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=67, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=67),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67] for update
[2025-07-19T20:31:08.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 60 (task 863, attempt 0, stage 9.0)
[2025-07-19T20:31:08.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 60.0 in stage 9.0 (TID 863). 5872 bytes result sent to driver
[2025-07-19T20:31:08.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 68.0 in stage 9.0 (TID 871) (8b44f3d35cfa, executor driver, partition 68, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:08.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:08.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 60.0 in stage 9.0 (TID 863) in 84 ms on 8b44f3d35cfa (executor driver) (61/200)
[2025-07-19T20:31:08.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 68.0 in stage 9.0 (TID 871)
[2025-07-19T20:31:08.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/.2.delta.33736739-a0a3-455f-887f-b63b7bf0d17b.TID864.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/2.delta
[2025-07-19T20:31:08.989+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/61/2.delta
[2025-07-19T20:31:08.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/.2.delta.ac1cf1d8-7c54-4af0-b1ae-c9f144a48a75.TID865.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/2.delta
[2025-07-19T20:31:08.990+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/62/2.delta
[2025-07-19T20:31:08.991+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/.2.delta.942b8099-48a1-4c6b-ba48-b5c06e034dac.TID866.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/2.delta
[2025-07-19T20:31:08.992+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.2.delta.88671f6d-ecbd-4452-9f9d-19c6830040d6.TID870.tmp
[2025-07-19T20:31:08.992+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/63/2.delta
[2025-07-19T20:31:08.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:08.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:08.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T20:31:08.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T20:31:08.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T20:31:08.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30013ed
[2025-07-19T20:31:08.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=68, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:08.996+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=68),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68] for update
[2025-07-19T20:31:08.997+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/.2.delta.f1f40f0e-d9ee-4867-9ba9-7e8db2a84b58.TID867.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/2.delta
[2025-07-19T20:31:09.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/64/2.delta
[2025-07-19T20:31:09.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Commit authorized for partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T20:31:09.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 63 (task 866, attempt 0, stage 9.0)
[2025-07-19T20:31:09.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 63.0 in stage 9.0 (TID 866). 5829 bytes result sent to driver
[2025-07-19T20:31:09.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 69.0 in stage 9.0 (TID 872) (8b44f3d35cfa, executor driver, partition 69, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 63.0 in stage 9.0 (TID 866) in 74 ms on 8b44f3d35cfa (executor driver) (62/200)
[2025-07-19T20:31:09.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 61 (task 864, attempt 0, stage 9.0)
[2025-07-19T20:31:09.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO DataWritingSparkTask: Committed partition 62 (task 865, attempt 0, stage 9.0)
[2025-07-19T20:31:09.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 62.0 in stage 9.0 (TID 865). 5829 bytes result sent to driver
[2025-07-19T20:31:09.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 69.0 in stage 9.0 (TID 872)
[2025-07-19T20:31:09.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Finished task 61.0 in stage 9.0 (TID 864). 5829 bytes result sent to driver
[2025-07-19T20:31:09.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 70.0 in stage 9.0 (TID 873) (8b44f3d35cfa, executor driver, partition 70, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.009+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 70.0 in stage 9.0 (TID 873)
[2025-07-19T20:31:09.015+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Starting task 71.0 in stage 9.0 (TID 874) (8b44f3d35cfa, executor driver, partition 71, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.016+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO Executor: Running task 71.0 in stage 9.0 (TID 874)
[2025-07-19T20:31:09.019+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 62.0 in stage 9.0 (TID 865) in 79 ms on 8b44f3d35cfa (executor driver) (63/200)
[2025-07-19T20:31:09.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO TaskSetManager: Finished task 61.0 in stage 9.0 (TID 864) in 88 ms on 8b44f3d35cfa (executor driver) (64/200)
[2025-07-19T20:31:09.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:08 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 64 (task 867, attempt 0, stage 9.0)
[2025-07-19T20:31:09.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 64.0 in stage 9.0 (TID 867). 5829 bytes result sent to driver
[2025-07-19T20:31:09.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.026+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 72.0 in stage 9.0 (TID 875) (8b44f3d35cfa, executor driver, partition 72, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@73e55abf
[2025-07-19T20:31:09.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 64.0 in stage 9.0 (TID 867) in 71 ms on 8b44f3d35cfa (executor driver) (65/200)
[2025-07-19T20:31:09.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 72.0 in stage 9.0 (TID 875)
[2025-07-19T20:31:09.029+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=69, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=69),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69] for update
[2025-07-19T20:31:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.2.delta.46716200-30bd-419f-ae12-6927108056e2.TID871.tmp
[2025-07-19T20:31:09.032+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3f7a25df
[2025-07-19T20:31:09.034+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=70, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=70),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70] for update
[2025-07-19T20:31:09.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fd3e173
[2025-07-19T20:31:09.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=71, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.037+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=71),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71] for update
[2025-07-19T20:31:09.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/.2.delta.b41f91a1-bcd6-4329-8fe7-785a09bfeed3.TID869.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/2.delta
[2025-07-19T20:31:09.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/66/2.delta
[2025-07-19T20:31:09.044+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.048+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@19389658
[2025-07-19T20:31:09.049+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T20:31:09.051+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=72, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.052+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=72),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72] for update
[2025-07-19T20:31:09.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/.2.delta.671c3ad1-f8e7-466b-bb86-32cf0ee4c68a.TID868.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/2.delta
[2025-07-19T20:31:09.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/65/2.delta
[2025-07-19T20:31:09.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T20:31:09.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.054+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 66 (task 869, attempt 0, stage 9.0)
[2025-07-19T20:31:09.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 66.0 in stage 9.0 (TID 869). 5829 bytes result sent to driver
[2025-07-19T20:31:09.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 73.0 in stage 9.0 (TID 876) (8b44f3d35cfa, executor driver, partition 73, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 66.0 in stage 9.0 (TID 869) in 76 ms on 8b44f3d35cfa (executor driver) (66/200)
[2025-07-19T20:31:09.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 73.0 in stage 9.0 (TID 876)
[2025-07-19T20:31:09.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 65 (task 868, attempt 0, stage 9.0)
[2025-07-19T20:31:09.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 65.0 in stage 9.0 (TID 868). 5829 bytes result sent to driver
[2025-07-19T20:31:09.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 74.0 in stage 9.0 (TID 877) (8b44f3d35cfa, executor driver, partition 74, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 74.0 in stage 9.0 (TID 877)
[2025-07-19T20:31:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 65.0 in stage 9.0 (TID 868) in 88 ms on 8b44f3d35cfa (executor driver) (67/200)
[2025-07-19T20:31:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4d1dab79
[2025-07-19T20:31:09.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=73, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=73),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73] for update
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.2.delta.a375f36b-5229-42ad-b09b-9cec6f209946.TID873.tmp
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.2.delta.62f642af-b3ea-41c2-9757-ac7618f8f7bd.TID872.tmp
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36bd35b6
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=74, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=74),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74] for update
[2025-07-19T20:31:09.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.2.delta.c5c8eaa4-9e3f-45a7-958f-e5c7bb23f7b7.TID874.tmp
[2025-07-19T20:31:09.068+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.2.delta.da98ceaf-86d5-4ce5-94ef-588d28b6d666.TID876.tmp
[2025-07-19T20:31:09.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.2.delta.bd4a3904-de01-4ea8-8bcd-bca69ff1b0e2.TID875.tmp
[2025-07-19T20:31:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/.2.delta.88671f6d-ecbd-4452-9f9d-19c6830040d6.TID870.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/2.delta
[2025-07-19T20:31:09.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/67/2.delta
[2025-07-19T20:31:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/.2.delta.46716200-30bd-419f-ae12-6927108056e2.TID871.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/2.delta
[2025-07-19T20:31:09.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/68/2.delta
[2025-07-19T20:31:09.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T20:31:09.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T20:31:09.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 68 (task 871, attempt 0, stage 9.0)
[2025-07-19T20:31:09.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 68.0 in stage 9.0 (TID 871). 5829 bytes result sent to driver
[2025-07-19T20:31:09.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.2.delta.f613fa2a-d299-45fa-be13-f5d3640dd4c3.TID877.tmp
[2025-07-19T20:31:09.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 67 (task 870, attempt 0, stage 9.0)
[2025-07-19T20:31:09.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 67.0 in stage 9.0 (TID 870). 5829 bytes result sent to driver
[2025-07-19T20:31:09.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 75.0 in stage 9.0 (TID 878) (8b44f3d35cfa, executor driver, partition 75, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 76.0 in stage 9.0 (TID 879) (8b44f3d35cfa, executor driver, partition 76, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 76.0 in stage 9.0 (TID 879)
[2025-07-19T20:31:09.087+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 67.0 in stage 9.0 (TID 870) in 110 ms on 8b44f3d35cfa (executor driver) (68/200)
[2025-07-19T20:31:09.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 68.0 in stage 9.0 (TID 871) in 104 ms on 8b44f3d35cfa (executor driver) (69/200)
[2025-07-19T20:31:09.091+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 75.0 in stage 9.0 (TID 878)
[2025-07-19T20:31:09.092+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@740800ed
[2025-07-19T20:31:09.093+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.094+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.102+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=76, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=76),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76] for update
[2025-07-19T20:31:09.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/.2.delta.62f642af-b3ea-41c2-9757-ac7618f8f7bd.TID872.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/2.delta
[2025-07-19T20:31:09.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/69/2.delta
[2025-07-19T20:31:09.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7d426a60
[2025-07-19T20:31:09.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T20:31:09.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=75, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=75),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75] for update
[2025-07-19T20:31:09.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.110+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 69 (task 872, attempt 0, stage 9.0)
[2025-07-19T20:31:09.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 69.0 in stage 9.0 (TID 872). 5829 bytes result sent to driver
[2025-07-19T20:31:09.112+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 77.0 in stage 9.0 (TID 880) (8b44f3d35cfa, executor driver, partition 77, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 69.0 in stage 9.0 (TID 872) in 116 ms on 8b44f3d35cfa (executor driver) (70/200)
[2025-07-19T20:31:09.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 77.0 in stage 9.0 (TID 880)
[2025-07-19T20:31:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/.2.delta.da98ceaf-86d5-4ce5-94ef-588d28b6d666.TID876.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/2.delta
[2025-07-19T20:31:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/73/2.delta
[2025-07-19T20:31:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/.2.delta.a375f36b-5229-42ad-b09b-9cec6f209946.TID873.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/2.delta
[2025-07-19T20:31:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/70/2.delta
[2025-07-19T20:31:09.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T20:31:09.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T20:31:09.122+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@80ecbfb
[2025-07-19T20:31:09.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/.2.delta.c5c8eaa4-9e3f-45a7-958f-e5c7bb23f7b7.TID874.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/2.delta
[2025-07-19T20:31:09.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/71/2.delta
[2025-07-19T20:31:09.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/.2.delta.bd4a3904-de01-4ea8-8bcd-bca69ff1b0e2.TID875.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/2.delta
[2025-07-19T20:31:09.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/72/2.delta
[2025-07-19T20:31:09.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.2.delta.1fa08011-3043-4c6a-afe3-c7015ad978df.TID879.tmp
[2025-07-19T20:31:09.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.2.delta.a697537b-4c24-4508-87d4-5d7a8559738a.TID878.tmp
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=77, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=77),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77] for update
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 70 (task 873, attempt 0, stage 9.0)
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 71 (task 874, attempt 0, stage 9.0)
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.129+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 71.0 in stage 9.0 (TID 874). 5829 bytes result sent to driver
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 72 (task 875, attempt 0, stage 9.0)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 78.0 in stage 9.0 (TID 881) (8b44f3d35cfa, executor driver, partition 78, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 72.0 in stage 9.0 (TID 875). 5829 bytes result sent to driver
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 79.0 in stage 9.0 (TID 882) (8b44f3d35cfa, executor driver, partition 79, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 79.0 in stage 9.0 (TID 882)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 72.0 in stage 9.0 (TID 875) in 123 ms on 8b44f3d35cfa (executor driver) (71/200)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 71.0 in stage 9.0 (TID 874) in 127 ms on 8b44f3d35cfa (executor driver) (72/200)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 78.0 in stage 9.0 (TID 881)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 73 (task 876, attempt 0, stage 9.0)
[2025-07-19T20:31:09.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 73.0 in stage 9.0 (TID 876). 5829 bytes result sent to driver
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 70.0 in stage 9.0 (TID 873). 5872 bytes result sent to driver
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 80.0 in stage 9.0 (TID 883) (8b44f3d35cfa, executor driver, partition 80, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 81.0 in stage 9.0 (TID 884) (8b44f3d35cfa, executor driver, partition 81, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 73.0 in stage 9.0 (TID 876) in 99 ms on 8b44f3d35cfa (executor driver) (73/200)
[2025-07-19T20:31:09.131+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 80.0 in stage 9.0 (TID 883)
[2025-07-19T20:31:09.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@53f99db6
[2025-07-19T20:31:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 70.0 in stage 9.0 (TID 873) in 133 ms on 8b44f3d35cfa (executor driver) (74/200)
[2025-07-19T20:31:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 81.0 in stage 9.0 (TID 884)
[2025-07-19T20:31:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=79, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=79),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79] for update
[2025-07-19T20:31:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.134+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4214f1
[2025-07-19T20:31:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=78, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.135+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=78),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78] for update
[2025-07-19T20:31:09.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@16e07425
[2025-07-19T20:31:09.143+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=81, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=81),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81] for update
[2025-07-19T20:31:09.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.144+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@33b55a97
[2025-07-19T20:31:09.146+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=80, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=80),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80] for update
[2025-07-19T20:31:09.147+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.2.delta.0f4f967b-d8bb-4299-af83-7fa4820590bb.TID880.tmp
[2025-07-19T20:31:09.152+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.2.delta.b7e7d2c1-8033-4340-b602-e4cd9cf5e483.TID881.tmp
[2025-07-19T20:31:09.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/.2.delta.f613fa2a-d299-45fa-be13-f5d3640dd4c3.TID877.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/2.delta
[2025-07-19T20:31:09.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/74/2.delta
[2025-07-19T20:31:09.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.2.delta.2cd5e638-0fb1-487b-84e1-f2dc24100b08.TID882.tmp
[2025-07-19T20:31:09.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T20:31:09.156+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 74 (task 877, attempt 0, stage 9.0)
[2025-07-19T20:31:09.157+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 74.0 in stage 9.0 (TID 877). 5829 bytes result sent to driver
[2025-07-19T20:31:09.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 82.0 in stage 9.0 (TID 885) (8b44f3d35cfa, executor driver, partition 82, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 74.0 in stage 9.0 (TID 877) in 122 ms on 8b44f3d35cfa (executor driver) (75/200)
[2025-07-19T20:31:09.160+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 82.0 in stage 9.0 (TID 885)
[2025-07-19T20:31:09.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@63639531
[2025-07-19T20:31:09.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=82, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=82),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82] for update
[2025-07-19T20:31:09.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.2.delta.ea7fdd82-fee8-40de-86c1-d6ea1a7ec8d6.TID884.tmp
[2025-07-19T20:31:09.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.2.delta.6c48dd1d-f97d-4f05-808a-790c3868848a.TID883.tmp
[2025-07-19T20:31:09.179+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.2.delta.c60a86f1-800e-460b-98ae-8fbb4bf680fa.TID885.tmp
[2025-07-19T20:31:09.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/.2.delta.a697537b-4c24-4508-87d4-5d7a8559738a.TID878.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/2.delta
[2025-07-19T20:31:09.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/75/2.delta
[2025-07-19T20:31:09.193+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T20:31:09.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/.2.delta.1fa08011-3043-4c6a-afe3-c7015ad978df.TID879.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/2.delta
[2025-07-19T20:31:09.197+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/76/2.delta
[2025-07-19T20:31:09.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 75 (task 878, attempt 0, stage 9.0)
[2025-07-19T20:31:09.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T20:31:09.203+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 76 (task 879, attempt 0, stage 9.0)
[2025-07-19T20:31:09.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 76.0 in stage 9.0 (TID 879). 5829 bytes result sent to driver
[2025-07-19T20:31:09.205+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 83.0 in stage 9.0 (TID 886) (8b44f3d35cfa, executor driver, partition 83, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 75.0 in stage 9.0 (TID 878). 5829 bytes result sent to driver
[2025-07-19T20:31:09.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 84.0 in stage 9.0 (TID 887) (8b44f3d35cfa, executor driver, partition 84, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 75.0 in stage 9.0 (TID 878) in 115 ms on 8b44f3d35cfa (executor driver) (76/200)
[2025-07-19T20:31:09.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 76.0 in stage 9.0 (TID 879) in 115 ms on 8b44f3d35cfa (executor driver) (77/200)
[2025-07-19T20:31:09.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 84.0 in stage 9.0 (TID 887)
[2025-07-19T20:31:09.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/.2.delta.b7e7d2c1-8033-4340-b602-e4cd9cf5e483.TID881.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/2.delta
[2025-07-19T20:31:09.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/.2.delta.0f4f967b-d8bb-4299-af83-7fa4820590bb.TID880.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/2.delta
[2025-07-19T20:31:09.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/77/2.delta
[2025-07-19T20:31:09.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/78/2.delta
[2025-07-19T20:31:09.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T20:31:09.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T20:31:09.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 77 (task 880, attempt 0, stage 9.0)
[2025-07-19T20:31:09.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 78 (task 881, attempt 0, stage 9.0)
[2025-07-19T20:31:09.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 77.0 in stage 9.0 (TID 880). 5829 bytes result sent to driver
[2025-07-19T20:31:09.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 78.0 in stage 9.0 (TID 881). 5829 bytes result sent to driver
[2025-07-19T20:31:09.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 85.0 in stage 9.0 (TID 888) (8b44f3d35cfa, executor driver, partition 85, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 86.0 in stage 9.0 (TID 889) (8b44f3d35cfa, executor driver, partition 86, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 83.0 in stage 9.0 (TID 886)
[2025-07-19T20:31:09.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 86.0 in stage 9.0 (TID 889)
[2025-07-19T20:31:09.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.216+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 77.0 in stage 9.0 (TID 880) in 97 ms on 8b44f3d35cfa (executor driver) (78/200)
[2025-07-19T20:31:09.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 78.0 in stage 9.0 (TID 881) in 80 ms on 8b44f3d35cfa (executor driver) (79/200)
[2025-07-19T20:31:09.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:09.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
[2025-07-19T20:31:09.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 85.0 in stage 9.0 (TID 888)
[2025-07-19T20:31:09.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/.2.delta.2cd5e638-0fb1-487b-84e1-f2dc24100b08.TID882.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/2.delta
[2025-07-19T20:31:09.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/79/2.delta
[2025-07-19T20:31:09.222+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@667af341
[2025-07-19T20:31:09.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T20:31:09.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=83, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=83),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83] for update
[2025-07-19T20:31:09.224+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 79 (task 882, attempt 0, stage 9.0)
[2025-07-19T20:31:09.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e9239f3
[2025-07-19T20:31:09.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=85, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=85),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85] for update
[2025-07-19T20:31:09.232+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/.2.delta.ea7fdd82-fee8-40de-86c1-d6ea1a7ec8d6.TID884.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/2.delta
[2025-07-19T20:31:09.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/81/2.delta
[2025-07-19T20:31:09.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 79.0 in stage 9.0 (TID 882). 5829 bytes result sent to driver
[2025-07-19T20:31:09.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T20:31:09.234+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 87.0 in stage 9.0 (TID 890) (8b44f3d35cfa, executor driver, partition 87, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.235+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 79.0 in stage 9.0 (TID 882) in 92 ms on 8b44f3d35cfa (executor driver) (80/200)
[2025-07-19T20:31:09.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 87.0 in stage 9.0 (TID 890)
[2025-07-19T20:31:09.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a5173de
[2025-07-19T20:31:09.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/.2.delta.c60a86f1-800e-460b-98ae-8fbb4bf680fa.TID885.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/2.delta
[2025-07-19T20:31:09.237+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/82/2.delta
[2025-07-19T20:31:09.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=84, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.238+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T20:31:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=84),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84] for update
[2025-07-19T20:31:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3b0acc0b
[2025-07-19T20:31:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=86, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.240+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=86),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86] for update
[2025-07-19T20:31:09.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.2.delta.af4a24c0-11d9-4331-b93c-b95ab4d969dc.TID886.tmp
[2025-07-19T20:31:09.241+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/.2.delta.6c48dd1d-f97d-4f05-808a-790c3868848a.TID883.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/2.delta
[2025-07-19T20:31:09.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/80/2.delta
[2025-07-19T20:31:09.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T20:31:09.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.243+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 82 (task 885, attempt 0, stage 9.0)
[2025-07-19T20:31:09.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 82.0 in stage 9.0 (TID 885). 5829 bytes result sent to driver
[2025-07-19T20:31:09.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 88.0 in stage 9.0 (TID 891) (8b44f3d35cfa, executor driver, partition 88, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 88.0 in stage 9.0 (TID 891)
[2025-07-19T20:31:09.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 82.0 in stage 9.0 (TID 885) in 70 ms on 8b44f3d35cfa (executor driver) (81/200)
[2025-07-19T20:31:09.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 81 (task 884, attempt 0, stage 9.0)
[2025-07-19T20:31:09.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2507f0ec
[2025-07-19T20:31:09.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 81.0 in stage 9.0 (TID 884). 5829 bytes result sent to driver
[2025-07-19T20:31:09.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 89.0 in stage 9.0 (TID 892) (8b44f3d35cfa, executor driver, partition 89, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 89.0 in stage 9.0 (TID 892)
[2025-07-19T20:31:09.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 81.0 in stage 9.0 (TID 884) in 100 ms on 8b44f3d35cfa (executor driver) (82/200)
[2025-07-19T20:31:09.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 80 (task 883, attempt 0, stage 9.0)
[2025-07-19T20:31:09.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 80.0 in stage 9.0 (TID 883). 5829 bytes result sent to driver
[2025-07-19T20:31:09.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 90.0 in stage 9.0 (TID 893) (8b44f3d35cfa, executor driver, partition 90, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=87, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=87),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87] for update
[2025-07-19T20:31:09.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 80.0 in stage 9.0 (TID 883) in 103 ms on 8b44f3d35cfa (executor driver) (83/200)
[2025-07-19T20:31:09.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.252+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5d7f8fed
[2025-07-19T20:31:09.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=88, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=88),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88] for update
[2025-07-19T20:31:09.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 90.0 in stage 9.0 (TID 893)
[2025-07-19T20:31:09.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.2.delta.80c6a308-9d39-43fd-b7ed-626796f77b21.TID887.tmp
[2025-07-19T20:31:09.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@13052ada
[2025-07-19T20:31:09.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.255+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=89, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=89),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89] for update
[2025-07-19T20:31:09.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7917a3d9
[2025-07-19T20:31:09.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=90, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=90),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90] for update
[2025-07-19T20:31:09.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.2.delta.2ed8dd8f-7d85-4557-8a2d-99cbbe95f2b5.TID888.tmp
[2025-07-19T20:31:09.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.2.delta.60f9ea75-8e20-47f1-b203-1bb4a727779a.TID889.tmp
[2025-07-19T20:31:09.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.2.delta.12bfa200-f4aa-41a2-a085-ff28c531ab8f.TID891.tmp
[2025-07-19T20:31:09.260+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.2.delta.5e532ac0-2a9b-428f-948c-e2ae4b2d28ea.TID892.tmp
[2025-07-19T20:31:09.262+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.2.delta.a59b5d3c-e1a4-4fef-bdd3-5e86e48539f7.TID890.tmp
[2025-07-19T20:31:09.263+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.2.delta.f5ec40a8-cce5-4bb4-8281-c369d2ceccd1.TID893.tmp
[2025-07-19T20:31:09.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/.2.delta.af4a24c0-11d9-4331-b93c-b95ab4d969dc.TID886.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/2.delta
[2025-07-19T20:31:09.265+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/83/2.delta
[2025-07-19T20:31:09.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T20:31:09.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 83 (task 886, attempt 0, stage 9.0)
[2025-07-19T20:31:09.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 83.0 in stage 9.0 (TID 886). 5829 bytes result sent to driver
[2025-07-19T20:31:09.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 91.0 in stage 9.0 (TID 894) (8b44f3d35cfa, executor driver, partition 91, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.272+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 83.0 in stage 9.0 (TID 886) in 75 ms on 8b44f3d35cfa (executor driver) (84/200)
[2025-07-19T20:31:09.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 91.0 in stage 9.0 (TID 894)
[2025-07-19T20:31:09.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.276+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@47f26333
[2025-07-19T20:31:09.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=91, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=91),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91] for update
[2025-07-19T20:31:09.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/.2.delta.80c6a308-9d39-43fd-b7ed-626796f77b21.TID887.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/2.delta
[2025-07-19T20:31:09.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/84/2.delta
[2025-07-19T20:31:09.278+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T20:31:09.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/.2.delta.2ed8dd8f-7d85-4557-8a2d-99cbbe95f2b5.TID888.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/2.delta
[2025-07-19T20:31:09.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/85/2.delta
[2025-07-19T20:31:09.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 84 (task 887, attempt 0, stage 9.0)
[2025-07-19T20:31:09.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 84.0 in stage 9.0 (TID 887). 5829 bytes result sent to driver
[2025-07-19T20:31:09.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 92.0 in stage 9.0 (TID 895) (8b44f3d35cfa, executor driver, partition 92, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 84.0 in stage 9.0 (TID 887) in 85 ms on 8b44f3d35cfa (executor driver) (85/200)
[2025-07-19T20:31:09.285+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T20:31:09.286+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 92.0 in stage 9.0 (TID 895)
[2025-07-19T20:31:09.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 85 (task 888, attempt 0, stage 9.0)
[2025-07-19T20:31:09.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.2.delta.d24d75e7-2c21-425e-b0c3-08d8393967de.TID894.tmp
[2025-07-19T20:31:09.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 85.0 in stage 9.0 (TID 888). 5829 bytes result sent to driver
[2025-07-19T20:31:09.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/.2.delta.f5ec40a8-cce5-4bb4-8281-c369d2ceccd1.TID893.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/2.delta
[2025-07-19T20:31:09.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/90/2.delta
[2025-07-19T20:31:09.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/.2.delta.5e532ac0-2a9b-428f-948c-e2ae4b2d28ea.TID892.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/2.delta
[2025-07-19T20:31:09.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/89/2.delta
[2025-07-19T20:31:09.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/.2.delta.a59b5d3c-e1a4-4fef-bdd3-5e86e48539f7.TID890.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/2.delta
[2025-07-19T20:31:09.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/87/2.delta
[2025-07-19T20:31:09.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/.2.delta.12bfa200-f4aa-41a2-a085-ff28c531ab8f.TID891.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/2.delta
[2025-07-19T20:31:09.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/88/2.delta
[2025-07-19T20:31:09.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:09.295+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T20:31:09.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T20:31:09.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 93.0 in stage 9.0 (TID 896) (8b44f3d35cfa, executor driver, partition 93, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T20:31:09.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@342ac8a
[2025-07-19T20:31:09.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 85.0 in stage 9.0 (TID 888) in 87 ms on 8b44f3d35cfa (executor driver) (86/200)
[2025-07-19T20:31:09.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T20:31:09.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=92, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=92),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92] for update
[2025-07-19T20:31:09.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/.2.delta.60f9ea75-8e20-47f1-b203-1bb4a727779a.TID889.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/2.delta
[2025-07-19T20:31:09.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/86/2.delta
[2025-07-19T20:31:09.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T20:31:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 89 (task 892, attempt 0, stage 9.0)
[2025-07-19T20:31:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 89.0 in stage 9.0 (TID 892). 5829 bytes result sent to driver
[2025-07-19T20:31:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 90 (task 893, attempt 0, stage 9.0)
[2025-07-19T20:31:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 88 (task 891, attempt 0, stage 9.0)
[2025-07-19T20:31:09.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 94.0 in stage 9.0 (TID 897) (8b44f3d35cfa, executor driver, partition 94, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 87 (task 890, attempt 0, stage 9.0)
[2025-07-19T20:31:09.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 87.0 in stage 9.0 (TID 890). 5829 bytes result sent to driver
[2025-07-19T20:31:09.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 90.0 in stage 9.0 (TID 893). 5829 bytes result sent to driver
[2025-07-19T20:31:09.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 88.0 in stage 9.0 (TID 891). 5829 bytes result sent to driver
[2025-07-19T20:31:09.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 93.0 in stage 9.0 (TID 896)
[2025-07-19T20:31:09.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 89.0 in stage 9.0 (TID 892) in 69 ms on 8b44f3d35cfa (executor driver) (87/200)
[2025-07-19T20:31:09.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 94.0 in stage 9.0 (TID 897)
[2025-07-19T20:31:09.310+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 95.0 in stage 9.0 (TID 898) (8b44f3d35cfa, executor driver, partition 95, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 96.0 in stage 9.0 (TID 899) (8b44f3d35cfa, executor driver, partition 96, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 86 (task 889, attempt 0, stage 9.0)
[2025-07-19T20:31:09.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 97.0 in stage 9.0 (TID 900) (8b44f3d35cfa, executor driver, partition 97, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 87.0 in stage 9.0 (TID 890) in 79 ms on 8b44f3d35cfa (executor driver) (88/200)
[2025-07-19T20:31:09.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 86.0 in stage 9.0 (TID 889). 5786 bytes result sent to driver
[2025-07-19T20:31:09.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 90.0 in stage 9.0 (TID 893) in 68 ms on 8b44f3d35cfa (executor driver) (89/200)
[2025-07-19T20:31:09.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 88.0 in stage 9.0 (TID 891) in 72 ms on 8b44f3d35cfa (executor driver) (90/200)
[2025-07-19T20:31:09.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 96.0 in stage 9.0 (TID 899)
[2025-07-19T20:31:09.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 97.0 in stage 9.0 (TID 900)
[2025-07-19T20:31:09.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:09.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 95.0 in stage 9.0 (TID 898)
[2025-07-19T20:31:09.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 98.0 in stage 9.0 (TID 901) (8b44f3d35cfa, executor driver, partition 98, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4c386c25
[2025-07-19T20:31:09.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.2.delta.abff0559-a98f-401a-bd03-9f191fe67ff7.TID895.tmp
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=93, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 86.0 in stage 9.0 (TID 889) in 100 ms on 8b44f3d35cfa (executor driver) (91/200)
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=93),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93] for update
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 98.0 in stage 9.0 (TID 901)
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6ff872dd
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=94, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=94),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94] for update
[2025-07-19T20:31:09.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2f54fd01
[2025-07-19T20:31:09.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=97, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=97),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97] for update
[2025-07-19T20:31:09.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@571ae10c
[2025-07-19T20:31:09.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.2.delta.d2105628-f6a6-430f-ac5c-1416ce5ced7d.TID896.tmp
[2025-07-19T20:31:09.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=95, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=95),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95] for update
[2025-07-19T20:31:09.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/.2.delta.d24d75e7-2c21-425e-b0c3-08d8393967de.TID894.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/2.delta
[2025-07-19T20:31:09.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/91/2.delta
[2025-07-19T20:31:09.332+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T20:31:09.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@538dd965
[2025-07-19T20:31:09.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=98, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.333+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=98),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98] for update
[2025-07-19T20:31:09.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.2.delta.8297dbbe-262c-407e-acfb-d792ecccdef6.TID897.tmp
[2025-07-19T20:31:09.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 91 (task 894, attempt 0, stage 9.0)
[2025-07-19T20:31:09.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 91.0 in stage 9.0 (TID 894). 5829 bytes result sent to driver
[2025-07-19T20:31:09.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.2.delta.17187288-5022-4c74-93d1-0400d9e36873.TID900.tmp
[2025-07-19T20:31:09.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@601c6eda
[2025-07-19T20:31:09.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 99.0 in stage 9.0 (TID 902) (8b44f3d35cfa, executor driver, partition 99, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.335+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=96, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=96),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96] for update
[2025-07-19T20:31:09.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 91.0 in stage 9.0 (TID 894) in 57 ms on 8b44f3d35cfa (executor driver) (92/200)
[2025-07-19T20:31:09.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 99.0 in stage 9.0 (TID 902)
[2025-07-19T20:31:09.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7bef4b90
[2025-07-19T20:31:09.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=99, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=99),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99] for update
[2025-07-19T20:31:09.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.2.delta.2ee5ad54-ef5c-43cb-85de-c9d2b7ae7f06.TID898.tmp
[2025-07-19T20:31:09.341+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/.2.delta.abff0559-a98f-401a-bd03-9f191fe67ff7.TID895.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/2.delta
[2025-07-19T20:31:09.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/92/2.delta
[2025-07-19T20:31:09.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T20:31:09.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.2.delta.9697b775-d2b2-41d5-aff4-765c3bc5ba27.TID901.tmp
[2025-07-19T20:31:09.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.2.delta.d2d60ed7-8700-4349-ae3c-7308305cd7f8.TID899.tmp
[2025-07-19T20:31:09.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 92 (task 895, attempt 0, stage 9.0)
[2025-07-19T20:31:09.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 92.0 in stage 9.0 (TID 895). 5829 bytes result sent to driver
[2025-07-19T20:31:09.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 100.0 in stage 9.0 (TID 903) (8b44f3d35cfa, executor driver, partition 100, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 100.0 in stage 9.0 (TID 903)
[2025-07-19T20:31:09.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 92.0 in stage 9.0 (TID 895) in 62 ms on 8b44f3d35cfa (executor driver) (93/200)
[2025-07-19T20:31:09.348+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.349+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4933c061
[2025-07-19T20:31:09.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=100, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=100),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100] for update
[2025-07-19T20:31:09.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.359+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/.2.delta.d2105628-f6a6-430f-ac5c-1416ce5ced7d.TID896.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/2.delta
[2025-07-19T20:31:09.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/93/2.delta
[2025-07-19T20:31:09.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T20:31:09.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.2.delta.7129eaa9-7daa-4fa9-8fd3-5e7820595592.TID903.tmp
[2025-07-19T20:31:09.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 93 (task 896, attempt 0, stage 9.0)
[2025-07-19T20:31:09.365+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 93.0 in stage 9.0 (TID 896). 5829 bytes result sent to driver
[2025-07-19T20:31:09.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 101.0 in stage 9.0 (TID 904) (8b44f3d35cfa, executor driver, partition 101, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 101.0 in stage 9.0 (TID 904)
[2025-07-19T20:31:09.369+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/.2.delta.8297dbbe-262c-407e-acfb-d792ecccdef6.TID897.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/2.delta
[2025-07-19T20:31:09.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/94/2.delta
[2025-07-19T20:31:09.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 93.0 in stage 9.0 (TID 896) in 76 ms on 8b44f3d35cfa (executor driver) (94/200)
[2025-07-19T20:31:09.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T20:31:09.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.2.delta.7b3cc467-2df4-4fdf-81b7-ef99da759a3c.TID902.tmp
[2025-07-19T20:31:09.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 94 (task 897, attempt 0, stage 9.0)
[2025-07-19T20:31:09.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@685a01fb
[2025-07-19T20:31:09.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 94.0 in stage 9.0 (TID 897). 5829 bytes result sent to driver
[2025-07-19T20:31:09.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=101, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=101),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101] for update
[2025-07-19T20:31:09.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 102.0 in stage 9.0 (TID 905) (8b44f3d35cfa, executor driver, partition 102, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 94.0 in stage 9.0 (TID 897) in 78 ms on 8b44f3d35cfa (executor driver) (95/200)
[2025-07-19T20:31:09.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 102.0 in stage 9.0 (TID 905)
[2025-07-19T20:31:09.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/.2.delta.2ee5ad54-ef5c-43cb-85de-c9d2b7ae7f06.TID898.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/2.delta
[2025-07-19T20:31:09.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/95/2.delta
[2025-07-19T20:31:09.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T20:31:09.387+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a411fa9
[2025-07-19T20:31:09.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=102, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=102),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102] for update
[2025-07-19T20:31:09.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 95 (task 898, attempt 0, stage 9.0)
[2025-07-19T20:31:09.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 95.0 in stage 9.0 (TID 898). 5829 bytes result sent to driver
[2025-07-19T20:31:09.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 103.0 in stage 9.0 (TID 906) (8b44f3d35cfa, executor driver, partition 103, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/.2.delta.9697b775-d2b2-41d5-aff4-765c3bc5ba27.TID901.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/2.delta
[2025-07-19T20:31:09.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/98/2.delta
[2025-07-19T20:31:09.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T20:31:09.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/.2.delta.17187288-5022-4c74-93d1-0400d9e36873.TID900.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/2.delta
[2025-07-19T20:31:09.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 95.0 in stage 9.0 (TID 898) in 85 ms on 8b44f3d35cfa (executor driver) (96/200)
[2025-07-19T20:31:09.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 103.0 in stage 9.0 (TID 906)
[2025-07-19T20:31:09.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/97/2.delta
[2025-07-19T20:31:09.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 98 (task 901, attempt 0, stage 9.0)
[2025-07-19T20:31:09.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 98.0 in stage 9.0 (TID 901). 5829 bytes result sent to driver
[2025-07-19T20:31:09.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 104.0 in stage 9.0 (TID 907) (8b44f3d35cfa, executor driver, partition 104, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T20:31:09.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/.2.delta.d2d60ed7-8700-4349-ae3c-7308305cd7f8.TID899.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/2.delta
[2025-07-19T20:31:09.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 104.0 in stage 9.0 (TID 907)
[2025-07-19T20:31:09.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/96/2.delta
[2025-07-19T20:31:09.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 98.0 in stage 9.0 (TID 901) in 90 ms on 8b44f3d35cfa (executor driver) (97/200)
[2025-07-19T20:31:09.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.2.delta.2799ff10-ecde-4eac-a3ef-b6bee6c39062.TID904.tmp
[2025-07-19T20:31:09.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T20:31:09.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2333e343
[2025-07-19T20:31:09.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=103, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=103),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103] for update
[2025-07-19T20:31:09.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 97 (task 900, attempt 0, stage 9.0)
[2025-07-19T20:31:09.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@31c9517c
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=104, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=104),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104] for update
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 97.0 in stage 9.0 (TID 900). 5872 bytes result sent to driver
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 105.0 in stage 9.0 (TID 908) (8b44f3d35cfa, executor driver, partition 105, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 97.0 in stage 9.0 (TID 900) in 98 ms on 8b44f3d35cfa (executor driver) (98/200)
[2025-07-19T20:31:09.411+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 105.0 in stage 9.0 (TID 908)
[2025-07-19T20:31:09.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.2.delta.c42a4181-009e-4963-93ac-89cbf183fd89.TID905.tmp
[2025-07-19T20:31:09.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 96 (task 899, attempt 0, stage 9.0)
[2025-07-19T20:31:09.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 96.0 in stage 9.0 (TID 899). 5829 bytes result sent to driver
[2025-07-19T20:31:09.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2eff5937
[2025-07-19T20:31:09.414+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 106.0 in stage 9.0 (TID 909) (8b44f3d35cfa, executor driver, partition 106, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 96.0 in stage 9.0 (TID 899) in 105 ms on 8b44f3d35cfa (executor driver) (99/200)
[2025-07-19T20:31:09.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 106.0 in stage 9.0 (TID 909)
[2025-07-19T20:31:09.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=105, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=105),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105] for update
[2025-07-19T20:31:09.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59f3d960
[2025-07-19T20:31:09.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=106, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=106),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106] for update
[2025-07-19T20:31:09.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.2.delta.717373a1-e1ea-4104-87e7-20e9b0e07dc7.TID906.tmp
[2025-07-19T20:31:09.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/.2.delta.7129eaa9-7daa-4fa9-8fd3-5e7820595592.TID903.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/2.delta
[2025-07-19T20:31:09.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/100/2.delta
[2025-07-19T20:31:09.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T20:31:09.423+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.2.delta.47b1a81c-0f04-4431-ab23-939a498cbb32.TID907.tmp
[2025-07-19T20:31:09.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 100 (task 903, attempt 0, stage 9.0)
[2025-07-19T20:31:09.424+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 100.0 in stage 9.0 (TID 903). 5829 bytes result sent to driver
[2025-07-19T20:31:09.425+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 107.0 in stage 9.0 (TID 910) (8b44f3d35cfa, executor driver, partition 107, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.426+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 100.0 in stage 9.0 (TID 903) in 72 ms on 8b44f3d35cfa (executor driver) (100/200)
[2025-07-19T20:31:09.427+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 107.0 in stage 9.0 (TID 910)
[2025-07-19T20:31:09.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.428+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c65678d
[2025-07-19T20:31:09.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.2.delta.9daa2895-c6d7-4856-90f9-d9d699aefad3.TID908.tmp
[2025-07-19T20:31:09.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=107, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=107),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107] for update
[2025-07-19T20:31:09.431+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.2.delta.d13cc4ba-1e21-4291-b728-b5039c45bf3b.TID909.tmp
[2025-07-19T20:31:09.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/.2.delta.7b3cc467-2df4-4fdf-81b7-ef99da759a3c.TID902.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/2.delta
[2025-07-19T20:31:09.432+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/99/2.delta
[2025-07-19T20:31:09.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T20:31:09.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 99 (task 902, attempt 0, stage 9.0)
[2025-07-19T20:31:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 99.0 in stage 9.0 (TID 902). 5829 bytes result sent to driver
[2025-07-19T20:31:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 108.0 in stage 9.0 (TID 911) (8b44f3d35cfa, executor driver, partition 108, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 99.0 in stage 9.0 (TID 902) in 102 ms on 8b44f3d35cfa (executor driver) (101/200)
[2025-07-19T20:31:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 108.0 in stage 9.0 (TID 911)
[2025-07-19T20:31:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7dec7a26
[2025-07-19T20:31:09.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=108, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=108),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108] for update
[2025-07-19T20:31:09.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.2.delta.62e856c2-6f3e-4783-9ac0-afc388081597.TID910.tmp
[2025-07-19T20:31:09.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/.2.delta.c42a4181-009e-4963-93ac-89cbf183fd89.TID905.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/2.delta
[2025-07-19T20:31:09.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/102/2.delta
[2025-07-19T20:31:09.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T20:31:09.451+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/.2.delta.2799ff10-ecde-4eac-a3ef-b6bee6c39062.TID904.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/2.delta
[2025-07-19T20:31:09.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/101/2.delta
[2025-07-19T20:31:09.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.2.delta.a3854969-cb5d-4a68-8163-d7d937490509.TID911.tmp
[2025-07-19T20:31:09.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T20:31:09.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 102 (task 905, attempt 0, stage 9.0)
[2025-07-19T20:31:09.454+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 101 (task 904, attempt 0, stage 9.0)
[2025-07-19T20:31:09.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/.2.delta.717373a1-e1ea-4104-87e7-20e9b0e07dc7.TID906.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/2.delta
[2025-07-19T20:31:09.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/103/2.delta
[2025-07-19T20:31:09.457+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T20:31:09.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 102.0 in stage 9.0 (TID 905). 5872 bytes result sent to driver
[2025-07-19T20:31:09.459+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/.2.delta.47b1a81c-0f04-4431-ab23-939a498cbb32.TID907.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/2.delta
[2025-07-19T20:31:09.460+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/104/2.delta
[2025-07-19T20:31:09.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 101.0 in stage 9.0 (TID 904). 5915 bytes result sent to driver
[2025-07-19T20:31:09.461+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 109.0 in stage 9.0 (TID 912) (8b44f3d35cfa, executor driver, partition 109, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T20:31:09.465+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 109.0 in stage 9.0 (TID 912)
[2025-07-19T20:31:09.466+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 103 (task 906, attempt 0, stage 9.0)
[2025-07-19T20:31:09.468+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 110.0 in stage 9.0 (TID 913) (8b44f3d35cfa, executor driver, partition 110, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.469+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 101.0 in stage 9.0 (TID 904) in 100 ms on 8b44f3d35cfa (executor driver) (102/200)
[2025-07-19T20:31:09.470+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 102.0 in stage 9.0 (TID 905) in 92 ms on 8b44f3d35cfa (executor driver) (103/200)
[2025-07-19T20:31:09.471+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 110.0 in stage 9.0 (TID 913)
[2025-07-19T20:31:09.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 103.0 in stage 9.0 (TID 906). 5872 bytes result sent to driver
[2025-07-19T20:31:09.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 111.0 in stage 9.0 (TID 914) (8b44f3d35cfa, executor driver, partition 111, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.472+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 111.0 in stage 9.0 (TID 914)
[2025-07-19T20:31:09.473+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 104 (task 907, attempt 0, stage 9.0)
[2025-07-19T20:31:09.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 104.0 in stage 9.0 (TID 907). 5872 bytes result sent to driver
[2025-07-19T20:31:09.474+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 112.0 in stage 9.0 (TID 915) (8b44f3d35cfa, executor driver, partition 112, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.475+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.477+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.478+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3231eaf5
[2025-07-19T20:31:09.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 112.0 in stage 9.0 (TID 915)
[2025-07-19T20:31:09.479+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=109, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=109),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109] for update
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 103.0 in stage 9.0 (TID 906) in 87 ms on 8b44f3d35cfa (executor driver) (104/200)
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 104.0 in stage 9.0 (TID 907) in 80 ms on 8b44f3d35cfa (executor driver) (105/200)
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.480+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@410f4deb
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=111, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=111),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111] for update
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.481+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@223caef6
[2025-07-19T20:31:09.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=110, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.483+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=110),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110] for update
[2025-07-19T20:31:09.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3a6cafb7
[2025-07-19T20:31:09.484+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=112, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.485+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=112),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112] for update
[2025-07-19T20:31:09.486+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.487+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/.2.delta.d13cc4ba-1e21-4291-b728-b5039c45bf3b.TID909.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/2.delta
[2025-07-19T20:31:09.488+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/106/2.delta
[2025-07-19T20:31:09.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T20:31:09.489+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/.2.delta.9daa2895-c6d7-4856-90f9-d9d699aefad3.TID908.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/2.delta
[2025-07-19T20:31:09.490+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/105/2.delta
[2025-07-19T20:31:09.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T20:31:09.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.2.delta.18626711-312b-4ced-a789-156a755a7564.TID914.tmp
[2025-07-19T20:31:09.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.2.delta.e045b4dd-b427-4dc0-a1fa-25fdc9e335dd.TID912.tmp
[2025-07-19T20:31:09.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.2.delta.f4beaba6-379a-49b8-a5dd-b4e0ff55fa75.TID913.tmp
[2025-07-19T20:31:09.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 105 (task 908, attempt 0, stage 9.0)
[2025-07-19T20:31:09.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 105.0 in stage 9.0 (TID 908). 5872 bytes result sent to driver
[2025-07-19T20:31:09.495+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.2.delta.1fbad2c5-1913-4051-bd34-3f37f5580d20.TID915.tmp
[2025-07-19T20:31:09.496+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 106 (task 909, attempt 0, stage 9.0)
[2025-07-19T20:31:09.497+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/.2.delta.62e856c2-6f3e-4783-9ac0-afc388081597.TID910.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/2.delta
[2025-07-19T20:31:09.498+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/107/2.delta
[2025-07-19T20:31:09.499+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 106.0 in stage 9.0 (TID 909). 5872 bytes result sent to driver
[2025-07-19T20:31:09.501+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T20:31:09.503+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 113.0 in stage 9.0 (TID 916) (8b44f3d35cfa, executor driver, partition 113, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.505+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 114.0 in stage 9.0 (TID 917) (8b44f3d35cfa, executor driver, partition 114, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.507+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 105.0 in stage 9.0 (TID 908) in 107 ms on 8b44f3d35cfa (executor driver) (106/200)
[2025-07-19T20:31:09.509+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 106.0 in stage 9.0 (TID 909) in 103 ms on 8b44f3d35cfa (executor driver) (107/200)
[2025-07-19T20:31:09.511+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 107 (task 910, attempt 0, stage 9.0)
[2025-07-19T20:31:09.512+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 113.0 in stage 9.0 (TID 916)
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 107.0 in stage 9.0 (TID 910). 5872 bytes result sent to driver
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 115.0 in stage 9.0 (TID 918) (8b44f3d35cfa, executor driver, partition 115, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 115.0 in stage 9.0 (TID 918)
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 107.0 in stage 9.0 (TID 910) in 94 ms on 8b44f3d35cfa (executor driver) (108/200)
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.513+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 114.0 in stage 9.0 (TID 917)
[2025-07-19T20:31:09.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.516+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.517+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.517+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@282965c6
[2025-07-19T20:31:09.518+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=113, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.519+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=113),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113] for update
[2025-07-19T20:31:09.522+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@f39a560
[2025-07-19T20:31:09.525+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=115, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.528+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=115),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115] for update
[2025-07-19T20:31:09.533+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a226a6e
[2025-07-19T20:31:09.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=114, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.534+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=114),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114] for update
[2025-07-19T20:31:09.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/.2.delta.a3854969-cb5d-4a68-8163-d7d937490509.TID911.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/2.delta
[2025-07-19T20:31:09.536+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/108/2.delta
[2025-07-19T20:31:09.537+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T20:31:09.539+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 108 (task 911, attempt 0, stage 9.0)
[2025-07-19T20:31:09.540+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 108.0 in stage 9.0 (TID 911). 5872 bytes result sent to driver
[2025-07-19T20:31:09.541+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 108.0 in stage 9.0 (TID 911) in 111 ms on 8b44f3d35cfa (executor driver) (109/200)
[2025-07-19T20:31:09.542+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 116.0 in stage 9.0 (TID 919) (8b44f3d35cfa, executor driver, partition 116, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.561+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 116.0 in stage 9.0 (TID 919)
[2025-07-19T20:31:09.562+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/.2.delta.e045b4dd-b427-4dc0-a1fa-25fdc9e335dd.TID912.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/2.delta
[2025-07-19T20:31:09.563+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/109/2.delta
[2025-07-19T20:31:09.564+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T20:31:09.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.2.delta.056a01f2-8e76-453a-8df7-09cfec7c9343.TID917.tmp
[2025-07-19T20:31:09.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a78edba
[2025-07-19T20:31:09.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.2.delta.5ebd6ef0-6aeb-416b-bf2d-e38cc6e24c02.TID918.tmp
[2025-07-19T20:31:09.567+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/.2.delta.18626711-312b-4ced-a789-156a755a7564.TID914.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/2.delta
[2025-07-19T20:31:09.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/111/2.delta
[2025-07-19T20:31:09.571+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=116, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.572+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=116),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116] for update
[2025-07-19T20:31:09.574+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T20:31:09.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 8b44f3d35cfa:36593 in memory (size: 29.6 KiB, free: 434.3 MiB)
[2025-07-19T20:31:09.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.575+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 109 (task 912, attempt 0, stage 9.0)
[2025-07-19T20:31:09.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 109.0 in stage 9.0 (TID 912). 5829 bytes result sent to driver
[2025-07-19T20:31:09.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 117.0 in stage 9.0 (TID 920) (8b44f3d35cfa, executor driver, partition 117, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.576+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.2.delta.57d28359-f03c-4da1-b28a-047c4eb3ba44.TID916.tmp
[2025-07-19T20:31:09.578+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 117.0 in stage 9.0 (TID 920)
[2025-07-19T20:31:09.580+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 111 (task 914, attempt 0, stage 9.0)
[2025-07-19T20:31:09.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 111.0 in stage 9.0 (TID 914). 5829 bytes result sent to driver
[2025-07-19T20:31:09.582+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 109.0 in stage 9.0 (TID 912) in 114 ms on 8b44f3d35cfa (executor driver) (110/200)
[2025-07-19T20:31:09.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 111.0 in stage 9.0 (TID 914) in 110 ms on 8b44f3d35cfa (executor driver) (111/200)
[2025-07-19T20:31:09.585+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 118.0 in stage 9.0 (TID 921) (8b44f3d35cfa, executor driver, partition 118, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.586+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 118.0 in stage 9.0 (TID 921)
[2025-07-19T20:31:09.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@199c85f1
[2025-07-19T20:31:09.587+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=117, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=117),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117] for update
[2025-07-19T20:31:09.588+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.591+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59e85787
[2025-07-19T20:31:09.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=118, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=118),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118] for update
[2025-07-19T20:31:09.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.2.delta.8ef36f9c-884d-4fad-94f1-cbd32778a794.TID919.tmp
[2025-07-19T20:31:09.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.594+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 8b44f3d35cfa:36593 in memory (size: 35.4 KiB, free: 434.3 MiB)
[2025-07-19T20:31:09.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/.2.delta.f4beaba6-379a-49b8-a5dd-b4e0ff55fa75.TID913.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/2.delta
[2025-07-19T20:31:09.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/110/2.delta
[2025-07-19T20:31:09.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.2.delta.ef9d85bd-209e-45ed-ab1c-5fcb9083fdab.TID920.tmp
[2025-07-19T20:31:09.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T20:31:09.603+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.2.delta.087c82c3-ec4c-439e-b8cf-642f4f59b577.TID921.tmp
[2025-07-19T20:31:09.604+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/.2.delta.1fbad2c5-1913-4051-bd34-3f37f5580d20.TID915.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/2.delta
[2025-07-19T20:31:09.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/112/2.delta
[2025-07-19T20:31:09.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T20:31:09.605+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 110 (task 913, attempt 0, stage 9.0)
[2025-07-19T20:31:09.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 110.0 in stage 9.0 (TID 913). 5829 bytes result sent to driver
[2025-07-19T20:31:09.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 119.0 in stage 9.0 (TID 922) (8b44f3d35cfa, executor driver, partition 119, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.606+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 110.0 in stage 9.0 (TID 913) in 142 ms on 8b44f3d35cfa (executor driver) (112/200)
[2025-07-19T20:31:09.607+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 119.0 in stage 9.0 (TID 922)
[2025-07-19T20:31:09.610+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@54eaf8cb
[2025-07-19T20:31:09.611+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=119, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=119),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119] for update
[2025-07-19T20:31:09.612+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 112 (task 915, attempt 0, stage 9.0)
[2025-07-19T20:31:09.615+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 112.0 in stage 9.0 (TID 915). 5786 bytes result sent to driver
[2025-07-19T20:31:09.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 120.0 in stage 9.0 (TID 923) (8b44f3d35cfa, executor driver, partition 120, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.616+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 112.0 in stage 9.0 (TID 915) in 148 ms on 8b44f3d35cfa (executor driver) (113/200)
[2025-07-19T20:31:09.618+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 120.0 in stage 9.0 (TID 923)
[2025-07-19T20:31:09.619+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.620+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4b40f071
[2025-07-19T20:31:09.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=120, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.621+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=120),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120] for update
[2025-07-19T20:31:09.623+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/.2.delta.056a01f2-8e76-453a-8df7-09cfec7c9343.TID917.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/2.delta
[2025-07-19T20:31:09.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/114/2.delta
[2025-07-19T20:31:09.624+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T20:31:09.625+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.2.delta.f4e27ef0-ec01-4181-b549-e8c4395ebbd3.TID922.tmp
[2025-07-19T20:31:09.629+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 114 (task 917, attempt 0, stage 9.0)
[2025-07-19T20:31:09.630+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 114.0 in stage 9.0 (TID 917). 5829 bytes result sent to driver
[2025-07-19T20:31:09.631+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 121.0 in stage 9.0 (TID 924) (8b44f3d35cfa, executor driver, partition 121, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/.2.delta.5ebd6ef0-6aeb-416b-bf2d-e38cc6e24c02.TID918.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/2.delta
[2025-07-19T20:31:09.632+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/115/2.delta
[2025-07-19T20:31:09.633+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T20:31:09.633+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 121.0 in stage 9.0 (TID 924)
[2025-07-19T20:31:09.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 114.0 in stage 9.0 (TID 917) in 131 ms on 8b44f3d35cfa (executor driver) (114/200)
[2025-07-19T20:31:09.634+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.2.delta.50355fe5-952b-4163-bbdd-faf5ac029e2d.TID923.tmp
[2025-07-19T20:31:09.635+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.635+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.637+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@61afc51c
[2025-07-19T20:31:09.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/.2.delta.57d28359-f03c-4da1-b28a-047c4eb3ba44.TID916.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/2.delta
[2025-07-19T20:31:09.638+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/113/2.delta
[2025-07-19T20:31:09.639+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=121, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=121),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121] for update
[2025-07-19T20:31:09.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T20:31:09.640+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 115 (task 918, attempt 0, stage 9.0)
[2025-07-19T20:31:09.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 115.0 in stage 9.0 (TID 918). 5829 bytes result sent to driver
[2025-07-19T20:31:09.641+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 115.0 in stage 9.0 (TID 918) in 130 ms on 8b44f3d35cfa (executor driver) (115/200)
[2025-07-19T20:31:09.642+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 122.0 in stage 9.0 (TID 925) (8b44f3d35cfa, executor driver, partition 122, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.643+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 122.0 in stage 9.0 (TID 925)
[2025-07-19T20:31:09.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 113 (task 916, attempt 0, stage 9.0)
[2025-07-19T20:31:09.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 113.0 in stage 9.0 (TID 916). 5829 bytes result sent to driver
[2025-07-19T20:31:09.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 113.0 in stage 9.0 (TID 916) in 143 ms on 8b44f3d35cfa (executor driver) (116/200)
[2025-07-19T20:31:09.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.644+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 123.0 in stage 9.0 (TID 926) (8b44f3d35cfa, executor driver, partition 123, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.645+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 123.0 in stage 9.0 (TID 926)
[2025-07-19T20:31:09.646+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/.2.delta.8ef36f9c-884d-4fad-94f1-cbd32778a794.TID919.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/2.delta
[2025-07-19T20:31:09.647+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.648+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/116/2.delta
[2025-07-19T20:31:09.650+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T20:31:09.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@716a117f
[2025-07-19T20:31:09.651+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=122, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=122),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122] for update
[2025-07-19T20:31:09.652+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1bc93b26
[2025-07-19T20:31:09.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=123, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.653+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=123),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123] for update
[2025-07-19T20:31:09.654+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.655+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 116 (task 919, attempt 0, stage 9.0)
[2025-07-19T20:31:09.656+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.2.delta.e8d55f23-4d7c-462f-b247-7b6b4c21f880.TID924.tmp
[2025-07-19T20:31:09.657+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 116.0 in stage 9.0 (TID 919). 5829 bytes result sent to driver
[2025-07-19T20:31:09.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/.2.delta.ef9d85bd-209e-45ed-ab1c-5fcb9083fdab.TID920.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/2.delta
[2025-07-19T20:31:09.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/117/2.delta
[2025-07-19T20:31:09.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 124.0 in stage 9.0 (TID 927) (8b44f3d35cfa, executor driver, partition 124, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.658+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T20:31:09.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 124.0 in stage 9.0 (TID 927)
[2025-07-19T20:31:09.659+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 116.0 in stage 9.0 (TID 919) in 117 ms on 8b44f3d35cfa (executor driver) (117/200)
[2025-07-19T20:31:09.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.660+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@10adae85
[2025-07-19T20:31:09.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=124, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.661+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=124),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124] for update
[2025-07-19T20:31:09.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.665+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 117 (task 920, attempt 0, stage 9.0)
[2025-07-19T20:31:09.666+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 117.0 in stage 9.0 (TID 920). 5829 bytes result sent to driver
[2025-07-19T20:31:09.667+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 125.0 in stage 9.0 (TID 928) (8b44f3d35cfa, executor driver, partition 125, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 117.0 in stage 9.0 (TID 920) in 96 ms on 8b44f3d35cfa (executor driver) (118/200)
[2025-07-19T20:31:09.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 125.0 in stage 9.0 (TID 928)
[2025-07-19T20:31:09.669+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.671+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@b958ca1
[2025-07-19T20:31:09.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=125, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=125),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125] for update
[2025-07-19T20:31:09.674+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.2.delta.bac949dd-f980-4c20-9e58-061c0f0c875b.TID926.tmp
[2025-07-19T20:31:09.676+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/.2.delta.087c82c3-ec4c-439e-b8cf-642f4f59b577.TID921.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/2.delta
[2025-07-19T20:31:09.679+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/118/2.delta
[2025-07-19T20:31:09.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.2.delta.cc1634e4-1634-4da6-ab9c-d7b4bb60e066.TID925.tmp
[2025-07-19T20:31:09.680+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T20:31:09.681+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/.2.delta.f4e27ef0-ec01-4181-b549-e8c4395ebbd3.TID922.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/2.delta
[2025-07-19T20:31:09.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/119/2.delta
[2025-07-19T20:31:09.682+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T20:31:09.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.2.delta.dd85b723-a0f3-4f68-8e0a-d73d7c918c47.TID927.tmp
[2025-07-19T20:31:09.683+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 118 (task 921, attempt 0, stage 9.0)
[2025-07-19T20:31:09.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 118.0 in stage 9.0 (TID 921). 5829 bytes result sent to driver
[2025-07-19T20:31:09.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 126.0 in stage 9.0 (TID 929) (8b44f3d35cfa, executor driver, partition 126, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.686+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 126.0 in stage 9.0 (TID 929)
[2025-07-19T20:31:09.689+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 118.0 in stage 9.0 (TID 921) in 103 ms on 8b44f3d35cfa (executor driver) (119/200)
[2025-07-19T20:31:09.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.2.delta.fce1ab86-2c1d-4797-a95d-558553156408.TID928.tmp
[2025-07-19T20:31:09.691+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/.2.delta.50355fe5-952b-4163-bbdd-faf5ac029e2d.TID923.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/2.delta
[2025-07-19T20:31:09.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/120/2.delta
[2025-07-19T20:31:09.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f295516
[2025-07-19T20:31:09.692+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=126, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=126),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126] for update
[2025-07-19T20:31:09.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T20:31:09.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.693+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 119 (task 922, attempt 0, stage 9.0)
[2025-07-19T20:31:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 119.0 in stage 9.0 (TID 922). 5829 bytes result sent to driver
[2025-07-19T20:31:09.694+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 127.0 in stage 9.0 (TID 930) (8b44f3d35cfa, executor driver, partition 127, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.696+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 127.0 in stage 9.0 (TID 930)
[2025-07-19T20:31:09.696+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 119.0 in stage 9.0 (TID 922) in 82 ms on 8b44f3d35cfa (executor driver) (120/200)
[2025-07-19T20:31:09.696+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 120 (task 923, attempt 0, stage 9.0)
[2025-07-19T20:31:09.697+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 120.0 in stage 9.0 (TID 923). 5829 bytes result sent to driver
[2025-07-19T20:31:09.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.698+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 128.0 in stage 9.0 (TID 931) (8b44f3d35cfa, executor driver, partition 128, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 120.0 in stage 9.0 (TID 923) in 77 ms on 8b44f3d35cfa (executor driver) (121/200)
[2025-07-19T20:31:09.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38389988
[2025-07-19T20:31:09.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=127, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.699+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=127),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127] for update
[2025-07-19T20:31:09.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 128.0 in stage 9.0 (TID 931)
[2025-07-19T20:31:09.700+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.701+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@12e6745a
[2025-07-19T20:31:09.702+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=128, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=128),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128] for update
[2025-07-19T20:31:09.703+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.704+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.2.delta.23ee1e76-bedd-44ab-84fe-8eecb34081c3.TID929.tmp
[2025-07-19T20:31:09.706+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.2.delta.d0885e8c-2abb-4769-b232-ecad1e0d669a.TID930.tmp
[2025-07-19T20:31:09.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.2.delta.05f4b23b-4136-4049-8b3e-19b962f5bda5.TID931.tmp
[2025-07-19T20:31:09.709+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/.2.delta.e8d55f23-4d7c-462f-b247-7b6b4c21f880.TID924.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/2.delta
[2025-07-19T20:31:09.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/121/2.delta
[2025-07-19T20:31:09.710+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T20:31:09.713+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 121 (task 924, attempt 0, stage 9.0)
[2025-07-19T20:31:09.715+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 121.0 in stage 9.0 (TID 924). 5829 bytes result sent to driver
[2025-07-19T20:31:09.718+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 129.0 in stage 9.0 (TID 932) (8b44f3d35cfa, executor driver, partition 129, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.720+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 129.0 in stage 9.0 (TID 932)
[2025-07-19T20:31:09.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 121.0 in stage 9.0 (TID 924) in 87 ms on 8b44f3d35cfa (executor driver) (122/200)
[2025-07-19T20:31:09.721+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.722+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/.2.delta.bac949dd-f980-4c20-9e58-061c0f0c875b.TID926.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/2.delta
[2025-07-19T20:31:09.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/123/2.delta
[2025-07-19T20:31:09.723+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/.2.delta.cc1634e4-1634-4da6-ab9c-d7b4bb60e066.TID925.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/2.delta
[2025-07-19T20:31:09.724+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/122/2.delta
[2025-07-19T20:31:09.725+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1cc06f79
[2025-07-19T20:31:09.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T20:31:09.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T20:31:09.726+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=129, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.727+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=129),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129] for update
[2025-07-19T20:31:09.729+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.732+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 123 (task 926, attempt 0, stage 9.0)
[2025-07-19T20:31:09.733+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 123.0 in stage 9.0 (TID 926). 5829 bytes result sent to driver
[2025-07-19T20:31:09.734+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 122 (task 925, attempt 0, stage 9.0)
[2025-07-19T20:31:09.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 122.0 in stage 9.0 (TID 925). 5829 bytes result sent to driver
[2025-07-19T20:31:09.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 130.0 in stage 9.0 (TID 933) (8b44f3d35cfa, executor driver, partition 130, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.736+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 130.0 in stage 9.0 (TID 933)
[2025-07-19T20:31:09.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 131.0 in stage 9.0 (TID 934) (8b44f3d35cfa, executor driver, partition 131, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/.2.delta.fce1ab86-2c1d-4797-a95d-558553156408.TID928.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/2.delta
[2025-07-19T20:31:09.737+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/125/2.delta
[2025-07-19T20:31:09.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 123.0 in stage 9.0 (TID 926) in 84 ms on 8b44f3d35cfa (executor driver) (123/200)
[2025-07-19T20:31:09.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T20:31:09.738+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 122.0 in stage 9.0 (TID 925) in 90 ms on 8b44f3d35cfa (executor driver) (124/200)
[2025-07-19T20:31:09.739+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/.2.delta.dd85b723-a0f3-4f68-8e0a-d73d7c918c47.TID927.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/2.delta
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/124/2.delta
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 131.0 in stage 9.0 (TID 934)
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 125 (task 928, attempt 0, stage 9.0)
[2025-07-19T20:31:09.740+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 125.0 in stage 9.0 (TID 928). 5829 bytes result sent to driver
[2025-07-19T20:31:09.741+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 125.0 in stage 9.0 (TID 928) in 67 ms on 8b44f3d35cfa (executor driver) (125/200)
[2025-07-19T20:31:09.742+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 132.0 in stage 9.0 (TID 935) (8b44f3d35cfa, executor driver, partition 132, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.743+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 132.0 in stage 9.0 (TID 935)
[2025-07-19T20:31:09.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.2.delta.046db0e1-d079-4cfa-9da5-1ff7819e4a66.TID932.tmp
[2025-07-19T20:31:09.745+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.747+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b6800ff
[2025-07-19T20:31:09.748+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.749+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.750+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 124 (task 927, attempt 0, stage 9.0)
[2025-07-19T20:31:09.751+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=130, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.752+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=130),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130] for update
[2025-07-19T20:31:09.754+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/.2.delta.23ee1e76-bedd-44ab-84fe-8eecb34081c3.TID929.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/2.delta
[2025-07-19T20:31:09.755+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@d88f849
[2025-07-19T20:31:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/126/2.delta
[2025-07-19T20:31:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=131, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T20:31:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=131),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131] for update
[2025-07-19T20:31:09.756+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 124.0 in stage 9.0 (TID 927). 5872 bytes result sent to driver
[2025-07-19T20:31:09.757+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1432baac
[2025-07-19T20:31:09.758+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.759+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=132, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=132),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132] for update
[2025-07-19T20:31:09.760+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 133.0 in stage 9.0 (TID 936) (8b44f3d35cfa, executor driver, partition 133, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.763+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 133.0 in stage 9.0 (TID 936)
[2025-07-19T20:31:09.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 124.0 in stage 9.0 (TID 927) in 90 ms on 8b44f3d35cfa (executor driver) (126/200)
[2025-07-19T20:31:09.764+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 126 (task 929, attempt 0, stage 9.0)
[2025-07-19T20:31:09.765+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 126.0 in stage 9.0 (TID 929). 5829 bytes result sent to driver
[2025-07-19T20:31:09.768+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 134.0 in stage 9.0 (TID 937) (8b44f3d35cfa, executor driver, partition 134, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.769+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 134.0 in stage 9.0 (TID 937)
[2025-07-19T20:31:09.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 126.0 in stage 9.0 (TID 929) in 67 ms on 8b44f3d35cfa (executor driver) (127/200)
[2025-07-19T20:31:09.771+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.772+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.773+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4297fc9d
[2025-07-19T20:31:09.774+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=133, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=133),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133] for update
[2025-07-19T20:31:09.775+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/.2.delta.05f4b23b-4136-4049-8b3e-19b962f5bda5.TID931.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/2.delta
[2025-07-19T20:31:09.776+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/128/2.delta
[2025-07-19T20:31:09.777+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T20:31:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.2.delta.3fa96eb7-dbce-4f83-a459-7c2f53ad0a25.TID934.tmp
[2025-07-19T20:31:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6e84505c
[2025-07-19T20:31:09.778+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=134, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.779+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=134),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134] for update
[2025-07-19T20:31:09.780+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 128 (task 931, attempt 0, stage 9.0)
[2025-07-19T20:31:09.781+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.2.delta.5f75600e-2c27-420e-8496-e0e6d7265b2e.TID933.tmp
[2025-07-19T20:31:09.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 128.0 in stage 9.0 (TID 931). 5829 bytes result sent to driver
[2025-07-19T20:31:09.782+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 135.0 in stage 9.0 (TID 938) (8b44f3d35cfa, executor driver, partition 135, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.783+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 128.0 in stage 9.0 (TID 931) in 64 ms on 8b44f3d35cfa (executor driver) (128/200)
[2025-07-19T20:31:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 135.0 in stage 9.0 (TID 938)
[2025-07-19T20:31:09.784+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.2.delta.5c5e659c-f351-444f-99e9-a3e1b3f3225c.TID935.tmp
[2025-07-19T20:31:09.785+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.786+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:09.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@374b9f5d
[2025-07-19T20:31:09.787+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=135, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.789+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=135),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135] for update
[2025-07-19T20:31:09.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/.2.delta.d0885e8c-2abb-4769-b232-ecad1e0d669a.TID930.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/2.delta
[2025-07-19T20:31:09.790+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/127/2.delta
[2025-07-19T20:31:09.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T20:31:09.791+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.792+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.2.delta.3d248ecc-683c-4ff0-b48a-da48579d0e06.TID937.tmp
[2025-07-19T20:31:09.793+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 127 (task 930, attempt 0, stage 9.0)
[2025-07-19T20:31:09.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 127.0 in stage 9.0 (TID 930). 5829 bytes result sent to driver
[2025-07-19T20:31:09.794+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 136.0 in stage 9.0 (TID 939) (8b44f3d35cfa, executor driver, partition 136, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 136.0 in stage 9.0 (TID 939)
[2025-07-19T20:31:09.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 127.0 in stage 9.0 (TID 930) in 81 ms on 8b44f3d35cfa (executor driver) (129/200)
[2025-07-19T20:31:09.796+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.797+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.2.delta.183b7c83-2436-4895-a3d5-0a3c67bc399b.TID936.tmp
[2025-07-19T20:31:09.799+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6bc030d0
[2025-07-19T20:31:09.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=136, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=136),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136] for update
[2025-07-19T20:31:09.800+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.801+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/.2.delta.046db0e1-d079-4cfa-9da5-1ff7819e4a66.TID932.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/2.delta
[2025-07-19T20:31:09.802+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/129/2.delta
[2025-07-19T20:31:09.804+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T20:31:09.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.2.delta.df062cfe-977b-4a56-9373-d90900995a27.TID938.tmp
[2025-07-19T20:31:09.806+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.2.delta.5653eda7-6490-442f-b35d-8249d8cffa5d.TID939.tmp
[2025-07-19T20:31:09.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 129 (task 932, attempt 0, stage 9.0)
[2025-07-19T20:31:09.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 129.0 in stage 9.0 (TID 932). 5829 bytes result sent to driver
[2025-07-19T20:31:09.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 137.0 in stage 9.0 (TID 940) (8b44f3d35cfa, executor driver, partition 137, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.808+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 129.0 in stage 9.0 (TID 932) in 73 ms on 8b44f3d35cfa (executor driver) (130/200)
[2025-07-19T20:31:09.809+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 137.0 in stage 9.0 (TID 940)
[2025-07-19T20:31:09.811+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.814+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@370b66ba
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=137, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=137),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137] for update
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/.2.delta.3fa96eb7-dbce-4f83-a459-7c2f53ad0a25.TID934.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/2.delta
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/131/2.delta
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/.2.delta.5f75600e-2c27-420e-8496-e0e6d7265b2e.TID933.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/2.delta
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/130/2.delta
[2025-07-19T20:31:09.816+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T20:31:09.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T20:31:09.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/.2.delta.5c5e659c-f351-444f-99e9-a3e1b3f3225c.TID935.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/2.delta
[2025-07-19T20:31:09.817+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/132/2.delta
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 131 (task 934, attempt 0, stage 9.0)
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 131.0 in stage 9.0 (TID 934). 5829 bytes result sent to driver
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 130 (task 933, attempt 0, stage 9.0)
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 138.0 in stage 9.0 (TID 941) (8b44f3d35cfa, executor driver, partition 138, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 130.0 in stage 9.0 (TID 933). 5829 bytes result sent to driver
[2025-07-19T20:31:09.818+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 138.0 in stage 9.0 (TID 941)
[2025-07-19T20:31:09.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 131.0 in stage 9.0 (TID 934) in 80 ms on 8b44f3d35cfa (executor driver) (131/200)
[2025-07-19T20:31:09.820+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 139.0 in stage 9.0 (TID 942) (8b44f3d35cfa, executor driver, partition 139, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/.2.delta.3d248ecc-683c-4ff0-b48a-da48579d0e06.TID937.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/2.delta
[2025-07-19T20:31:09.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/134/2.delta
[2025-07-19T20:31:09.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 139.0 in stage 9.0 (TID 942)
[2025-07-19T20:31:09.821+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T20:31:09.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 130.0 in stage 9.0 (TID 933) in 84 ms on 8b44f3d35cfa (executor driver) (132/200)
[2025-07-19T20:31:09.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 132 (task 935, attempt 0, stage 9.0)
[2025-07-19T20:31:09.822+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 132.0 in stage 9.0 (TID 935). 5829 bytes result sent to driver
[2025-07-19T20:31:09.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:09.823+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 140.0 in stage 9.0 (TID 943) (8b44f3d35cfa, executor driver, partition 140, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 132.0 in stage 9.0 (TID 935) in 79 ms on 8b44f3d35cfa (executor driver) (133/200)
[2025-07-19T20:31:09.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 140.0 in stage 9.0 (TID 943)
[2025-07-19T20:31:09.824+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@383a9b72
[2025-07-19T20:31:09.825+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=138, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 134 (task 937, attempt 0, stage 9.0)
[2025-07-19T20:31:09.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=138),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138] for update
[2025-07-19T20:31:09.826+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.2.delta.903350f1-e006-4520-bbe6-f51019dfeac2.TID940.tmp
[2025-07-19T20:31:09.827+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.828+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.829+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 134.0 in stage 9.0 (TID 937). 5786 bytes result sent to driver
[2025-07-19T20:31:09.830+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 141.0 in stage 9.0 (TID 944) (8b44f3d35cfa, executor driver, partition 141, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 141.0 in stage 9.0 (TID 944)
[2025-07-19T20:31:09.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 134.0 in stage 9.0 (TID 937) in 68 ms on 8b44f3d35cfa (executor driver) (134/200)
[2025-07-19T20:31:09.831+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.832+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5de2653f
[2025-07-19T20:31:09.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=139, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.833+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=139),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139] for update
[2025-07-19T20:31:09.834+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@29c67fb6
[2025-07-19T20:31:09.835+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=141, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=141),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141] for update
[2025-07-19T20:31:09.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.837+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@a78a28e
[2025-07-19T20:31:09.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=140, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.838+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=140),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140] for update
[2025-07-19T20:31:09.839+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.841+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/.2.delta.5653eda7-6490-442f-b35d-8249d8cffa5d.TID939.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/2.delta
[2025-07-19T20:31:09.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/136/2.delta
[2025-07-19T20:31:09.842+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.2.delta.f3e09790-ef19-45e9-8b3a-701f5c07a7cb.TID941.tmp
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/.2.delta.df062cfe-977b-4a56-9373-d90900995a27.TID938.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/2.delta
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/135/2.delta
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.2.delta.df12f074-8736-4d06-bdc5-86d7a971b069.TID944.tmp
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/.2.delta.183b7c83-2436-4895-a3d5-0a3c67bc399b.TID936.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/2.delta
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/133/2.delta
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T20:31:09.843+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 135 (task 938, attempt 0, stage 9.0)
[2025-07-19T20:31:09.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 133 (task 936, attempt 0, stage 9.0)
[2025-07-19T20:31:09.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 133.0 in stage 9.0 (TID 936). 5829 bytes result sent to driver
[2025-07-19T20:31:09.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 136 (task 939, attempt 0, stage 9.0)
[2025-07-19T20:31:09.844+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 136.0 in stage 9.0 (TID 939). 5829 bytes result sent to driver
[2025-07-19T20:31:09.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 142.0 in stage 9.0 (TID 945) (8b44f3d35cfa, executor driver, partition 142, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.845+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 143.0 in stage 9.0 (TID 946) (8b44f3d35cfa, executor driver, partition 143, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.846+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 142.0 in stage 9.0 (TID 945)
[2025-07-19T20:31:09.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 133.0 in stage 9.0 (TID 936) in 90 ms on 8b44f3d35cfa (executor driver) (135/200)
[2025-07-19T20:31:09.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 135.0 in stage 9.0 (TID 938). 5829 bytes result sent to driver
[2025-07-19T20:31:09.847+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 143.0 in stage 9.0 (TID 946)
[2025-07-19T20:31:09.848+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 136.0 in stage 9.0 (TID 939) in 66 ms on 8b44f3d35cfa (executor driver) (136/200)
[2025-07-19T20:31:09.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 144.0 in stage 9.0 (TID 947) (8b44f3d35cfa, executor driver, partition 144, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.849+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 135.0 in stage 9.0 (TID 938) in 80 ms on 8b44f3d35cfa (executor driver) (137/200)
[2025-07-19T20:31:09.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 144.0 in stage 9.0 (TID 947)
[2025-07-19T20:31:09.850+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.851+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.852+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.853+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@21254f28
[2025-07-19T20:31:09.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=143, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.854+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=143),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143] for update
[2025-07-19T20:31:09.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3d69d0a1
[2025-07-19T20:31:09.855+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=142, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=142),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142] for update
[2025-07-19T20:31:09.856+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.2.delta.a17c180c-20da-4609-935a-7f80f8193e72.TID942.tmp
[2025-07-19T20:31:09.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2ff7ce5e
[2025-07-19T20:31:09.857+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=144, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=144),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144] for update
[2025-07-19T20:31:09.858+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.2.delta.08df6e87-68cf-4491-8890-e2303d8e1c5c.TID943.tmp
[2025-07-19T20:31:09.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.2.delta.7f702315-29e8-4734-ad35-ef822d42ab6c.TID945.tmp
[2025-07-19T20:31:09.859+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.2.delta.bb0a220b-d5cf-43a5-98d4-cfb88581aaba.TID946.tmp
[2025-07-19T20:31:09.861+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.2.delta.770cd158-e6ea-47e2-a1d7-904fc70a9a48.TID947.tmp
[2025-07-19T20:31:09.862+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/.2.delta.903350f1-e006-4520-bbe6-f51019dfeac2.TID940.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/2.delta
[2025-07-19T20:31:09.864+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/137/2.delta
[2025-07-19T20:31:09.867+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T20:31:09.871+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/.2.delta.f3e09790-ef19-45e9-8b3a-701f5c07a7cb.TID941.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/2.delta
[2025-07-19T20:31:09.872+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/138/2.delta
[2025-07-19T20:31:09.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T20:31:09.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 137 (task 940, attempt 0, stage 9.0)
[2025-07-19T20:31:09.873+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 137.0 in stage 9.0 (TID 940). 5829 bytes result sent to driver
[2025-07-19T20:31:09.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/.2.delta.df12f074-8736-4d06-bdc5-86d7a971b069.TID944.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/2.delta
[2025-07-19T20:31:09.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/141/2.delta
[2025-07-19T20:31:09.874+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T20:31:09.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 145.0 in stage 9.0 (TID 948) (8b44f3d35cfa, executor driver, partition 145, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 138 (task 941, attempt 0, stage 9.0)
[2025-07-19T20:31:09.875+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 137.0 in stage 9.0 (TID 940) in 82 ms on 8b44f3d35cfa (executor driver) (138/200)
[2025-07-19T20:31:09.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 138.0 in stage 9.0 (TID 941). 5829 bytes result sent to driver
[2025-07-19T20:31:09.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 146.0 in stage 9.0 (TID 949) (8b44f3d35cfa, executor driver, partition 146, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 145.0 in stage 9.0 (TID 948)
[2025-07-19T20:31:09.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 138.0 in stage 9.0 (TID 941) in 65 ms on 8b44f3d35cfa (executor driver) (139/200)
[2025-07-19T20:31:09.876+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 146.0 in stage 9.0 (TID 949)
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 141 (task 944, attempt 0, stage 9.0)
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 141.0 in stage 9.0 (TID 944). 5829 bytes result sent to driver
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 147.0 in stage 9.0 (TID 950) (8b44f3d35cfa, executor driver, partition 147, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 141.0 in stage 9.0 (TID 944) in 61 ms on 8b44f3d35cfa (executor driver) (140/200)
[2025-07-19T20:31:09.877+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 147.0 in stage 9.0 (TID 950)
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/.2.delta.a17c180c-20da-4609-935a-7f80f8193e72.TID942.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/2.delta
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/139/2.delta
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@56a8008d
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=145, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=145),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145] for update
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T20:31:09.878+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.879+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4a81ed73
[2025-07-19T20:31:09.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=147, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=147),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147] for update
[2025-07-19T20:31:09.882+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@490f21ef
[2025-07-19T20:31:09.883+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.884+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/.2.delta.7f702315-29e8-4734-ad35-ef822d42ab6c.TID945.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/2.delta
[2025-07-19T20:31:09.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/142/2.delta
[2025-07-19T20:31:09.885+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T20:31:09.886+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=146, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.887+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=146),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146] for update
[2025-07-19T20:31:09.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 139 (task 942, attempt 0, stage 9.0)
[2025-07-19T20:31:09.888+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 139.0 in stage 9.0 (TID 942). 5829 bytes result sent to driver
[2025-07-19T20:31:09.889+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.890+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 148.0 in stage 9.0 (TID 951) (8b44f3d35cfa, executor driver, partition 148, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 139.0 in stage 9.0 (TID 942) in 81 ms on 8b44f3d35cfa (executor driver) (141/200)
[2025-07-19T20:31:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 142 (task 945, attempt 0, stage 9.0)
[2025-07-19T20:31:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 142.0 in stage 9.0 (TID 945). 5829 bytes result sent to driver
[2025-07-19T20:31:09.891+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 149.0 in stage 9.0 (TID 952) (8b44f3d35cfa, executor driver, partition 149, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 142.0 in stage 9.0 (TID 945) in 59 ms on 8b44f3d35cfa (executor driver) (142/200)
[2025-07-19T20:31:09.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 148.0 in stage 9.0 (TID 951)
[2025-07-19T20:31:09.892+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 149.0 in stage 9.0 (TID 952)
[2025-07-19T20:31:09.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.2.delta.65f400be-6e93-4c0b-af13-5d26a43a80d3.TID948.tmp
[2025-07-19T20:31:09.893+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.894+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@39ca4c37
[2025-07-19T20:31:09.895+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=148, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=148),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148] for update
[2025-07-19T20:31:09.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5e55fb2c
[2025-07-19T20:31:09.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=149, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.896+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=149),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149] for update
[2025-07-19T20:31:09.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.898+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.900+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.2.delta.80deaf8f-1306-4d65-b533-f1f62a8085cc.TID950.tmp
[2025-07-19T20:31:09.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/.2.delta.08df6e87-68cf-4491-8890-e2303d8e1c5c.TID943.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/2.delta
[2025-07-19T20:31:09.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/140/2.delta
[2025-07-19T20:31:09.903+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T20:31:09.912+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/.2.delta.bb0a220b-d5cf-43a5-98d4-cfb88581aaba.TID946.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/2.delta
[2025-07-19T20:31:09.913+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/143/2.delta
[2025-07-19T20:31:09.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T20:31:09.914+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 140 (task 943, attempt 0, stage 9.0)
[2025-07-19T20:31:09.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 140.0 in stage 9.0 (TID 943). 5829 bytes result sent to driver
[2025-07-19T20:31:09.915+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.2.delta.4c78a05b-9147-4809-ac07-536b24d316e2.TID952.tmp
[2025-07-19T20:31:09.916+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 150.0 in stage 9.0 (TID 953) (8b44f3d35cfa, executor driver, partition 150, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.2.delta.8479a9a3-36c3-49fc-99f3-df3df4a75224.TID951.tmp
[2025-07-19T20:31:09.917+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 150.0 in stage 9.0 (TID 953)
[2025-07-19T20:31:09.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.918+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/.2.delta.770cd158-e6ea-47e2-a1d7-904fc70a9a48.TID947.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/2.delta
[2025-07-19T20:31:09.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/144/2.delta
[2025-07-19T20:31:09.919+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.2.delta.953c46de-a829-484e-8a2c-23992afb3696.TID949.tmp
[2025-07-19T20:31:09.922+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 140.0 in stage 9.0 (TID 943) in 112 ms on 8b44f3d35cfa (executor driver) (143/200)
[2025-07-19T20:31:09.923+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T20:31:09.925+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 143 (task 946, attempt 0, stage 9.0)
[2025-07-19T20:31:09.926+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 143.0 in stage 9.0 (TID 946). 5829 bytes result sent to driver
[2025-07-19T20:31:09.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 151.0 in stage 9.0 (TID 954) (8b44f3d35cfa, executor driver, partition 151, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@74301fdd
[2025-07-19T20:31:09.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=150, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=150),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150] for update
[2025-07-19T20:31:09.928+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 143.0 in stage 9.0 (TID 946) in 96 ms on 8b44f3d35cfa (executor driver) (144/200)
[2025-07-19T20:31:09.929+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 151.0 in stage 9.0 (TID 954)
[2025-07-19T20:31:09.930+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/.2.delta.65f400be-6e93-4c0b-af13-5d26a43a80d3.TID948.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/2.delta
[2025-07-19T20:31:09.931+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/145/2.delta
[2025-07-19T20:31:09.932+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.933+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T20:31:09.936+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 144 (task 947, attempt 0, stage 9.0)
[2025-07-19T20:31:09.937+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/.2.delta.80deaf8f-1306-4d65-b533-f1f62a8085cc.TID950.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/2.delta
[2025-07-19T20:31:09.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/147/2.delta
[2025-07-19T20:31:09.938+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 144.0 in stage 9.0 (TID 947). 5786 bytes result sent to driver
[2025-07-19T20:31:09.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T20:31:09.939+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 152.0 in stage 9.0 (TID 955) (8b44f3d35cfa, executor driver, partition 152, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.940+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 152.0 in stage 9.0 (TID 955)
[2025-07-19T20:31:09.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 147 (task 950, attempt 0, stage 9.0)
[2025-07-19T20:31:09.941+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 145 (task 948, attempt 0, stage 9.0)
[2025-07-19T20:31:09.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 144.0 in stage 9.0 (TID 947) in 107 ms on 8b44f3d35cfa (executor driver) (145/200)
[2025-07-19T20:31:09.942+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@25e07ac1
[2025-07-19T20:31:09.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 147.0 in stage 9.0 (TID 950). 5829 bytes result sent to driver
[2025-07-19T20:31:09.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 153.0 in stage 9.0 (TID 956) (8b44f3d35cfa, executor driver, partition 153, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.943+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=151, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=151),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151] for update
[2025-07-19T20:31:09.944+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 153.0 in stage 9.0 (TID 956)
[2025-07-19T20:31:09.945+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 145.0 in stage 9.0 (TID 948). 5829 bytes result sent to driver
[2025-07-19T20:31:09.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.946+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 154.0 in stage 9.0 (TID 957) (8b44f3d35cfa, executor driver, partition 154, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 147.0 in stage 9.0 (TID 950) in 68 ms on 8b44f3d35cfa (executor driver) (146/200)
[2025-07-19T20:31:09.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 145.0 in stage 9.0 (TID 948) in 76 ms on 8b44f3d35cfa (executor driver) (147/200)
[2025-07-19T20:31:09.947+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.948+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:09.949+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 154.0 in stage 9.0 (TID 957)
[2025-07-19T20:31:09.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7e678f82
[2025-07-19T20:31:09.950+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.2.delta.49ac1ed1-d017-4c73-9556-9bd614936ab6.TID953.tmp
[2025-07-19T20:31:09.952+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=152, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=152),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152] for update
[2025-07-19T20:31:09.953+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2025-07-19T20:31:09.954+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.955+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5efb8b0
[2025-07-19T20:31:09.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=153, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=153),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153] for update
[2025-07-19T20:31:09.956+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.957+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7ba671d4
[2025-07-19T20:31:09.958+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=154, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=154),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154] for update
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/.2.delta.953c46de-a829-484e-8a2c-23992afb3696.TID949.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/2.delta
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.2.delta.8e355f04-ff94-4b03-8e89-d69a2c5f3982.TID955.tmp
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/146/2.delta
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.2.delta.09216425-ff11-459e-a25c-02f9b5e41ae1.TID954.tmp
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/.2.delta.4c78a05b-9147-4809-ac07-536b24d316e2.TID952.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/2.delta
[2025-07-19T20:31:09.959+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/149/2.delta
[2025-07-19T20:31:09.961+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.2.delta.b5a4893d-8e49-48ef-9712-762c4e2a7039.TID956.tmp
[2025-07-19T20:31:09.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T20:31:09.963+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T20:31:09.964+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.2.delta.0f6cc35d-3446-4a7c-b62b-dda8cbd7246c.TID957.tmp
[2025-07-19T20:31:09.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 149 (task 952, attempt 0, stage 9.0)
[2025-07-19T20:31:09.969+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 149.0 in stage 9.0 (TID 952). 5829 bytes result sent to driver
[2025-07-19T20:31:09.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/.2.delta.8479a9a3-36c3-49fc-99f3-df3df4a75224.TID951.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/2.delta
[2025-07-19T20:31:09.970+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/148/2.delta
[2025-07-19T20:31:09.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T20:31:09.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 146 (task 949, attempt 0, stage 9.0)
[2025-07-19T20:31:09.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 146.0 in stage 9.0 (TID 949). 5829 bytes result sent to driver
[2025-07-19T20:31:09.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 155.0 in stage 9.0 (TID 958) (8b44f3d35cfa, executor driver, partition 155, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 149.0 in stage 9.0 (TID 952) in 78 ms on 8b44f3d35cfa (executor driver) (148/200)
[2025-07-19T20:31:09.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 156.0 in stage 9.0 (TID 959) (8b44f3d35cfa, executor driver, partition 156, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 146.0 in stage 9.0 (TID 949) in 100 ms on 8b44f3d35cfa (executor driver) (149/200)
[2025-07-19T20:31:09.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 155.0 in stage 9.0 (TID 958)
[2025-07-19T20:31:09.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 156.0 in stage 9.0 (TID 959)
[2025-07-19T20:31:09.973+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 148 (task 951, attempt 0, stage 9.0)
[2025-07-19T20:31:09.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.974+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:09.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2025-07-19T20:31:09.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 148.0 in stage 9.0 (TID 951). 5915 bytes result sent to driver
[2025-07-19T20:31:09.976+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 157.0 in stage 9.0 (TID 960) (8b44f3d35cfa, executor driver, partition 157, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 157.0 in stage 9.0 (TID 960)
[2025-07-19T20:31:09.977+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 148.0 in stage 9.0 (TID 951) in 90 ms on 8b44f3d35cfa (executor driver) (150/200)
[2025-07-19T20:31:09.978+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@40532f3e
[2025-07-19T20:31:09.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:09.979+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:09.981+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=156, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=156),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156] for update
[2025-07-19T20:31:09.982+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@657acce8
[2025-07-19T20:31:09.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=157, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.983+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=157),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157] for update
[2025-07-19T20:31:09.984+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.985+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@75b1a5a3
[2025-07-19T20:31:09.986+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=155, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:09.987+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=155),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155] for update
[2025-07-19T20:31:09.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.988+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:09.993+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/.2.delta.49ac1ed1-d017-4c73-9556-9bd614936ab6.TID953.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/2.delta
[2025-07-19T20:31:09.994+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/150/2.delta
[2025-07-19T20:31:09.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Commit authorized for partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T20:31:09.995+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO DataWritingSparkTask: Committed partition 150 (task 953, attempt 0, stage 9.0)
[2025-07-19T20:31:09.998+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Finished task 150.0 in stage 9.0 (TID 953). 5872 bytes result sent to driver
[2025-07-19T20:31:09.999+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Starting task 158.0 in stage 9.0 (TID 961) (8b44f3d35cfa, executor driver, partition 158, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:09.999+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO Executor: Running task 158.0 in stage 9.0 (TID 961)
[2025-07-19T20:31:10.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO TaskSetManager: Finished task 150.0 in stage 9.0 (TID 953) in 81 ms on 8b44f3d35cfa (executor driver) (151/200)
[2025-07-19T20:31:10.000+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.2.delta.b24a00a5-0278-4f0c-a63d-c7679dd4a0b5.TID960.tmp
[2025-07-19T20:31:10.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.2.delta.95792eed-3211-43c1-8396-0193b5b915bf.TID958.tmp
[2025-07-19T20:31:10.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.001+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1d075429
[2025-07-19T20:31:10.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=158, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.002+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=158),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158] for update
[2025-07-19T20:31:10.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:09 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.2.delta.053efa4b-cb05-4bde-b3da-9e8a38178924.TID959.tmp
[2025-07-19T20:31:10.003+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/.2.delta.09216425-ff11-459e-a25c-02f9b5e41ae1.TID954.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/2.delta
[2025-07-19T20:31:10.004+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/151/2.delta
[2025-07-19T20:31:10.005+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T20:31:10.006+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 151 (task 954, attempt 0, stage 9.0)
[2025-07-19T20:31:10.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 151.0 in stage 9.0 (TID 954). 5872 bytes result sent to driver
[2025-07-19T20:31:10.007+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 159.0 in stage 9.0 (TID 962) (8b44f3d35cfa, executor driver, partition 159, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 159.0 in stage 9.0 (TID 962)
[2025-07-19T20:31:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 151.0 in stage 9.0 (TID 954) in 81 ms on 8b44f3d35cfa (executor driver) (152/200)
[2025-07-19T20:31:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.008+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@43791895
[2025-07-19T20:31:10.011+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=159, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.013+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=159),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159] for update
[2025-07-19T20:31:10.014+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/.2.delta.8e355f04-ff94-4b03-8e89-d69a2c5f3982.TID955.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/2.delta
[2025-07-19T20:31:10.017+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/152/2.delta
[2025-07-19T20:31:10.019+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/.2.delta.b5a4893d-8e49-48ef-9712-762c4e2a7039.TID956.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/2.delta
[2025-07-19T20:31:10.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/153/2.delta
[2025-07-19T20:31:10.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T20:31:10.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/.2.delta.0f6cc35d-3446-4a7c-b62b-dda8cbd7246c.TID957.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/2.delta
[2025-07-19T20:31:10.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/154/2.delta
[2025-07-19T20:31:10.020+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T20:31:10.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T20:31:10.021+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 153 (task 956, attempt 0, stage 9.0)
[2025-07-19T20:31:10.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 153.0 in stage 9.0 (TID 956). 5872 bytes result sent to driver
[2025-07-19T20:31:10.022+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 152 (task 955, attempt 0, stage 9.0)
[2025-07-19T20:31:10.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 152.0 in stage 9.0 (TID 955). 5872 bytes result sent to driver
[2025-07-19T20:31:10.023+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 153.0 in stage 9.0 (TID 956) in 74 ms on 8b44f3d35cfa (executor driver) (153/200)
[2025-07-19T20:31:10.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 160.0 in stage 9.0 (TID 963) (8b44f3d35cfa, executor driver, partition 160, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 160.0 in stage 9.0 (TID 963)
[2025-07-19T20:31:10.024+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 154 (task 957, attempt 0, stage 9.0)
[2025-07-19T20:31:10.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 161.0 in stage 9.0 (TID 964) (8b44f3d35cfa, executor driver, partition 161, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 154.0 in stage 9.0 (TID 957). 5872 bytes result sent to driver
[2025-07-19T20:31:10.025+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 152.0 in stage 9.0 (TID 955) in 77 ms on 8b44f3d35cfa (executor driver) (154/200)
[2025-07-19T20:31:10.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.2.delta.c1d55475-361b-4397-850b-22c55f9872f1.TID961.tmp
[2025-07-19T20:31:10.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 161.0 in stage 9.0 (TID 964)
[2025-07-19T20:31:10.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 162.0 in stage 9.0 (TID 965) (8b44f3d35cfa, executor driver, partition 162, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 162.0 in stage 9.0 (TID 965)
[2025-07-19T20:31:10.027+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 154.0 in stage 9.0 (TID 957) in 76 ms on 8b44f3d35cfa (executor driver) (155/200)
[2025-07-19T20:31:10.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.028+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.030+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@725d60b8
[2025-07-19T20:31:10.031+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=161, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=161),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161] for update
[2025-07-19T20:31:10.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7a77c790
[2025-07-19T20:31:10.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=160, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.033+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=160),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160] for update
[2025-07-19T20:31:10.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.2.delta.42249772-edeb-464f-b04e-8050af2dd48c.TID962.tmp
[2025-07-19T20:31:10.035+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@190f54cb
[2025-07-19T20:31:10.036+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=162, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.039+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=162),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162] for update
[2025-07-19T20:31:10.039+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.2.delta.f1215446-e171-4e7d-a913-e12aadbab49d.TID964.tmp
[2025-07-19T20:31:10.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/.2.delta.b24a00a5-0278-4f0c-a63d-c7679dd4a0b5.TID960.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/2.delta
[2025-07-19T20:31:10.040+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/157/2.delta
[2025-07-19T20:31:10.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T20:31:10.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.2.delta.0cc90eca-fa32-4697-97e9-02d11e2facb7.TID963.tmp
[2025-07-19T20:31:10.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 157 (task 960, attempt 0, stage 9.0)
[2025-07-19T20:31:10.041+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 157.0 in stage 9.0 (TID 960). 5829 bytes result sent to driver
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 163.0 in stage 9.0 (TID 966) (8b44f3d35cfa, executor driver, partition 163, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 157.0 in stage 9.0 (TID 960) in 60 ms on 8b44f3d35cfa (executor driver) (156/200)
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 163.0 in stage 9.0 (TID 966)
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26dcb34d
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=163, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=163),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163] for update
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.2.delta.7539b6f8-c8e2-4621-a1ce-a148b35e7be1.TID965.tmp
[2025-07-19T20:31:10.042+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/.2.delta.95792eed-3211-43c1-8396-0193b5b915bf.TID958.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/2.delta
[2025-07-19T20:31:10.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/155/2.delta
[2025-07-19T20:31:10.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T20:31:10.043+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 155 (task 958, attempt 0, stage 9.0)
[2025-07-19T20:31:10.051+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 155.0 in stage 9.0 (TID 958). 5915 bytes result sent to driver
[2025-07-19T20:31:10.053+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 164.0 in stage 9.0 (TID 967) (8b44f3d35cfa, executor driver, partition 164, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 155.0 in stage 9.0 (TID 958) in 83 ms on 8b44f3d35cfa (executor driver) (157/200)
[2025-07-19T20:31:10.055+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 164.0 in stage 9.0 (TID 967)
[2025-07-19T20:31:10.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/.2.delta.053efa4b-cb05-4bde-b3da-9e8a38178924.TID959.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/2.delta
[2025-07-19T20:31:10.056+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/156/2.delta
[2025-07-19T20:31:10.057+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@28181db4
[2025-07-19T20:31:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=164, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=164),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164] for update
[2025-07-19T20:31:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.2.delta.d394a349-ad32-4b53-bc5d-9015fb35380d.TID966.tmp
[2025-07-19T20:31:10.058+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T20:31:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 156 (task 959, attempt 0, stage 9.0)
[2025-07-19T20:31:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 156.0 in stage 9.0 (TID 959). 5829 bytes result sent to driver
[2025-07-19T20:31:10.059+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 165.0 in stage 9.0 (TID 968) (8b44f3d35cfa, executor driver, partition 165, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.060+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 156.0 in stage 9.0 (TID 959) in 90 ms on 8b44f3d35cfa (executor driver) (158/200)
[2025-07-19T20:31:10.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 165.0 in stage 9.0 (TID 968)
[2025-07-19T20:31:10.061+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.062+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f3f6984
[2025-07-19T20:31:10.063+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=165, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.064+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=165),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165] for update
[2025-07-19T20:31:10.065+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.069+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.2.delta.40c005e8-b131-4d64-8683-71d3ebc0e963.TID967.tmp
[2025-07-19T20:31:10.069+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/.2.delta.c1d55475-361b-4397-850b-22c55f9872f1.TID961.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/2.delta
[2025-07-19T20:31:10.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/158/2.delta
[2025-07-19T20:31:10.070+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T20:31:10.073+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.2.delta.653f25b2-d7ee-4438-9679-9ba2b3f92028.TID968.tmp
[2025-07-19T20:31:10.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 158 (task 961, attempt 0, stage 9.0)
[2025-07-19T20:31:10.074+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 158.0 in stage 9.0 (TID 961). 5872 bytes result sent to driver
[2025-07-19T20:31:10.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 166.0 in stage 9.0 (TID 969) (8b44f3d35cfa, executor driver, partition 166, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.075+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 166.0 in stage 9.0 (TID 969)
[2025-07-19T20:31:10.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 158.0 in stage 9.0 (TID 961) in 80 ms on 8b44f3d35cfa (executor driver) (159/200)
[2025-07-19T20:31:10.076+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.077+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.078+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@abbcb8a
[2025-07-19T20:31:10.079+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=166, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=166),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166] for update
[2025-07-19T20:31:10.080+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/.2.delta.42249772-edeb-464f-b04e-8050af2dd48c.TID962.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/2.delta
[2025-07-19T20:31:10.081+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/159/2.delta
[2025-07-19T20:31:10.082+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T20:31:10.083+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 159 (task 962, attempt 0, stage 9.0)
[2025-07-19T20:31:10.084+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 159.0 in stage 9.0 (TID 962). 5872 bytes result sent to driver
[2025-07-19T20:31:10.085+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/.2.delta.f1215446-e171-4e7d-a913-e12aadbab49d.TID964.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/2.delta
[2025-07-19T20:31:10.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/161/2.delta
[2025-07-19T20:31:10.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 167.0 in stage 9.0 (TID 970) (8b44f3d35cfa, executor driver, partition 167, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.086+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 159.0 in stage 9.0 (TID 962) in 77 ms on 8b44f3d35cfa (executor driver) (160/200)
[2025-07-19T20:31:10.088+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 167.0 in stage 9.0 (TID 970)
[2025-07-19T20:31:10.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T20:31:10.089+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/.2.delta.0cc90eca-fa32-4697-97e9-02d11e2facb7.TID963.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/2.delta
[2025-07-19T20:31:10.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/160/2.delta
[2025-07-19T20:31:10.090+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/.2.delta.7539b6f8-c8e2-4621-a1ce-a148b35e7be1.TID965.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/2.delta
[2025-07-19T20:31:10.091+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/162/2.delta
[2025-07-19T20:31:10.092+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T20:31:10.095+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.096+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.097+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2385a820
[2025-07-19T20:31:10.097+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T20:31:10.098+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=167, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.099+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=167),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167] for update
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 161 (task 964, attempt 0, stage 9.0)
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 162 (task 965, attempt 0, stage 9.0)
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 162.0 in stage 9.0 (TID 965). 5872 bytes result sent to driver
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 161.0 in stage 9.0 (TID 964). 5872 bytes result sent to driver
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.2.delta.942522e9-2896-4ebe-a3cc-d4882295c376.TID969.tmp
[2025-07-19T20:31:10.100+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 160 (task 963, attempt 0, stage 9.0)
[2025-07-19T20:31:10.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 160.0 in stage 9.0 (TID 963). 5872 bytes result sent to driver
[2025-07-19T20:31:10.101+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/.2.delta.d394a349-ad32-4b53-bc5d-9015fb35380d.TID966.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/2.delta
[2025-07-19T20:31:10.103+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/163/2.delta
[2025-07-19T20:31:10.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 168.0 in stage 9.0 (TID 971) (8b44f3d35cfa, executor driver, partition 168, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.104+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 168.0 in stage 9.0 (TID 971)
[2025-07-19T20:31:10.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 169.0 in stage 9.0 (TID 972) (8b44f3d35cfa, executor driver, partition 169, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.105+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 162.0 in stage 9.0 (TID 965) in 78 ms on 8b44f3d35cfa (executor driver) (161/200)
[2025-07-19T20:31:10.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 170.0 in stage 9.0 (TID 973) (8b44f3d35cfa, executor driver, partition 170, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 170.0 in stage 9.0 (TID 973)
[2025-07-19T20:31:10.106+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 161.0 in stage 9.0 (TID 964) in 80 ms on 8b44f3d35cfa (executor driver) (162/200)
[2025-07-19T20:31:10.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 160.0 in stage 9.0 (TID 963) in 81 ms on 8b44f3d35cfa (executor driver) (163/200)
[2025-07-19T20:31:10.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 169.0 in stage 9.0 (TID 972)
[2025-07-19T20:31:10.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T20:31:10.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.107+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.108+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5c484465
[2025-07-19T20:31:10.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 163 (task 966, attempt 0, stage 9.0)
[2025-07-19T20:31:10.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 163.0 in stage 9.0 (TID 966). 5872 bytes result sent to driver
[2025-07-19T20:31:10.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=168, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=168),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168] for update
[2025-07-19T20:31:10.109+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.110+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 171.0 in stage 9.0 (TID 974) (8b44f3d35cfa, executor driver, partition 171, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.110+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 171.0 in stage 9.0 (TID 974)
[2025-07-19T20:31:10.111+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 163.0 in stage 9.0 (TID 966) in 68 ms on 8b44f3d35cfa (executor driver) (164/200)
[2025-07-19T20:31:10.112+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.2.delta.5b015430-9fb7-4fa4-954c-b83dc41df0ac.TID970.tmp
[2025-07-19T20:31:10.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@36f6ab7d
[2025-07-19T20:31:10.113+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=169, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=169),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169] for update
[2025-07-19T20:31:10.114+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.115+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@26907c7a
[2025-07-19T20:31:10.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=170, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.116+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=170),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170] for update
[2025-07-19T20:31:10.119+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.120+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@4ee0a9ac
[2025-07-19T20:31:10.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=171, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.121+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=171),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171] for update
[2025-07-19T20:31:10.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.123+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/.2.delta.653f25b2-d7ee-4438-9679-9ba2b3f92028.TID968.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/2.delta
[2025-07-19T20:31:10.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/165/2.delta
[2025-07-19T20:31:10.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T20:31:10.124+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/.2.delta.40c005e8-b131-4d64-8683-71d3ebc0e963.TID967.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/2.delta
[2025-07-19T20:31:10.125+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/164/2.delta
[2025-07-19T20:31:10.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T20:31:10.126+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.2.delta.ebed7cf4-48bb-4ab2-8aa9-2cfe07928e04.TID971.tmp
[2025-07-19T20:31:10.127+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.2.delta.95b045eb-82fa-4192-9c06-ad256ac7f2b8.TID973.tmp
[2025-07-19T20:31:10.128+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 165 (task 968, attempt 0, stage 9.0)
[2025-07-19T20:31:10.130+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 165.0 in stage 9.0 (TID 968). 5829 bytes result sent to driver
[2025-07-19T20:31:10.132+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.2.delta.ee9d5c50-b697-409f-acfd-2720b807e669.TID974.tmp
[2025-07-19T20:31:10.133+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 172.0 in stage 9.0 (TID 975) (8b44f3d35cfa, executor driver, partition 172, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 164 (task 967, attempt 0, stage 9.0)
[2025-07-19T20:31:10.136+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 172.0 in stage 9.0 (TID 975)
[2025-07-19T20:31:10.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.2.delta.8e51331a-f248-46de-8604-1391f5ad52b2.TID972.tmp
[2025-07-19T20:31:10.137+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 164.0 in stage 9.0 (TID 967). 5829 bytes result sent to driver
[2025-07-19T20:31:10.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 173.0 in stage 9.0 (TID 976) (8b44f3d35cfa, executor driver, partition 173, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.138+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 164.0 in stage 9.0 (TID 967) in 82 ms on 8b44f3d35cfa (executor driver) (165/200)
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 173.0 in stage 9.0 (TID 976)
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@239be16c
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=173, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=173),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173] for update
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 165.0 in stage 9.0 (TID 968) in 75 ms on 8b44f3d35cfa (executor driver) (166/200)
[2025-07-19T20:31:10.139+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3db1a0b9
[2025-07-19T20:31:10.140+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=172, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=172),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172] for update
[2025-07-19T20:31:10.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.141+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.2.delta.3b9cdb42-3b10-46b5-ba84-b5bbb3cd53b6.TID976.tmp
[2025-07-19T20:31:10.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/.2.delta.942522e9-2896-4ebe-a3cc-d4882295c376.TID969.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/2.delta
[2025-07-19T20:31:10.148+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/166/2.delta
[2025-07-19T20:31:10.149+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T20:31:10.151+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.2.delta.51c91220-7f6a-4cbc-83f6-add0111afeee.TID975.tmp
[2025-07-19T20:31:10.153+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 166 (task 969, attempt 0, stage 9.0)
[2025-07-19T20:31:10.154+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/.2.delta.5b015430-9fb7-4fa4-954c-b83dc41df0ac.TID970.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/2.delta
[2025-07-19T20:31:10.155+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/167/2.delta
[2025-07-19T20:31:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 166.0 in stage 9.0 (TID 969). 5829 bytes result sent to driver
[2025-07-19T20:31:10.156+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T20:31:10.158+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 174.0 in stage 9.0 (TID 977) (8b44f3d35cfa, executor driver, partition 174, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.163+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 174.0 in stage 9.0 (TID 977)
[2025-07-19T20:31:10.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 166.0 in stage 9.0 (TID 969) in 85 ms on 8b44f3d35cfa (executor driver) (167/200)
[2025-07-19T20:31:10.164+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 167 (task 970, attempt 0, stage 9.0)
[2025-07-19T20:31:10.165+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 167.0 in stage 9.0 (TID 970). 5829 bytes result sent to driver
[2025-07-19T20:31:10.166+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 175.0 in stage 9.0 (TID 978) (8b44f3d35cfa, executor driver, partition 175, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.167+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.168+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 167.0 in stage 9.0 (TID 970) in 78 ms on 8b44f3d35cfa (executor driver) (168/200)
[2025-07-19T20:31:10.169+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 175.0 in stage 9.0 (TID 978)
[2025-07-19T20:31:10.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1ef91ed1
[2025-07-19T20:31:10.170+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=174, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=174),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174] for update
[2025-07-19T20:31:10.171+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.172+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@37db5ec7
[2025-07-19T20:31:10.173+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=175, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=175),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175] for update
[2025-07-19T20:31:10.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/.2.delta.ebed7cf4-48bb-4ab2-8aa9-2cfe07928e04.TID971.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/2.delta
[2025-07-19T20:31:10.174+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/168/2.delta
[2025-07-19T20:31:10.176+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T20:31:10.177+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.178+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/.2.delta.95b045eb-82fa-4192-9c06-ad256ac7f2b8.TID973.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/2.delta
[2025-07-19T20:31:10.179+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/170/2.delta
[2025-07-19T20:31:10.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/.2.delta.8e51331a-f248-46de-8604-1391f5ad52b2.TID972.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/2.delta
[2025-07-19T20:31:10.180+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/169/2.delta
[2025-07-19T20:31:10.181+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T20:31:10.183+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T20:31:10.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 168 (task 971, attempt 0, stage 9.0)
[2025-07-19T20:31:10.184+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 168.0 in stage 9.0 (TID 971). 5829 bytes result sent to driver
[2025-07-19T20:31:10.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 176.0 in stage 9.0 (TID 979) (8b44f3d35cfa, executor driver, partition 176, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 176.0 in stage 9.0 (TID 979)
[2025-07-19T20:31:10.185+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 168.0 in stage 9.0 (TID 971) in 86 ms on 8b44f3d35cfa (executor driver) (169/200)
[2025-07-19T20:31:10.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/.2.delta.ee9d5c50-b697-409f-acfd-2720b807e669.TID974.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/2.delta
[2025-07-19T20:31:10.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/171/2.delta
[2025-07-19T20:31:10.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.2.delta.2ceaf3de-d9c5-47d3-bca6-d04f172316b9.TID977.tmp
[2025-07-19T20:31:10.186+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 170 (task 973, attempt 0, stage 9.0)
[2025-07-19T20:31:10.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T20:31:10.187+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 170.0 in stage 9.0 (TID 973). 5829 bytes result sent to driver
[2025-07-19T20:31:10.188+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 177.0 in stage 9.0 (TID 980) (8b44f3d35cfa, executor driver, partition 177, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.190+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.192+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.194+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 170.0 in stage 9.0 (TID 973) in 84 ms on 8b44f3d35cfa (executor driver) (170/200)
[2025-07-19T20:31:10.195+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 177.0 in stage 9.0 (TID 980)
[2025-07-19T20:31:10.196+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.2.delta.4dac5035-36c8-48cd-8e90-ef6860f4e2e4.TID978.tmp
[2025-07-19T20:31:10.198+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7f25ba5c
[2025-07-19T20:31:10.199+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 169 (task 972, attempt 0, stage 9.0)
[2025-07-19T20:31:10.200+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 169.0 in stage 9.0 (TID 972). 5829 bytes result sent to driver
[2025-07-19T20:31:10.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 178.0 in stage 9.0 (TID 981) (8b44f3d35cfa, executor driver, partition 178, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.201+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 169.0 in stage 9.0 (TID 972) in 88 ms on 8b44f3d35cfa (executor driver) (171/200)
[2025-07-19T20:31:10.202+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=176, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.203+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=176),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176] for update
[2025-07-19T20:31:10.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.204+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 178.0 in stage 9.0 (TID 981)
[2025-07-19T20:31:10.206+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.207+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@59aaee0c
[2025-07-19T20:31:10.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:10.208+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=177, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=177),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177] for update
[2025-07-19T20:31:10.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 171 (task 974, attempt 0, stage 9.0)
[2025-07-19T20:31:10.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 171.0 in stage 9.0 (TID 974). 5829 bytes result sent to driver
[2025-07-19T20:31:10.209+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/.2.delta.3b9cdb42-3b10-46b5-ba84-b5bbb3cd53b6.TID976.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/2.delta
[2025-07-19T20:31:10.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/173/2.delta
[2025-07-19T20:31:10.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@781bfe0e
[2025-07-19T20:31:10.210+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 179.0 in stage 9.0 (TID 982) (8b44f3d35cfa, executor driver, partition 179, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.211+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T20:31:10.212+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=178, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.213+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=178),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178] for update
[2025-07-19T20:31:10.214+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 179.0 in stage 9.0 (TID 982)
[2025-07-19T20:31:10.215+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 171.0 in stage 9.0 (TID 974) in 90 ms on 8b44f3d35cfa (executor driver) (172/200)
[2025-07-19T20:31:10.217+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.218+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 173 (task 976, attempt 0, stage 9.0)
[2025-07-19T20:31:10.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.219+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e3d6fa4
[2025-07-19T20:31:10.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=179, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=179),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179] for update
[2025-07-19T20:31:10.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 173.0 in stage 9.0 (TID 976). 5829 bytes result sent to driver
[2025-07-19T20:31:10.220+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.221+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 180.0 in stage 9.0 (TID 983) (8b44f3d35cfa, executor driver, partition 180, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 173.0 in stage 9.0 (TID 976) in 63 ms on 8b44f3d35cfa (executor driver) (173/200)
[2025-07-19T20:31:10.227+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 180.0 in stage 9.0 (TID 983)
[2025-07-19T20:31:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.2.delta.3e96d379-3073-4700-a7d6-7a4a1b7c5b72.TID979.tmp
[2025-07-19T20:31:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/.2.delta.51c91220-7f6a-4cbc-83f6-add0111afeee.TID975.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/2.delta
[2025-07-19T20:31:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/172/2.delta
[2025-07-19T20:31:10.228+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@5fa512c3
[2025-07-19T20:31:10.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T20:31:10.229+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=180, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=180),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180] for update
[2025-07-19T20:31:10.230+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.231+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 172 (task 975, attempt 0, stage 9.0)
[2025-07-19T20:31:10.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 172.0 in stage 9.0 (TID 975). 5829 bytes result sent to driver
[2025-07-19T20:31:10.233+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.2.delta.28dbbda4-7ebc-4cb9-ac53-69c10996a314.TID980.tmp
[2025-07-19T20:31:10.236+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.2.delta.7278d5b1-c6e8-4a85-a6df-2343906af731.TID981.tmp
[2025-07-19T20:31:10.239+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 181.0 in stage 9.0 (TID 984) (8b44f3d35cfa, executor driver, partition 181, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.242+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 172.0 in stage 9.0 (TID 975) in 76 ms on 8b44f3d35cfa (executor driver) (174/200)
[2025-07-19T20:31:10.244+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 181.0 in stage 9.0 (TID 984)
[2025-07-19T20:31:10.245+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.2.delta.2a8002ef-a2a5-4ee5-b802-81523dfa5e5d.TID982.tmp
[2025-07-19T20:31:10.246+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.248+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.249+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@67ececc6
[2025-07-19T20:31:10.250+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=181, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.251+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=181),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181] for update
[2025-07-19T20:31:10.253+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.254+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.2.delta.9e58df33-57f7-45a1-bc55-0c0cee93f591.TID983.tmp
[2025-07-19T20:31:10.256+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/.2.delta.2ceaf3de-d9c5-47d3-bca6-d04f172316b9.TID977.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/2.delta
[2025-07-19T20:31:10.257+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/174/2.delta
[2025-07-19T20:31:10.258+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T20:31:10.259+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/.2.delta.4dac5035-36c8-48cd-8e90-ef6860f4e2e4.TID978.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/2.delta
[2025-07-19T20:31:10.261+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/175/2.delta
[2025-07-19T20:31:10.264+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.2.delta.03edf3cf-6f45-405f-ab37-148a0da5545d.TID984.tmp
[2025-07-19T20:31:10.266+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T20:31:10.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 174 (task 977, attempt 0, stage 9.0)
[2025-07-19T20:31:10.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 174.0 in stage 9.0 (TID 977). 5829 bytes result sent to driver
[2025-07-19T20:31:10.267+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 182.0 in stage 9.0 (TID 985) (8b44f3d35cfa, executor driver, partition 182, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.268+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 174.0 in stage 9.0 (TID 977) in 87 ms on 8b44f3d35cfa (executor driver) (175/200)
[2025-07-19T20:31:10.269+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 175 (task 978, attempt 0, stage 9.0)
[2025-07-19T20:31:10.270+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 182.0 in stage 9.0 (TID 985)
[2025-07-19T20:31:10.271+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 175.0 in stage 9.0 (TID 978). 5829 bytes result sent to driver
[2025-07-19T20:31:10.273+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 183.0 in stage 9.0 (TID 986) (8b44f3d35cfa, executor driver, partition 183, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.274+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 175.0 in stage 9.0 (TID 978) in 85 ms on 8b44f3d35cfa (executor driver) (176/200)
[2025-07-19T20:31:10.275+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.276+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.277+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 183.0 in stage 9.0 (TID 986)
[2025-07-19T20:31:10.279+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@3097c556
[2025-07-19T20:31:10.280+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=182, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=182),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182] for update
[2025-07-19T20:31:10.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.281+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.282+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@42baf287
[2025-07-19T20:31:10.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.283+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=183, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=183),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183] for update
[2025-07-19T20:31:10.284+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.287+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/.2.delta.3e96d379-3073-4700-a7d6-7a4a1b7c5b72.TID979.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/2.delta
[2025-07-19T20:31:10.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/176/2.delta
[2025-07-19T20:31:10.288+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T20:31:10.289+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/.2.delta.7278d5b1-c6e8-4a85-a6df-2343906af731.TID981.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/2.delta
[2025-07-19T20:31:10.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/178/2.delta
[2025-07-19T20:31:10.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T20:31:10.290+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 176 (task 979, attempt 0, stage 9.0)
[2025-07-19T20:31:10.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 176.0 in stage 9.0 (TID 979). 5829 bytes result sent to driver
[2025-07-19T20:31:10.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 184.0 in stage 9.0 (TID 987) (8b44f3d35cfa, executor driver, partition 184, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.291+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 176.0 in stage 9.0 (TID 979) in 97 ms on 8b44f3d35cfa (executor driver) (177/200)
[2025-07-19T20:31:10.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 184.0 in stage 9.0 (TID 987)
[2025-07-19T20:31:10.292+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 178 (task 981, attempt 0, stage 9.0)
[2025-07-19T20:31:10.293+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 178.0 in stage 9.0 (TID 981). 5829 bytes result sent to driver
[2025-07-19T20:31:10.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.296+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 185.0 in stage 9.0 (TID 988) (8b44f3d35cfa, executor driver, partition 185, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.297+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 178.0 in stage 9.0 (TID 981) in 97 ms on 8b44f3d35cfa (executor driver) (178/200)
[2025-07-19T20:31:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 185.0 in stage 9.0 (TID 988)
[2025-07-19T20:31:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6370f963
[2025-07-19T20:31:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.2.delta.aa9f6ce3-1909-421e-9e3b-b88c64bce122.TID986.tmp
[2025-07-19T20:31:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.2.delta.0d571e1a-8783-410e-a610-98206889e1e9.TID985.tmp
[2025-07-19T20:31:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/.2.delta.28dbbda4-7ebc-4cb9-ac53-69c10996a314.TID980.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/2.delta
[2025-07-19T20:31:10.298+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=184, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/177/2.delta
[2025-07-19T20:31:10.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=184),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184] for update
[2025-07-19T20:31:10.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T20:31:10.299+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.300+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.301+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.302+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/.2.delta.2a8002ef-a2a5-4ee5-b802-81523dfa5e5d.TID982.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/2.delta
[2025-07-19T20:31:10.303+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/179/2.delta
[2025-07-19T20:31:10.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 177 (task 980, attempt 0, stage 9.0)
[2025-07-19T20:31:10.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T20:31:10.304+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 177.0 in stage 9.0 (TID 980). 5829 bytes result sent to driver
[2025-07-19T20:31:10.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@2a12fdd5
[2025-07-19T20:31:10.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 186.0 in stage 9.0 (TID 989) (8b44f3d35cfa, executor driver, partition 186, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 186.0 in stage 9.0 (TID 989)
[2025-07-19T20:31:10.305+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=185, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=185),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185] for update
[2025-07-19T20:31:10.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 177.0 in stage 9.0 (TID 980) in 108 ms on 8b44f3d35cfa (executor driver) (179/200)
[2025-07-19T20:31:10.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.306+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.307+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.308+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1048007
[2025-07-19T20:31:10.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 179 (task 982, attempt 0, stage 9.0)
[2025-07-19T20:31:10.309+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/.2.delta.9e58df33-57f7-45a1-bc55-0c0cee93f591.TID983.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/2.delta
[2025-07-19T20:31:10.310+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/180/2.delta
[2025-07-19T20:31:10.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T20:31:10.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 179.0 in stage 9.0 (TID 982). 5829 bytes result sent to driver
[2025-07-19T20:31:10.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 187.0 in stage 9.0 (TID 990) (8b44f3d35cfa, executor driver, partition 187, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.311+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=186, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=186),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186] for update
[2025-07-19T20:31:10.312+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 179.0 in stage 9.0 (TID 982) in 104 ms on 8b44f3d35cfa (executor driver) (180/200)
[2025-07-19T20:31:10.313+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 187.0 in stage 9.0 (TID 990)
[2025-07-19T20:31:10.314+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 180 (task 983, attempt 0, stage 9.0)
[2025-07-19T20:31:10.315+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 180.0 in stage 9.0 (TID 983). 5829 bytes result sent to driver
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 188.0 in stage 9.0 (TID 991) (8b44f3d35cfa, executor driver, partition 188, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 188.0 in stage 9.0 (TID 991)
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 180.0 in stage 9.0 (TID 983) in 105 ms on 8b44f3d35cfa (executor driver) (181/200)
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@38c4368d
[2025-07-19T20:31:10.316+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2025-07-19T20:31:10.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/.2.delta.03edf3cf-6f45-405f-ab37-148a0da5545d.TID984.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/2.delta
[2025-07-19T20:31:10.317+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/181/2.delta
[2025-07-19T20:31:10.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.2.delta.dfffa43f-44c3-4159-8c11-7d99c6bd56c2.TID987.tmp
[2025-07-19T20:31:10.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.2.delta.d211de9c-fd47-4e52-9c4b-49d26e93b795.TID988.tmp
[2025-07-19T20:31:10.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=187, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.318+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=187),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187] for update
[2025-07-19T20:31:10.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T20:31:10.319+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@17329acd
[2025-07-19T20:31:10.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 181 (task 984, attempt 0, stage 9.0)
[2025-07-19T20:31:10.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 181.0 in stage 9.0 (TID 984). 5829 bytes result sent to driver
[2025-07-19T20:31:10.320+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 189.0 in stage 9.0 (TID 992) (8b44f3d35cfa, executor driver, partition 189, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=188, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=188),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188] for update
[2025-07-19T20:31:10.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 181.0 in stage 9.0 (TID 984) in 103 ms on 8b44f3d35cfa (executor driver) (182/200)
[2025-07-19T20:31:10.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 189.0 in stage 9.0 (TID 992)
[2025-07-19T20:31:10.321+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.322+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7b57824e
[2025-07-19T20:31:10.323+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=189, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.324+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=189),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189] for update
[2025-07-19T20:31:10.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.325+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.2.delta.263d06c5-45ed-423f-a7dd-bad3058dba3f.TID989.tmp
[2025-07-19T20:31:10.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.2.delta.3087cd4b-1902-4de7-8129-c7058866fead.TID990.tmp
[2025-07-19T20:31:10.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.2.delta.9e272957-a6d5-425a-bed3-dbc137de538a.TID991.tmp
[2025-07-19T20:31:10.326+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/.2.delta.0d571e1a-8783-410e-a610-98206889e1e9.TID985.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/2.delta
[2025-07-19T20:31:10.327+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/182/2.delta
[2025-07-19T20:31:10.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T20:31:10.328+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.2.delta.fdaddf21-e4a6-4015-97aa-1ec4ea2e2a38.TID992.tmp
[2025-07-19T20:31:10.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 182 (task 985, attempt 0, stage 9.0)
[2025-07-19T20:31:10.330+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 182.0 in stage 9.0 (TID 985). 5829 bytes result sent to driver
[2025-07-19T20:31:10.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 190.0 in stage 9.0 (TID 993) (8b44f3d35cfa, executor driver, partition 190, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 190.0 in stage 9.0 (TID 993)
[2025-07-19T20:31:10.331+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 182.0 in stage 9.0 (TID 985) in 92 ms on 8b44f3d35cfa (executor driver) (183/200)
[2025-07-19T20:31:10.334+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.336+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@1a014dbc
[2025-07-19T20:31:10.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=190, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.337+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=190),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190] for update
[2025-07-19T20:31:10.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/.2.delta.aa9f6ce3-1909-421e-9e3b-b88c64bce122.TID986.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/2.delta
[2025-07-19T20:31:10.338+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/183/2.delta
[2025-07-19T20:31:10.339+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T20:31:10.340+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/.2.delta.dfffa43f-44c3-4159-8c11-7d99c6bd56c2.TID987.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/2.delta
[2025-07-19T20:31:10.342+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/184/2.delta
[2025-07-19T20:31:10.343+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T20:31:10.344+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 183 (task 986, attempt 0, stage 9.0)
[2025-07-19T20:31:10.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 183.0 in stage 9.0 (TID 986). 5829 bytes result sent to driver
[2025-07-19T20:31:10.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 191.0 in stage 9.0 (TID 994) (8b44f3d35cfa, executor driver, partition 191, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 191.0 in stage 9.0 (TID 994)
[2025-07-19T20:31:10.345+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 183.0 in stage 9.0 (TID 986) in 99 ms on 8b44f3d35cfa (executor driver) (184/200)
[2025-07-19T20:31:10.346+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 184 (task 987, attempt 0, stage 9.0)
[2025-07-19T20:31:10.347+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 184.0 in stage 9.0 (TID 987). 5829 bytes result sent to driver
[2025-07-19T20:31:10.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.350+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 192.0 in stage 9.0 (TID 995) (8b44f3d35cfa, executor driver, partition 192, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 184.0 in stage 9.0 (TID 987) in 74 ms on 8b44f3d35cfa (executor driver) (185/200)
[2025-07-19T20:31:10.351+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 192.0 in stage 9.0 (TID 995)
[2025-07-19T20:31:10.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@296821d1
[2025-07-19T20:31:10.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=191, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.352+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=191),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191] for update
[2025-07-19T20:31:10.353+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.354+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@209cd20e
[2025-07-19T20:31:10.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=192, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.355+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=192),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192] for update
[2025-07-19T20:31:10.356+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.357+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.2.delta.fa07e3e5-99be-433d-9253-0669284c5434.TID993.tmp
[2025-07-19T20:31:10.358+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/.2.delta.d211de9c-fd47-4e52-9c4b-49d26e93b795.TID988.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/2.delta
[2025-07-19T20:31:10.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/185/2.delta
[2025-07-19T20:31:10.360+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T20:31:10.361+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 185 (task 988, attempt 0, stage 9.0)
[2025-07-19T20:31:10.362+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 185.0 in stage 9.0 (TID 988). 5829 bytes result sent to driver
[2025-07-19T20:31:10.363+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 193.0 in stage 9.0 (TID 996) (8b44f3d35cfa, executor driver, partition 193, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.363+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 185.0 in stage 9.0 (TID 988) in 81 ms on 8b44f3d35cfa (executor driver) (186/200)
[2025-07-19T20:31:10.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 193.0 in stage 9.0 (TID 996)
[2025-07-19T20:31:10.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/.2.delta.263d06c5-45ed-423f-a7dd-bad3058dba3f.TID989.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/2.delta
[2025-07-19T20:31:10.364+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/186/2.delta
[2025-07-19T20:31:10.365+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T20:31:10.366+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.2.delta.4cc3aec9-1ea1-41fe-9170-84f8ba4067e0.TID994.tmp
[2025-07-19T20:31:10.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.367+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.368+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.2.delta.f502d36c-ea6f-41fb-8d7e-8a615187d8f6.TID995.tmp
[2025-07-19T20:31:10.370+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 186 (task 989, attempt 0, stage 9.0)
[2025-07-19T20:31:10.371+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 186.0 in stage 9.0 (TID 989). 5829 bytes result sent to driver
[2025-07-19T20:31:10.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6a8b75d1
[2025-07-19T20:31:10.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 194.0 in stage 9.0 (TID 997) (8b44f3d35cfa, executor driver, partition 194, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.372+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=193, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.374+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=193),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193] for update
[2025-07-19T20:31:10.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 186.0 in stage 9.0 (TID 989) in 80 ms on 8b44f3d35cfa (executor driver) (187/200)
[2025-07-19T20:31:10.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 194.0 in stage 9.0 (TID 997)
[2025-07-19T20:31:10.375+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.377+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-07-19T20:31:10.379+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/.2.delta.fdaddf21-e4a6-4015-97aa-1ec4ea2e2a38.TID992.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/2.delta
[2025-07-19T20:31:10.380+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/189/2.delta
[2025-07-19T20:31:10.380+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.380+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@30532ff0
[2025-07-19T20:31:10.380+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T20:31:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/.2.delta.9e272957-a6d5-425a-bed3-dbc137de538a.TID991.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/2.delta
[2025-07-19T20:31:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/188/2.delta
[2025-07-19T20:31:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=194, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.381+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=194),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194] for update
[2025-07-19T20:31:10.382+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T20:31:10.383+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.384+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/.2.delta.3087cd4b-1902-4de7-8129-c7058866fead.TID990.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/2.delta
[2025-07-19T20:31:10.385+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/187/2.delta
[2025-07-19T20:31:10.386+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T20:31:10.388+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 188 (task 991, attempt 0, stage 9.0)
[2025-07-19T20:31:10.390+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 188.0 in stage 9.0 (TID 991). 5829 bytes result sent to driver
[2025-07-19T20:31:10.391+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 189 (task 992, attempt 0, stage 9.0)
[2025-07-19T20:31:10.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 195.0 in stage 9.0 (TID 998) (8b44f3d35cfa, executor driver, partition 195, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.392+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 189.0 in stage 9.0 (TID 992). 5829 bytes result sent to driver
[2025-07-19T20:31:10.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 195.0 in stage 9.0 (TID 998)
[2025-07-19T20:31:10.393+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 187 (task 990, attempt 0, stage 9.0)
[2025-07-19T20:31:10.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 187.0 in stage 9.0 (TID 990). 5829 bytes result sent to driver
[2025-07-19T20:31:10.394+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.395+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.396+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 188.0 in stage 9.0 (TID 991) in 84 ms on 8b44f3d35cfa (executor driver) (188/200)
[2025-07-19T20:31:10.397+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@273c45a3
[2025-07-19T20:31:10.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 196.0 in stage 9.0 (TID 999) (8b44f3d35cfa, executor driver, partition 196, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.398+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 197.0 in stage 9.0 (TID 1000) (8b44f3d35cfa, executor driver, partition 197, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.399+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 197.0 in stage 9.0 (TID 1000)
[2025-07-19T20:31:10.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=195, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=195),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195] for update
[2025-07-19T20:31:10.400+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 196.0 in stage 9.0 (TID 999)
[2025-07-19T20:31:10.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 189.0 in stage 9.0 (TID 992) in 76 ms on 8b44f3d35cfa (executor driver) (189/200)
[2025-07-19T20:31:10.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 187.0 in stage 9.0 (TID 990) in 91 ms on 8b44f3d35cfa (executor driver) (190/200)
[2025-07-19T20:31:10.401+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.402+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.2.delta.7f44ff9d-ebb1-47dc-88eb-d821becfb218.TID996.tmp
[2025-07-19T20:31:10.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@214226fe
[2025-07-19T20:31:10.403+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=196, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=196),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196] for update
[2025-07-19T20:31:10.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@e8eee6e
[2025-07-19T20:31:10.404+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=197, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.405+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=197),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197] for update
[2025-07-19T20:31:10.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/.2.delta.fa07e3e5-99be-433d-9253-0669284c5434.TID993.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/2.delta
[2025-07-19T20:31:10.406+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/190/2.delta
[2025-07-19T20:31:10.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T20:31:10.407+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.408+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.2.delta.874022b8-38a9-4f67-951b-73527e7672bc.TID997.tmp
[2025-07-19T20:31:10.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.409+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.2.delta.59fd58f4-cf3f-4ce9-ba16-ebe7432c071e.TID998.tmp
[2025-07-19T20:31:10.410+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 190 (task 993, attempt 0, stage 9.0)
[2025-07-19T20:31:10.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 190.0 in stage 9.0 (TID 993). 5829 bytes result sent to driver
[2025-07-19T20:31:10.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 198.0 in stage 9.0 (TID 1001) (8b44f3d35cfa, executor driver, partition 198, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 198.0 in stage 9.0 (TID 1001)
[2025-07-19T20:31:10.412+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 190.0 in stage 9.0 (TID 993) in 70 ms on 8b44f3d35cfa (executor driver) (191/200)
[2025-07-19T20:31:10.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/.2.delta.4cc3aec9-1ea1-41fe-9170-84f8ba4067e0.TID994.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/2.delta
[2025-07-19T20:31:10.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/191/2.delta
[2025-07-19T20:31:10.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T20:31:10.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.2.delta.a049f16f-7ae8-4391-b4ba-fda8f8a659bf.TID1000.tmp
[2025-07-19T20:31:10.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.413+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.414+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@6df5448f
[2025-07-19T20:31:10.414+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=198, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=198),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198] for update
[2025-07-19T20:31:10.415+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/.2.delta.f502d36c-ea6f-41fb-8d7e-8a615187d8f6.TID995.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/2.delta
[2025-07-19T20:31:10.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/192/2.delta
[2025-07-19T20:31:10.416+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T20:31:10.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.2.delta.116fcdee-295f-4bf8-8119-4c739c955668.TID999.tmp
[2025-07-19T20:31:10.417+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 191 (task 994, attempt 0, stage 9.0)
[2025-07-19T20:31:10.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 191.0 in stage 9.0 (TID 994). 5829 bytes result sent to driver
[2025-07-19T20:31:10.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 191.0 in stage 9.0 (TID 994) in 66 ms on 8b44f3d35cfa (executor driver) (192/200)
[2025-07-19T20:31:10.418+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Starting task 199.0 in stage 9.0 (TID 1002) (8b44f3d35cfa, executor driver, partition 199, PROCESS_LOCAL, 8999 bytes)
[2025-07-19T20:31:10.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Running task 199.0 in stage 9.0 (TID 1002)
[2025-07-19T20:31:10.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 192 (task 995, attempt 0, stage 9.0)
[2025-07-19T20:31:10.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 192.0 in stage 9.0 (TID 995). 5829 bytes result sent to driver
[2025-07-19T20:31:10.419+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 192.0 in stage 9.0 (TID 995) in 68 ms on 8b44f3d35cfa (executor driver) (193/200)
[2025-07-19T20:31:10.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-07-19T20:31:10.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-07-19T20:31:10.420+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Retrieved reference to StateStoreCoordinator: org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef@7cec011a
[2025-07-19T20:31:10.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO StateStore: Reported that the loaded instance StateStoreProviderId(StateStoreId[ checkpointRootLocation=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state, operatorId=0, partitionId=199, storeName=default ],949692c4-67e9-4193-b7c5-0e7f8bd5bdfd) is active
[2025-07-19T20:31:10.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Retrieved version 1 of HDFSStateStoreProvider[id = (op=0,part=199),dir = file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199] for update
[2025-07-19T20:31:10.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CodecPool: Got brand-new compressor [.zstd]
[2025-07-19T20:31:10.421+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.2.delta.6651831d-6e05-46f0-bce5-3d79ad0a6207.TID1001.tmp
[2025-07-19T20:31:10.422+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/2.delta using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.2.delta.8b772b4f-43fc-4ddc-b480-8058b409d11e.TID1002.tmp
[2025-07-19T20:31:10.429+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/.2.delta.7f44ff9d-ebb1-47dc-88eb-d821becfb218.TID996.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/2.delta
[2025-07-19T20:31:10.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/193/2.delta
[2025-07-19T20:31:10.430+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T20:31:10.433+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 193 (task 996, attempt 0, stage 9.0)
[2025-07-19T20:31:10.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/.2.delta.874022b8-38a9-4f67-951b-73527e7672bc.TID997.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/2.delta
[2025-07-19T20:31:10.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/194/2.delta
[2025-07-19T20:31:10.434+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 193.0 in stage 9.0 (TID 996). 5829 bytes result sent to driver
[2025-07-19T20:31:10.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T20:31:10.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/.2.delta.59fd58f4-cf3f-4ce9-ba16-ebe7432c071e.TID998.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/2.delta
[2025-07-19T20:31:10.435+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/195/2.delta
[2025-07-19T20:31:10.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 193.0 in stage 9.0 (TID 996) in 76 ms on 8b44f3d35cfa (executor driver) (194/200)
[2025-07-19T20:31:10.436+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T20:31:10.439+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 195 (task 998, attempt 0, stage 9.0)
[2025-07-19T20:31:10.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 194 (task 997, attempt 0, stage 9.0)
[2025-07-19T20:31:10.440+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 195.0 in stage 9.0 (TID 998). 5829 bytes result sent to driver
[2025-07-19T20:31:10.441+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 194.0 in stage 9.0 (TID 997). 5829 bytes result sent to driver
[2025-07-19T20:31:10.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 195.0 in stage 9.0 (TID 998) in 61 ms on 8b44f3d35cfa (executor driver) (195/200)
[2025-07-19T20:31:10.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 194.0 in stage 9.0 (TID 997) in 72 ms on 8b44f3d35cfa (executor driver) (196/200)
[2025-07-19T20:31:10.442+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/.2.delta.a049f16f-7ae8-4391-b4ba-fda8f8a659bf.TID1000.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/2.delta
[2025-07-19T20:31:10.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/197/2.delta
[2025-07-19T20:31:10.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T20:31:10.443+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/.2.delta.116fcdee-295f-4bf8-8119-4c739c955668.TID999.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/2.delta
[2025-07-19T20:31:10.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/196/2.delta
[2025-07-19T20:31:10.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 197 (task 1000, attempt 0, stage 9.0)
[2025-07-19T20:31:10.444+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 197.0 in stage 9.0 (TID 1000). 5829 bytes result sent to driver
[2025-07-19T20:31:10.445+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T20:31:10.445+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 197.0 in stage 9.0 (TID 1000) in 59 ms on 8b44f3d35cfa (executor driver) (197/200)
[2025-07-19T20:31:10.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 196 (task 999, attempt 0, stage 9.0)
[2025-07-19T20:31:10.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 196.0 in stage 9.0 (TID 999). 5829 bytes result sent to driver
[2025-07-19T20:31:10.446+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 196.0 in stage 9.0 (TID 999) in 63 ms on 8b44f3d35cfa (executor driver) (198/200)
[2025-07-19T20:31:10.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/.2.delta.8b772b4f-43fc-4ddc-b480-8058b409d11e.TID1002.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/2.delta
[2025-07-19T20:31:10.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/199/2.delta
[2025-07-19T20:31:10.447+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T20:31:10.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/.2.delta.6651831d-6e05-46f0-bce5-3d79ad0a6207.TID1001.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/2.delta
[2025-07-19T20:31:10.449+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HDFSBackedStateStoreProvider: Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198] to file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/state/0/198/2.delta
[2025-07-19T20:31:10.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Commit authorized for partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T20:31:10.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 199 (task 1002, attempt 0, stage 9.0)
[2025-07-19T20:31:10.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 199.0 in stage 9.0 (TID 1002). 5829 bytes result sent to driver
[2025-07-19T20:31:10.450+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 199.0 in stage 9.0 (TID 1002) in 40 ms on 8b44f3d35cfa (executor driver) (199/200)
[2025-07-19T20:31:10.451+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DataWritingSparkTask: Committed partition 198 (task 1001, attempt 0, stage 9.0)
[2025-07-19T20:31:10.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO Executor: Finished task 198.0 in stage 9.0 (TID 1001). 5829 bytes result sent to driver
[2025-07-19T20:31:10.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSetManager: Finished task 198.0 in stage 9.0 (TID 1001) in 53 ms on 8b44f3d35cfa (executor driver) (200/200)
[2025-07-19T20:31:10.452+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-07-19T20:31:10.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DAGScheduler: ResultStage 9 (start at <unknown>:0) finished in 7.601 s
[2025-07-19T20:31:10.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-07-19T20:31:10.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-07-19T20:31:10.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO DAGScheduler: Job 4 finished: start at <unknown>:0, took 7.661387 s
[2025-07-19T20:31:10.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] is committing.
[2025-07-19T20:31:10.453+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO SparkWrite: Committing epoch 1 for query 60d03bb1-c474-4483-93df-474e93ff0d37 in append mode
[2025-07-19T20:31:10.458+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO SparkWrite: Committing streaming append with 0 new data files to table my_catalog.bronze.Feedback_raw
[2025-07-19T20:31:10.499+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO HadoopTableOperations: Committed a new metadata file s3a://warehouse/bronze/Feedback_raw/metadata/v111.metadata.json
[2025-07-19T20:31:10.514+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO SnapshotProducer: Committed snapshot 8605482614809979969 (FastAppend)
[2025-07-19T20:31:10.531+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO LoggingMetricsReporter: Received metrics report: CommitReport{tableName=my_catalog.bronze.Feedback_raw, snapshotId=8605482614809979969, sequenceNumber=110, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.070017542S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=null, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=5124}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=null, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=6930}, addedFilesSizeInBytes=null, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=14751161}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}}, metadata={engine-version=3.5.6, app-id=local-1752957046551, engine-name=spark, iceberg-version=Apache Iceberg 1.4.0 (commit 10367c380098c2e06a49521a33681ac7f6c64b2c)}}
[2025-07-19T20:31:10.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO SparkWrite: Committed in 70 ms
[2025-07-19T20:31:10.532+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 1, writer: IcebergStreamingWrite(table=my_catalog.bronze.Feedback_raw, format=PARQUET)] committed.
[2025-07-19T20:31:10.535+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/1 using temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/.1.168a09d6-cdb7-4c1b-855e-823b439195b1.tmp
[2025-07-19T20:31:10.559+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/.1.168a09d6-cdb7-4c1b-855e-823b439195b1.tmp to file:/tmp/checkpoints/feedback/scheduled__2025-07-19T20:28:00+00:00/commits/1
[2025-07-19T20:31:10.560+0000] {subprocess.py:93} INFO - 25/07/19 20:31:10 INFO MicroBatchExecution: Streaming query made progress: {
[2025-07-19T20:31:10.560+0000] {subprocess.py:93} INFO -   "id" : "60d03bb1-c474-4483-93df-474e93ff0d37",
[2025-07-19T20:31:10.560+0000] {subprocess.py:93} INFO -   "runId" : "949692c4-67e9-4193-b7c5-0e7f8bd5bdfd",
[2025-07-19T20:31:10.560+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-07-19T20:31:02.466Z",
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -   "batchId" : 1,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -   "numInputRows" : 0,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 0.0,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -     "addBatch" : 7905,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -     "commitOffsets" : 30,
[2025-07-19T20:31:10.561+0000] {subprocess.py:93} INFO -     "getBatch" : 0,
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "latestOffset" : 16,
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "queryPlanning" : 80,
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "triggerExecution" : 8092,
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "walCommit" : 58
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -   "eventTime" : {
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "watermark" : "2025-07-17T20:30:40.000Z"
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -   },
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -   "stateOperators" : [ {
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "operatorName" : "dedupe",
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "numRowsTotal" : 207,
[2025-07-19T20:31:10.562+0000] {subprocess.py:93} INFO -     "numRowsUpdated" : 0,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "allUpdatesTimeMs" : 165,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "numRowsRemoved" : 0,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "allRemovalsTimeMs" : 81,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "commitTimeMs" : 14429,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "memoryUsedBytes" : 142312,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "numRowsDroppedByWatermark" : 0,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "numShufflePartitions" : 200,
[2025-07-19T20:31:10.563+0000] {subprocess.py:93} INFO -     "numStateStoreInstances" : 200,
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -     "customMetrics" : {
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -       "loadedMapCacheHitCount" : 200,
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -       "loadedMapCacheMissCount" : 0,
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -       "numDroppedDuplicateRows" : 0,
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -       "stateOnCurrentVersionSizeBytes" : 63848
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:10.564+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-07-19T20:31:10.565+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[feedback]]",
[2025-07-19T20:31:10.565+0000] {subprocess.py:93} INFO -     "startOffset" : {
[2025-07-19T20:31:10.565+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:31:10.565+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:10.566+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:10.566+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:10.566+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-07-19T20:31:10.566+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:31:10.567+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:10.567+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:10.567+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:10.567+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -       "feedback" : {
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -         "0" : 207
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -       }
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -     },
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -     "numInputRows" : 0,
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 0.0,
[2025-07-19T20:31:10.568+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-07-19T20:31:10.569+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-07-19T20:31:10.569+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-07-19T20:31:10.569+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-07-19T20:31:10.569+0000] {subprocess.py:93} INFO -     }
[2025-07-19T20:31:10.569+0000] {subprocess.py:93} INFO -   } ],
[2025-07-19T20:31:10.569+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-07-19T20:31:10.570+0000] {subprocess.py:93} INFO -     "description" : "my_catalog.bronze.Feedback_raw",
[2025-07-19T20:31:10.570+0000] {subprocess.py:93} INFO -     "numOutputRows" : 0
[2025-07-19T20:31:10.570+0000] {subprocess.py:93} INFO -   }
[2025-07-19T20:31:10.570+0000] {subprocess.py:93} INFO - }
[2025-07-19T20:31:15.962+0000] {subprocess.py:93} INFO - 25/07/19 20:31:15 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:18.490+0000] {subprocess.py:93} INFO - 25/07/19 20:31:18 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:20.566+0000] {subprocess.py:93} INFO - 25/07/19 20:31:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:25.967+0000] {subprocess.py:93} INFO - 25/07/19 20:31:25 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:28.491+0000] {subprocess.py:93} INFO - 25/07/19 20:31:28 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:30.569+0000] {subprocess.py:93} INFO - 25/07/19 20:31:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:35.972+0000] {subprocess.py:93} INFO - 25/07/19 20:31:35 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:38.493+0000] {subprocess.py:93} INFO - 25/07/19 20:31:38 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:40.581+0000] {subprocess.py:93} INFO - 25/07/19 20:31:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:45.975+0000] {subprocess.py:93} INFO - 25/07/19 20:31:45 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:48.494+0000] {subprocess.py:93} INFO - 25/07/19 20:31:48 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-07-19T20:31:49.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T20:31:49.583+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3, groupId=spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T20:31:49.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Metrics scheduler closed
[2025-07-19T20:31:49.592+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T20:31:49.593+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Metrics reporters closed
[2025-07-19T20:31:49.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-08814e90-f56d-45a5-beac-29478f9ec431-1656520978-executor-3 unregistered
[2025-07-19T20:31:49.596+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T20:31:49.597+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1, groupId=spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T20:31:49.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Metrics scheduler closed
[2025-07-19T20:31:49.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T20:31:49.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Metrics reporters closed
[2025-07-19T20:31:49.598+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-20f0682c-a4c4-40da-a715-f4696269e925-1109023025-executor-1 unregistered
[2025-07-19T20:31:49.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-07-19T20:31:49.599+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2, groupId=spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-07-19T20:31:49.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Metrics scheduler closed
[2025-07-19T20:31:49.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-07-19T20:31:49.600+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO Metrics: Metrics reporters closed
[2025-07-19T20:31:49.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-a437053b-8ff2-47b6-a3d9-e4ba07c755fe-131052947-executor-2 unregistered
[2025-07-19T20:31:49.601+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO SparkContext: Invoking stop() from shutdown hook
[2025-07-19T20:31:49.602+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-07-19T20:31:49.613+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO SparkUI: Stopped Spark web UI at http://8b44f3d35cfa:4041
[2025-07-19T20:31:49.627+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-07-19T20:31:49.662+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO MemoryStore: MemoryStore cleared
[2025-07-19T20:31:49.663+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO BlockManager: BlockManager stopped
[2025-07-19T20:31:49.668+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-07-19T20:31:49.670+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-07-19T20:31:49.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO SparkContext: Successfully stopped SparkContext
[2025-07-19T20:31:49.684+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ShutdownHookManager: Shutdown hook called
[2025-07-19T20:31:49.685+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-29747d4e-737b-4d6e-944c-6694157c6f98/pyspark-b83df429-4876-4116-8d7a-5db8bea0167a
[2025-07-19T20:31:49.696+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-29747d4e-737b-4d6e-944c-6694157c6f98
[2025-07-19T20:31:49.716+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-f3ff0ed6-59b8-47fc-a71c-0d55e93bf574
[2025-07-19T20:31:49.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-07-19T20:31:49.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-07-19T20:31:49.746+0000] {subprocess.py:93} INFO - 25/07/19 20:31:49 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-07-19T20:31:50.167+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-19T20:31:50.197+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=restaurant_pipeline, task_id=stream_to_bronze, execution_date=20250719T202800, start_date=20250719T203044, end_date=20250719T203150
[2025-07-19T20:31:50.245+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-19T20:31:50.278+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
